{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycocoa in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (25.4.8)\n",
      "Requirement already satisfied: pyobjc-framework-Quartz in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (12.0)\n",
      "Requirement already satisfied: pyobjc-framework-Vision in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (12.0)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.7-cp314-cp314-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (2.2.6)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (2.32.5)\n",
      "Collecting pillow\n",
      "  Downloading pillow-12.0.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (4.67.1)\n",
      "Requirement already satisfied: pyobjc-core>=12.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (from pyobjc-framework-Quartz) (12.0)\n",
      "Requirement already satisfied: pyobjc-framework-Cocoa>=12.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (from pyobjc-framework-Quartz) (12.0)\n",
      "Requirement already satisfied: pyobjc-framework-CoreML>=12.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (from pyobjc-framework-Vision) (12.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.60.1-cp314-cp314-macosx_10_13_universal2.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp314-cp314-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (from matplotlib) (25.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.7-cp314-cp314-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.0.0-cp314-cp314-macosx_11_0_arm64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp314-cp314-macosx_11_0_arm64.whl (273 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.1-cp314-cp314-macosx_10_13_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp314-cp314-macosx_11_0_arm64.whl (64 kB)\n",
      "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [matplotlib]7\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.60.1 kiwisolver-1.4.9 matplotlib-3.10.7 pillow-12.0.0 pyparsing-3.2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocoa pyobjc-framework-Quartz  pyobjc-framework-Vision matplotlib numpy requests pillow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import tqdm\n",
    "import Quartz\n",
    "import Vision\n",
    "import CoreFoundation\n",
    "from Cocoa import NSURL\n",
    "from Foundation import NSDictionary, NSArray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# needed to capture system-level stderr\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    \"\"\"Rearrange coordinates to order:\n",
    "    top-left, top-right, bottom-right, bottom-left\"\"\"\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    pts = np.array(pts)\n",
    "    s = pts.sum(axis=1)\n",
    "    # Top-left point will have the smallest sum.\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    # Bottom-right point will have the largest sum.\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    # Top-right point will have the smallest difference.\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    # Bottom-left will have the largest difference.\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect.astype(\"int\").tolist()\n",
    "\n",
    "\n",
    "def find_dest(pts):\n",
    "    (tl, tr, br, bl) = pts\n",
    "    # Finding the maximum width.\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # Finding the maximum height.\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    # Final destination co-ordinates.\n",
    "    destination_corners = [[0, 0], [maxWidth, 0], [maxWidth, maxHeight], [0, maxHeight]]\n",
    "\n",
    "    return order_points(destination_corners)\n",
    "\n",
    "\n",
    "def scan(img, name=\"\"):\n",
    "    # Resize image to workable size\n",
    "    dim_limit = 1920\n",
    "    max_dim = max(img.shape)\n",
    "    if max_dim > dim_limit:\n",
    "        resize_scale = dim_limit / max_dim\n",
    "        img = cv2.resize(img, None, fx=resize_scale, fy=resize_scale)\n",
    "    # Create a copy of resized original image for later use\n",
    "    orig_img = img.copy()\n",
    "    # Repeated Closing operation to remove text from the document.\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    # GrabCut\n",
    "    mask = np.zeros(img.shape[:2], np.uint8)\n",
    "    bgdModel = np.zeros((1, 65), np.float64)\n",
    "    fgdModel = np.zeros((1, 65), np.float64)\n",
    "    rect = (20, 20, img.shape[1] - 20, img.shape[0] - 20)\n",
    "    cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype(\"uint8\")\n",
    "    img = img * mask2[:, :, np.newaxis]\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (11, 11), 0)\n",
    "    # Edge Detection.\n",
    "    canny = cv2.Canny(gray, 0, 200)\n",
    "    canny = cv2.dilate(canny, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)))\n",
    "\n",
    "    # Finding contours for the detected edges.\n",
    "    contours, hierarchy = cv2.findContours(canny, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    # Keeping only the largest detected contour.\n",
    "    page = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n",
    "\n",
    "    # Detecting Edges through Contour approximation.\n",
    "    # Loop over the contours.\n",
    "    if len(page) == 0:\n",
    "        return orig_img\n",
    "    candidates = []\n",
    "    for c in page:\n",
    "        # Approximate the contour.\n",
    "        epsilon = 0.02 * cv2.arcLength(c, True)\n",
    "        corners = cv2.approxPolyDP(c, epsilon, True)\n",
    "        area = cv2.contourArea(corners)\n",
    "        # If our approximated contour has four points.\n",
    "        if len(corners) == 4:\n",
    "            candidates.append((corners, area))\n",
    "    if len(candidates) == 0:\n",
    "        return orig_img\n",
    "    candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "    corners = candidates[0][0]\n",
    "    print(candidates)\n",
    "    # Sorting the corners and converting them to desired shape.\n",
    "    corners = sorted(np.concatenate(corners).tolist())\n",
    "    # For 4 corner points being detected.\n",
    "    corners = order_points(corners)\n",
    "\n",
    "    destination_corners = find_dest(corners)\n",
    "\n",
    "    h, w = orig_img.shape[:2]\n",
    "    # Getting the homography.\n",
    "    M = cv2.getPerspectiveTransform(\n",
    "        np.float32(corners), np.float32(destination_corners)\n",
    "    )\n",
    "    # Perspective transform using homography.\n",
    "    final = cv2.warpPerspective(\n",
    "        orig_img,\n",
    "        M,\n",
    "        (destination_corners[2][0], destination_corners[2][1]),\n",
    "        flags=cv2.INTER_LINEAR,\n",
    "    )\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = glob(\"pics/*.jpeg\")\n",
    "# for img in tqdm(imgs):\n",
    "#     print(img)\n",
    "#     img_dat=cv2.imread(img)\n",
    "#     final=scan(img_dat)\n",
    "#     cv2.imwrite('out/'+img.split('/')[-1], final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request_handler_img(results):\n",
    "    \"\"\"results: list to store results\"\"\"\n",
    "    if not isinstance(results, list):\n",
    "        raise ValueError(\"results must be a list\")\n",
    "\n",
    "    def handler(request, error):\n",
    "        if error:\n",
    "            print(f\"Error! {error}\")\n",
    "        else:\n",
    "            observations: \"list[Vision.VNRecognizedTextObservation]\" = request.results()\n",
    "            for text_observation in observations:\n",
    "                recognized_text = text_observation.topCandidates_(1)[0]\n",
    "                corners = {\n",
    "                    \"tl\": text_observation.topLeft(),\n",
    "                    \"tr\": text_observation.topRight(),\n",
    "                    \"bl\": text_observation.bottomLeft(),\n",
    "                    \"br\": text_observation.bottomRight(),\n",
    "                }\n",
    "                corners = {k: (v.x, v.y) for k, v in corners.items()}\n",
    "                results.append(\n",
    "                    [recognized_text.string(), recognized_text.confidence(), corners]\n",
    "                )\n",
    "\n",
    "    return handler\n",
    "\n",
    "\n",
    "def image_to_text(\n",
    "    img_path, lang=\"eng\"\n",
    ") -> \"list[tuple[str, float, dict[str,tuple[float,float]]]]\":\n",
    "    input_url = NSURL.fileURLWithPath_(img_path)\n",
    "\n",
    "    input_image = Quartz.CIImage.imageWithContentsOfURL_(input_url)\n",
    "\n",
    "    vision_options = NSDictionary.dictionaryWithDictionary_({})\n",
    "\n",
    "    vision_handler = Vision.VNImageRequestHandler.alloc().initWithCIImage_options_(\n",
    "        input_image, vision_options\n",
    "    )\n",
    "    results = []\n",
    "    handler = make_request_handler_img(results)\n",
    "    vision_request = Vision.VNRecognizeTextRequest.alloc().initWithCompletionHandler_(\n",
    "        handler\n",
    "    )\n",
    "    # print(vision_request.recognitionLanguages())\n",
    "    vision_request.setRecognitionLanguages_(\n",
    "        NSArray.arrayWithArray_(\n",
    "            [\n",
    "                lang,\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    # vision_request.setCustomWords_(NSArray.arrayWithArray_(['für',]))\n",
    "    # print(type(vision_request.recognitionLanguages()))\n",
    "    # print(vision_request.recognitionLanguages())\n",
    "    vision_request.setUsesCPUOnly_(False)  # somehow improves accuracy??\n",
    "    error = vision_handler.performRequests_error_([vision_request], None)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 79\u001b[39m\n\u001b[32m     74\u001b[39m     error = vision_handler.performRequests_error_([vision_request], \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m res = image_doc_handler(\u001b[43mimgs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m     80\u001b[39m res\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "def find_dest_doc(pts):\n",
    "    (tl, tr, br, bl) = pts\n",
    "    # Finding the maximum width.\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # Finding the maximum height.\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    # Final destination co-ordinates.\n",
    "    destination_corners = [[0, maxHeight], [maxWidth, maxHeight], [0, 0], [maxWidth, 0]]\n",
    "\n",
    "    return destination_corners\n",
    "\n",
    "\n",
    "def make_request_handler_doc(results):\n",
    "    \"\"\"results: list to store results\"\"\"\n",
    "    if not isinstance(results, list):\n",
    "        raise ValueError(\"results must be a list\")\n",
    "\n",
    "    def handler(request, error):\n",
    "        if error:\n",
    "            print(f\"Error! {error}\")\n",
    "        else:\n",
    "            observations = request.results()\n",
    "            for obs in observations:\n",
    "                # print(obs)\n",
    "                # print(obs.bottomLeft())\n",
    "                # print(obs.bottomRight())\n",
    "                bbox = obs.boundingBox()\n",
    "                corners = {\n",
    "                    \"tl\": obs.topLeft(),\n",
    "                    \"tr\": obs.topRight(),\n",
    "                    \"bl\": obs.bottomLeft(),\n",
    "                    \"br\": obs.bottomRight(),\n",
    "                }\n",
    "                corners = {k: (v.x, v.y) for k, v in corners.items()}\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"bbox\": corners,\n",
    "                        \"bbox_obj\": bbox,\n",
    "                        \"conf\": obs.confidence(),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return handler\n",
    "\n",
    "\n",
    "def image_doc_handler(img_path: str) -> str:\n",
    "    input_url = NSURL.fileURLWithPath_(img_path)\n",
    "\n",
    "    input_image = Quartz.CIImage.imageWithContentsOfURL_(input_url)\n",
    "\n",
    "    vision_options = NSDictionary.dictionaryWithDictionary_({})\n",
    "\n",
    "    vision_handler = Vision.VNImageRequestHandler.alloc().initWithCIImage_options_(\n",
    "        input_image, vision_options\n",
    "    )\n",
    "    results = []\n",
    "    handler = make_request_handler_doc(results)\n",
    "    vision_request = (\n",
    "        Vision.VNDetectDocumentSegmentationRequest.alloc().initWithCompletionHandler_(\n",
    "            handler\n",
    "        )\n",
    "    )\n",
    "    # print(vision_request.recognitionLanguages())\n",
    "    # vision_request.setRecognitionLanguages_(NSArray.arrayWithArray_([lang,]))\n",
    "    # vision_request.setCustomWords_(NSArray.arrayWithArray_(['für',]))\n",
    "    # print(type(vision_request.recognitionLanguages()))\n",
    "    # print(vision_request.recognitionLanguages())\n",
    "    # vision_request.setUsesCPUOnly_(False) # somehow improves accuracy??\n",
    "    error = vision_handler.performRequests_error_([vision_request], None)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "res = image_doc_handler(imgs[0])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imgs[4]\n",
    "res = image_doc_handler(img)\n",
    "img_dat = cv2.imread(img)\n",
    "src = np.array([list(p) for p in res[0][\"bbox\"].values()])\n",
    "dst = np.array([[0, 1], [1, 1], [0, 0], [1, 0]])\n",
    "src = src * img_dat.shape[:-1]\n",
    "dst = find_dest_doc(dst * img_dat.shape[:-1])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src.astype(\"float32\"), np.array(dst).astype(\"float32\"))\n",
    "warped = cv2.warpPerspective(img_dat, M, img_dat.shape[:-1])\n",
    "\n",
    "\n",
    "src, dst\n",
    "\n",
    "plt.imshow(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authors_text(texts):\n",
    "    results = texts\n",
    "    for textbox in results:\n",
    "        commas = (\n",
    "            textbox[0].count(\",\")\n",
    "            + textbox[0].count(\"and\")\n",
    "            + textbox[0].count(\"&\")\n",
    "            + textbox[0].count(\".\")\n",
    "        )\n",
    "\n",
    "        textbox.append(commas)\n",
    "    results.sort(key=lambda x: x[-1], reverse=True)\n",
    "    return results[0][0] if len(results) else \"\"\n",
    "\n",
    "\n",
    "def biggest_text(texts):\n",
    "    results = texts\n",
    "    for textbox in results:\n",
    "        dims = textbox[2]\n",
    "        poss = np.array([dims[\"tl\"], dims[\"tr\"], dims[\"br\"], dims[\"bl\"]]).astype(\n",
    "            np.float32\n",
    "        )\n",
    "        area = cv2.contourArea(poss)\n",
    "        textbox.append(area)\n",
    "    results.sort(key=lambda x: x[-1], reverse=True)\n",
    "    return results[0][0] if len(results) else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:22<00:00,  2.36it/s]\n"
     ]
    }
   ],
   "source": [
    "outs = glob(\"out_good/*.jpeg\")\n",
    "for img in tqdm(outs):\n",
    "    img_dat = cv2.imread(img)\n",
    "    # downscale image\n",
    "    dim_limit = 1080\n",
    "    max_dim = max(img_dat.shape)\n",
    "    if max_dim > dim_limit:\n",
    "        resize_scale = dim_limit / max_dim\n",
    "        img_dat = cv2.resize(img_dat, None, fx=resize_scale, fy=resize_scale)\n",
    "    cv2.imwrite(\"out_reduced/\" + img.split(\"/\")[-1], img_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [22:14<00:00, 25.65s/it]   \n"
     ]
    }
   ],
   "source": [
    "outs = glob(\"out_good/*.jpeg\")\n",
    "data = []\n",
    "for img in tqdm(outs):\n",
    "\n",
    "    texts = image_to_text(img, \"eng\")\n",
    "    title = biggest_text(texts)\n",
    "    authors = authors_text(texts)\n",
    "\n",
    "    # print(title, authors)\n",
    "    data.append({\"title\": title, \"authors\": authors, \"texts\": texts, \"img\": img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pylatex\n",
      "  Downloading PyLaTeX-1.4.2.tar.gz (59 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting arxiv\n",
      "  Downloading arxiv-2.3.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting ordered-set (from pylatex)\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting feedparser~=6.0.10 (from arxiv)\n",
      "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: requests~=2.32.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (from arxiv) (2.32.5)\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (from requests~=2.32.0->arxiv) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (from requests~=2.32.0->arxiv) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (from requests~=2.32.0->arxiv) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/py14/lib/python3.14/site-packages (from requests~=2.32.0->arxiv) (2025.10.5)\n",
      "Downloading arxiv-2.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
      "Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Building wheels for collected packages: pylatex, sgmllib3k\n",
      "  Building wheel for pylatex (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pylatex: filename=pylatex-1.4.2-py3-none-any.whl size=43654 sha256=45fc4606f9d571709027c379554196383c6b124d89b17f43eb24cfd1d3a39a86\n",
      "  Stored in directory: /Users/benedikt/Library/Caches/pip/wheels/28/0b/a1/5137ced897f19e9f76e9eae4dcd6eca477e11978276454b6ee\n",
      "  Building wheel for sgmllib3k (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6089 sha256=12b33816a0d38c30f5bcdbc93687b1cf5fd87749736925331ff9f67a9f0fd8b4\n",
      "  Stored in directory: /Users/benedikt/Library/Caches/pip/wheels/e3/43/83/0f6e317d0698ac38ee6a5b6e214019c167057916a11bad91ab\n",
      "Successfully built pylatex sgmllib3k\n",
      "Installing collected packages: sgmllib3k, ordered-set, feedparser, pylatex, arxiv\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [arxiv]\n",
      "\u001b[1A\u001b[2KSuccessfully installed arxiv-2.3.0 feedparser-6.0.12 ordered-set-4.1.0 pylatex-1.4.2 sgmllib3k-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pylatex arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [03:09<00:00,  3.64s/it]\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "\n",
    "client = arxiv.Client()\n",
    "arxiv_data = []\n",
    "for poster in tqdm(data):\n",
    "    # poster = data[0]\n",
    "    query = f\"{poster['title'].lower()} {poster['authors'].lower().split(',')[0]}\"\n",
    "    search = arxiv.Search(\n",
    "        query=query, max_results=1, sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "    results = list(client.results(search))\n",
    "    if len(results) > 0:\n",
    "        result = results[0]\n",
    "        poster[\"arxiv\"] = result\n",
    "        poster[\"title_a\"] = result.title\n",
    "        poster[\"authors_a\"] = \",\".join([a.name for a in result.authors])\n",
    "        poster[\"abstract_a\"] = result.summary\n",
    "        poster[\"url\"] = result.links[0].href\n",
    "    else:\n",
    "        poster[\"title_a\"] = poster[\"title\"]\n",
    "        poster[\"authors_a\"] = \",\".join([str(poster[\"authors\"])])\n",
    "        poster[\"abstract_a\"] = \"\"\n",
    "        poster[\"url\"] = \"\"\n",
    "\n",
    "    arxiv_data.append(poster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylatex.utils import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./posters.tex\", \"w\") as f:\n",
    "    f.write(\"| **Poster** | **Title** | **Information** | \\n\")\n",
    "    separator=\"| -- | -- | -- | \\n\"\n",
    "    f.write(separator)\n",
    "    lines=[\n",
    "        f'| ![poster](out_reduced/{poster[\"img\"].split(\"/\")[-1]}) | {(poster[\"title_a\"].replace(\"|\", \" \"))} | *{(poster[\"authors_a\"].replace(\"|\", \" \"))}*, [{(poster[\"title\"].replace(\"≥\", \" \"))}]({(poster[\"url\"])}) | \\n' for poster in arxiv_data\n",
    "    ]\n",
    "    f.write(\"\".join(lines))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
