{
  "resource-list": [
    {
      "paper": {
        "hashed_id": "e02e27e04fdff967ba7d76fb24b8069d",
        "title": "The Agent Perspective In LLM-Based Strategic Information Retrieval Ecosystems",
        "abstract": "The rise of generative AI and the emergence of Large Language Models (LLMs) have sparked a new line of research on the evolution of strategic information retrieval ecosystems. My research adopts an agent-based perspective to analyze sponsored search and competitive search ecosystems. The primary motivation of my work is to examine how agent strategies influence social welfare and the existence of equilibrium. To that end, I leverage frameworks from game theory and mechanism design.",
        "doi": "10.1145/3726302.3730125",
        "sheridan_id": "dc2601",
        "position": 2,
        "track_id": 11,
        "slot_id": 45
      }
    },
    {
      "paper": {
        "hashed_id": "32b991e5d77ad140559ffb95522992d0",
        "title": "Continuous Evaluation in Information Retrieval Across Methods and Time",
        "abstract": "Evaluating Information Retrieval (IR) systems is essential yet challenging. The dynamic nature of information and relevance further complicates IR. For example, Adar et al. observed that as early as 2009, websites frequently changed multiple times per hour. In response, recent IR systems have become more personalized, semantic, and context-aware. They evolved from lexical ranking functions to complex neural models embedded in feature-rich systems. While this often improves retrieval quality, it also challenges their reliability and robustness. The proposed research is motivated by the overarching goal of maintaining the trustworthiness of IR systems. To do so a rigorous evaluation is needed. Only by assessing the quality of a system can it be maintained and improved. Such an evaluation can not take place in isolation but must consider the dynamics of the search setting at all stages of a system\u2014from development to maintenance and improvement. Based on the CRISP-DM methodology, these stages are sketched out as an ``IR Life Cycle``, which we will further define and oppose with a continuous evaluation framework in future work. In this regard, the changing search setting and the alignment between evaluation methods are key problems to be investigated. The dynamic nature of the search setting makes it difficult to compare evaluation outcomes from different points in time. As systems and testbeds evolve, a common ground for comparison becomes elusive. Furthermore, when evaluations are conducted under dynamic conditions, their temporal validity becomes limited once the testbeds no longer match the current search setting. This calls into question how temporally robust evaluations are. Therefore, we aim to systematically reintroduce changes into evaluations and to identify synergies among evaluation methods. This will be addressed along the following research areas: Classifying changes: Initially, a formal definition of the search setting and its dynamics is created. Accordingly, we will examine how search settings and systems evolve. To track the effectiveness over time, especially the relation between observable queries and latent information needs, need to be investigated.  Comparing results: The changing setting makes a direct comparison of retrieval results difficult. To retain expressible and interpretable results and attribute the measured effects, we explored comparison strategies as a reproducibility problem.     Repeating evaluations: When the search setting deviates from the testbed, its validity becomes uncertain, and systems need to be re-evaluated. By estimating this uncertainty, it should be assessed if it is worth to update the testbed and re-evaluate the system.  Aligning evaluation methods: To improve the feasibility of repeated evaluations, we aim to align evaluation methods to identify alternatives for demanding components and to uncover synergies between complementary components. In summary, it is intended to scrutinize the abstractions made by conventional IR evaluations and assess systems from multiple perspectives to gain a more holistic understanding of IR systems.",
        "doi": "10.1145/3726302.3730124",
        "sheridan_id": "dc2600",
        "position": 1,
        "track_id": 11,
        "slot_id": 48
      }
    },
    {
      "paper": {
        "hashed_id": "50abc3e730e36b387ca8e02c26dc0a22",
        "title": "Search Efficiency for Score-at-a-Time Retrieval",
        "abstract": "Impact-ordered indexes, and thus Score-at-a-Time (SaaT) retrieval, is seeing a resurgence due to the emergence of learned sparse representations [4] (LSR) which employ the use of neural networks to learn the term-document weights. Within this context, SaaT has been found to be a competitive alternative to the more studied Document-at-a-Time (DaaT) approach.Even so, JASSv2 [2, 6] and IOQP [4] remain the only well-known open-source SaaT search engines.We believe that a thorough study into their operation and components may provide valuable insights. We wish to use this knowledge to build a better baseline system for SaaT retrieval. Once established, we aim to improve upon it. Specifically, we ask: (1) Can we build a better baseline for Score-at-a-Time retrieval by finding the most efficient and effective components from existing systems?(2) Can we improve upon the baseline by updating QMX to make use of more recent SIMD technologies?(3) Can we improve upon the baseline with a new accumulator management strategy?(4) Can we improve upon the baseline with a new approach to early termination/pruning?It is not obvious what the current baseline for SaaT should be, or what components are the most efficient. Through investigating various aspects of the search engines \u2014 specifically integer compression, accumulator management, and early termination (\u03c1) -- we will build a more indicative baseline system. We highlight these components in particular as we have reason to believe they will be influential.",
        "doi": "10.1145/3726302.3730123",
        "sheridan_id": "dc2599",
        "position": 1,
        "track_id": 11,
        "slot_id": 50
      }
    },
    {
      "paper": {
        "hashed_id": "67478479ad1213a3e9341881175ee3b6",
        "title": "Federated Recommender System Based on Diffusion Augmentation and Guided Denoising",
        "abstract": "Sequential recommender systems often struggle with accurate personalized recommendations due to data sparsity issues. Existing works use variational autoencoders and generative adversarial network methods to enrich sparse data. However, they often overlook diversity in the latent data distribution, hindering the model\u2019s generative capacity. This characteristic of generative methods can introduce additional noise in many cases. Moreover, retaining personalized user preferences through the generation process remains a challenge. This work introduces DGFedRS, a Federated Recommender System Based on Diffusion Augmentation and Guided Denoising, designed to capture the diversity in the latent data distribution while preserving user-specific information and suppressing noise. In particular, we pre-train the diffusion model using the recommender dataset and use a diffusion augmentation strategy to generate interaction sequences, expanding the sparse user-item interactions in the discrete space. To preserve user-specific preferences in the generated interactions, we employ a guided denoising strategy to guide the generation process during reverse diffusion. Subsequently, we design a noise control strategy to reduce the damage to personalized information during the diffusion process. Additionally, a stepwise scheduling strategy is devised to input generated data into the sequential recommender model based on their challenge levels. The success of the DGFedRS approach is demonstrated by thorough experiments conduct on three real-world datasets.",
        "doi": "10.1145/3688570",
        "sheridan_id": "TOIS-2024-0040.R1",
        "position": 0,
        "track_id": 2,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "1175defd049d3301e047ce50d93e9c7a",
        "title": "From Professional Search to Generative Deep Research Systems: How Can Expert Oversight Improve Search Outcomes?",
        "abstract": "Generative AI (GenAI) models are increasingly employed for professional search tasks, from enterprise copilots to systematic reviews. Recently introduced \"deep research\" products (OpenAI, Google), marketed as automated professional search agents, promise comprehensive query generation and synthesis from large document sets. However, this drive toward automation risks minimizing user involvement, potentially leading to misaligned results and inappropriate reliance on AI-generated outputs \\cite{spatharioti2025effects}. Professional search, especially in domains such as biomedical research and systematic reviews, necessitates expert input, transparency, and user control, requirements often not met by current generative search tools. Interactive Information Retrieval (IIR) literature has long emphasized the value of user interactions and iterative search refinement \\cite{kelly2009methods}. The rise of generative search introduces innovative methods of accessing information through natural language interactions, which show promise in addressing complex information needs \\cite{suri2024usegenerativesearchengines}. However, professional search tasks differ substantially from general consumer searches, involving transparent criteria for relevance judgments and systematic data extraction processes \\cite{verbeneprofsearch}. Despite early evidence suggesting increased productivity among knowledge workers using GenAI tools \\cite{cambon2023early}, these systems also exhibit substantial shortcomings. Studies highlight issues such as unsupported claims, inaccurate citations, and overreliance on generated content, questioning the reliability and suitability of current generative search systems for high-stakes professional use \\cite{spatharioti2025effects}.Given these challenges, this work explores systematically integrating structured expert feedback at multiple stages of a generative search process, specifically query formulation, relevance judgments, and information extraction. We aim to shift the focus from full automation toward increased expert control and quality assurance. Our key research questions are:\\newline \\textbf{RQ1:} How can expert feedback be systematically integrated into GenAI-driven retrieval systems to improve result quality? \\newline \\textbf{RQ2:} How does a feedback-driven generative search system compare to fully automated approaches in terms of retrieval effectiveness and task performance?\\newline \\textbf{RQ3:} Does the integration of human expert feedback improve professional search outcomes compared to GenAI-simulated expert feedback?\\newline Building on our earlier experiments that assessed the performance of GenAI models in a fully automated setting for biomedical question answering \\cite{ateiakruschwitz} and introduced an interactive system for refining generated queries \\cite{ateia2025bioragent}, we now seek to evaluate how a structured, human-in-the-loop feedback approach might improve retrieval and task effectiveness over fully automated pipelines. By evaluating our proposed framework on biomedical Q&A datasets such as CLEF BioASQ and TREC BioGen as well as systematic review datasets, we want to highlight the value of human guidance for professional generative search.",
        "doi": "10.1145/3726302.3730131",
        "sheridan_id": "dc2612",
        "position": 3,
        "track_id": 11,
        "slot_id": 43
      }
    },
    {
      "paper": {
        "hashed_id": "d3fad7d3634dbfb61018813546edbccb",
        "title": "Evaluating the Impact of Automated Labeling on Retrieval Instability in Neural IR",
        "abstract": "Effective information retrieval (IR) depends on accurate relevance classification.  But when the criteria are subjective or underspecified, small variations in classification can cause consequential shifts in retrieval results. The potential for such variability becomes critical for institutions when they use IR for research assessment. Retrieval instability can lead to relevant literature being overlooked, hindering a comprehensive understanding of the research landscape, and potentially undermining the validity of subsequent analyses and decisions. We investigate this problem within the context of the United Nations Sustainable Development Goals (SDGs), a global framework for addressing environmental, social, and economic challenges. Scholarly research is vital for understanding, implementing, and monitoring SDG progress. Universities report SDG-related research to demonstrate impact, and international rankings incorporate SDG alignment into evaluations, influencing funding, policy, and institutional strategy. However, the nuanced nature of the SDGs makes it difficult to define what constitutes an SDG contribution[1]. Commonly used Boolean queries and controlled vocabularies for SDG retrieval cannot reliably differentiate substantive contributions (based on semantic relevance) from mere term occurrences. In prior work, Large Language Models (LLMs) have been used to filter Boolean search results in systematic reviews by scoring documents for relevance to a specific information need[2]. Other studies demonstrate that LLMs can generate high-quality relevance labels for IR evaluation[4]. This prompted an investigation into using LLMs to judge SDG contribution through relevance filtering, which revealed variability in the judgments made by different LLMs on the same set of documents[3]. This observation suggests that the classification behavior of LLMs are sensitive to the specific parameters inherent to each model. In this study, we prompt multiple LLMs to judge the SDG relevance of abstracts retrieved using Boolean queries. Abstracts judged relevant are used as positive training examples for fine-tuning multi-label SDG classifiers. We use these classifiers to simulate retrieval, applying fixed scoring functions to isolate fluctuations in ranking stability attributable to the different LLM relevance judgments. Our goal is to analyze how the structured signal of upstream inconsistencies in LLM-derived relevance judgments manifests as variations in retrieval outcomes, providing a novel lens for investigating ranking stability under classification uncertainty. This research centers on three key questions: RQ1: How do different LLMs diverge in their filtering decisions, and what effect does this have on ranking stability in retrieval systems trained on filtered data? RQ2: Can divergence in labeling decisions be systematically explained or predicted from document content? RQ3: What distinguishes documents where LLMs disagree on relevance, and can these differences be predicted from lexical or surface-level features? Using SDG classification as a case study of subjective relevance, we evaluate retrieval stability under classification uncertainty and address broader concerns regarding the reproducibility of LLM-based classification pipelines and their downstream effects.",
        "doi": "10.1145/3726302.3730128",
        "sheridan_id": "dc2605",
        "position": 3,
        "track_id": 11,
        "slot_id": 48
      }
    },
    {
      "paper": {
        "hashed_id": "8dc5983b8c4ef1d8fcd5f325f9a65511",
        "title": "Enhancing Knowledge Injection in Large Language Models for Efficient and Trustworthy Responses",
        "abstract": "Large Language Models (LLMs) have shown remarkable proficiency in Natural Language Generation (NLG) across various tasks. However, they often require additional resources beyond their internal knowledge to respond reliably to user queries. Determining the optimal methods, content, and timing for introducing new knowledge remains a critical challenge without clear solutions~\\cite{Soudani23Data}. Our main objective is to enhance knowledge injection in LLMs to generate trustworthy responses. Therefore, this research is centered around two main research questions. \\emph{\\textbf{(RQ1)} What are the most effective and efficient choices of knowledge injection for question-answering over less popular knowledge?} A key challenge in knowledge injection is determining how to introduce new knowledge into an LLM while balancing both effectiveness and efficiency~\\cite{Soudani24survey}. RAG and FT with synthetic data have emerged as two distinct paradigms, yet there has been no comprehensive comparison that highlights both their strengths and limitations~\\cite{Soudani24Fine}. To address this, we conduct an extensive evaluation of RAG and FT for handling less popular factual knowledge, assuming limited textual descriptions are available for a given domain and application. Through this analysis, we find that RAG substantially outperforms FT in this setup.Our second research question is: \\textit{(\\textbf{RQ2}) How can we quantify the uncertainty of LLMs during response generation and leverage it to improve the reliability of their outputs?} By knowing LLMs uncertainty, one can determine when to leverage RAG and when to rely solely on LLMs` internal knowledge. However, existing Uncertainty Estimation (UE) techniques primarily focus on scenarios where the input consists only of a user query, overlooking the complexities introduced by retrieved knowledge. We investigate UE in the context of RAG and find that the performance of current UE methods is inconsistent, often degrading when non-parametric knowledge is incorporated into the input prompt. We propose an axiomatic framework to formalize optimal behavior of UE methods.Recent advancements in active RAG aim to enhance the dynamic interaction between retrievers and generators~\\cite{Jiang23Active}. In this context, UE is primarily employed to determine when retrieval is necessary. Typically, uncertainty is measured based on next-token probabilities, and the interpretation of an uncertainty value is based on comparing it with accuracy. However, we raise three key questions: \\emph{\\textbf{(RQ2.1)} What is the optimal method for measuring uncertainty?} We argue that relying solely on probability-based methods may not be the most effective approach. Furthermore, in conversational systems, previous turns or sessions do not directly influence next-token probabilities, highlighting the need for a new UE method. \\emph{\\textbf{(RQ2.2)} How should uncertainty values be interpreted?} Current approaches, which define uncertainty through relative comparisons with other values, lack precision. Additionally, some applications correlate uncertainty with correctness, but how should uncertainty be interpreted in cases where correctness labels are unavailable?  Moreover, we aim to enhance conversational interactions by leveraging an appropriate UE method. Specifically, we will investigate the research question: \\emph{\\textbf{(RQ2.3)} Can an LLM anticipate its next action, identify its information needs, and then generate an appropriate response?} To explore this, we will utilize UE to help the LLM determine its next step, whether to generate a response, retrieve relevant information, ask a clarification question, or take an alternative action.",
        "doi": "10.1145/3726302.3730130",
        "sheridan_id": "dc2610",
        "position": 2,
        "track_id": 11,
        "slot_id": 50
      }
    },
    {
      "paper": {
        "hashed_id": "26751be1181460baf78db8d5eb7aad39",
        "title": "DeepReport: An AI-assisted Idea Generation System for Scientific Research",
        "abstract": "Nowadays, the explosive growth of academic literature has been going far beyond scientists` limited capability to read through, making it increasingly difficult for them to absorb disciplinary insights and extract intellectual essences critical for generating novel research ideas in interdisciplinary studies. To address this, we develop DeepReport, an AI-assisted scientific idea generation system to alleviate the research burden. Technically, DeepReport maintains evolving concept co-occurrence graphs to extract core insights from over 260 million publications across all disciplines. These concepts are periodically collected and updated, enabling the automatic extraction of hidden cross-domain connections. Combining temporal link prediction and analysis techniques with large language models, DeepReport is able to further transform these patterns of insights into actionable ideas. With the function of integrating up-to-date academic databases, visualizing dynamic relationships of concepts, and automatically generating new ideas, DeepReport empowers researchers to navigate complex knowledge landscapes, reduce cognitive burdens, and accelerate the generation of groundbreaking concepts. This work provides an in-depth exploration of DeepReport`s architecture, functionalities, and applications, highlighting its transformative potential for advancing interdisciplinary research and fostering innovation. DeepReport is available at https://idea.acemap.cn/.",
        "doi": "10.1145/3726302.3730151",
        "sheridan_id": "de1694",
        "position": 4,
        "track_id": 10,
        "slot_id": 104
      }
    },
    {
      "paper": {
        "hashed_id": "26621877e74d60fabed43cea37a77651",
        "title": "The In-Situ Effect of Offensive Ads on Search Engine Users",
        "abstract": "Unscrupulous advertisers may try to increase attention to search ads by using offensive ads, which can increase attention and recall to the detriment of individuals and society. Here, we investigate whether offensive ads, when shown to search engine users, have such effects. We developed 12 search scenarios and created 4 versions of the search results page (SERP) for each scenario, where some of the ads were changed to be irrelevant and/or offensive. Crowdsourced judges found a strong correlation (>=0.63) between the reported number of annoying ads and the actual number of offensive and irrelevant ads, suggesting people conflate these attributes. Furthermore, we found that judges who assessed the SERPs for themselves reported lower positive affect and higher negative affect than judges asked to imagine the results were provided to someone else. In the latter case offensive ads also lead to slightly lower positive (-4%) and higher negative affect (+61%). Finally, in a recall test, only 6% of judges reported seeing an offensive ad when using search engines. Our work should further detract advertisers from using offensive ads since, in addition to previously documented adverse effects, such ads have a small but statistically significant negative effect on people\u2019s emotional experience.",
        "doi": "10.1145/3704438",
        "sheridan_id": "TOIS-2023-0135.R2",
        "position": 7,
        "track_id": 2,
        "slot_id": 9
      }
    },
    {
      "paper": {
        "hashed_id": "d9d4f495e875a2e075a1a4a6e1b9770f",
        "title": "AiReview: An Open Platform for Accelerating Systematic Reviews with LLMs",
        "abstract": "Systematic reviews are fundamental to evidence-based medicine. Creating one is time-consuming and labour-intensive, mainly due to the need to screen, or assess, many studies for inclusion in the review.  Existing tools help streamline this process, mostly using traditional machine learning. Large language models (LLMs) offer new opportunities to speed up screening, yet no tool currently enables users to directly apply LLMs or ensures systematic and transparent use of these methods. This paper presents (i) a flexible framework for using LLMs in systematic review tasks, especially title and abstract screening, and (ii) a web-based interface for LLM-assisted screening. Together, they form AiReview\u2014a novel platform that connects cutting-edge LLM-assisted screening methods with real-world systematic review practice. The live tool is available at https://aireview.ielab.io. We also release the code publicly at https://github.com/ielab/ai-review.",
        "doi": "10.1145/3726302.3730133",
        "sheridan_id": "de0046",
        "position": 2,
        "track_id": 10,
        "slot_id": 104
      }
    },
    {
      "paper": {
        "hashed_id": "e5b294b70c9647dcf804d7baa1903918",
        "title": "ROKSANA: An Open-Source Toolkit for Robust Graph-Based Keyword Search",
        "abstract": "We introduce ROKSANA, an open-source Python toolkit designed to support research in graph-based keyword search under adversarial settings. ROKSANA provides a modular environment for dataset handling, graph neural network (GNN)-based retrieval, and adversarial attack modeling, enabling systematic evaluation of search robustness. The framework integrates built-in retrieval and attack methods while allowing seamless customization of search algorithms and perturbation strategies. Users can benchmark performance on a centralized leaderboard, generate reproducible evaluation reports, and explore ranking behaviors through an interactive web-based visualization interface. By centering around reproducibility, extensibility, and collaborative benchmarking, ROKSANA serves as a comprehensive platform for advancing robust and interpretable keyword search in graphs. This demonstration will showcase ROKSANA`s capabilities in real-time, illustrating its impact on experimental workflows and adversarial robustness analysis in graph IR research.",
        "doi": "10.1145/3726302.3730154",
        "sheridan_id": "de1927",
        "position": 8,
        "track_id": 10,
        "slot_id": 104
      }
    },
    {
      "paper": {
        "hashed_id": "fc9b003bb003a298c2ad0d05e4342bdc",
        "title": "Artifact Sharing for Information Retrieval Research",
        "abstract": "Sharing artifacts\u2014such as trained models, pre-built indexes, and the code to use them\u2014aids in reproducibility efforts by allowing researchers to validate intermediate steps and improves the sustainability of research by allowing multiple groups to build off one another`s prior computational work. Although there are de facto consensuses on how to share research code (through a git repository linked to from publications) and trained models (via HuggingFace Hub), there is no consensus for other types of artifacts, such as built indexes. Given the practical utility of using shared indexes, researchers have resorted to self-hosting these resources or performing ad hoc file transfers upon request, ultimately limiting the artifacts` discoverability and reuse. This demonstration introduces a flexible and interoperable way to share artifacts for Information Retrieval research, improving both their accessibility and usability.",
        "doi": "10.1145/3726302.3730147",
        "sheridan_id": "de1749",
        "position": 1,
        "track_id": 10,
        "slot_id": 112
      }
    },
    {
      "paper": {
        "hashed_id": "7df5523bb26e62f32b12cf0cebe3297d",
        "title": "CAFE+: Towards Compact, Adaptive, and Fast Embedding for Large-scale Online Recommendation Models",
        "abstract": "The growing memory demands of embedding tables in Deep Learning Recommendation Models (DLRMs) pose great challenges for model training and deployment. Existing embedding compression solutions cannot simultaneously achieve memory efficiency, low latency, and adaptability to dynamic data distribution. This article presents CAFE+, a Compact, Adaptive, and Fast Embedding compression framework that meets the above requirements. The design philosophy of CAFE+ is to dynamically allocate more memory to important features and less to unimportant ones. We assign unique embedding to important feature and allow multiple unimportant features sharing one embedding. We propose a fast and lightweight feature monitor, to real-time capture feature importance and report important features. We theoretically analyze the accuracy of our feature monitor and prove the superiority of CAFE+ from the aspect of model convergence. Extensive experiments show CAFE+ outperforms existing embedding compression methods, yielding 3.94% and 3.94% superior testing AUC on Criteo Kaggle dataset and CriteoTB dataset at a compression ratio of 10,000 X. Building on our conference version [114], this journal version introduces several novel designs (implicit importance attenuation, adaptive threshold adjustment, and ColdSifter) that enable CAFE+ to more effectively adapt to long-term online learning and achieve better model quality. All codes are available at GitHub [112].",
        "doi": "10.1145/3713072",
        "sheridan_id": "TOIS-2024-0425.R1",
        "position": 3,
        "track_id": 2,
        "slot_id": 1
      }
    },
    {
      "paper": {
        "hashed_id": "f6e794a75c5d51de081dbefa224304f9",
        "title": "Multimodal Search in Chemical Documents and Reactions",
        "abstract": "We present a multimodal search tool for retrieval of chemical reactions, molecular structures, and associated text from scientific literature. Queries may combine molecular diagrams, textual descriptions, and reaction data, allowing users to connect different chemical information representations. Indexing includes chemical diagram extraction and parsing, extraction of reaction data from text in tabular form, and cross-modal linking of diagrams with their mentions in text. We describe the system\u2019s architecture and retrieval features, along with expert assessments of the system. Our demo highlights the workflow and search components. Online demo: https://www.cs.rit.edu/~dprl/reactionminer-demo-landing",
        "doi": "10.1145/3726302.3730152",
        "sheridan_id": "de2132",
        "position": 12,
        "track_id": 10,
        "slot_id": 104
      }
    },
    {
      "paper": {
        "hashed_id": "2557911c1bf75c2b643afb4ecbfc8ec2",
        "title": "Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification",
        "abstract": "Biomedical misinformation --- ranging from misleading social media posts to fake news articles and deepfake videos --- is increasingly pervasive across digital platforms, posing significant risks to public health and clinical decision-making. We developed CER, a comprehensive fact-checking system designed specifically for biomedical content. CER integrates specialized components for claim detection, scientific evidence retrieval, and veracity assessment, leveraging both transformer models and large language models to process textual and multimedia content. Unlike existing fact-checking systems that focus solely on structured text, CER can analyze claims from diverse sources including videos and web content through automatic transcription and text extraction. The system interfaces with PubMed for evidence retrieval, employing both sparse and dense retrieval methods to gather relevant scientific literature. Our evaluations on standard benchmarks including HealthFC, BioASQ-7, and SciFact demonstrate that CER achieves state-of-the-art performance, with F1-score improvements compared to existing approaches. To ensure reproducibility and transparency, we release the GitHub repository with the source code, within which you can reach an interactive demonstration of the system published on HuggingFace and a video demonstration of the system \\https://github.com/PRAISELab-PicusLab/CER-Fact-Checking.",
        "doi": "10.1145/3726302.3730155",
        "sheridan_id": "de2038",
        "position": 3,
        "track_id": 10,
        "slot_id": 112
      }
    },
    {
      "paper": {
        "hashed_id": "4afd521d77158e02aed37e2274b90c9c",
        "title": "Conversational Bibliographic Search",
        "abstract": "Conversational Bibliographic Search is a conversational search engine designed to support users in retrieving scientific papers and authors within the domain of computer science. It enables natural language-based searches for data within the dblp computer science bibliography, which is enriched with data from Semantic Scholar. The system presents a novel user interface and bridges the gap between keyword-based search engines, faceted search systems, and generative conversational approaches. It enables users to access the latest publications, formulate intricate queries, as often required in scholarly research, and engage in multi-turn conversations to discover the most relevant results. Users can iteratively refine their queries and ask follow-up questions. Conversational Bibliographic Search actively supports the search process by posing clarification questions and providing suggestions.",
        "doi": "10.1145/3726302.3730144",
        "sheridan_id": "de1977",
        "position": 4,
        "track_id": 10,
        "slot_id": 112
      }
    },
    {
      "paper": {
        "hashed_id": "53c6de78244e9f528eb3e1cda69699bb",
        "title": "Towards Efficient and Effective Multi-modal Retrieval",
        "abstract": "Information Retrieval systems are becoming increasingly multimodal, and one interesting and natural modality for human information interaction is audio. Audio data is rapidly expanding in both volume and popularity. For example, more than 4 million podcasts are available worldwide \u2013 each containing tens to thousands of episodes \u2013 with over 500 million expected listeners as of 2024. Searching such large and evolving audio corpora involves multiple challenges, ranging from content and style diversity, expensive audio processing, and various indexing considerations such as retrieval segmentation and text vs audio retrieval modalities. In this thesis, we aim to address the challenges linked to audio retrieval and devise novel approaches to improve state-of-the-art (SOTA) performance. We divide the work into four main milestones that target answering the following research questions: RQ1: How does the quality of an ASR model affect retrieval effectiveness? One of the approaches to search spoken audio is to reduce the problem to text retrieval using ASR models to generate text transcripts. Spina et al. [2] showed that the quality of ASR has a clear impact on the summaries generated by ASR. Motivated by this, we are interested in examining how automatic transcription algorithms impact the effectiveness of audio retrieval and re-ranking in dense and sparse retrieval configurations. In many real-world scenarios, resource limits require cheaper ASR models to be used. Therefore, we are interested in exploring if dense semantic search methods can reduce the impact of ASR model choice. RQ2: How can we build more complete, comprehensive, and representative audio retrieval resources to promote further research on audio retrieval? After reviewing the literature and performing a preliminary experiment on the Spotify podcasts dataset [1], we noted two main gaps in the available resources. Firstly, the large audio dataset released in TREC suffers from the shallow pooling issue, where new systems retrieve many unseen judgments, making it difficult to assess the quality of modern IR techniques. Secondly, there is a scarcity of audio datasets available for low-resource languages. Our plan to bridge these gaps comprises two parts: (1) Assessing the missed judgments Motivated by the recent literature on using LLMs as a judge [3], we plan to resolve the unjudged passages issue by assessing the relevance with multiple large language models (LLMs). (2) Curate a multi-lingual audio dataset with a focus on low-resource languages. Since there is a scarcity of audio datasets in low-resource languages, we plan to collect a large number of audio files in multiple low-resource languages, unify their format, and make them publicly available as a first step toward building test collections that enable research and advancements in such languages. RQ3: How can we combine audio and text to produce an efficient and effective multi-modal ranking model? We will focus on solutions that depend on processing both text and audio signals during indexing and retrieval. Our first study will be focused on improving the effectiveness of low-cost ASR systems. Another promising direction is to use the phonetic features as a representation of a word or token. Then, we can devise a suitable indexing paradigm to support searching over these representations. RQ4: What are the challenges affecting audio indexing and search performance, and what is the best way to mitigate against similar issues in the future? One of the main challenges in multi-modal search is identifying the suitable length for the retrieval unit. The retrieval unit satisfying an information need might vary in length from a couple of minutes to 10 minutes to one hour or a whole episode or series. Other challenges will stem from failure cases within state-of-the-art text/audio retrieval systems. So, in parallel with answering the previous questions, we will also study such failure cases, investigate the reasons behind them, and propose solutions that can mitigate their negative impacts.",
        "doi": "10.1145/3726302.3730129",
        "sheridan_id": "dc2607",
        "position": 1,
        "track_id": 11,
        "slot_id": 43
      }
    },
    {
      "paper": {
        "hashed_id": "3416a75f4cea9109507cacd8e2f2aefc",
        "title": "Pre-train, Align, and Disentangle: Empowering Sequential Recommendation with Large Language Models",
        "abstract": "Sequential Recommendation (SR) aims to leverage the sequential patterns in users` historical interactions to accurately track their preferences. However, the primary reliance of existing SR methods on collaborative data results in challenges such as the cold-start problem and sub-optimal performance. Concurrently, despite the proven effectiveness of large language models (LLMs), their integration into commercial recommender systems is impeded by issues such as high inference latency, incomplete capture of all distribution statistics, and catastrophic forgetting. To address these issues, we introduce a novel Pre-train, Align, and Disentangle (PAD) framework to enhance SR models with LLMs. In particular, we initially pre-train both the SR and LLM models to obtain collaborative and textual embeddings. Subsequently, we propose a characteristic recommendation-anchored alignment loss using multi-kernel maximum mean discrepancy with Gaussian kernels. Lastly, a triple-experts architecture, comprising aligned and modality-specific experts with disentangled embeddings, is fine-tuned in a frequency-aware manner. Experimental results on three public datasets validate the efficacy of PAD, indicating substantial enhancements and compatibility with various SR backbone models, particularly for cold items. The code and datasets are accessible for reproduction: https://github.com/Applied-Machine-Learning-Lab/PAD.",
        "doi": "10.1145/3726302.3730059",
        "sheridan_id": "fp0041",
        "position": 1,
        "track_id": 1,
        "slot_id": 7
      }
    },
    {
      "paper": {
        "hashed_id": "f8e59f4b2fe7c5705bf878bbd494ccdf",
        "title": "Targeted Multi-Modal Passage Search for Molecules and their Synthesis Pathways",
        "abstract": "We present a chemical extraction and search pipeline intended to support information tasks related to drug discovery. Commonly used search tools for drug discovery such as Reaxys and SciFinder do not allow users to obtain retrieval results at the passage level. To address this, we present a passage retrieval tool for chemical patents that supports queries combining text and molecule diagrams expressed in SMILES. When SMILES is provided as a part of a query, the system refines text retrieval results through matching both textual names and drawn figures based on extracted SMILES representations. Molecule matches are obtained through substructure matching and structural similarity. This functionality was motivated by a chemist`s need to find synthesis pathways for specific molecules containing a substructure of interest that binds and thus inhibits specific human genes. For this demonstration, we index a collection of 131 PDF patents categorized into 12 specific genes enabling a user to search on them. There are 32,301 document pages in the collection. Our user interface can be accessed at https://unichemfinder.gccis.rit.edu/. Our source code and data is available at https://gitlab.com/dprl/unichemfinder.",
        "doi": "10.1145/3726302.3730149",
        "sheridan_id": "de2171",
        "position": 5,
        "track_id": 10,
        "slot_id": 112
      }
    },
    {
      "paper": {
        "hashed_id": "1e8c391abfde9abea82d75a2d60278d4",
        "title": "Constructing and Evaluating Declarative RAG Pipelines in PyTerrier",
        "abstract": "Search engines often follow a pipeline architecture, where complex but effective reranking components are used to refine the results of an initial retrieval. Retrieval augmented generation (RAG) is an exciting application of the pipeline architecture, where the final component generates a coherent answer for the users from the retrieved documents. In this demo paper, we describe how such RAG pipelines can be formulated in the declarative PyTerrier architecture, and the advantages of doing so. Our PyTerrier-RAG extension for PyTerrier provides easy access to standard RAG datasets and evaluation measures, state-of-the-art LLM readers, and using PyTerrier`s unique operator notation, easy-to-build pipelines. We demonstrate the succinctness of indexing and RAG pipelines on standard datasets (including Natural Questions) and how to build on the larger PyTerrier ecosystem with state-of-the-art sparse, learned-sparse, and dense retrievers, and other neural rankers.",
        "doi": "10.1145/3726302.3730150",
        "sheridan_id": "de2154",
        "position": 6,
        "track_id": 10,
        "slot_id": 112
      }
    },
    {
      "paper": {
        "hashed_id": "efdf562ce2fb0ad460fd8e9d33e57f57",
        "title": "TINK: Text Information Navigation Kit",
        "abstract": "In many cases it is desirable to navigate an arbitrary text collection. While current technologies allow for fast and efficient text collection search, comparable technologies do not yet exist for navigation. Our prior work has proposed Hypergraph of Text (HoT) as a structure that could enable such navigation, but there is not yet a general system that allows users to interact with such a structure. To address this challenge, we introduce Text Information Navigation Kit (TINK) a novel tool-kit that allows users to turn any collection of plain text documents into a navigable collection. We discuss the modular and extensible two-part structure of TINK. In this demonstration paper we discuss this novel system, its strengths and its weaknesses. The code for TINK can be found in our GitHub repo here: https://github.com/TIMAN-group/TINK",
        "doi": "10.1145/3726302.3730141",
        "sheridan_id": "de2227",
        "position": 8,
        "track_id": 10,
        "slot_id": 112
      }
    },
    {
      "paper": {
        "hashed_id": "a11f9e533f28593768ebf87075ab34f2",
        "title": "Tevatron 2.0: Unified Document Retrieval Toolkit across Scale, Language, and Modality",
        "abstract": "Recent advancements in large language models (LLMs) have driven interest in billion-scale retrieval models with strong generalization across retrieval tasks and languages. Additionally, progress in large vision-language models has created new opportunities for multimodal retrieval. In response, we have updated the Tevatron toolkit, introducing a unified pipeline that enables researchers to explore retriever models at different scales, across multiple languages, and with various modalities. This demo paper highlights the toolkit\u2019s key features, bridging academia and industry by supporting efficient training, inference, and evaluation of neural retrievers. We showcase a unified dense retriever achieving strong multilingual and multimodal effectiveness, and conduct a cross-modality zero-shot study to demonstrate its research potential. Alongside, we release OmniEmbed, to the best of our knowledge, the first embedding model that unifies text, image document, video, and audio retrieval, serving as a baseline for future research.",
        "doi": "10.1145/3726302.3730135",
        "sheridan_id": "de2319",
        "position": 9,
        "track_id": 10,
        "slot_id": 112
      }
    },
    {
      "paper": {
        "hashed_id": "9bf31c7ff062936a96d3c8bd1f8f2ff3",
        "title": "Parametric Retrieval Augmented Generation",
        "abstract": "Retrieval-augmented generation (RAG) has emerged as a promising solution to enhance the reliability of large language models (LLMs) with external knowledge.Existing RAG methods share a common strategy for knowledge injection: they place the retrieved documents into the input context of the LLM, which we refer to as the in-context knowledge injection method. While this approach is simple and often effective, it has inherent limitations. Firstly, increasing the context length and number of relevant documents can lead to higher computational overhead and degraded performance, especially in complex reasoning tasks. More importantly, in-context knowledge injection operates primarily at the input level, but LLMs store their internal knowledge in their parameters. This gap fundamentally limits the capacity of in-context methods. To this end, we introduce Parametric RAG, a new RAG paradigm that integrates external knowledge directly into the feed-forward networks of an LLM through document parameterization. This approach not only reduces online computational costs by shortening the input context length, but also deepens the integration of external knowledge by enabling LLMs to utilize it in the same way as internal parametric knowledge. Experimental results demonstrate that Parametric RAG substantially enhances the effectiveness and efficiency of knowledge augmentation in LLMs. Also, it can be combined with in-context RAG methods to achieve even better performance. We have open-sourced all the code, data, and models in the following GitHub link: https://github.com/oneal2000/PRAG",
        "doi": "10.1145/3726302.3729957",
        "sheridan_id": "fp0015",
        "position": 1,
        "track_id": 1,
        "slot_id": 3
      }
    },
    {
      "paper": {
        "hashed_id": "68053af2923e00204c3ca7c6a3150cf7",
        "title": "Towards Explainable and Safe Systems for Health Data",
        "abstract": "The integration of artificial intelligence into healthcare holds immense potential to transform medical services through personalized care, early diagnosis, and more informed decision-making. However, despite significant advances in digital health technologies, the adoption of AI-driven systems remains limited, particularly in sensitive domains such as mental health, due to concerns around transparency, safety, and user trust. These concerns are compounded by the complexity of clinical language, the high stakes of decision-making, and the need for accountability in automated systems. This research addresses these challenges by investigating how Large Language Models (LLMs) and related techniques can be adapted to create explainable, interpretable, and safe health information systems. Positioned at the intersection of health informatics, Natural Language Processing (NLP), and Information Retrieval (IR), this work explores both the potential and limitations of LLMs in clinical contexts. While LLMs are effective at processing large textual datasets and producing fluent responses, their black-box nature, tendency to hallucinate, and associated privacy risks make them unsuitable for direct application in healthcare without significant adaptation.This thesis proposes methodologies and systems focused on improving explanation generation, clinical relevance, and the safety of model outputs in health-related queries. The research is guided by eight specific goals: (1) Characterizing health-related language: Modeling the vocabulary used by individuals with specific health conditions using relevance-based statistical language models; (2) Generating natural language explanations: Designing interpretable models that explain classification outputs in ways meaningful to clinicians; (3) Adapting LLMs to clinical reasoning: Fine-tuning LLMs to reflect clinical workflows, particularly for retrieving symptom evidence and supporting diagnostic decisions; (4) Improving answer retrieval: Developing search systems for health queries with better result quality and contextual relevance; (5) Building health recommendation systems: Creating personalized tools for discovering reliable and relevant health information; (6) Ensuring safety and reliability: Creating ``guardrails`` to reduce hallucinations, biases, and misinformation in model outputs; and (7) Supporting multilingual and under-resourced settings: Extending solutions to diverse linguistic and cultural environments.Substantial progress has already been made. Goals G2 and G3 led to a Q1 journal publication on explainable depression detection using social media data, where we proposed and evaluated two architectures: a dual-model approach separating classification and explanation, and a unified LLM-based model that performs both tasks. For G4, we developed MindWell, a conversational agent for depression screening. Based on transformer models and grounded in the Beck Depression Inventory-II (BDI-II), MindWell contextualizes user-generated content from social media to assist clinicians in identifying emotional patterns and symptoms. Ongoing work on G1 involves using statistical language models to identify lexical patterns linked to depressive behaviors online. For G7, we have trained an LLM adapted to Galician, an underrepresented co-official language in Spain, and are currently evaluating its performance in localized health information contexts.",
        "doi": "10.1145/3726302.3730121",
        "sheridan_id": "dc0789",
        "position": 2,
        "track_id": 11,
        "slot_id": 43
      }
    },
    {
      "paper": {
        "hashed_id": "98f13708210194c475687be6106a3b84",
        "title": "LLM-Generated Fake News Induces Truth Decay in News Ecosystem: A Case Study on Neural News Recommendation",
        "abstract": "Online fake news moderation now faces a new challenge brought by the malicious use of large language models (LLMs) in fake news production. Though existing works have shown LLM-generated fake news is hard to detect from an individual aspect, it remains underexplored how its large-scale release will impact the news ecosystem. In this study, we develop a simulation pipeline and a dataset with ~56k generated news of diverse types to investigate the effects of LLM-generated fake news within neural news recommendation systems. Our findings expose a truth decay phenomenon, where real news is gradually losing its advantageous position in news ranking against fake news as LLM-generated news is involved in news recommendation. We further provide an explanation about why truth decay occurs from a familiarity perspective and show the positive correlation between perplexity and news ranking. Finally, we discuss the threats of LLM-generated fake news and provide possible countermeasures. We urge stakeholders to address this emerging challenge to preserve the integrity of news ecosystems.",
        "doi": "10.1145/3726302.3730027",
        "sheridan_id": "fp0020",
        "position": 1,
        "track_id": 1,
        "slot_id": 31
      }
    },
    {
      "paper": {
        "hashed_id": "b53477c2821c1bf0da5d40e57b870d35",
        "title": "NodeRec+: A Lightweight Framework for Federated Recommender Systems",
        "abstract": "Data privacy is a critical concern in today`s data-driven world. To this end, Federated Learning (FL) has been researched extensively, as it allows sensitive data to be kept secure on local devices while training global Machine Learning (ML) models across multiple devices. Several FL topologies have been introduced to address different users` needs. FL fits well within the Recommender Systems (RS) domain, with decentralised large-scale datasets and user privacy issues, as it improves personalised recommendations and accuracy while keeping users` sensitive data secure.   In this paper, we introduce NodeRec+, the prototype of an FL framework, geared towards enabling the design and evaluation of decentralised RS. NodeRec+ allows quick and easy composition of various FL topologies in simple Python code and comes ready integrated with a number of RS models and evaluation protocols, enabling rapid benchmarking of models in various FL topologies. In contrast to most similar frameworks that are either used for simulations or focused solely on a single FL topology, NodeRec+ provides a framework to build real decentralised networks of nodes that can work jointly using several FL topologies in RS settings. A demonstration video showcasing the NodeRec+ framework can be found at https://www.youtube.com/watch?v=IIo3Cr56YyI. Code is provided at https://github.com/SEDIMARK-UCD/noderec.",
        "doi": "10.1145/3726302.3730138",
        "sheridan_id": "de2405",
        "position": 12,
        "track_id": 10,
        "slot_id": 112
      }
    },
    {
      "paper": {
        "hashed_id": "1fb2a1c37b18aa4611c3949d6148d0f8",
        "title": "ClusterChat: Multi-Feature Search for Corpus Exploration",
        "abstract": "Exploring large-scale text corpora presents a significant challenge in biomedical, finance, and legal domains, where vast amounts of documents are continuously published. Traditional search methods, such as keyword-based search, often retrieve documents in isolation, limiting the user`s ability to easily inspect corpus-wide trends and relationships. We present \\textit{ClusterChat}\\footnote{The demo video and source code are available at: \\url{https://github.com/achouhan93/ClusterChat}}, an open-source system for corpus exploration that integrates cluster-based organization of documents using textual embeddings with lexical and semantic search, timeline-driven exploration, and corpus and document-level question answering (QA) as multi-feature search capabilities. We validate the system with two case studies on a four million abstract PubMed dataset, demonstrating that \\textit{ClusterChat} enhances corpus exploration by delivering context-aware insights while maintaining scalability and responsiveness on large-scale document collections.",
        "doi": "10.1145/3726302.3730137",
        "sheridan_id": "de2430",
        "position": 13,
        "track_id": 10,
        "slot_id": 112
      }
    },
    {
      "paper": {
        "hashed_id": "fface8385abbf94b4593a0ed53a0c70f",
        "title": "Interactive Code Information Integrated Programming Knowledge Tracing",
        "abstract": "Programming Knowledge Tracing (PKT) aims to estimate students` programming proficiency by analyzing their historical coding activities. It is important to leverage interactive information for PKT code representations, as code submissions are problem-specific interactive solutions evaluated by Online Judge (OJ) feedback. However, most existing PKT models only rely on pre-trained language models to capture static code information, overlooking feedback scores and problem-specific context. To address this issue, we propose an Interactive Information integrated Code Embedding for Programming Knowledge Tracing (IICE-PKT). This model learns a unified code representation by integrating comprehensive interactive information, including code text, OJ feedback scores, problem statement text, problem-skill correlations, and problem difficulties. IICE-PKT consists of three modules: Problem Representation module generates enhanced problem embeddings based on problem-skill correlations and problem difficulties; Code Representation module combines fine-tuned CodeBERT-based code text embeddings, GPT-generated problem text embeddings, and enhanced problem embeddings with supervised feedback scores to produce a unified code representation; Dual-Sequence Modeling module employs two independent GRUs to separately model the problem sequence and the code sequence. Extensive experiments demonstrate the superiority of IICE-PKT. Ablation studies confirm that integrating interactive information into code representations significantly enhances effectiveness.",
        "doi": "10.1145/3726302.3730214",
        "sheridan_id": "sp1827",
        "position": 34,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "1ff1de774005f8da13f42943881c655f",
        "title": "CLIP-AdaM: Adapting Multi-view CLIP for Open-set 3D Object Retrieval",
        "abstract": "Open-set 3D object retrieval (3DOR) aims to learn discriminative and generalizable embeddings for unseen categories of 3D objects.  However, attaining this objective typically requires the costly acquisition of large-scale 3D object datasets and associated resources for model training.  Building upon the strong open-world representation capabilities of CLIP, we introduce CLIP-AdaM, which, to our knowledge, represents the first attempt to adapt a CLIP model for open-set 3DOR with minimal effort.  We first find that a pretrained CLIP already delivers a surprisingly acceptable performance on multi-view images.  To further unleash its potential, we design a customized adapter for learning to aggregate and adapt its pretrained features towards better 3D embeddings.  For aggregation, it learns two sets of view scores to weigh the contributions of view images for fusion. One is learned by a tiny view-score network at the instance level, and the other is learned implicitly at the dataset level, aiding generalization to unseen categories.  The adaptation component comprises only a basic linear layer yet yields superior results.  During training, the adapter with such a small amount of parameters can be efficiently fine-tuned with limited 3D closed-set data, effectively mitigating the overfitting issue while harnessing the prior knowledge from pretrained models.   Without bells and whistles, CLIP-AdaM attains state-of-the-art performance on four open-set 3DOR benchmarks. Additionally, it demonstrates strong extensibility to broader scenarios, including zero-shot, few-shot, and seen/unseen 3D representation learning.",
        "doi": "10.1145/3726302.3729925",
        "sheridan_id": "fp0024",
        "position": 7,
        "track_id": 1,
        "slot_id": 5
      }
    },
    {
      "paper": {
        "hashed_id": "e2ef524fbf3d9fe611d5a8e90fefdc9c",
        "title": "Diffusion-based Multi-modal Synergy Interest Network for Click-through Rate Prediction",
        "abstract": "In click-through rate prediction, click-through rate prediction is used to model users` interests. However, most of the existing CTR prediction methods are mainly based on the ID modality. As a result, they are unable to comprehensively model users` multi-modal preferences. Therefore, it is necessary to introduce multi-modal CTR prediction. Although it seems appealing to directly apply the existing multi-modal fusion methods to click-through rate prediction models, these methods (1) fail to effectively disentangle commonalities and specificities across different modalities; (2) fail to consider the synergistic effects between modalities and model the complex interactions between modalities.  To address the above issues, this paper proposes the Diffusion-based Multi-modal Synergy Interest Network (Diff-MSIN) framework for click-through prediction. This framework introduces three innovative modules: the Multi-modal Feature Enhancement (MFE) Module Synergistic Relationship Capture (SRC) Module, and the Feature Dynamic Adaptive Fusion (FDAF) Module. The MFE Module and SRC Module extract synergistic, common, and special information among different modalities. They effectively enhances the representation of the modalities, improving the overall quality of the fusion. To encourage distinctiveness among different features, we design a Knowledge Decoupling method. Additionally, the FDAF Module focuses on capturing user preferences and reducing fusion noise. To validate the effectiveness of the Diff-MSIN framework, we conducted extensive experiments using the Rec-Tmall and three Amazon datasets. The results demonstrate that our approach yields a significant improvement of at least 1.67% compared to the baseline, highlighting its potential for enhancing multi-modal recommendation systems. Our code is available at the following link: https://github.com/Cxx-0/Diff-MSIN.",
        "doi": "10.1145/3726302.3729949",
        "sheridan_id": "fp0097",
        "position": 1,
        "track_id": 1,
        "slot_id": 9
      }
    },
    {
      "paper": {
        "hashed_id": "cfecdb276f634854f3ef915e2e980c31",
        "title": "Incorporating Communication Style and Interaction of Speakers for Sarcasm Explanation in Dialogue",
        "abstract": "Sarcasm Explanation in Dialogue (SED) task aims to uncover the underlying meaning of sarcastic expressions in multimodal dialogues.  While previous studies have largely focused on modeling dialogue content, they often neglect the influence of speakers and the interactions between utterances.  To address this gap, we propose a novel framework called CISI, which integrates personalized communication styles, inter-speaker interaction relationships, and sarcasm-centric multimodal cues to enhance SED.   To capture how personalized styles influence sarcasm expression, we model speakers` communication styles using Satir`s Communication Model in psychology. Furthermore, we model the flow of sarcasm through discourse parsing, constructing explicit conversational interaction and dependencies between speakers. Lastly, we design a multimodal fusion module that aligns modality-specific cues with sarcasm-related semantics to enhance understanding.  Extensive experiments on the WITS dataset demonstrate that CISI achieves superior performance. We also obtain competitive results on the MUStARD dataset for dialogue-level multimodal sarcasm detection, further showcasing the generalizability of CISI.",
        "doi": "10.1145/3726302.3730006",
        "sheridan_id": "fp0190",
        "position": 3,
        "track_id": 1,
        "slot_id": 23
      }
    },
    {
      "paper": {
        "hashed_id": "4e732ced3463d06de0ca9a15b6153677",
        "title": "Balancing Self-Presentation and Self-Hiding for Exposure-Aware Recommendation Based on Graph Contrastive Learning",
        "abstract": "Recent advances in graph contrastive learning (GCL) have significantly enhanced recommendation systems. However, most existing approaches predominantly focus on optimizing training data fit while overlooking exposure bias, a critical issue that can substantially impact recommendation effectiveness. Drawing inspiration from sociological theories of human interaction patterns\u2014specifically how individuals balance self-presentation and self-hiding behaviors in social contexts\u2014this paper proposes \\textbf{BPH4Rec}, a novel \\textbf{B}alancing self-\\textbf{P}resentation and self-\\textbf{H}iding approach \\textbf{for} exposure-aware \\textbf{Rec}ommendation based on GCL. Within the GCL framework, BPH4Rec introduces two complementary mechanisms: (1) a self-hiding mechanism that modifies the adjacency matrix of contrastive views through custom inverse propensity scoring (IPS), effectively addressing exposure bias, and (2) a self-presentation mechanism that incorporates densification factors during matrix reconstruction to mitigate sparsity-induced biases. Through extensive evaluation on six public benchmark datasets, BPH4Rec demonstrates substantial improvements over state-of-the-art baselines, particularly in promoting long-tail item discovery while maintaining recommendation accuracy.",
        "doi": "10.1145/3726302.3729900",
        "sheridan_id": "fp0026",
        "position": 3,
        "track_id": 1,
        "slot_id": 2
      }
    },
    {
      "paper": {
        "hashed_id": "14bfa6bb14875e45bba028a21ed38046",
        "title": "Data Augmentation as Free Lunch: Exploring the Test-Time Augmentation for Sequential Recommendation",
        "abstract": "Data augmentation has become a promising method of mitigating data sparsity in sequential recommendation. Existing methods generate new yet effective data during model training to improve performance. However, deploying them requires retraining, architecture modification, or introducing additional learnable parameters. These steps are time-consuming and costly for well-trained models, especially when the model scale becomes large. In this work, we explore the test-time augmentation (TTA) for sequential recommendation, which augments the inputs during the model inference and then aggregates the model`s predictions for augmented data to improve final accuracy. It avoids significant time and cost overhead from the previously mentioned steps. We first experimentally disclose the potential of existing augmentation operators for TTA and find that the Mask and Substitute consistently achieve better performance. Further analysis reveals that these two operators are effective because they retain the original sequential pattern while adding appropriate perturbations. Meanwhile, we argue that these two operators still face time-consuming item selection or interference information from mask tokens. Based on the analysis and limitations, we present TNoise and TMask. The former injects uniform noise into the original representation, avoiding the computational overhead of item selection. The latter blocks mask token from participating in model calculations or directly removes interactions that should have been replaced with mask tokens. Comprehensive experiments demonstrate the effectiveness, efficiency, and generalizability of our method. Our codes are available at https://github.com/KingGugu/TTA4SR.",
        "doi": "10.1145/3726302.3729943",
        "sheridan_id": "fp0069",
        "position": 2,
        "track_id": 1,
        "slot_id": 7
      }
    },
    {
      "paper": {
        "hashed_id": "253614bbac999b38b5b60cae531c4969",
        "title": "GEAR: Generalized Alternating Regressor for Multi-Behavior Sequential Recommendation",
        "abstract": "Modern recommender systems face a critical challenge in modeling the intricate interplay between multi-behavior interactions of users (e.g., clicks, adds-to-cart and purchases) and temporal dynamics that drive evolving preferences. While existing multi-behavior sequential recommendation methods attempt to capture these signals, they often suffer from fragmented modeling, such as decoupling behaviors and items into separate sequences, neglecting time-aware transitions, or relying on computationally intensive architectures that hinder real-world scalability. To address these limitations, we propose GEneralized Alternating Regressor (GEAR), a novel framework that unifies behaviors, items, and temporal contexts into a single autoregressive sequence through an alternating architecture. At its core, GEAR represents user interactions as triplets and processes them through a modular transformer architecture. In this architecture, each triplet is alternately modeled at lower layers to disentangle fine-grained patterns, while upper layers jointly learn cross-signal dependencies. This design mimics the interlocking mechanism of gears, enabling the seamless transitions between multi-behavior dynamics and item transitions. Additionally, we incorporate a time-bias term to quantify the decay of behavioral influence across both short- and long-term horizons. Extensive experiments on real-world datasets validate the effectiveness, generalizability, and computational efficiency of the proposed framework.",
        "doi": "10.1145/3726302.3730200",
        "sheridan_id": "sp2012",
        "position": 59,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "28dd2c7955ce926456240b2ff0100bde",
        "title": "Measuring Text-Image Retrieval Fairness with Synthetic Data",
        "abstract": "In this paper, we study social bias in cross-modal text-image retrieval systems, focusing on the interaction between textual queries and image responses. Despite the significant advancements in cross-modal retrieval models, the potential for social bias in their responses remains a pressing concern, necessitating a comprehensive framework for assessment and mitigation. We introduce a novel framework for evaluating social bias in cross-modal retrieval systems, leveraging a new dataset and appropriate metrics specifically designed for this purpose. Our dataset, Social Inclusive Synthetic Professionals Images (SISPI), comprises 49K images generated using state-of-the-art text-to-image models, ensuring a balanced representation of demographic groups across various professional roles. We use this dataset to conduct an extensive analysis of social bias (gender and ethnic) in state of the art cross-modal retrieval deep models, including CLIP, ALIGN, BLIP, FLAVA, COCA, and many others. Using diversity metrics, grounded in the distribution of different demographic groups` images in the retrieval rankings, we provide a quantitative measure of fairness, facilitating a detailed analysis of models` behavior. Our work sheds light on biases present in current cross-modal retrieval systems and emphasizes the importance of training data curation, providing a foundation for future research and development towards more equitable and unbiased models. The dataset and code of our framework is publicly available at \\url{https://sispi-benchmark.github.io/sispi-benchmark/}.",
        "doi": "10.1145/3726302.3730030",
        "sheridan_id": "fp0077",
        "position": 1,
        "track_id": 1,
        "slot_id": 39
      }
    },
    {
      "paper": {
        "hashed_id": "38b3eff8baf56627478ec76a704e9b52",
        "title": "A Pattern-Driven Information Diffusion Prediction Model Based on Multisource Resonance and Cognitive Adaptation",
        "abstract": "The significant societal impact of online public opinion has spurred extensive research into the underlying mechanisms of information diffusion. While existing diffusion prediction models have effectively leveraged network structure, they often lack a deep understanding of the intrinsic patterns governing information dissemination, thus limiting their predictive power. To address this critical gap, we introduce PMRCA, a novel information diffusion prediction model inspired by social psychology and driven by fundamental propagation patterns. PMRCA posits that two key patterns underpin topic propagation: multisource resonance, where consensus emerges from consistent narratives across multiple sources, and cognitive adaptation, where information is tailored to align with audience cognitive features. Correspondingly, PMRCA incorporates two dedicated learning tasks: structural contrastive learning based on node homogeneity to capture multisource resonance, and clustering contrastive learning based on cognitive clusters to model cognitive adaptation. Extensive experiments on four real-world datasets demonstrate that PMRCA significantly outperforms existing mainstream models. Importantly, our pattern-driven approach is model-agnostic, allowing it to be flexibly applied to various diffusion prediction scenarios and enhance performance.",
        "doi": "10.1145/3726302.3729883",
        "sheridan_id": "fp0101",
        "position": 2,
        "track_id": 1,
        "slot_id": 9
      }
    },
    {
      "paper": {
        "hashed_id": "7fd804295ef7f6a2822bf4c61f9dc4a8",
        "title": "Retrieval for Semantic People Search",
        "abstract": "These days we have a large number of open-source embedding LLMs that can be leveraged in a bi-encoder architecture for retrieval. However, they do not perform very well when leveraged as is for people search because the (query, document) pairs encountered in people search are much more complex than the text pairs that these open-source embedding LLMs are trained on. In this paper we present our experiments, learnings and solution to the problem of retrieval for people search. Our solution involves query simplification, document simplification, fine-tuning of a 7B parameter embedding LLM, and compression of embeddings through Matryoshka learning.",
        "doi": "10.1145/3726302.3731938",
        "sheridan_id": "sir2444",
        "position": 4,
        "track_id": 12,
        "slot_id": 186
      }
    },
    {
      "paper": {
        "hashed_id": "82aa4b0af34c2313a562076992e50aa3",
        "title": "Hyperbolic Multi-Criteria Rating Recommendation",
        "abstract": "Multi-criteria (MC) ratings as auxiliary supervisory signals can improve the prediction accuracy of recommender systems. The existing MC methods learn the representations of users and items in Euclidean space to estimate the interaction probabilities. However, this modeling paradigm ignores two important aspects. Firstly, when embedding power-law distribution data and personalized MC preferences in Euclidean space, the model may produce suboptimal solutions due to the distortion of the hierarchical structure. Secondly, the inevitable noise in MC ratings may hinder the recommendation quality of the model. To address the above issues, we propose a novel framework called Hyperbolic Multi-Criteria Recommendation (HMCR), which aims to mine users` MC behavioral features on hyperbolic manifolds and mitigate the noise interference through knowledge transfer among the criteria. Specifically, we map the representations on each criterion view to a hyperbolic space with adjustable curvature based on the Lorentz model, which is used to capture the hierarchical structure of collective user behavior. The MC preferences of individual users are fused by calculating the hyperbolic attention among each criterion and the overall rating. Moreover, we design a self-supervised contrastive loss to suppress the negative impact of noise interactions on the model. The experimental results on four real-world datasets show that the HMCR significantly outperforms the existing baselines.",
        "doi": "10.1145/3726302.3730000",
        "sheridan_id": "fp0162",
        "position": 1,
        "track_id": 1,
        "slot_id": 30
      }
    },
    {
      "paper": {
        "hashed_id": "006f52e9102a8d3be2fe5614f42ba989",
        "title": "The Magnitude of Truth: On Using Magnitude Estimation for Truthfulness Assessment",
        "abstract": "Assessing the truthfulness of information is a critical task in fact-checking, and is typically performed using binary or coarse ordinal scales (2\u20136 levels), though fine-grained scales (e.g., 100 levels) have also been explored. Magnitude Estimation (\\me) takes this approach further by allowing assessors to assign any value in the range $(0, +\\infty)$. However, it introduces challenges, including the need for aggregation of assessments from individuals with different interpretations of the scale. Despite these, its successful applications in other domains suggest its potential suitability for truthfulness assessment.We conduct a crowdsourcing study by collecting assessments on claims sourced from the \\politifact fact-checking organization using \\me. To the best of our knowledge, this is the first systematic investigation of \\me in the context of truthfulness assessment.Our results show that while aggregation methods significantly impact assessment quality, optimal aggregation strategies yield accuracy and reliability comparable to traditional scales. More importantly, \\me allows capturing subtle differences in truthfulness, offering richer insights than conventional coarse-grained scales.",
        "doi": "10.1145/3726302.3730091",
        "sheridan_id": "fp0168",
        "position": 2,
        "track_id": 1,
        "slot_id": 31
      }
    },
    {
      "paper": {
        "hashed_id": "149e9677a5989fd342ae44213df68868",
        "title": "Efficiency and Effectiveness of LLM-Based Summarization of Evidence in Crowdsourced Fact-Checking",
        "abstract": "Evaluating the truthfulness of online content is critical for combating misinformation. This study examines the efficiency and effectiveness of crowdsourced truthfulness assessments through a comparative analysis of two approaches: one involving full-length webpages as evidence for each claim, and another using summaries for each evidence document generated with an LLM. Using an A/B testing setting, we engage a diverse pool of participants tasked with evaluating the truthfulness of statements under these conditions. Our analysis explores both the quality of assessments and the behavioral patterns of participants. The results reveal that relying on summarized evidence offers comparable accuracy and error metrics to the standard modality while significantly improving efficiency. Workers in the \\summary setting complete a significantly higher number of assessments, reducing task duration and costs. Additionally, the \\summary modality maximizes internal agreement and maintains consistent reliance on and perceived usefulness of evidence, demonstrating its potential to streamline large-scale truthfulness evaluations.",
        "doi": "10.1145/3726302.3729960",
        "sheridan_id": "fp0170",
        "position": 3,
        "track_id": 1,
        "slot_id": 31
      }
    },
    {
      "paper": {
        "hashed_id": "38af86134b65d0f10fe33d30dd76442e",
        "title": "Reconciling Efficiency and Effectiveness of Exercise Retreival: An Uncertainty Reduction Hashing Approach for Computerized Adaptive Testing",
        "abstract": "With the rapid development of intelligent education, Computerized Adaptive Testing(CAT) has garnered significant attention for its ability to tailor exercises to individual examinees. The adaptability of CAT is primarily achieved through the alternating optimization of two core components: the cognitive diagnosis model and the exercise selection module. However, existing CAT approaches, despite their remarkable achievements, often come at the expense of high time costs. Statistical-based approaches incur increased time overhead due to complex computations, while data-driven approaches further exacerbate time inefficiency because of the iterative processes in reinforcement learning, making it challenging to balance evaluation effectiveness and time efficiency. To this end, in this paper, we propose \\textbf{HashCAT}, an efficient CAT approach based on learning to hash, aiming to balance efficiency and evaluation effectiveness. Our approach comprises two stages: the hash representation generation and the exercise selection. In the first stage, we design an information alignment module and a novel cognitive diagnosis function to model the interaction between examinees and exercises, generating hash representations with clear physical significance. In the second stage, we propose an uncertainty reduction-based algorithm that utilize information entropy to quantify the uncertainty in student ability estimation and selects exercises that most effectively reduce this uncertainty. Experimental results on four real-world datasets demonstrate that the proposed method significantly improves question selection efficiency while maintaining competitive evaluation performance. The code exists anonymously in \\url{https://github.com/sherklock/Intelligent-Education/tree/main/HashCAT-main}.",
        "doi": "10.1145/3726302.3730072",
        "sheridan_id": "fp0176",
        "position": 1,
        "track_id": 1,
        "slot_id": 24
      }
    },
    {
      "paper": {
        "hashed_id": "9dcb88e0137649590b755372b040afad",
        "title": "Exploring Training and Inference Scaling Laws in Generative Retrieval",
        "abstract": "Generative retrieval reformulates retrieval as an autoregressive generation task, where large language models (LLMs) generate target documents directly from a query. As a novel paradigm, the mechanisms that underpin its performance and scalability remain largely unexplored. We systematically investigate training and inference scaling laws in generative retrieval, exploring how model size, training data scale, and inference-time compute jointly influence performance. We propose a novel evaluation metric inspired by contrastive entropy and generation loss, providing a continuous performance signal that enables robust comparisons across diverse generative retrieval methods. Our experiments show that n-gram-based methods align strongly with training and inference scaling laws. We find that increasing model size, training data scale, and inference-time compute all contribute to improved performance, highlighting the complementary roles of these factors in enhancing generative retrieval. Across these settings, LLaMA models consistently outperform T5 models, suggesting a particular advantage for larger decoder-only models in generative retrieval. Our findings underscore that model sizes, data availability, and inference computation interact to unlock the full potential of generative retrieval, offering new insights for designing and optimizing future systems. We release code at SLGR GitHub repository.",
        "doi": "10.1145/3726302.3729973",
        "sheridan_id": "fp0188",
        "position": 2,
        "track_id": 1,
        "slot_id": 23
      }
    },
    {
      "paper": {
        "hashed_id": "0aa1883c6411f7873cb83dacb17b0afc",
        "title": "ULP: Unlabeled Location Prediction from Text",
        "abstract": "With the popularity of smart mobile devices, location-based services (LBS) have been widely applied. Predicting geographical locations from text holds significant value for smart cities and personalized travel. Existing research primarily focuses on the retrieval or prediction of labeled locations, such as cities or points of interest (POIs). However, in scenarios like autonomous driving navigation and autonomous logistics delivery, it is necessary to precisely predict the coordinates of unlabeled locations, for example, 200 meters northwest of a certain location. Consequently, we introduce a new task to infer fine-grained unlabeled locations from text. This task is particularly challenging because of the ambiguous text and the semantic gap between geographic and textual modalities. In this paper, we aim to construct an end-to-end fine-grained location prediction model to accurately predict the unlabeled locations mentioned in texts. First, we encode the geographic coordinates and transform the location prediction problem into a geographic encoding generation problem. Second, we propose a multi-scale cross-modal loss (MCL) to learn the implicit mapping between geographic and textual modalities. Lastly, we design a multi-task prediction model ULP to predict the coordinates of unlabeled locations. We conducted experiments on two real-world datasets, and the results show that our proposed method outperforms existing state-of-the-art retrieval-based methods.",
        "doi": "10.1145/3726302.3730104",
        "sheridan_id": "fp0191",
        "position": 6,
        "track_id": 1,
        "slot_id": 4
      }
    },
    {
      "paper": {
        "hashed_id": "bd686fd640be98efaae0091fa301e613",
        "title": "Unleashing the Potential of Diffusion Models Towards Diversified Sequential Recommendations",
        "abstract": "Sequential recommender systems (SRSs) aim to recommend the next items to well match users` preferences. In addition to recommendation accuracy, diversity is another critical aspect in evaluating SRSs. Recently, the emerging diffusion models (DMs) have been widely adopted in SRSs. Their employed learning-to-generate paradigm allows them to cover a much broader range of users` preferences and thus generate more diversified items. However, existing DM-based SRSs still face two significant gaps that prevent them from further improving the recommendation diversity: (1) they often rely on \\textbf{non-diversified users` preferences as guidance} to direct the training of diffusion networks, restricting networks` ability to generate diverse items; and (2) they are based on \\textbf{a homogeneous diffusion inference mechanism} to generate the next items and thus can only accommodate users` major preferences. Such a practice neglects users` heterogeneous preferences towards various types of items, further limiting recommendation diversity. To bridge these two critical gaps and to further unleash the potential of DMs in enhancing the recommendation diversity of SRSs, we propose a novel diversity-guided diffusion model for sequential recommendations, called \\textit{DiffDiv} for short. To be specific, first, a new diversity-aware guidance learning mechanism is devised to direct the training of DMs to effectively capture users` diversified preferences from  their historical interactions. Then, a novel heterogeneous diffusion inference mechanism is designed to generate diversified items to accommodate users` heterogeneous preferences, further boosting the recommendation diversity. Extensive experiments on real-world datasets validate the effectiveness of DiffDiv in terms of both recommendation accuracy and diversity.",
        "doi": "10.1145/3726302.3730109",
        "sheridan_id": "fp0193",
        "position": 3,
        "track_id": 1,
        "slot_id": 7
      }
    },
    {
      "paper": {
        "hashed_id": "7eabe3a1649ffa2b3ff8c02ebfd5659f",
        "title": "Denoising Multi-Interest-Aware Logical Reasoning for Long-Sequence Recommendation",
        "abstract": "Logical reasoning-based recommendation methods employ logical rules to mitigate the adverse effects of noise items in short interaction sequences on recommendation accuracy. However, there are two problems with existing methods: 1) As the length of the interaction sequence increases, introducing more noise items exacerbates the negative impact on logical reasoning, thereby reducing the accuracy of these methods. 2) They are often dominated by the user`s single primary interest, which prevents simultaneous consideration of users` multiple-aspect interests in long sequences. To address these issues, we propose a novel dEnoising Multi-Interest-aware Logical rEasoning (EMILE) method for long-sequence recommendation. Specifically, we design a logical rule-based interest extractor that enhances the importance of preferred items in constructing user interests while minimizing the negative impact of disliked items. This extractor effectively mitigates the adverse effects of noise items in long interaction sequences. Furthermore, we propose a novel multi-interest learning strategy that optimizes two new objective functions\u2014interest probability distribution contrastive loss and interest logical reasoning contrastive loss\u2014to ensure the model simultaneously considers multiple-aspect interests. These two objective functions require that the target item is more closely aligned with multiple interests than the single primary interest, both in the probability distribution space and during logical reasoning. Experimental results on four public datasets demonstrate that our method significantly outperforms all compared baselines regarding recommendation accuracy. Code is available at https://github.com/muzi1998/Denoising-Multi-Interest-Aware-Logical-Reasoning.",
        "doi": "10.1145/3726302.3729944",
        "sheridan_id": "fp0206",
        "position": 4,
        "track_id": 1,
        "slot_id": 7
      }
    },
    {
      "paper": {
        "hashed_id": "7d04bbbe5494ae9d2f5a76aa1c00fa2f",
        "title": "Improving LLM-powered Recommendations with Personalized Information",
        "abstract": "Due to the lack of explicit reasoning modeling, existing LLM-powered recommendations fail to leverage LLMs` reasoning capabilities effectively. In this paper, we propose a pipeline called CoT-Rec, which integrates two key Chain-of-Thought (CoT) processes---user preference analysis and item perception analysis---into LLM-powered recommendations, thereby enhancing the utilization of LLMs` reasoning abilities. CoT-Rec consists of two stages: (1) personalized information extraction, where user preferences and item perception are extracted, and (2) personalized information utilization, where this information is incorporated into the LLM-powered recommendation process. Experimental results demonstrate that CoT-Rec shows potential for improving LLM-powered recommendations. The implementation is publicly available at https://github.com/jhliu0807/CoT-Rec.",
        "doi": "10.1145/3726302.3730211",
        "sheridan_id": "sp0486",
        "position": 2,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "e77dbaf6759253c7c6d0efc5690369c7",
        "title": "LexRAG: Benchmarking Retrieval-Augmented Generation in Multi-Turn Legal Consultation Conversation",
        "abstract": "Retrieval-augmented generation (RAG) has proven highly effective in improving large language models (LLMs) across various domains. However, there is no benchmark specifically designed to assess the effectiveness of RAG in the legal domain, which restricts progress in this area. To fill this gap, we propose LexRAG, the first benchmark to evaluate RAG systems for multi-turn legal consultations. LexRAG consists of 1,013 multi-turn dialogue samples and 17,228 candidate legal articles. Each sample is annotated by legal experts and consists of five rounds of progressive questioning. LexRAG includes two key tasks: (1) Conversational knowledge retrieval, requiring accurate retrieval of relevant legal articles based on multi-turn context. (2) Response generation, focusing on producing legally sound answers. To ensure reliable reproducibility, we develop LexiT, a legal RAG toolkit that provides a comprehensive implementation of RAG system components tailored for the legal domain. Additionally, we introduce an LLM-as-a-judge evaluation pipeline to enable detailed and effective assessment. Through experimental analysis of various LLMs and retrieval methods, we reveal the key limitations of existing RAG systems in handling legal consultation conversations. LexRAG establishes a new benchmark for the practical application of RAG systems in the legal domain, with its code and data available at https://github.com/CSHaitao/LexRAG.",
        "doi": "10.1145/3726302.3730340",
        "sheridan_id": "rr2332",
        "position": 93,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "c24cd76e1ce41366a4bbe8a49b02a028",
        "title": "X-Cross: Dynamic Integration of Language Models for Cross-Domain Sequential Recommendation",
        "abstract": "As new products are emerging daily, recommendation systems are required to quickly adapt to possible new domains without needing extensive retraining. This work presents ``X-Cross`` -- a novel cross-domain sequential-recommendation model that recommends products in new domains by integrating several domain-specific language models; each model is fine-tuned with low-rank adapters (LoRA). Given a recommendation prompt, operating layer by layer, X-Cross dynamically refines the representation of each source language model by integrating knowledge from all other models. These refined representations are propagated from one layer to the next, leveraging the activations from each domain adapter to ensure domain-specific nuances are preserved while enabling adaptability across domains. Using Amazon datasets for sequential recommendation, X-Cross achieves performance comparable to a model that is fine-tuned with LoRA, while using only 25% of the additional parameters. In cross-domain tasks, such as adapting from Toys domain to Tools, Electronics or Sports, X-Cross demonstrates robust performance, while requiring about 50%-75% less fine-tuning data than LoRA to make fine-tuning effective. Furthermore, X-Cross achieves significant improvement in accuracy over alternative cross-domain baselines. Overall, X-Cross enables scalable and adaptive cross-domain recommendations, reducing computational overhead and providing an efficient solution for data-constrained environments.",
        "doi": "10.1145/3726302.3730117",
        "sheridan_id": "fp0253",
        "position": 5,
        "track_id": 1,
        "slot_id": 7
      }
    },
    {
      "paper": {
        "hashed_id": "b1a59b315fc9a3002ce38bbe070ec3f5",
        "title": "ReARTeR: Retrieval-Augmented Reasoning with Trustworthy Process Rewarding",
        "abstract": "Retrieval-Augmented Generation (RAG) systems for Large Language Models (LLMs) have shown promise in knowledge-intensive tasks, yet their reasoning capabilities, particularly for complex multi-step reasoning, remain limited. Although recent approaches have explored integrating RAG with chain-of-thought reasoning or incorporating test-time search with process reward model (PRM), these methods face several untrustworthy challenges, including lack of explanations, bias in PRM training data, early-step bias in PRM scores, and ignoring post-training that fails to fully optimize reasoning potential. To address these issues, we propose Retrieval-Augmented Reasoning through Trustworthy Process Rewarding (ReARTeR), a framework that enhances RAG systems` reasoning capabilities through both post-training and test-time scaling. At test time, ReARTeR introduces Trustworthy Process Rewarding via a Process Reward Model for accurate scalar scoring and a Process Explanation Model (PEM) for generating natural language explanations, enabling step refinement. During post-training, we leverage Monte Carlo Tree Search guided by Trustworthy Process Rewarding to collect high-quality step-level preference data, which is used to optimize the model through Iterative Preference Optimization. ReARTeR tackles three key challenges: (1) misalignment between PRM and PEM, addressed through off-policy preference learning; (2) bias in PRM training data, mitigated by a balanced annotation method and incorporating stronger annotations for difficult examples; and (3) early-step bias in PRM, resolved via a temporal-difference-based look-ahead search strategy. Experimental results on multi-step reasoning benchmarks demonstrate that ReARTeR significantly improves reasoning performance, highlighting its potential to advance the reasoning capability of RAG systems.",
        "doi": "10.1145/3726302.3730102",
        "sheridan_id": "fp0261",
        "position": 2,
        "track_id": 1,
        "slot_id": 3
      }
    },
    {
      "paper": {
        "hashed_id": "63923f49e5241343aa7acb6a06a751e7",
        "title": "Addressing Missing Data Issue for Diffusion-based Recommendation",
        "abstract": "Diffusion models have shown significant potential in generating oracle items that best match user preference with guidance from user historical interaction sequences. However, the quality of guidance is often compromised by unpredictable missing data in observed sequence, leading to suboptimal item generation. Since missing data is uncertain in both occurrence and content, recovering it is impractical and may introduce additional errors. To tackle this challenge, we propose a novel dual-side Thompson sampling-based Diffusion Model (TDM), which simulates extra missing data in the guidance signals and allows diffusion models to handle existing missing data through extrapolation. To preserve user preference evolution in sequences despite extra missing data, we introduce Dual-side Thompson Sampling to implement simulation with two probability models, sampling by exploiting user preference from both item continuity and sequence stability. TDM strategically removes items from sequences based on dual-side Thompson sampling and treats these edited sequences as guidance for diffusion models, enhancing models` robustness to missing data through consistency regularization. Additionally, to enhance the generation efficiency, TDM is implemented under the denoising diffusion implicit models to accelerate the reverse process. Extensive experiments and theoretical analysis validate the effectiveness of TDM in addressing missing data in sequential recommendations.",
        "doi": "10.1145/3726302.3729890",
        "sheridan_id": "fp0275",
        "position": 8,
        "track_id": 1,
        "slot_id": 1
      }
    },
    {
      "paper": {
        "hashed_id": "ed519dacc89b2bead3f453b0b05a4a8b",
        "title": "GINGER: Grounded Information Nugget-Based Generation of Responses",
        "abstract": "Retrieval-augmented generation (RAG) faces challenges related to factual correctness, source attribution, and response completeness. To address them, we propose a modular pipeline for grounded response generation that operates on information nuggets - minimal, atomic units of relevant information extracted from retrieved documents. The multistage pipeline encompasses nugget detection, clustering, ranking, top cluster summarization, and fluency enhancement. It guarantees grounding in specific facts, facilitates source attribution, and ensures maximum information inclusion within length constraints. Experiments on the TREC RAG`24 dataset, using the AutoNuggetizer framework, demonstrate that GINGER achieves state-of-the-art performance on this benchmark.",
        "doi": "10.1145/3726302.3730166",
        "sheridan_id": "sp1825",
        "position": 32,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "20f07591c6fcb220ffe637cda29bb3f6",
        "title": "OmniNER2025: Diverse and Comprehensive Fine-Grained NER Dataset and Benchmark for Chinese",
        "abstract": "As Named Entity Recognition (NER) tasks have evolved, artificial intelligence has been widely applied in this field. However, most benchmarks are limited to English, making it challenging to replicate successful experiences in other languages. To expand NER to informal and diverse Chinese text scenarios, we have proposed a new large-scale Chinese NER dataset, OmniNER2025. This dataset, obtained from user posts on a popular Chinese social media platform Xiaohongshu, contains 195,568 samples and 89 categories, all manually annotated. To our knowledge, it is currently the largest Chinese open-source NER dataset in terms of sample size, category diversity, and domain coverage. This dataset is more challenging than existing Chinese NER datasets and better reflects real-world applications. The large sample size and diverse entity types provide valuable research resources. Additionally, we introduced the ERRTA tool for error analysis and teacher model guidance, significantly reducing model errors and improving performance. In the future, we will refine the ERRTA framework and explore optimization strategies to enhance the practical value of NER models. By releasing the OmniNER2025 dataset and introducing the ERRTA tool, we have advanced fine-grained NER research and improved model performance, promoting its application and development in real-world scenarios.",
        "doi": "10.1145/3726302.3730048",
        "sheridan_id": "fp0277",
        "position": 1,
        "track_id": 1,
        "slot_id": 41
      }
    },
    {
      "paper": {
        "hashed_id": "6ba3af5d7b2790e73f0de32e5c8c1798",
        "title": "FairDiverse: A Comprehensive Toolkit for Fairness- and Diversity-aware Information Retrieval",
        "abstract": "In modern information retrieval (IR), going beyond accuracy is crucial for maintaining a healthy ecosystem, particularly in meeting fairness and diversity requirements. To address these needs, various datasets, algorithms, and evaluation methods have been developed. These algorithms are often tested with different metrics, datasets, and experimental settings, making comparisons inconsistent and challenging. Consequently, there is an urgent need for a comprehensive IR toolkit, enabling standardized assessments of fairness- and diversity-aware algorithms across IR tasks. To address these issues, we introduce an open-source standardized toolkit called FairDiverse. First, FairDiverse provides a comprehensive framework for incorporating fairness- and diversity-aware approaches, including pre-processing, in-processing, and post-processing methods, into different pipeline stages of IR. Second, FairDiverse enables the evaluation of 29 fairness, and diversity algorithms across 16 base models for two fundamental IR tasks\u2014search and recommendation\u2014facilitating the establishment of a comprehensive benchmark. Finally, FairDiverse is highly extensible, offering multiple APIs to enable IR researchers to quickly develop their own fairness- and diversity-aware IR models, and allows for fair comparisons with existing baselines. The project is open-sourced on GitHub:~ https://github.com/XuChen0427/FairDiverse.",
        "doi": "10.1145/3726302.3730280",
        "sheridan_id": "rr1631",
        "position": 95,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "6883966fd8f918a4aa29be29d2c386fb",
        "title": "AdaRPT: An Adaptive Rule Pattern Transfer Model for Fully Inductive Knowledge Graph Reasoning",
        "abstract": "Knowledge graph reasoning (KGR) is a key technology that infers missing facts in knowledge graphs (KGs). Given that real-world scenarios typically encounter unseen KGs with new entities and new relations, researchers have begun to explore fully inductive KGR methods. This setting presents greater challenges and has not been fully explored. Current methods primarily construct relation graphs based on the original KG to facilitate message passing between relations. These models have made significant progress in achieving fully inductive reasoning. However, as relation graphs focus solely on the co-occurrence patterns between relations, they often fail to capture reasoning patterns in KGs, which causes the model to struggle in effectively distinguishing between different relations and entities. This limitation severely restrict the reasoning capabilities of existing methods.In light of this, we propose the \\textbf{Ada}ptive \\textbf{R}ule \\textbf{P}attern \\textbf{T}ransfer model (AdaRPT) for KGR. It aims to leverage logical rules for each relation in the KG to learn more comprehensive and transferable knowledge representations for entities and relations. For entities, we design a non-parameter message passing model that aggregates path information from the query entity to other entities. The path information for each entity is then matched with rules to obtain the transferable feature of each entity. And for relations, we extract both reasoning and co-occurrence patterns from KGs as transferable relation features. Finally, a path-based graph neural network (GNN) is employed on the transferable features of entities and relations to perform reasoning on KGs. Extensive experimental evaluations on 43 datasets for both inductive and transductive reasoning demonstrate the effectiveness and generalization capability of AdaRPT.",
        "doi": "10.1145/3726302.3729889",
        "sheridan_id": "fp0294",
        "position": 6,
        "track_id": 1,
        "slot_id": 8
      }
    },
    {
      "paper": {
        "hashed_id": "68ce199ec2c5517597ce0a4d89620f55",
        "title": "Predicting RAG Performance for Text Completion",
        "abstract": "We address the challenge of predicting the performance of using retrieval augmented generation (RAG) in large language models (LLMs) for the task of text completion; specifically, we predict the perplexity gain attained by applying RAG. We present novelsupervised post-retrieval prediction methods that utilize the specific characteristics of the text completion setting. Our predictors substantially outperform a wide variety of prediction methods originally proposed for ad hoc document retrieval. We then show thatintegrating our post-retrieval predictors with recently proposed post-generation predictors \u2014 i.e., those analyzing the next-token distribution \u2014 is of much merit: the resultant prediction quality is statistically significantly better than that of using the post-generation predictors alone. Finally, we show that our post-retrieval predictors are as effective as post-generation predictors for selective application of RAG. This finding is of utmost importance in terms ofefficiency of selective RAG.",
        "doi": "10.1145/3726302.3730062",
        "sheridan_id": "fp0465",
        "position": 5,
        "track_id": 1,
        "slot_id": 3
      }
    },
    {
      "paper": {
        "hashed_id": "07cdfd23373b17c6b337251c22b7ea57",
        "title": "QDER: Query-Specific Document and Entity Representations for Multi-Vector Document Re-Ranking",
        "abstract": "Neural IR has advanced through two distinct paths: entity-oriented approaches leveraging knowledge graphs and multi-vector models capturing fine-grained semantics. We introduce QDER, a neural re-ranking model that unifies these approaches by integrating knowledge graph semantics into a multi-vector model.  QDER`s key innovation lies in its modeling of query-document relationships: rather than computing similarity scores on aggregated embeddings, we maintain individual token and entity representations throughout the ranking process, performing aggregation only at the final scoring stage\u2014an approach we call ``late aggregation.`` We first transform these fine-grained representations through learned attention patterns, then apply carefully chosen mathematical operations for precise matches. Experiments across five standard benchmarks show that QDER achieves significant performance gains, with improvements of 36% in nDCG@20 over the strongest baseline on TREC Robust 2004 and similar improvements on other datasets. QDER particularly excels on difficult queries, achieving an nDCG@20 of 0.70 where traditional approaches fail completely (nDCG@20 = 0.0), setting a foundation for future work in entity-aware retrieval.",
        "doi": "10.1145/3726302.3730065",
        "sheridan_id": "fp0278",
        "position": 3,
        "track_id": 1,
        "slot_id": 29
      }
    },
    {
      "paper": {
        "hashed_id": "49182f81e6a13cf5eaa496d51fea6406",
        "title": "LLM-Empowered Creator Simulation for Long-Term Evaluation of Recommender Systems Under Information Asymmetry",
        "abstract": "Maintaining the long-term sustainability of recommender systems (RS) is crucial. Traditional RS evaluation methods primarily focus on the user`s immediate feedback (e.g., click), however, they often overlook the long-term effect involved by the content creators. In the real world, content creators can strategically create and upload new items to the platform by analyzing users` feedback and preference trends. Although previous studies have attempted to model creator behaviors, they often overlook that such behaviors are under conditions of information asymmetry. This asymmetry arises because creators mainly access the user feedback on the items they produce, while the platform has access to the full spectrum of feedback data. However, existing RS simulators often fail to consider such a condition, making the long-term RS evaluation inaccurate.  To bridge this gap, we propose a Large Language Model (LLM)-empowered creator simulation agent named CreAgent. By utilizing the belief mechanism from game theory and the fast-and-slow thinking framework, we can simulate the creator`s behaviors well under information asymmetry. Furthermore, to enhance CreAgent`s simulation ability, we utilize Proximal Policy Optimization to fine-tune CreAgent. Our credibility validation experiments demonstrate that our simulation environment effectively aligns with the behaviors of real-world platforms and creators, thereby enhancing the reliability of long-term evaluations in RS. Furthermore, leveraging this simulator, we can examine whether RS algorithms, such as fairness- and diversity-aware methods, contribute to improving long-term performance for different stakeholders.",
        "doi": "10.1145/3726302.3730026",
        "sheridan_id": "fp0295",
        "position": 6,
        "track_id": 1,
        "slot_id": 25
      }
    },
    {
      "paper": {
        "hashed_id": "9fd81843ad7f202f26c1a174c7357585",
        "title": "Queries Are Not Alone: Clustering Text Embeddings for Video Search",
        "abstract": "The rapid proliferation of video content across various platforms has highlighted the urgent need for advanced video retrieval systems. Traditional methods, which primarily depend on directly matching textual queries with video metadata, often fail to bridge the semantic gap between text descriptions and the multifaceted nature of video content. This paper introduces a novel framework, the Video-Text Cluster (VTC), which enhances video retrieval by clustering text queries to capture a broader semantic scope. We propose a unique clustering mechanism that groups related queries, enabling our system to consider multiple interpretations and nuances of each query. This clustering is further refined by our innovative Sweeper module, which identifies and mitigates noise within these clusters. Additionally, we introduce the Video-Text Cluster-Attention (VTC-Att) mechanism, which dynamically adjusts focus within the clusters based on the video content, ensuring that the retrieval process emphasizes the most relevant textual features.Further experiments have demonstrated that our proposed model surpasses existing state-of-the-art models on five public datasets.",
        "doi": "10.1145/3726302.3730066",
        "sheridan_id": "fp0297",
        "position": 1,
        "track_id": 1,
        "slot_id": 11
      }
    },
    {
      "paper": {
        "hashed_id": "eddea82ad2755b24c4e168c5fc2ebd40",
        "title": "MGIPF: Multi-Granularity Interest Prediction Framework for Personalized Recommendation",
        "abstract": "Personalized recommender systems, which focus on predicting users` interests, have significantly enhanced user experiences across diverse applications. However, existing approaches implicitly model users` preferences through fitting the fine-grained labels (e.g., click labels), but often neglecting the coarse-grained interest information inherent in the inputs themselves. Relying solely on the fine-grained labels could bring negative impact on interest modeling and limit the performance, as the labels may carry inevitable noise in real-world scenarios. In addition, it is considerably demanding in terms of data for most existing approaches to effectively model users` multi-granularity interests with limited or no supporting examples, resulting in subpar performance due to the significant long-tail phenomenon. To tackle these issues, we propose a novel learning framework named the Multi-Granularity Interest Prediction Framework (MGIPF), for better modeling users` diverse interests. Unlike prior work, our key idea is to utilize both the coarse-grained and fine-grained interests for supervising the training of models. Specifically, we introduce a pseudo-labeling approach explicitly mining users` potential multi-granularity interests from the raw data, and propose coarse-grained interest prediction modules that collaborate to utilize the multi-granularity supervision signals to enhance the learning of low-frequency items. The corresponding coarse-grained losses are softly weighted, taking into account the varying confidence of potential multi-granularity preferences on positive and negative samples. Importantly, our framework is lightweight and adaptable, capable of being applied effectively to mainstream recommendation models, establishing a comprehensive end-to-end training process. Extensive experiments conducted on three publicly available datasets have demonstrated the efficacy of our approach. The code is available at https://github.com/GeWu-Lab/MGIPF.",
        "doi": "10.1145/3726302.3730033",
        "sheridan_id": "fp0309",
        "position": 2,
        "track_id": 1,
        "slot_id": 30
      }
    },
    {
      "paper": {
        "hashed_id": "06eb61b839a0cefee4967c67ccb099dc",
        "title": "Locality-Sensitive Indexing for Graph-Based Approximate Nearest Neighbor Search",
        "abstract": "The burgeoning size of modern text datasets has heightened the need for efficient text retrieval systems. For such applications, Approximate Nearest Neighbor (ANN) search algorithms, and in particular graph-based methods have long been established as the leading approach in terms of recall and search speed. However, the data and execution dependencies of vertices increase the construction workload and complicate maintenance processes for the constructed index. In this paper, we present Locality-Sensitive Indexing for Graph-Based Search (or LIGS), which utilizes independent locality-sensitive hashing algorithms to simulate a proximity graph, on which a standard graph search can be performed. We show that LIGS offers substantially faster maintenance (insertion/deletion) speeds and better conservation of graph quality compared to state-of-the-art graph-based ANN methods, demonstrating LIGS as a promising alternative for maintenance-heavy scenarios.",
        "doi": "10.1145/3726302.3730028",
        "sheridan_id": "fp0310",
        "position": 1,
        "track_id": 1,
        "slot_id": 19
      }
    },
    {
      "paper": {
        "hashed_id": "f2fc990265c712c49d51a18a32b39f0c",
        "title": "DePro: Domain Ensemble using Decoupled Prompts for Universal Cross-Domain Retrieval",
        "abstract": "This paper investigates the potential of vision-language models (VLMs) in addressing the challenges of universal cross-domain retrieval (UCDR), where queries originate from unseen domains or classes. A common approach to adapting VLMs for downstream tasks involves prompt tuning, which alleviates the computational burden of full fine-tuning. However, this approach often struggles with the domain and semantic shifts inherent in UCDR. To overcome these limitations, we propose a novel prompt decoupling strategy that separates prompts into universal domain prompts (UDPs) and class prompts (CPs). Specifically, UDPs are designed to unify features from both seen and unseen domains into a cohesive universal domain, while CPs are tailored to capture class-specific visual characteristics, enabling robust retrieval across both known and unknown classes. To ensure effective decoupling, we introduce a dedicated decoupling loss that enforces the domain-agnostic nature of CPs. Additionally, we employ a regulation loss to align features from the frozen CLIP domain with those of the universal domain by selectively integrating or excluding UDPs. This mechanism fosters a synergistic domain ensemble effect, enhancing retrieval generalization across diverse domains. Finally, we propose the domain-aware triplet-hard (DaTri) loss to mitigate overfitting by reducing the risk of class collapse. The proposed framework, referred to as Domain Ensemble using Decoupled Prompts (DePro), demonstrates state-of-the-art performance and effectively enhances the model`s generalization capacity across unseen domains and classes, as validated through extensive experiments. Code is here.",
        "doi": "10.1145/3726302.3729946",
        "sheridan_id": "fp0324",
        "position": 1,
        "track_id": 1,
        "slot_id": 5
      }
    },
    {
      "paper": {
        "hashed_id": "89f0fd5c927d466d6ec9a21b9ac34ffa",
        "title": "Social Context-Aware Community-Level Propagation Prediction",
        "abstract": "With the increasing prevalence of online communities, social networks have become pivotal platforms for information propagation. However, this rise is accompanied by issues such as the spread of misinformation and online rumors. Community Level Information Pathway Prediction (CLIPP) is proposed to effectively stop the propagation of harmful information within specific communities. While progress has been made in understanding user-level propagation, there is a significant gap in addressing the CLIPP problem at the community level, particularly with regard to social context interpretation and the cold start problem in niche communities. To bridge this gap, we propose a novel model, named Community-Level Propagation Prediction with LLM enhanced Social Context Interpretation and Community Coldstart (ComPaSC3), which integrates three primary modules. The video enhancement module leverages LLMs to enrich the interpretation of multimedia content by embedding world knowledge. The community portrait building module utilizes LLMs to generate detailed community portraits for community interpretation. To tackle the community cold start problem, the dynamic commLink module links non-popular communities to the popular ones based on their portrait similarity, and dynamically updates their relationship weights. Our experimental results demonstrate that ComPaSC3 significantly improves predictive accuracy in both popular and non-popular scenarios. Particularly in non-popular communities, our approach outperforms existing state-of-the-art methods, achieving improvements of 10.00% - 15.20% in Rec@5 and 7.31% - 12.32% in NDCG@10.",
        "doi": "10.1145/3726302.3730085",
        "sheridan_id": "fp0325",
        "position": 5,
        "track_id": 1,
        "slot_id": 37
      }
    },
    {
      "paper": {
        "hashed_id": "a666587afda6e89aec274a3657558a27",
        "title": "LUSIFER: Language Universal Space Integration for Enhanced Representation in Multilingual Text Embedding Models",
        "abstract": "Recent advancements in large language models (LLMs) based embedding models have established new state-of-the-art benchmarks for text embedding tasks, particularly in dense vector-based retrieval. However, these models predominantly focus on English, leaving multilingual embedding capabilities largely unexplored. To address this limitation, we present LUSIFER, a novel zero-shot approach that adapts LLM-based embedding models for multilingual tasks without requiring multilingual supervision. LUSIFER`s architecture combines a multilingual encoder, serving as a language-universal learner, with an LLM-based embedding model optimized for embedding-specific tasks. These components are seamlessly integrated through a minimal set of trainable parameters that act as a connector, effectively transferring the multilingual encoder`s language understanding capabilities to the specialized embedding model. Additionally, to comprehensively evaluate multilingual embedding performance, we introduce a new benchmark encompassing 5 primary embedding tasks, 123 diverse datasets, and coverage across 14 languages. Extensive experimental results demonstrate that LUSIFER significantly enhances the multilingual performance across various embedding tasks, particularly for medium and low-resource languages, without requiring explicit multilingual training data. The code and dataset for training are available at: https://github.com/hieum98/lusifer",
        "doi": "10.1145/3726302.3730029",
        "sheridan_id": "fp0326",
        "position": 4,
        "track_id": 1,
        "slot_id": 23
      }
    },
    {
      "paper": {
        "hashed_id": "b83aac23b9528732c23cc7352950e880",
        "title": "CSMF: Cascaded Selective Mask Fine-Tuning for Multi-Objective Embedding-Based Retrieval",
        "abstract": "Multi-objective embedding-based retrieval (EBR) has become increasingly critical due to the growing complexity of user behaviors and commercial objectives. While traditional approaches often suffer from data sparsity and limited information sharing between objectives, recent methods utilizing a shared network alongside dedicated sub-networks for each objective partially address these limitations. However, such methods significantly increase the model parameters, leading to an increased retrieval latency and a limited ability to model causal relationships between objectives. To address these challenges, we propose the Cascaded Selective Mask Fine-Tuning (CSMF), a novel method that enhances both retrieval efficiency and serving performance for multi-objective EBR. The CSMF framework selectively masks model parameters to free up independent learning space for each objective, leveraging the cascading relationships between objectives during the sequential fine-tuning. Without increasing network parameters or online retrieval overhead, CSMF computes a linearly weighted fusion score for multiple objective probabilities while supporting flexible adjustment of each objective`s weight across various recommendation scenarios. Experimental results on real-world datasets demonstrate the superior performance of CSMF, and online experiments validate its significant practical value.",
        "doi": "10.1145/3726302.3729939",
        "sheridan_id": "fp0327",
        "position": 5,
        "track_id": 1,
        "slot_id": 1
      }
    },
    {
      "paper": {
        "hashed_id": "6faa8040da20ef399b63a72d0e4ab575",
        "title": "Question-Answering Dense Video Events",
        "abstract": "This paper presents question-answering on dense video events, a novel task that answers and grounds dense-event questions in long videos, thus challenging MLLMs to faithfully comprehend and reason about multiple events over extended periods of time. To facilitate the study, we construct DeVE-QA -- a dataset featuring 78K questions about 26K events on 10.6K long videos. Our benchmarking shows that state-of-the-art MLLMs struggle on DeVE-QA. For improvement, we propose DeVi, a novel training-free MLLM approach that highlights a hierarchical captioning module, a temporal event memory module, and a self-consistency checking module to respectively detect, contextualize and memorize, and ground dense-events in long videos for question answering. Extensive experiments show that DeVi is superior at answering dense-event questions and grounding relevant video moments. Compared with existing MLLMs, it achieves a notable increase of 4.8% and 2.1% for G(round)QA accuracy on DeVE-QA and NExT-GQA, respectively. Data and code are available at https://github.com/QHUni/DeVE-QA.",
        "doi": "10.1145/3726302.3729945",
        "sheridan_id": "fp0329",
        "position": 2,
        "track_id": 1,
        "slot_id": 11
      }
    },
    {
      "paper": {
        "hashed_id": "2f2b265625d76a6704b08093c652fd79",
        "title": "Exploring the Escalation of Source Bias in User, Data, and Recommender System Feedback Loop",
        "abstract": "Recommender systems are essential for information access, allowing users to present their content for recommendation. With the rise of large language models (LLMs), AI-generated content (AIGC), primarily in the form of text, has become a central part of the content ecosystem. As AIGC becomes increasingly prevalent, it is important to understand how it affects the performance and dynamics of recommender systems. To this end, we construct an environment that incorporates AIGC to explore its short-term impact. The results from popular sequential recommendation models reveal that AIGC are ranked higher in the recommender system, reflecting the phenomenon of source bias. To further explore the long-term impact of AIGC, we introduce a feedback loop with realistic simulators. The results show that the model`s preference for AIGC increases as the user clicks on AIGC rises and the model trains on simulated click data. This leads to two issues: In the short term, bias toward AIGC encourages LLM-based content creation, increasing AIGC content, and causing unfair traffic distribution. From a long-term perspective, our experiments also show that when AIGC dominates the content ecosystem after a feedback loop, it can lead to a decline in recommendation performance. To address these issues, we propose a debiasing method based on L1-loss optimization to maintain long-term content ecosystem balance. In a real-world environment with AIGC generated by mainstream LLMs, our method ensures a balance between AIGC and human-generated content in the ecosystem. The code and dataset are available at https://github.com/Yuqi-Zhou/Rec_SourceBias.",
        "doi": "10.1145/3726302.3729972",
        "sheridan_id": "fp0334",
        "position": 1,
        "track_id": 1,
        "slot_id": 15
      }
    },
    {
      "paper": {
        "hashed_id": "6855456e2fe46a9d49d3d3af4f57443d",
        "title": "Towards Better Evaluating Multi-Query Sessions: A Measure Based on the Theory of Planned Behavior",
        "abstract": "To evaluate multi-query sessions, recent studies usually add a second ``session`` dimension to the query-level evaluation framework, deriving corresponding session-version evaluation metrics such as sDCG, sRBP, and sINST. However, these existing metrics do not sufficiently consider the different impacts of users` expectations of gains and costs on their behaviors such as query reformulation, nor the bounded rationality characteristic of users in expectation management. To address these issues and better explain user behavior in multi-query sessions, we design a user model based on the Theory of Planned Behavior (TPB), which links user expectations to user behaviors. Within the TPB framework, we propose sTPB, a new measure that adapts to users` expectation management modes by considering users` expectations of gains and costs. To demonstrate the effectiveness of sTPB in evaluating multi-query sessions, we compare it with existing session metrics on two publicly available user search behavior datasets. The results show that sTPB significantly outperforms other metrics in terms of both fitting user behavior and measuring user satisfaction. Additionally, we explore the differences between optimal parameters under different user characteristics and task types in session search evaluation. We find that different user characteristics and task types lead to various preferences in users` choices between continuing to examine results and reformulating queries. Our study not only validates the effectiveness of sTPB in evaluating multi-query sessions but also highlights the necessity of considering the influence of user characteristics and task types when designing metrics.",
        "doi": "10.1145/3726302.3730096",
        "sheridan_id": "fp0336",
        "position": 1,
        "track_id": 1,
        "slot_id": 25
      }
    },
    {
      "paper": {
        "hashed_id": "13f9896df61279c928f19721878fac41",
        "title": "HyperG:Hypergraph-Enhanced LLMs for Structured Knowledge",
        "abstract": "Given that substantial amounts of domain-specific knowledge are stored in structured formats, such as web data organized through HTML, Large Language Models (LLMs) are expected to fully comprehend this structured information to broaden their applications in various real-world downstream tasks. Current approaches for applying LLMs to structured data fall into two main categories: serialization-based and operation-based methods. Both approaches, whether relying on serialization or using SQL-like operations as an intermediary, encounter difficulties in fully capturing structural relationships and effectively handling sparse data. To address these unique characteristics of structured data, we propose HyperG, a hypergraph-based generation framework aimed at enhancing LLMs` ability to process structured knowledge. Specifically, HyperG first augment sparse data with contextual information, leveraging the generative power of LLMs, and incorporate a prompt-attentive hypergraph learning (PHL) network to encode both the augmented information and the intricate structural relationships within the data. To validate the effectiveness and generalization of HyperG, we conduct extensive experiments across two different downstream tasks requiring structured knowledge. Our code is publicly available at: https://github.com/s1ruihuang/HyperG.",
        "doi": "10.1145/3726302.3730002",
        "sheridan_id": "fp0346",
        "position": 7,
        "track_id": 1,
        "slot_id": 8
      }
    },
    {
      "paper": {
        "hashed_id": "41f1f19176d383480afa65d325c06ed0",
        "title": "A Learnable Fully Interacted Two-Tower Model for Pre-Ranking System",
        "abstract": "Pre-ranking plays a crucial role in large-scale recommender systemsby significantly improving the efficiency and scalability within theconstraints of providing high-quality candidate sets in real time.The two-tower model is widely used in pre-ranking systems due toa good balance between efficiency and effectiveness with decoupledarchitecture, which independently processes user and item inputsbefore calculating their interaction (e.g. dot product or similaritymeasure). However, this independence also leads to the lack ofinformation interaction between the two towers, resulting in lesseffectiveness. In this paper, a novel architecture named learnableFully Interacted Two-tower Model (FIT) is proposed, which enablesrich information interactions while ensuring inference efficiency.FIT mainly consists of two parts: Meta Query Module (MQM) andLightweight Similarity Scorer (LSS). Specifically, MQM introducesa learnable item meta matrix to achieve expressive early interactionbetween user and item features. Moreover, LSS is designed to furtherobtain effective late interaction between the user and item towers.Finally, experimental results on several public datasets show thatour proposed FIT significantly outperforms the state-of-the-artbaseline pre-ranking models.",
        "doi": "10.1145/3726302.3729881",
        "sheridan_id": "fp0371",
        "position": 3,
        "track_id": 1,
        "slot_id": 30
      }
    },
    {
      "paper": {
        "hashed_id": "9de6d14fff9806d4bcd1ef555be766cd",
        "title": "Generative Auto-Bidding with Value-Guided Explorations",
        "abstract": "Auto-bidding, with its strong capability to optimize bidding decisions within dynamic and competitive online environments, has become a pivotal strategy for advertising platforms. Existing approaches typically employ rule-based strategies or Reinforcement Learning (RL) techniques. However, rule-based strategies lack the flexibility to adapt to time-varying market conditions, and RL-based methods struggle to capture essential historical dependencies and observations within Markov Decision Process (MDP) frameworks. Furthermore, these approaches often face challenges in ensuring strategy adaptability across diverse advertising objectives. Additionally, as offline training methods are increasingly adopted to facilitate the deployment and maintenance of stable online strategies, the issues of documented behavioral patterns and behavioral collapse resulting from training on fixed offline datasets become increasingly significant.To address these limitations, this paper introduces a novel offline Generative Auto-bidding framework with Value-Guided Explorations (GAVE). GAVE accommodates various advertising objectives through a score-based Return-To-Go (RTG) module. Moreover, GAVE integrates an action exploration mechanism with an RTG-based evaluation method to explore novel actions while ensuring stability-preserving updates. A learnable value function is also designed to guide the direction of action exploration and mitigate Out-of-Distribution (OOD) problems.Experimental results on two offline datasets and real-world deployments demonstrate that GAVE outperforms state-of-the-art baselines in both offline evaluations and online A/B tests. By applying the core methods of this framework, we proudly secured first place in the NeurIPS 2024 competition, `AIGB Track: Learning Auto-Bidding Agents with Generative Models`.",
        "doi": "10.1145/3726302.3729987",
        "sheridan_id": "fp0350",
        "position": 4,
        "track_id": 1,
        "slot_id": 4
      }
    },
    {
      "paper": {
        "hashed_id": "fb7b9ffa5462084c5f4e7e85a093e6d7",
        "title": "CoDIME: A Counterfactual Approach for Dimension Importance Estimation through Click Logs",
        "abstract": "Contextual dense representation models for text marked a shift in text processing, enabling a richer semantic understanding of the text and more effective Information Retrieval. These models project pieces of text into a latent space, describing them in terms of shared latent concepts, which are not explicitly tied to the text`s content.   Previous work has shown that certain dimensions of such dense text representations can be irrelevant and detrimental to retrieval effectiveness depending on the information need specified in the query.   Higher effectiveness can be achieved by performing retrieval within a linear subspace that excludes these dimensions.   Dimension IMportance Estimators (DIMEs) are models designed to identify such harmful dimensions, refining the representations of queries and documents to retain only the useful ones.  Current DIMEs rely either on pseudo-relevance feedback, which often delivers inconsistent effectiveness, or on explicit relevance feedback, which is challenging to collect.  Inspired by counterfactual modelling, we introduce Counterfactual DIMEs (CoDIMEs), designed to leverage noisy implicit feedback to assess the importance of each dimension.  The CoDIME framework presented here approximates the relationship between a document`s click frequency and its interaction with a given query dimension through a linear model. Empirical evaluations demonstrate that CoDIME outperforms traditional pseudo-relevance feedback-based DIMEs and surpasses other unsupervised counterfactual methods that utilize implicit feedback.",
        "doi": "10.1145/3726302.3729926",
        "sheridan_id": "fp0357",
        "position": 1,
        "track_id": 1,
        "slot_id": 12
      }
    },
    {
      "paper": {
        "hashed_id": "c058f544c737782deacefa532d9add4c",
        "title": "Unveiling Knowledge Utilization Mechanisms in LLM-based Retrieval-Augmented Generation",
        "abstract": "Considering the inherent limitations of parametric knowledge in large language models (LLMs), retrieval-augmented generation (RAG) is widely employed to expand their knowledge scope. Since RAG has shown promise in knowledge-intensive tasks like open-domain question answering, its broader application to complex tasks and intelligent assistants has further advanced its utility. Despite this progress, the underlying knowledge utilization mechanisms of LLM-based RAG remain underexplored. In this paper, we present a systematic investigation of the intrinsic mechanisms by which LLMs integrate internal (parametric) and external (retrieved) knowledge in RAG scenarios. Specially, we employ knowledge stream analysis at the macroscopic level, and investigate the function of individual modules at the microscopic level. Drawing on knowledge streaming analyses, we decompose the knowledge utilization process into four distinct stages within LLM layers: knowledge refinement, knowledge elicitation, knowledge expression, and knowledge contestation. We further demonstrate that the relevance of passages guides the streaming of knowledge through these stages. At the module level, we introduce a new method, knowledge activation probability entropy (KAPE) for neuron identification associated with either internal or external knowledge. By selectively deactivating these neurons, we achieve targeted shifts in the LLM\u2019s reliance on one knowledge source over the other. Moreover, we discern complementary roles for multi-head attention and multi-layer perceptron layers during knowledge formation. These insights offer a foundation for improving interpretability and reliability in retrieval-augmented LLMs, paving the way for more robust and transparent generative solutions in knowledge-intensive domains.",
        "doi": "10.1145/3726302.3730112",
        "sheridan_id": "fp0359",
        "position": 3,
        "track_id": 1,
        "slot_id": 3
      }
    },
    {
      "paper": {
        "hashed_id": "52720e003547c70561bf5e03b95aa99f",
        "title": "RankingSHAP \u2013 Faithful Listwise Feature AttributionExplanations for Ranking Models",
        "abstract": "While SHAP (SHapley Additive exPlanations) and other feature attribution methods are commonly employed to explain model predictions, their application within information retrieval (IR), particularly for complex outputs such as ranked lists, remains limited. Existing attribution methods typically provide pointwise explanations, focusing on why a single document received a high-ranking score, rather than considering the relationships between documents in a ranked list. We present three key contributions to address this gap. First, we rigorously define listwise feature attribution for ranking models. Secondly, we introduce RankingSHAP, extending the popular SHAP framework to accommodate listwise ranking attribution, addressing a significant methodological gap in the field. Third, we propose two novel evaluation paradigms for assessing the faithfulness of attributions in learning-to-rank models, measuring the correctness and completeness of the explanation with respect to different aspects. Through experiments on standard learning-to-rank datasets, we demonstrate RankingSHAP\u2019s practical application while identifying the constraints of selection-based explanations. We further employ a simulated study with an interpretable model to showcase how listwise ranking attributions can be used to examine model decisions and conduct a qualitative evaluation of explanations. Due to the contrastive nature of the ranking task, our understanding of ranking model decisions can substantially benefit from feature attribution explanations like RankingSHAP.",
        "doi": "10.1145/3726302.3729971",
        "sheridan_id": "fp0361",
        "position": 2,
        "track_id": 1,
        "slot_id": 22
      }
    },
    {
      "paper": {
        "hashed_id": "142949df56ea8ae0be8b5306971900a4",
        "title": "Efficiency Unleashed: Inference Acceleration for LLM-based Recommender Systems with Speculative Decoding",
        "abstract": "The past few years have witnessed a growing interest in LLM-based recommender systems (RSs), although their industrial deployment remains in a preliminary stage. Most existing deployments leverage LLMs offline as feature enhancers, generating augmented knowledge for downstream tasks. However, in recommendation scenarios with numerous users and items, even offline knowledge generation with LLMs demands significant time and computational resources. This inefficiency arises from the autoregressive nature of LLMs. A promising solution is speculative decoding, a Draft-Then-Verify approach that increases the number of tokens generated per decoding step.In this work, we first identify recommendation knowledge generation as a highly fitting use case for retrieval-based speculative decoding. Then, we discern its two characteristics: (1) the vast number of items and users in RSs leads to retrieval inefficiency, and (2) RSs exhibit high diversity tolerance for LLM-generated text. Building on these insights, we introduce Lossless Acceleration via Speculative Decoding for LLM-based Recommender Systems (LASER), which features a Customized Retrieval Pool to enhance retrieval efficiency and Relaxed Verification to improve the acceptance rate of draft tokens. LASER achieves a 3-5x speedup on public datasets and saves about 67\\% of computational resources during the online A/B test on a large-scale advertising scenario with lossless downstream recommendation performance. Our code is available at https://github.com/YunjiaXi/LASER",
        "doi": "10.1145/3726302.3729961",
        "sheridan_id": "fp0376",
        "position": 1,
        "track_id": 1,
        "slot_id": 38
      }
    },
    {
      "paper": {
        "hashed_id": "d34ab169b70c9dcd35e62896010cd9ff",
        "title": "Understanding Accuracy-Fairness Trade-offs in Re-ranking through Elasticity in Economics",
        "abstract": "Fairness is an increasingly important factor in re-ranking tasks. Prior work has identified a trade-off between ranking accuracy and item fairness. However, the underlying mechanisms are still not fully understood. An analogy can be drawn between re-ranking and the dynamics of economic transactions. The accuracy-fairness trade-off parallels the coupling of the commodity tax transfer process. Fairness considerations in re-ranking, similar to a commodity tax on suppliers, ultimately translate into a cost passed on to consumers. Analogously, item-side fairness constraints result in a decline in user-side accuracy. In economics, the extent to which commodity tax on the supplier (item fairness) transfers to commodity tax on users (accuracy loss) is formalized using the notion of elasticity. The re-ranking fairness-accuracy trade-off is similarly governed by the elasticity of utility between item groups. This insight underscores the limitations of current fair re-ranking evaluations, which often rely solely on a single fairness metric, hindering comprehensive assessment of fair re-ranking algorithms.    Centered around the concept of elasticity, this work presents two significant contributions. We introduce the Elastic Fairness Curve (EF-Curve) as an evaluation framework. This framework enables a comparative analysis of algorithm performance across different elasticity levels, facilitating the selection of the most suitable approach.  Furthermore, we propose ElasticRank, a fair re-ranking algorithm that employs elasticity calculations to adjust inter-item distances within a curved space.  Experiments on three widely used ranking datasets",
        "doi": "10.1145/3726302.3730106",
        "sheridan_id": "fp0377",
        "position": 2,
        "track_id": 1,
        "slot_id": 39
      }
    },
    {
      "paper": {
        "hashed_id": "a02ffd91ece5e7efeb46db8f10a74059",
        "title": "Improving Sequential Recommenders through Counterfactual Augmentation of System Exposure",
        "abstract": "In sequential recommendation, system exposure refers to items that are exposed to the user. Typically, the user only interactions with a few of the exposed items. Although sequential recommendation has achieved great success in predicting future user interests, existing sequential recommendation methods do not fully exploit system exposure data. Most methods only model items that have been interacted with, while the large volume of exposed but non-interacted items is overlooked. Even methods that consider system exposure typically train the recommender using only the logged historical system exposure, without exploring unseen user interests. In this paper, we propose counterfactual augmentation over system exposure for sequential recommendation (CaseRec). To better model historical system exposure, CaseRec introduces reinforcement learning to account for different exposure rewards. CaseRec uses a decision transformer-based sequential model to take an exposure sequence as input and assigns different rewards according to the user feedback. To explore unseen user interests, CaseRec performs counterfactual augmentation, where exposed items are replaced with counterfactual items. Then, a transformer based user simulator is used to predict the user feedback reward for the augmented items. Augmentation, together with the user simulator, gives rise to counterfactual exposure sequences to uncover new user interests. Finally, CaseRec uses the logged exposure sequences with the counterfactual exposure sequences to train a decision transformer-based sequential model for generating recommendation. Experiments on three real-world benchmarks show the effectiveness of CaseRec. Our code is available at https://github.com/ZiqiZhao1/CaseRec.",
        "doi": "10.1145/3726302.3730005",
        "sheridan_id": "fp0379",
        "position": 6,
        "track_id": 1,
        "slot_id": 7
      }
    },
    {
      "paper": {
        "hashed_id": "00ec53c4682d36f5c4359f4ae7bd7ba1",
        "title": "Robust Fine-tuning for Retrieval Augmented Generation against Retrieval Defects",
        "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by integrating external knowledge retrieved from a knowledge base. However, its effectiveness is fundamentally constrained by the reliability of both the retriever and the knowledge base (i.e., the retrieval system). In real-world scenarios, imperfections in these components often lead to the retrieval of noisy, irrelevant, or misleading counterfactual information, ultimately undermining the trustworthiness of RAG systems. To address this challenge, we propose Robust Fine-Tuning (RbFT), a method designed to enhance the resilience of LLMs against retrieval defects through two targeted fine-tuning tasks. Experimental results demonstrate that RbFT significantly improves the robustness of RAG systems across diverse retrieval conditions, surpassing existing methods while maintaining high inference efficiency and compatibility with other robustness techniques.",
        "doi": "10.1145/3726302.3730078",
        "sheridan_id": "fp0381",
        "position": 4,
        "track_id": 1,
        "slot_id": 3
      }
    },
    {
      "paper": {
        "hashed_id": "70c639df5e30bdee440e4cdf599fec2b",
        "title": "NR4DER: Neural Re-ranking for Diversified Exercise Recommendation",
        "abstract": "With the widespread adoption of online education platforms, an increasing number of students are gaining new knowledge through Massive Open Online Courses (MOOCs). Exercise recommendation have made strides toward improving student learning outcomes. However, existing methods not only struggle with high dropout rates but also fail to match the diverse learning pace of students. They frequently face difficulties in adjusting to inactive students` learning patterns and in accommodating individualized learning paces, resulting in limited accuracy and diversity in recommendations. To tackle these challenges, we propose Neural Re-ranking for Diversified Exercise Recommendation (in short, NR4DER). NR4DER first leverages the mLSTM model to improve the effectiveness of the exercise filter module. It then employs a sequence enhancement method to enhance the representation of inactive students, accurately matches students with exercises of appropriate difficulty. Finally, it utilizes neural re-ranking to generate diverse recommendation lists based on individual students` learning histories. Extensive experimental results indicate that NR4DER significantly outperforms existing methods across multiple real-world datasets and effectively caters to the diverse learning pace of students.",
        "doi": "10.1145/3726302.3730046",
        "sheridan_id": "fp0393",
        "position": 1,
        "track_id": 1,
        "slot_id": 17
      }
    },
    {
      "paper": {
        "hashed_id": "e46de7e1bcaaced9a54f1e9d0d2f800d",
        "title": "Pre-training for Recommendation Unlearning",
        "abstract": "Modern recommender systems powered by Graph Neural Networks (GNNs) excel at modeling complex user-item interactions, yet increasingly face scenarios requiring selective forgetting of training data. Beyond user requests to remove specific interactions due to privacy concerns or preference changes, regulatory frameworks mandate recommender systems` ability to eliminate the influence of certain user data from models. This recommendation unlearning challenge presents unique difficulties as removing connections within interaction graphs creates ripple effects throughout the model, potentially impacting recommendations for numerous users. Traditional approaches suffer from significant drawbacks: fragmentation methods damage graph structure and diminish performance, while influence function techniques make assumptions that may not hold in complex GNNs, particularly with self-supervised or random architectures. To address these limitations, we propose a novel model-agnostic pre-training paradigm UnlearnRec that prepares systems for efficient unlearning operations. Our Influence Encoder takes unlearning requests together with existing model parameters and directly produces updated parameters of unlearned model with little fine-tuning, avoiding complete retraining while preserving model performance characteristics. Extensive evaluation on public benchmarks demonstrates that our method delivers exceptional unlearning effectiveness while providing more than 10x speedup compared to retraining approaches. We release our method implementation at: https://github.com/HKUDS/UnlearnRec.",
        "doi": "10.1145/3726302.3730060",
        "sheridan_id": "fp0397",
        "position": 4,
        "track_id": 1,
        "slot_id": 1
      }
    },
    {
      "paper": {
        "hashed_id": "69cb3ea317a32c4e6143e665fdb20b14",
        "title": "OBELLA: Open the Book for Evaluating Long-Form Large Language Model Answers in Open-Domain Question Answering",
        "abstract": "Reliable factuality evaluation is critical for the iterative development of open-domain question answering (ODQA) systems, especially given the rise of large language models (LLMs) and their propensity for hallucination. However, state-of-the-art (SOTA) automatic metrics, which are mostly supervised, remain notably less reliable than humans. In this paper, we find two key challenges behind this gap: (1) length distribution mismatch between lengthy LLM answers and shorter training answers used by current metrics; and (2) reference incompleteness, where current metrics often misjudge valid system answers absent from given references\u2014a challenge worsened by the diversity of LLM outputs. To address these issues, we present a new ODQA factuality evaluation dataset called OBELLA (Open-Book Evaluation for Long-form LLM Answers). OBELLA narrows the length distribution mismatch by significantly increasing the candidate answer length to align with LLM outputs. Moreover, it introduces a neutral class for plausible yet under-supported candidate answers to differentiate reference incompleteness from outright incorrectness, thus enabling flexible reevaluation by consulting external knowledge for more references. Based on OBELLA, we propose a novel metric named OBELLAM (OBELLA Metric). OBELLAM integrates a cross-attention mechanism to enhance long-form candidate answer representations and employs a dynamic closed\u2013open book evaluation strategy to tackle reference incompleteness. Our OBELLAM sets a new SOTA in aligning with human judgments across two ODQA evaluation benchmarks, marking a promising step toward more robust ODQA factuality evaluation.",
        "doi": "10.1145/3726302.3730047",
        "sheridan_id": "fp0402",
        "position": 2,
        "track_id": 1,
        "slot_id": 42
      }
    },
    {
      "paper": {
        "hashed_id": "17d63b1625c816c22647a73e1482372b",
        "title": "Triplet Contrastive Learning with Learnable Sequence Augmentation for Sequential Recommendation",
        "abstract": "The quality of augmented data directly affects the performance of contrastive learning. Low-quality augmentation offers limited benefits for model optimization. Existing contrastive learning-based sequential recommendation works primarily utilize heuristic data augmentation methods, which often exhibit excessive randomness and struggle to generate positive samples that align with users` true intentions. To address this limitation, we propose Triplet Contrastive learning with Learnable sequence Augmentation for sequential Recommendation (TCLARec). Unlike heuristic or rule-based augmentation methods, we train a learnable sequence augmentation module that can automatically leverage the self-supervised information from global context to select appropriate modification positions and augmentation operations, thereby generating positive samples that more accurately reflect user preferences. Furthermore, we design a ranking-based triplet contrastive loss to enhance the positive feedback from augmented sequence generated by the augmentation module, providing more nuanced contrastive signals for model optimization. Extensive experiments on three real-world datasets demonstrate that TCLARec outperforms state-of-the-art sequential recommendation baselines. Our in-depth analyses confirm that both the learnable augmentation and triplet contrastive learning contribute to improving recommendation accuracy. We have released the code at https://github.com/anonymityww/TCLA.",
        "doi": "10.1145/3726302.3730101",
        "sheridan_id": "fp0411",
        "position": 7,
        "track_id": 1,
        "slot_id": 7
      }
    },
    {
      "paper": {
        "hashed_id": "66808e327dc79d135ba18e051673d906",
        "title": "Meta-Guided Adaptive Weight Learner for Noisy Correspondence",
        "abstract": "Cross-modal retrieval with noisy correspondences is a critical challenge, especially when data annotations for large-scale multimodal datasets are prone to systematic corruption. To mitigate the impact of noise, many existing methods rely on small-loss sample selection to filter out clean samples. However, these methods can ineluctably result in the inclusion of false positives, which significantly degrade the performance. To tackle this issue, we propose a novel method, named the Meta Similarity Importance Assignment Network (MSIAN), to achieve robust cross-modal retrieval. MSIAN employs a meta-learning strategy to dynamically learn the importance of each sample through a two-level optimization process. With adaptively guiding the learning process, MSIAN adjusts the importance weight of each sample based on its inherent trustworthiness. Thereby, thus iterative mechanism progressively shifts the network`s focus on the most reliable data points, amplifying the impact of credible samples while diminishing the adaptive weight of noisy ones. Furthermore, MSIAN dynamically adapts the soft margin of each sample through continuously updated adaptive weights, thereby improving the robustness of the model. Extensive experiments on three widely used datasets, including Flickr30K, MS-COCO, and Conceptual Captions, demonstrate the effectiveness of our approach in improving cross-modal retrieval performance.",
        "doi": "10.1145/3726302.3730032",
        "sheridan_id": "fp0414",
        "position": 2,
        "track_id": 1,
        "slot_id": 5
      }
    },
    {
      "paper": {
        "hashed_id": "8fe0093bb30d6f8c31474bd0764e6ac0",
        "title": "Generative Meta-Learning for Zero-Shot Relation Triplet Extraction",
        "abstract": "Zero-shot Relation Triplet Extraction (ZeroRTE) aims to extract relation triplets from texts containing unseen relation types. This capability benefits various downstream information retrieval (IR) tasks. The primary challenge lies in enabling models to generalize effectively to unseen relation categories. Existing approaches typically leverage the knowledge embedded in pre-trained language models to accomplish the generalization process. However, these methods focus solely on fitting the training data during training, without specifically improving the model`s generalization performance, resulting in limited generalization capability. For this reason, we explore the integration of bi-level optimization (BLO) with pre-trained language models for learning generalized knowledge directly from the training data, and propose a generative meta-learning framework which exploits the `learning-to-learn` ability of meta-learning to boost the generalization capability of generative models. Specifically, we introduce a BLO approach that simultaneously addresses data fitting and generalization. This is achieved by constructing an upper-level loss to focus on generalization and a lower-level loss to ensure accurate data fitting. Building on this, we subsequently develop three generative meta-learning methods, each tailored to a distinct category of meta-learning. Extensive experimental results demonstrate that our framework performs well on the ZeroRTE task. Our code is available at https://github.com/leeworry/TGM-MetaLearning.",
        "doi": "10.1145/3726302.3729988",
        "sheridan_id": "fp0416",
        "position": 5,
        "track_id": 1,
        "slot_id": 23
      }
    },
    {
      "paper": {
        "hashed_id": "061412e4a03c02f9902576ec55ebbe77",
        "title": "Understanding the Effect of Opinion Polarization in Short Video Browsing",
        "abstract": "This paper explores the impact of Opinion Polarization (OP) in the increasingly prevalent context of short video browsing, a dominant medium in the contemporary digital landscape with significant influence on public opinion and social dynamics.We investigate the effects of OP on user perceptions and behaviors in short video consumption, and find that traditional user feedback signals, such as like and browsing duration, are not effective in detecting and measuring OP. Recognizing this problem, our study employs Electroencephalogram (EEG) signals as a novel, noninvasive approach to assess the neural processing of perception and cognition related to OP. Our user study reveals that OP notably affects users` sentiments, resulting in measurable changes in brain signals.Furthermore, we demonstrate the potential of using EEG signals to predict users` exposure to polarized short video content. By exploring the relationships between OP, brain signals, and user behavior, our research offers a novel perspective in understanding the dynamics of short video browsing and proposes an innovative method for quantifying the impact of OP in this context.",
        "doi": "10.1145/3726302.3730107",
        "sheridan_id": "fp0896",
        "position": 4,
        "track_id": 1,
        "slot_id": 11
      }
    },
    {
      "paper": {
        "hashed_id": "b6f0479ae87d244975439c6124592772",
        "title": "VoRec: Enhancing Recommendation with Voronoi Diagram in Hyperbolic Space",
        "abstract": "The sparse user-item interactions in recommender systems hinder the quality of embedding representations and degraded recommendation performance. Existing methods attempt to alleviate this sparsity issue by incorporating auxiliary information via item tags, but often neglect structured characteristics of embedding space, such as semantic distribution and logical relations. To this end, we propose VoRec, a novel framework that explores the spatial distribution of items and their associated tags to achieve accurate recommendations in hyperbolic space. Specifically, we employ the Voronoi diagram to partition hyperbolic space into logically related subspaces, based on tag distributions and relationships derived from existing tag taxonomies. In addition, we combine the Voronoi diagram with the Hyperbolic Graph Convolutional Network (HGCN) and exploit the respective advantages of the Poincar\u00e9 and Lorentz models in hyperbolic space. Finally, we develop two types of Voronoi site update strategies, namely active and passive ones, to optimize the Voronoi diagram for recommendation tasks. The active strategy employs contrastive learning to guide updates to the Voronoi diagram, while the passive strategy adaptively freezes parameters based on information gain to regulate the update rate. Extensive experiments on four real-world benchmark datasets demonstrate that our proposed VoRec framework delivers substantial performance improvements, achieving an average 16.35% enhancement in Recall and NDCG metrics compared to state-of-the-art baselines. The model implementation is publicly available at: https://github.com/s35lay/VoRec.",
        "doi": "10.1145/3726302.3730114",
        "sheridan_id": "fp0420",
        "position": 7,
        "track_id": 1,
        "slot_id": 2
      }
    },
    {
      "paper": {
        "hashed_id": "e0c641195b27425bb056ac56f8953d24",
        "title": "IGP: Efficient Multi-Vector Retrieval via Proximity Graph Index",
        "abstract": "Neural embedding models are extensively employed in retrieval applications, including passage retrieval, question answering, and web search. In particular, multi-vector models (e.g., ColBERTv2), which represent a document as multiple embedding vectors, have been demonstrated to achieve superior retrieval quality.Nevertheless, these models incur significant overhead at the retrieval time due to the massive amount of embedding vectors.Several promising proposals (e.g., PLAID, DESSERT, EMVB, and MUVERA) have been made to optimize the query latency. To yield high recall, these methods need to generate a considerable amount (e.g., ten thousands) of document candidates, rendering both the candidate generation phase and the refinement phase inefficient. In this paper, we propose a high-quality candidate generation technique that produces only hundreds of candidates yet achieves high recall. Specifically, we develop an incremental next-similar retrieval technique for a proximity graph index in order to facilitate high-quality candidate generation.Our experiments on real datasets show that our proposed method IGP achieves 2x-3x query throughput compared to existing methods at the same accuracy level.",
        "doi": "10.1145/3726302.3730004",
        "sheridan_id": "fp0421",
        "position": 7,
        "track_id": 1,
        "slot_id": 33
      }
    },
    {
      "paper": {
        "hashed_id": "8b16ebc056e613024c057be590b542eb",
        "title": "AV-NAS: Audio-Visual Multi-Level Semantic Neural Architecture Search for Video Hashing",
        "abstract": "Existing video hashing techniques for large-scale video retrieval often overlook inherent audio signals, which can potentially compromise retrieval performance. Incorporating both visual and audio signals, however, complicates neural architecture design, rendering the manual crafting of joint audio-visual neural network models challenging. To address this issue, we propose AV-NAS, a method that leverages data-driven Neural Architecture Search (NAS) within a tailored audio-visual network space to automatically discover the optimal video hashing network. Our approach offers: (1) a versatile multi-level semantic architecture based on audio-visual signals, defining a mixed search space encompassing diverse network modules such as MLP, CNN, Transformer, and Mamba, as well as operations like Add, Hadamard, SiLU, LayerNorm, and Skip; (2) a differentiable relaxation of the combinatorial search problem, converting it into a unified differentiable optimization problem which we tackle through our ``coarse search-pruning-finetuning`` strategy. Our experiments on large-scale video datasets show that AV-NAS can discover architectures distinct from expert designs and lead to substantial performance improvements over current state-of-the-art methods including the recently emerged AVHash.",
        "doi": "10.1145/3726302.3729899",
        "sheridan_id": "fp0569",
        "position": 3,
        "track_id": 1,
        "slot_id": 11
      }
    },
    {
      "paper": {
        "hashed_id": "18997733ec258a9fcaf239cc55d53363",
        "title": "Collaboration and Controversy Among Experts: Rumor Early Detection by Tuning a Comment Generator",
        "abstract": "Over the past decade, social media platforms have been key in spreading rumors, leading to significant negative impacts. To counter this, the community has developed various Rumor Detection (RD) algorithms to automatically identify them using user comments as evidence. However, these RD methods often fail in the early stages of rumor propagation when only limited user comments are available, leading the community to focus on a more challenging topic named Rumor Early Detection (RED). Typically, existing RED methods learn from limited semantics in early comments. However, our preliminary experiment reveals that the RED models always perform best when the number of training and test comments is consistent and extensive. This inspires us to address the RED issue by generating more human-like comments to support this hypothesis. To implement this idea, we tune a comment generator by simulating expert collaboration and controversy and propose a new RED framework named CAMERED. Specifically, we integrate a mixture-of-expert structure into a generative language model and present a novel routing network for expert collaboration. Additionally, we synthesize a knowledgeable dataset and design an adversarial learning strategy to align the style of generated comments with real-world comments. We further integrate generated and original comments with a mutual controversy fusion module. Experimental results show that CAMERED outperforms state-of-the-art RED baseline models and generation methods, demonstrating its effectiveness.",
        "doi": "10.1145/3726302.3729928",
        "sheridan_id": "fp0427",
        "position": 4,
        "track_id": 1,
        "slot_id": 31
      }
    },
    {
      "paper": {
        "hashed_id": "2421fcb1263b9530df88f7f002e78ea5",
        "title": "General Neural Embedding for Sequence Distance Approximation",
        "abstract": "Sequence distance computation is a critical and fundamental task in many fields, such as bioinformatics, and time series analysis. Traditional functions for computing the distance between sequences are often based on dynamic programming to find a globally optimal alignment, which has quadratic complexity and is difficult to parallelize, thus limiting their application in large-scale datasets with long sequences. To solve this problem, various fields have designed some specialized models to approximate these distance functions inspired by deep representation learning, i.e., projecting the sequence into a geometric embedding space through an embedding function, so that the distance between sequences can be approximated by the distance in the high-dimensional embedding space, thereby reducing the quadratic complexity to linear.  However, we note that even though the element types in sequence and distance functions are different across various fields, the core problem that needs to be solved remains the same. In this paper, we attempt to unify the sequence distance computation approximation from various fields and propose GnesDA. Specifically, we first unify the input representation of sequences in which the element type is the symbol and numeric values. We then encode the sequence using a convolutional block and a Transformer block sequentially, which can effectively capture local patterns and long dependencies respectively. Extensive experiments on four distance functions as well as four large-scale real-world datasets demonstrate that GnesDA achieves state-of-the-art in terms of both versatility and effectiveness. For the task of similarity retrieval, GnesDA can improve the edit distance, NW distance, DTW, and EDR by an average of 10.55\\%, 6.67\\%, 4.51\\%, and 12.00\\% on all metrics.",
        "doi": "10.1145/3726302.3729985",
        "sheridan_id": "fp0436",
        "position": 4,
        "track_id": 1,
        "slot_id": 24
      }
    },
    {
      "paper": {
        "hashed_id": "a8abb4bb284b5b27aa7cb790dc20f80b",
        "title": "Stitching Inner Product and Euclidean Metrics for Topology-aware Maximum Inner Product Search",
        "abstract": "Maximum Inner Product Search (MIPS) is a fundamental challenge in machine learning and information retrieval, particularly in high-dimensional data applications. Existing approaches to MIPS either rely solely on Inner Product (IP) similarity, which faces issues with local optima and redundant computations, or reduce the MIPS problem to the Nearest Neighbor Search under the Euclidean metric via space projection, leading to topology destruction and information loss. Despite the divergence of the two paradigms, we argue that there is no inherent binary opposition between IP and Euclidean metrics. By stitching IP and Euclidean in the design of indexing and search algorithms, we can significantly enhance MIPS performance. Specifically, this paper explores the theoretical and empirical connections between these two metrics from the MIPS perspective. Our investigation, grounded in graph-based search, reveals that different indexing and search strategies offer distinct advantages for MIPS, depending on the underlying data topology. Building on these insights, we introduce a novel graph-based index called Metric-Amphibious Graph (MAG) and a corresponding search algorithm, Adaptive Navigation with Metric Switch (ANMS). To facilitate parameter tuning for optimal performance, we identify three statistical indicators that capture essential data topology properties and correlate strongly with parameter tuning. Extensive experiments on 12 real-world datasets demonstrate that MAG outperforms existing state-of-the-art methods, achieving up to 4x search speedup while maintaining adaptability and scalability.",
        "doi": "10.1145/3726302.3730088",
        "sheridan_id": "fp0440",
        "position": 2,
        "track_id": 1,
        "slot_id": 12
      }
    },
    {
      "paper": {
        "hashed_id": "e44fea3bec53bcea3b7513ccef5857ac",
        "title": "Modeling Social Behavior in Collaborative Filtering",
        "abstract": "Nowadays, many online services use recommendation systems to provide personalized item recommendations to users. Collaborative filtering is the major paradigm in recommendation systems. Based on user-item interaction data, collaborative filtering recommends items to a user based on other similar users. The problem of interest disentanglement in recommendation now has attracted the attention of many researchers. Several works have proposed methods to disentangle conformity from user private interest, by assuming that conformity is correlated to item popularity. However, such modeling is simplistic and overlooks many possibilities between user public and private interest, and the item popularity. For example, a user can privately like a popular movie or buy a niche music album due to the stimulation of the social environment. In this paper, we propose a more comprehensive social behavior model that describes fine-grained relationships between user interest and item popularity. Our model does not use explicit user relationship data. Instead, we extract social behavior patterns directly from user-item interaction data. We also make our model into a recommendation framework called Disentangled Social Consumer Preference (DSCP), which can be integrated into existing recommendation models such as BPRMF. Our extensive experiments with four datasets from different services show that our model can outperform state-of-the-art baseline models. We achieve better recommendation accuracy in both the usual random test and the intervened test that shows debiasing effect.",
        "doi": "10.1145/3726302.3730039",
        "sheridan_id": "fp0454",
        "position": 1,
        "track_id": 1,
        "slot_id": 37
      }
    },
    {
      "paper": {
        "hashed_id": "98b297950041a42470269d56260243a1",
        "title": "On the Scaling of Robustness and Effectiveness in Dense Retrieval",
        "abstract": "Robustness and Effectiveness are critical aspects of developing dense retrieval models for real-world applications. It is known that there is a trade-off between the two. Recent work has addressed scaling laws of effectiveness in dense retrieval, revealing a power-law relationship between effectiveness and the size of models and data. Does robustness follow scaling laws too? If so, can scaling improve both robustness and effectiveness together, or do they remain locked in a trade-off? To answer these questions, we conduct a comprehensive experimental study. We find that: (i) Robustness, including out-of-distribution and adversarial robustness, also follows a scaling law. (ii) Robustness and effectiveness exhibit different scaling patterns, leading to significant resource costs when jointly improving both. Given these findings, we shift to the third factor that affects model performance, namely the optimization strategy, beyond the model size and data size. We find that: (i) By fitting different optimization strategies, the joint performance of robustness and effectiveness traces out a Pareto frontier. (ii) When the optimization strategy strays from Pareto efficiency, the joint performance scales in a sub-optimal direction. (iii) By adjusting the optimization weights to fit the Pareto efficiency, we can achieve Pareto training, where the scaling of joint performance becomes most efficient. Even without requiring additional resources, Pareto training is comparable to the performance of scaling resources several times under optimization strategies that overly prioritize either robustness or effectiveness. Finally, we demonstrate that our findings can help deploy dense retrieval models in real-world applications that scale efficiently and are balanced for robustness and effectiveness.",
        "doi": "10.1145/3726302.3730049",
        "sheridan_id": "fp0460",
        "position": 3,
        "track_id": 1,
        "slot_id": 12
      }
    },
    {
      "paper": {
        "hashed_id": "cfee398643cbc3dc5eefc89334cacdc1",
        "title": "FIM: Frequency-Aware Multi-View Interest Modeling for Local-Life Service Recommendation",
        "abstract": "People`s daily lives involve numerous periodic behaviors, such as eating and traveling. Local-life platforms cater to these recurring needs by providing essential services tied to daily routines. Therefore, users` periodic intentions are reflected in their interactions with the platforms. There are two main challenges in modeling users` periodic behaviors in the local-life service recommendation systems: 1) the diverse demands of users exhibit varying periodicities, which are difficult to distinguish as they are mixed in the behavior sequences; 2) the periodic behaviors of users are subject to dynamic changes due to factors such as holidays and promotional events. Existing methods struggle to distinguish the periodicities of diverse demands and overlook the importance of dynamically capturing changes in users` periodic behaviors. To this end, we employ a Frequency-Aware Multi-View Interest Modeling framework (FIM). Specifically, we propose a multi-view search strategy that decomposes users` demands from different perspectives to separate their various periodic intentions. This allows the model to comprehensively extract their periodic features than category-searched-only methods. Moreover, we propose a frequency-domain perception and evolution module. This module uses the Fourier Transform to convert users` temporal behaviors into the frequency domain, enabling the model to dynamically perceive their periodic features. Extensive offline experiments demonstrate that FIM achieves significant improvements on public and industrial datasets, showing its capability to effectively model users` periodic intentions. Furthermore, the model has been deployed on the Kuaishou local-life service platform. Through online A/B experiments, the transaction volume has been significantly improved.",
        "doi": "10.1145/3726302.3729978",
        "sheridan_id": "fp0478",
        "position": 2,
        "track_id": 1,
        "slot_id": 17
      }
    },
    {
      "paper": {
        "hashed_id": "d4c2e4a3297fe25a71d030b67eb83bfc",
        "title": "BotBR: Social Bot Detection with Balanced Feature Fusion and Reliability-Enhanced Graph Learning",
        "abstract": "The rise of social bots poses a significant threat to online platforms, making their detection an urgent priority. Recent advancements in Graph Neural Networks (GNNs) have significantly improved bot detection by leveraging the rich relational data within social networks. However, existing approaches face two key challenges: imbalanced feature fusion across different modalities and edge heterophily, which limit their effectiveness. To address these issues, we propose BotBR, a novel bot detection framework. BotBR tackles feature imbalance by employing decision trees to extract behavioral patterns from user-related numerical features and utilizes an attention mechanism to seamlessly integrate multi-modal feature embeddings. To mitigate edge heterophily, BotBR incorporates an edge detector to differentiate between high- and low-reliability edges, optimizing the utilization of structural graph information. Furthermore, a homophily-based graph is introduced for consistency contrastive learning, enhancing the model`s robustness. Experimental results on real-world bot detection benchmark datasets demonstrate that BotBR achieves state-of-the-art performance while maintaining efficiency comparable to classical methods.",
        "doi": "10.1145/3726302.3729908",
        "sheridan_id": "fp0728",
        "position": 3,
        "track_id": 1,
        "slot_id": 22
      }
    },
    {
      "paper": {
        "hashed_id": "e1e32e235eee1f970470a3a6658dfdd5",
        "title": "Disentangling and Generating Modalities for Recommendation in Missing Modality Scenarios",
        "abstract": "Multi-modal recommender systems (MRSs) have achieved notable success in improving personalization by leveraging diverse modalities such as images, text, and audio. However, two key challenges remain insufficiently addressed: (1) Insufficient consideration of missing modality scenarios and (2) the overlooking of unique characteristics of modality features. These challenges result in significant performance degradation in realistic situations where modalities are missing. To address these issues, we propose Disentangling and Generating Modality Recommender (DGMRec), a novel framework tailored for missing modality scenarios. DGMRec disentangles modality features into general and specific modality features from an information-based perspective, enabling richer representations for recommendation. Building on this, it generates missing modality features by integrating aligned features from other modalities and leveraging user modality preferences. Extensive experiments show that DGMRec consistently outperforms state-of-the-art MRSs in challenging scenarios, including missing modalities and new item settings as well as diverse missing ratios and varying levels of missing modalities. Moreover, DGMRec`s generation-based approach enables cross-modal retrieval, a task inapplicable for existing MRSs, highlighting its adaptability and potential for real-world applications.  Our code is available at https://github.com/ptkjw1997/DGMRec.",
        "doi": "10.1145/3726302.3729953",
        "sheridan_id": "fp0483",
        "position": 1,
        "track_id": 1,
        "slot_id": 34
      }
    },
    {
      "paper": {
        "hashed_id": "46922a0880a8f11f8f69cbb52b1396be",
        "title": "WebANNS: Fast and Efficient Approximate Nearest Neighbor Search in Web Browsers",
        "abstract": "Approximate nearest neighbor search (ANNS) has become vital to modern AI infrastructure, particularly in retrieval-augmented generation (RAG) applications. Numerous in-browser ANNS engines have emerged to seamlessly integrate with popular LLM-based web applications, while addressing privacy protection and challenges of heterogeneous device deployments.However, web browsers present unique challenges for ANNS, including computational limitations, external storage access issues, and memory utilization constraints, which state-of-the-art (SOTA) solutions fail to address comprehensively.We propose WebANNS, a novel ANNS engine specifically designed for web browsers. WebANNS leverages WebAssembly to overcome computational bottlenecks, designs a lazy loading strategy to optimize data retrieval from external storage, and applies a heuristic approach to reduce memory usage.Experiments show that WebANNS is fast and memory efficient, achieving up to $743.8\\times$ improvement in 99th percentile query latency over the SOTA engine, while reducing memory usage by up to 39\\%.Note that WebANNS decreases query time from 10 seconds to the 10-millisecond range in browsers, making in-browser ANNS practical with user-acceptable latency.",
        "doi": "10.1145/3726302.3730115",
        "sheridan_id": "fp0582",
        "position": 1,
        "track_id": 1,
        "slot_id": 33
      }
    },
    {
      "paper": {
        "hashed_id": "c3c59e5f8b3e9753913f4d435b53c308",
        "title": "FedCIA: Federated Collaborative Information Aggregation for Privacy-Preserving Recommendation",
        "abstract": "Recommendation algorithms rely on user historical interactions to deliver personalized suggestions, which raises significant privacy concerns. Federated recommendation algorithms tackle this issue by combining local model training with server-side model aggregation, where most existing algorithms use a uniform weighted summation to aggregate item embeddings from different client models. This approach has three major limitations: 1) information loss during aggregation, 2) failure to retain personalized local features, and 3) incompatibility with parameter-free recommendation algorithms. To address these limitations, we first review the development of recommendation algorithms and recognize that their core function is to share collaborative information, specifically the global relationship between users and items. With this understanding, we propose a novel aggregation paradigm named collaborative information aggregation, which focuses on sharing collaborative information rather than item parameters. Based on this new paradigm, we introduce the federated collaborative information aggregation (FedCIA) method for privacy-preserving recommendation. This method requires each client to upload item similarity matrices for aggregation, which allows clients to align their local models without constraining embeddings to a unified vector space. As a result, it mitigates information loss caused by direct summation, preserves the personalized embedding distributions of individual clients, and supports the aggregation of parameter-free models. Theoretical analysis and experimental results on real-world datasets demonstrate the superior performance of FedCIA compared with the state-of-the-art federated recommendation algorithms. Code is available at https://github.com/Mingzhe-Han/FedCIA.",
        "doi": "10.1145/3726302.3729977",
        "sheridan_id": "fp0488",
        "position": 2,
        "track_id": 1,
        "slot_id": 15
      }
    },
    {
      "paper": {
        "hashed_id": "55a7cf9c71f1c9c495413f934dd1a158",
        "title": "Dynamic Time-aware Continual User Representation Learning",
        "abstract": "Traditional user modeling (UM) approaches have primarily focused on designing models for a single specific task, but they face limitations in generalization and adaptability across various tasks. Recognizing these challenges, recent studies have shifted towards continual learning (CL)-based universal user representation learning aiming to develop a single model capable of handling multiple tasks. Despite advancements, existing methods are in fact evaluated under an unrealistic scenario that does not consider the passage of time as tasks progress, which overlooks newly emerged items that may change the item distribution of previous tasks.In this paper, we introduce a practical evaluation scenario on which CL-based universal user representation learning approaches should be evaluated, which takes into account the passage of time as tasks progress. Then, we propose a novel framework \\textsf{\\textbf{D}}ynam\\textsf{\\textbf{I}}c \\textsf{\\textbf{T}}ime-aware con\\textsf{\\textbf{T}}inual user representati\\textsf{\\textbf{O}}n learner, named \\proposed, designed to alleviate catastrophic forgetting despite continuous shifts in item distribution, while also allowing the knowledge acquired from previous tasks to adapt to the current shifted item distribution.Through our extensive experiments, we demonstrate the superiority of~\\proposed~over state-of-the-art methods under a practical evaluation scenario. Our source code is available at \\url{https://github.com/seungyoon-Choi/DITTO_official}.",
        "doi": "10.1145/3726302.3729959",
        "sheridan_id": "fp0492",
        "position": 1,
        "track_id": 1,
        "slot_id": 20
      }
    },
    {
      "paper": {
        "hashed_id": "3cf166c6b73f030b4f67eeaeba301103",
        "title": "BALI: Enhancing Biomedical Language Representations through Knowledge Graph and Language Model Alignment",
        "abstract": "In recent years, there has been substantial progress in using pretrained Language Models (LMs) on a range of tasks aimed at improving the understanding of biomedical texts. Nonetheless, existing biomedical LLMs show limited comprehension of complex, domain-specific concept structures and the factual information encoded in biomedical Knowledge Graphs (KGs). In this work, we propose BALI (Biomedical Knowledge Graph and Language Model Ali gnment), a novel joint LM and KG pre-training method that augments an LM with external knowledge by the simultaneous learning of a dedicated KG encoder and aligning the representations of both the LM and the graph. For a given textual sequence, we link biomedical concept mentions to the Unified Medical Language System (UMLS) KG and utilize local KG subgraphs as cross-modal positive samples for these mentions. Our empirical findings indicate that implementing our method on several leading biomedical LMs, such as PubMedBERT and BioLinkBERT, improves their performance on a range of language understanding tasks and the quality of entity representations, even with minimal pre-training on a small alignment dataset sourced from PubMed scientific abstracts.",
        "doi": "10.1145/3726302.3729901",
        "sheridan_id": "fp0499",
        "position": 1,
        "track_id": 1,
        "slot_id": 8
      }
    },
    {
      "paper": {
        "hashed_id": "d5cfead94f5350c12c322b5b664544c1",
        "title": "COHESION: Composite Graph Convolutional Network with Dual-Stage Fusion for Multimodal Recommendation",
        "abstract": "Recent works in multimodal recommendations, which leverage diverse modal information to address data sparsity and enhance recommendation accuracy, have garnered considerable interest. Two key processes in multimodal recommendations are modality fusion and representation learning. Previous approaches in modality fusion often employ simplistic attentive or pre-defined strategies at early or late stages, failing to effectively handle irrelevant information among modalities. In representation learning, prior research has constructed heterogeneous and homogeneous graph structures encapsulating user-item, user-user, and item-item relationships to better capture user interests and item profiles. Modality fusion and representation learning were considered as two independent processes in previous work. This paper reveals that these two processes are complementary and can support each other. Specifically, powerful representation learning enhances modality fusion, while effective fusion improves representation quality. Stemming from these two processes, we introduce a COmposite grapH convolutional nEtwork with dual-stage fuSION for the multimodal recommendation, named COHESION. Specifically, it introduces a dual-stage fusion strategy to reduce the impact of irrelevant information, refining all modalities using behavior modality in the early stage and fusing their representations at the late stage. It also proposes a composite graph convolutional network that utilizes user-item, user-user, and item-item graphs to extract heterogeneous and homogeneous latent relationships within users and items. Besides, it introduces a novel adaptive optimization to ensure balanced and reasonable representations across modalities. Extensive experiments on three public datasets demonstrate the significant superiority of COHESION over various competitive baselines.",
        "doi": "10.1145/3726302.3729927",
        "sheridan_id": "fp0730",
        "position": 2,
        "track_id": 1,
        "slot_id": 34
      }
    },
    {
      "paper": {
        "hashed_id": "8d34201a5b85900908db6cae92723617",
        "title": "Embracing Plasticity: Balancing Stability and Plasticity in Continual Recommender Systems",
        "abstract": "In the era of big data and AI, recommender systems must adapt to evolving user preferences and new users/items to maintain high-quality recommendations. Fine-tuning, which updates model parameters using only new data, offers an efficient alternative to full retraining but struggles to balance stability (retaining past knowledge) and plasticity (adapting to new knowledge). While existing methods prioritize stability to address catastrophic forgetting, we argue that plasticity must also be explicitly strengthened, especially for users with rapidly changing preferences. In this work, we propose PlastIcity and StAbility balancing continual recommender systems (PISA), a novel framework that adaptively balances stability and plasticity based on user preference shifts. PISA quantifies preference shifts as changes in user distances to item clusters, and then guides user embeddings by prioritizing stability for stable users and plasticity for dynamic users. To achieve this, PISA leverages backward knowledge from the previous model and forward knowledge from fine-tuning on current data. During training, PISA maximizes mutual information between user-specific parameters and the relevant reference knowledge. Theoretically, we show thatenhancing plasticity mitigates distribution shifts more effectively than fine-tuning alone. Empirically, extensive experiments on three real-world datasets validate PISA\u2019s superiority over existing methods and highlight the contributions of its components.",
        "doi": "10.1145/3726302.3729964",
        "sheridan_id": "fp0548",
        "position": 1,
        "track_id": 1,
        "slot_id": 1
      }
    },
    {
      "paper": {
        "hashed_id": "5b69b9cb83065d403869739ae7f0995e",
        "title": "Review-driven Personalized Preference Reasoning with Large Language Models for Recommendation",
        "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated exceptional performance across a wide range of tasks, generating significant interest in their application to recommendation systems. However, existing methods have not fully harnessed the potential of LLMs, often constrained by limited input information or failing to fully utilize their advanced reasoning capabilities. To address these limitations, we introduce EXP3RT, a novel LLM-based recommender designed to leverage rich preference information contained in user and item reviews.EXP3RT is basically fine-tuned through distillation from a teacher LLM to perform three key steps in order: (1) preference extraction, (2) profile construction, and (3) textual reasoning for rating prediction. EXP3RT first extracts and encapsulates essential subjective preferences from raw reviews, next aggregates and summarizes them according to specific criteria to create user and item profiles. It then generates detailed step-by-step reasoning followed by predicted rating, i.e., reasoning-enhanced rating prediction, by considering both subjective and objective information from user/item profiles and item descriptions. This personalized preference reasoning from EXP3RT enhances rating prediction accuracy and also provides faithful and reasonable explanations for recommendation. Extensive experiments show that EXP3RT outperforms existing methods on both rating prediction and candidate item reranking for top-k recommendation, while significantly enhancing the explainability of recommendation systems.",
        "doi": "10.1145/3726302.3730055",
        "sheridan_id": "fp0501",
        "position": 3,
        "track_id": 1,
        "slot_id": 15
      }
    },
    {
      "paper": {
        "hashed_id": "a760880003e7ddedfef56acb3b09697f",
        "title": "DARLR: Dual-Agent Offline Reinforcement Learning for Recommender Systems with Dynamic Reward",
        "abstract": "Model-based offline reinforcement learning (RL) has emerged as a promising approach for recommender systems, enabling effective policy learning by interacting with frozen world models. However, the reward functions in these world models, trained on sparse offline logs, often suffer from inaccuracies. Specifically, existing methods face two major limitations in addressing this challenge: (1) deterministic use of reward functions as static look-up tables, which propagates inaccuracies during policy learning, and (2) static uncertainty designs that fail to effectively capture decision risks and mitigate the impact of these inaccuracies. In this work, a dual-agent framework, DARLR, is proposed to dynamically update world models to enhance recommendation policies. To achieve this, a \\textbf{\\textit{selector}} is introduced to identify reference users by balancing similarity and diversity so that the \\textbf{\\textit{recommender}} can aggregate information from these users and iteratively refine reward estimations for dynamic reward shaping. Further, the statistical features of the selected users guide the dynamic adaptation of an uncertainty penalty to better align with evolving recommendation requirements. Extensive experiments on four benchmark datasets demonstrate the superior performance of DARLR, validating its effectiveness. The code is available at this address.",
        "doi": "10.1145/3726302.3729942",
        "sheridan_id": "fp0511",
        "position": 4,
        "track_id": 1,
        "slot_id": 30
      }
    },
    {
      "paper": {
        "hashed_id": "10a7cdd970fe135cf4f7bb55c0e3b59f",
        "title": "Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models",
        "abstract": "When deciding to read an article or incorporate it into their research, scholars often seek to quickly identify and understand its main ideas. In this paper, we aim to extract these key concepts and contributions from scientific articles in the form of Question and Answer (QA) pairs. We propose two distinct approaches for generating QAs. The first approach involves selecting salient paragraphs, using a Large Language Model (LLM) to generate questions, ranking these questions by the likelihood of obtaining meaningful answers, and subsequently generating answers. This method relies exclusively on the content of the articles. However, assessing an article`s novelty typically requires comparison with the existing literature. Therefore, our second approach leverages a Knowledge Graph (KG) for QA generation. We construct a KG by fine-tuning an Entity Relationship (ER) extraction model on scientific articles and using it to build the graph. We then employ a salient triplet extraction method to select the most pertinent ERs per article, utilizing metrics such as the centrality of entities based on a triplet TF-IDF-like measure. This measure assesses the saliency of a triplet based on its importance within the article compared to its prevalence in the literature. For evaluation, we generate QAs using both approaches and have them assessed by Subject Matter Experts (SMEs) through a set of predefined metrics to evaluate the quality of both questions and answers. Our evaluations demonstrate that the KG-based approach effectively captures the main ideas discussed in the articles. Furthermore, our findings indicate that fine-tuning the ER extraction model on our scientific corpus is crucial for extracting high-quality triplets from such documents.",
        "doi": "10.1145/3726302.3730068",
        "sheridan_id": "fp0512",
        "position": 3,
        "track_id": 1,
        "slot_id": 42
      }
    },
    {
      "paper": {
        "hashed_id": "0d7de1aca9299fe63f3e0041f02638a3",
        "title": "Towards Lossless Token Pruning in Late-Interaction Retrieval Models",
        "abstract": "Late interaction neural IR models like ColBERT offer a competitive effectiveness-efficiency trade-off across many benchmarks. However, they require a huge memory space to store the contextual representation for all the document tokens. Some works have proposed using either heuristics or statistical-based techniques to prune tokens from each document. This however doesn`t guarantee that the removed tokens have no impact on the retrieval score. Our work uses a principled approach to define how to prune tokens without impacting the score between a document and a query. We introduce three regularization losses, that induce a solution with high pruning ratios, as well as two pruning strategies. We study them experimentally (in and out-domain), showing that we can preserve ColBERT`s performance while using only 30% of the tokens.",
        "doi": "10.1145/3726302.3730100",
        "sheridan_id": "fp0674",
        "position": 8,
        "track_id": 1,
        "slot_id": 12
      }
    },
    {
      "paper": {
        "hashed_id": "6150ccc6069bea6b5716254057a194ef",
        "title": "Tip of the Tongue Query Elicitation for Simulated Evaluation",
        "abstract": "Tip-of-the-tongue (TOT) search occurs when a user struggles to recall a specific identifier, such as a document title. While common, existing search systems often fail to effectively support TOT scenarios. Research on TOT retrieval is further constrained by the challenge of collecting queries, as current approaches rely heavily on community question-answering (CQA) websites, leading to labor-intensive evaluation and domain bias. To overcome these limitations, we introduce two methods for eliciting TOT queries\u2014leveraging large language models (LLMs) and human participants\u2014to facilitate simulated evaluations of TOT retrieval systems. Our LLM-based TOT user simulator generates synthetic TOT queries at scale, achieving high correlations with how CQA-based TOT queries rank TOT retrieval systems when tested in the Movie domain. Additionally, these synthetic queries exhibit high linguistic similarity to CQA-derived queries. For human-elicited queries, we developed an interface that uses visual stimuli to place participants in a TOT state, enabling the collection of natural queries. In the Movie domain, system rank correlation and linguistic similarity analyses confirm that human-elicited queries are both effective and closely resemble CQA-based queries. These approaches reduce reliance on CQA-based data collection while expanding coverage to underrepresented domains, such as Landmark and Person. LLM-elicited queries for the Movie, Landmark, and Person domains have been released as test queries in the TREC 2024 TOT track, with human-elicited queries scheduled for inclusion in the TREC 2025 TOT track. Additionally, we provide source code for synthetic query generation and the human query collection interface, along with curated visual stimuli used for eliciting TOT queries.",
        "doi": "10.1145/3726302.3730335",
        "sheridan_id": "rr2276",
        "position": 106,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "69421f032498c97020180038fddb8e24",
        "title": "Reasoning and Retrieval for Complex Semi-structured Tables via Reinforced Relational Data Transformation",
        "abstract": "We introduce TabFormer, a framework that normalizes diverse semi-structured tables into relational data via large language models to facilitate various table retrieval and reasoning tasks. Our approach employs a chain-of-thought methodology, transforming one or multiple tables through a sequence of soft operations. Compared to existing operators that are sensitive and brittle to human-induced artifacts in real-world tables, soft operators are designed with greater flexibility to accommodate diverse formatting variations.  To address the lack of ground-truth labels for table transformation, we propose a reinforced fine-tuning strategy that sequentially and jointly optimizes table transformation and symbolic reasoning within a single LLM call. This process is guided by two novel reward functions without requiring human annotations on table transformation: (1) relational normalization quality and (2) symbolic reasoning accuracy.  TabFormer is a scalable, one-time framework that leverages LLMs to transform one ore multiple tables in a single inference step, thereby enhancing both retrieval and reasoning for a wide range of tabular data tasks. Experimental evaluations on datasets such as WTQ, HiTab, MultiHiertt, and TabFact demonstrate significant gains in accuracy\u2014improvements ranging from 4% to 17%\u2014when applied to state-of-the-art methods, including GPT-4-based E5, Chain-of-Table, TableLlama, and others.",
        "doi": "10.1145/3726302.3730071",
        "sheridan_id": "fp0525",
        "position": 6,
        "track_id": 1,
        "slot_id": 23
      }
    },
    {
      "paper": {
        "hashed_id": "85422afb467e9456013a2a51d4dff702",
        "title": "GlFoMR: A Glance-then-Focus Multimodal Reasoning Framework for Diagram Question Answering",
        "abstract": "Diagram question answering (DQA) is a challenging task that requires models to combine with domain-specific knowledge and reason over the diagrams to answer questions. Multimodal Large Language Models (MLLMs) have recently made notable strides in combining textual and visual information, emerging as a promising solution for addressing the DQA task. However, they still encounter challenges in deliberate multimodal reasoning over the fine-grained visual details of content-rich and knowledge-grounded diagrams. The tight interweaving of visual and textual reasoning for MLLMs is also susceptible to hallucinations. To overcome these limitations, we propose a \\textbf{Gl}ance-then-\\textbf{Fo}cus \\textbf{M}ultimodal \\textbf{R}easoning framework named \\textbf{GlFoMR} for DQA, which features a flexible architecture for comprehensive visual and text interaction. Firstly, the diagram is parsed into a hierarchical structure spanning different granularities including isolated single-object, object-group, and whole-diagram. Subsequently, the Glance-Plan and Focus-Reason stages collaborate to decouple the complex reasoning process. Glance-Plan first generates a preliminary plan by glancing at the multimodal context, specifying sub-goals related to knowledge extraction, visual perception, and visual reasoning. Based on these sub-goals, Focus-Reason further integrates domain-specific knowledge and visual details to enable more deliberate reasoning. The parsed multi-granularity diagram information is seamlessly incorporated into the corresponding sub-goal achievement process, enhancing the perception and reasoning capabilities of MLLMs for better DQA performance. Extensive experimental results on four DQA datasets demonstrate that GlFoMR achieves substantial improvements, showcasing its potential to advance the development of multimodal reasoning.",
        "doi": "10.1145/3726302.3729990",
        "sheridan_id": "fp0526",
        "position": 4,
        "track_id": 1,
        "slot_id": 42
      }
    },
    {
      "paper": {
        "hashed_id": "5ea1649a31336092c05438df996a3e59",
        "title": "Optimizing Tail-Head Trade-off for Extreme Multi-Label Text Classification (XMTC) with RAG-Labels and a Dynamic Two-Stage Retrieval and Fusion Pipeline",
        "abstract": "We tackle Extreme Multi-Label Text Classification (XMTC), which involves assigning relevant labels to texts from a huge label space. Attempting to optimize the underexplored tail-head trade-off, we address the XMTC task through its core challenges of \\textbf{volume}, \\textbf{skewness}, and \\textbf{quality} by proposing \\textbf{xCoRetriev}, a novel two-stage retrieving and fusing ranking pipeline. Our pipeline addresses the \\textbf{volume} challenge by dynamically slicing the large label space; it also tackles the \\textbf{skewness} challenge by favoring the tail labels while fusing sparse and dense retrievers. Finally, \\textbf{xCoRetriev} faces the \\textbf{quality} challenge by enhancing the label space with  Retrieval-Augmented Generated (RAG)-labels. Our experiments with four XMTC benchmarks with hundreds of thousands of text documents and labels against six state-of-the-art XMTC baselines demonstrate \\textbf{xCoRetriev}`s strengths in terms of: (i)~scalability for large label spaces, being among the most efficient methods at training and prediction; (ii)~effectiveness in the face of high skewness, with gains of up to \\textbf{48\\%} in propensity-scored metrics against the best state-of-the-art baselines; and (iii)~capability of handling very noisy datasets by exploiting \\textbf{RAG-labels}.",
        "doi": "10.1145/3726302.3730052",
        "sheridan_id": "fp0537",
        "position": 1,
        "track_id": 1,
        "slot_id": 40
      }
    },
    {
      "paper": {
        "hashed_id": "ffeabd223de0d4eacb9a3e6e53e5448d",
        "title": "FashionDPO:Fine-tune Fashion Outfit Generation Model using Direct Preference Optimization",
        "abstract": "Personalized outfit generation aims to construct a set of compatible and personalized fashion items as an outfit. Recently, generative AI models have received widespread attention, as they can generate fashion items for users to complete an incomplete outfit or create a complete outfit. However, they have limitations in terms of lacking diversity and relying on the supervised learning paradigm. Recognizing this gap, we propose a novel framework FashionDPO, which fine-tunes the fashion outfit generation model using direct preference optimization. This framework aims to provide a general fine-tuning approach to fashion generative models, refining a pre-trained fashion outfit generation model using automatically generated feedback, without the need to design a task-specific reward function. To make sure that the feedback is comprehensive and objective, we design a multi-expert feedback generation module which covers three evaluation perspectives, i.e., quality, compatibility and personalization. Experiments on two established datasets, i.e., iFashion and Polyvore-U, demonstrate the effectiveness of our framework in enhancing the model`s ability to align with users` personalized preferences while adhering to fashion compatibility principles. Our code and model checkpoints are available at https://github.com/Yzcreator/FashionDPO.",
        "doi": "10.1145/3726302.3729976",
        "sheridan_id": "fp0575",
        "position": 1,
        "track_id": 1,
        "slot_id": 4
      }
    },
    {
      "paper": {
        "hashed_id": "3a0772443a0739141292a5429b952fe6",
        "title": "Techie: Tackling Video Prefetching at Edge Networks as POMDP Via an Intrinsically Motivated RL Agent",
        "abstract": "Video prefetching techniques play a critical role in hiding the I/O latency of video delivery from cloud networks to access networks by optimizing edge networks. Content Delivery Networks rely on edge computing to improve Quality of Experience at the client-side, and improve resource utilization at edge and cloud networks simultaneously by utilizing prefetching optimization techniques. Recently, we have witnessed a trend in shifting intelligence to edge networks by building video prefetchers that utilize deep reinforcement learning to make online prefetching decisions. Unfortunately, these methods often lack generalization to different workloads when dealing with long sequences, rendering them incapable of adapting to distribution shifts and various changes in users` requests which represent a non i.i.d distribution. In this work, we tackle video prefetching at edge networks as a Partially Observable Markov Decision Process, and propose Techie, an intrinsically motivated policy-gradient reinforcement learning agent that differentiates intrinsic rewards from extrinsic rewards based on their availability to edge networks. Techie is adaptive to unseen user requests by prefetching aggressively to handle randomization in workloads, achieving 52.27% of prefetching accuracy and 34.34% of prefetching coverage. Our results show that Techie improves prefetching accuracy and coverage by at least 16.12% and 6.57%, respectively, compared to baseline approaches that utilize deep learning, deep reinforcement learning, or video popularity to build prefetching algorithms. Consequently, Techie minimizes end-to-end latency by at least 7.5% and reduces cache pollution with an improvement of at least 13.1% on unseen user requests compared to baselines.",
        "doi": "10.1145/3726302.3730089",
        "sheridan_id": "fp0559",
        "position": 8,
        "track_id": 1,
        "slot_id": 11
      }
    },
    {
      "paper": {
        "hashed_id": "cbcb58ac2e496207586df2854b17995f",
        "title": "Simulating Before Planning: Constructing Intrinsic User World Model for User-Tailored Dialogue Policy Planning",
        "abstract": "Recent advancements in dialogue policy planning have focused on optimizing system agent policies to achieve predefined goals, emphasizing strategy design, trajectory acquisition, and training efficiency. However, these approaches often overlook the critical role of user characteristics, which are essential in real-world scenarios like conversational search and recommendation, where interactions must adapt to individual user traits such as personality, preferences, and goals. To address this gap, we conduct a comprehensive study using task-specific user personas to evaluate dialogue policy planning under diverse user behaviors. Our analysis, based on these user profiles, reveals significant shortcomings in existing approaches, underscoring the necessity for user-tailored dialogue policies. Building on these insights, we propose the User-Tailored Dialogue Policy Planning (UDP) framework, which integrates an Intrinsic User World Model to capture user traits and feedback. UDP operates in three stages: (1) User Persona Portraying, employing a diffusion model to dynamically infer user profiles; (2) User Feedback Anticipating, using a Brownian Bridge-inspired mechanism to predict user reactions; and (3) User-Tailored Policy Planning, synthesizing these elements to optimize response strategies. To enhance robustness, we introduce an active learning approach that prioritizes challenging user personas during training. Extensive experiments across benchmarks, including both collaborative and non-collaborative settings, demonstrate UDP\u2019s effectiveness in learning user-specific dialogue strategies. Results confirm the framework\u2019s utility, highlighting its robustness, adaptability, and potential to advance user-centric dialogue systems.",
        "doi": "10.1145/3726302.3730084",
        "sheridan_id": "fp0565",
        "position": 8,
        "track_id": 1,
        "slot_id": 9
      }
    },
    {
      "paper": {
        "hashed_id": "db85e2590b6109813dafa101ceb2faeb",
        "title": "CSE-SFP: Enabling Unsupervised Sentence Representation Learning via a Single Forward Pass",
        "abstract": "As a fundamental task in Information Retrieval and Computational Linguistics, sentence representation has profound implications for a wide range of practical applications such as text clustering, content analysis, question-answering systems, and web search. Recent advances in pre-trained language models (PLMs) have driven remarkable progress in this field, particularly through unsupervised embedding derivation methods centered on discriminative PLMs like BERT. However, due to time and computational constraints, few efforts have attempted to integrate unsupervised sentence representation with generative PLMs, which typically possess much larger parameter sizes. Given that state-of-the-art models in both academia and industry are predominantly based on generative architectures, there is a pressing need for an efficient unsupervised text representation framework tailored to decoder-only PLMs. To address this concern, we propose CSE-SFP, an innovative method that exploits the structural characteristics of generative models. Compared to existing strategies, CSE-SFP requires only a single forward pass to perform effective unsupervised contrastive learning. Rigorous experimentation demonstrates that CSE-SFP not only produces higher-quality embeddings but also significantly reduces both training time and memory consumption. Furthermore, we introduce two ratio metrics that jointly assess alignment and uniformity, thereby providing a more robust means for evaluating the semantic spatial properties of encoding models. Our code and checkpoints are available at https://github.com/ZBWpro/CSE-SFP.",
        "doi": "10.1145/3726302.3729938",
        "sheridan_id": "fp0566",
        "position": 2,
        "track_id": 1,
        "slot_id": 40
      }
    },
    {
      "paper": {
        "hashed_id": "fde9264cf376fffe2ee4ddf4a988880d",
        "title": "Fairness-Aware Classification over Incomplete Data",
        "abstract": "The missing values widely existed in tabular data hinder the effective analysis of algorithmic fairness. Existing fairness intervention algorithms incorporate constraints or regularizers to reduce discrimination which rely on the complete information. They cannot effectively handle common tabular data with missing values in both sensitive and non-sensitive attributes without imputation. In this paper, we propose a novel Transformer-based fairness-aware prediction model FATE that mitigates the bias introduced by missing values to achieve algorithmic fairness without imputation. FATE consists of two modules, i.e., an incomplete data encoding (IDE) module and a debiased representation learning (DRL) module. IDE designs an incomplete tabular data embedding strategy and a missingness-aware Transformer block to effectively learn the observed data distribution and the missing state information. DRL converts fairness into attention parity when the sensitive attributes are completely missing. It offers a debiased attention mechanism to normalize attention weights in the attention score calculation process. We theoretically prove that, the differences in attention scores can represent the demographic disparities among sensitive groups which in FATE are bounded by a constant, substantially minimizing the group discrimination. Extensive experiments on three public real-world datasets demonstrate that, FATE, with the competitive fairness, yields more than 22% accuracy gain, compared to the state of the arts.",
        "doi": "10.1145/3726302.3729975",
        "sheridan_id": "fp0577",
        "position": 3,
        "track_id": 1,
        "slot_id": 39
      }
    },
    {
      "paper": {
        "hashed_id": "08b255a5d42b89b0585260b6f2360bdd",
        "title": "Open-World Fine-Grained Fashion Retrieval with LLM-based Commonsense Knowledge Infusion",
        "abstract": "Attribute-Specific Fashion Retrieval (ASFR) focuses on retrieving images based on fine-grained, attribute-specific criteria rather than naive global visual similarity, enabling more precise and interpretable search results. Existing ASFR methods ideally assume that all attribute semantics are in-domain distributions of the training datasets. However, realistic scenarios are generally more complex and naturally contain unseen attribute information, often resulting in ungeneralizable retrieval outcomes. In this paper, we take the first step to address the new and challenging open-world ASFR setting, which involves handling diverse and practical attributes instead of relying solely on predefined attribute sets in closed-world scenarios. Specifically, to comprehend unseen attributes, we propose a novel LLM-based Commonsense Knowledge Infusion (CoKi) framework that integrates commonsense knowledge as complementary context into attribute representations using a Large Language Model (LLM). By infusing such LLM-based commonsense knowledge through descriptive contexts, our method enables robust semantic enrichment and effective generalization to unseen attributes. Additionally, we introduce a modality-switchable prompt and an imputation mechanism to ensure model robustness across diverse input configurations by dynamically adapting to missing modalities. Extensive experiments demonstrate that our approach not only achieves state-of-the-art in-domain retrieval performance but also significantly enhances adaptability to unseen attributes and cross-domain generalization, establishing a new benchmark for fine-grained fashion retrieval in open-world scenarios. Our source code is publicly available at https://github.com/HuiGuanLab/CoKi.",
        "doi": "10.1145/3726302.3730050",
        "sheridan_id": "fp0590",
        "position": 2,
        "track_id": 1,
        "slot_id": 4
      }
    },
    {
      "paper": {
        "hashed_id": "02a32ad2669e6fe298e607fe7cc0e1a0",
        "title": "Graph Spectral Filtering with Chebyshev Interpolation for Recommendation",
        "abstract": "Graph convolutional networks have recently gained prominence in collaborative filtering (CF) for recommendations. However, we identify potential bottlenecks in two foundational components. First, the embedding layer leads to a latent space with limited capacity, overlooking locally observed but potentially valuable preference patterns. Also, the widely-used neighborhood aggregation is limited in its ability to leverage diverse preference patterns in a fine-grained manner. Building on spectral graph theory, we reveal that these limitations stem from graph filtering with a cut-off in the frequency spectrum and a restricted linear form. To address these issues, we introduce ChebyCF, a CF framework based on graph spectral filtering. Instead of a learned embedding, it takes a user`s raw interaction history to utilize the full spectrum of signals contained in it. Also, it adopts Chebyshev interpolation to effectively approximate a flexible non-linear graph filter, and further enhances it by using an additional ideal pass filter and degree-based normalization. Through extensive experiments, we verify that ChebyCF overcomes the aforementioned bottlenecks and achieves state-of-the-art performance across multiple benchmarks and reasonably fast inference. Our code is available at https://github.com/snuviplab/ChebyCF.",
        "doi": "10.1145/3726302.3729991",
        "sheridan_id": "fp0841",
        "position": 2,
        "track_id": 1,
        "slot_id": 37
      }
    },
    {
      "paper": {
        "hashed_id": "d7a728a67d909e714c0774e22cb806f2",
        "title": "Continual Origin Tracing of LLM-Generated Text",
        "abstract": "The rapid development of large language models (LLMs) raises concerns about their potential misuse. Accurately identifying and tracing the origin of LLM-generated content is crucial for accountability and transparency. Previous methods typically frame origin tracing as multi-class classification with a fixed label set, thus struggle to adapt to new LLMs without frequent retraining. This paper introduces a new task, continual origin tracing of LLM-generated text, which frames origin tracing in a continual learning or, more precisely, class-incremental learning manner, where new LLMs continuously emerge, and a model incrementally learns to identify new LLMs without forgetting old ones. A novel training-free method is further devised for the task, which continually extracts prototypes for emerging LLMs using a frozen pre-trained model, and conducts global and local prototype decorrelation to improve prototype matching, thus favoring more accurate tracing. To facilitate evaluation on the new task, we construct a benchmark comprising text generated by 19 recently released LLMs from 12 vendors that simulates a real-world scenario where these LLMs emerge over time and need to be recognized incrementally across 8 diverse domains. Rigorous evaluations on this benchmark highlight the effectiveness and potential of the proposed method in the new task, offering a promising direction for future research.",
        "doi": "10.1145/3726302.3729935",
        "sheridan_id": "fp0609",
        "position": 5,
        "track_id": 1,
        "slot_id": 31
      }
    },
    {
      "paper": {
        "hashed_id": "b73dfe25b4b8714c029b37a6ad3006fa",
        "title": "STAR-Rec: Making Peace with Length Variance and Pattern Diversity in Sequential Recommendation",
        "abstract": "Recent deep sequential recommendation models often struggle to effectively model key characteristics of user behaviors, particularly in handling sequence length variations and capturing diverse interaction patterns. We propose STAR-Rec, a novel architecture that synergistically combines preference-aware attention and state-space modeling through a sequence-level mixture-of-experts framework. STAR-Rec addresses these challenges by: (1) employing preference-aware attention to capture both inherently similar item relationships and diverse preferences, (2) utilizing state-space modeling to efficiently process variable-length sequences with linear complexity, and (3) incorporating a mixture-of-experts component that adaptively routes different behavioral patterns to specialized experts, handling both focused category-specific browsing and diverse category exploration patterns. We theoretically demonstrate how the state space model and attention mechanisms can be naturally unified in recommendation scenarios, where SSM captures temporal dynamics through state compression while attention models both similar and diverse item relationships. Extensive experiments on four real-world datasets demonstrate that STAR-Rec consistently outperforms state-of-the-art sequential recommendation methods, particularly in scenarios involving diverse user behaviors and varying sequence lengths. The implementation code is available anonymously online for easy reproducibility.",
        "doi": "10.1145/3726302.3730087",
        "sheridan_id": "fp0620",
        "position": 8,
        "track_id": 1,
        "slot_id": 7
      }
    },
    {
      "paper": {
        "hashed_id": "788d986905533aba051261497ecffcbb",
        "title": "ID-Free Not Risk-Free: LLM-Powered Agents Unveil Risks in ID-Free Recommender Systems",
        "abstract": "Recent advances in ID-free recommender systems have attracted significant attention for effectively addressing the cold start problem. However, their vulnerability to malicious attacks remains largely unexplored. In this paper, we unveil a critical yet overlooked risk: LLM-powered agents can be strategically deployed to attack ID-free recommenders, stealthily promoting low-quality items in black-box settings. This attack exploits a novel rewriting-based deception strategy, where malicious agents synthesize deceptive textual descriptions by simulating the characteristics of popular items. To achieve this, the attack mechanism integrates two primary components: (1) a popularity extraction component that captures essential characteristics of popular items and (2) a multi-agent collaboration mechanism that enables iterative refinement of promotional textual descriptions through independent thinking and team discussion. To counter this risk, we further introduce a detection method to identify suspicious text generated by our discovered attack. By unveiling this risk, our work aims to underscore the urgent need to enhance the security of ID-free recommender systems.",
        "doi": "10.1145/3726302.3730003",
        "sheridan_id": "fp0717",
        "position": 2,
        "track_id": 1,
        "slot_id": 38
      }
    },
    {
      "paper": {
        "hashed_id": "9cc138f8dc04cbf16240daa92d8d50e2",
        "title": "LLM-Assisted Relevance Assessments: When Should We Ask LLMs for Help?",
        "abstract": "Test collections are information retrieval tools that allow researchers to quickly and easily evaluate ranking algorithms. While test collections have become an integral part of IR research, the process of data creation involves significant manual annotation effort, which often makes it very expensive and time-consuming. Consequently, test collections could become too small when the budget is limited, which may lead to unstable evaluations. As a cheaper alternative, recent studies have proposed the use of large language models (LLMs) to completely replace human assessors. However, while LLMs seem to somewhat correlate with human judgments, their predictions are not perfect and often show bias. Thus, a complete replacement with LLMs is argued to be too risky and not fully reliable.In this paper, we propose LLM-Assisted Relevance Assessments (LARA), an effective method to balance manual annotations with LLM annotations, which helps to build a rich and reliable test collection even under a low budget. We use the LLM`s predicted relevance probabilities to select the most profitable documents to manually annotate under a budget constraint. With theoretical reasoning, LARA effectively guides the human annotation process by actively learning to calibrate the LLM`s predicted relevance probabilities. Then, using the calibration model learned from the limited manual annotations, LARA debiases the LLM predictions to annotate the remaining non-assessed data. Empirical evaluations on TREC-7 Ad Hoc, TREC-8 Ad Hoc, TREC Robust 2004, and TREC-COVID datasets show that LARA outperforms alternative solutions under almost any budget constraint.",
        "doi": "10.1145/3726302.3729916",
        "sheridan_id": "fp0630",
        "position": 2,
        "track_id": 1,
        "slot_id": 41
      }
    },
    {
      "paper": {
        "hashed_id": "4ffce04d92a4d6cb21c1494cdfcd6dc1",
        "title": "Hierarchical Tree Search-based User Lifelong Behavior Modeling on Large Language Model",
        "abstract": "Large Language Models (LLMs) have garnered significant attention in Recommendation Systems (RS) due to their extensive world knowledge and robust reasoning capabilities. However, a critical challenge lies in enabling LLMs to effectively comprehend and extract insights from massive user behaviors. Current approaches that directly leverage LLMs for user interest learning face limitations in handling long sequential behaviors, effectively extracting interest, and applying interest in practical scenarios. To address these issues, we propose a Hierarchical Tree Search-based User Lifelong Behavior Modeling framework (HiT-LBM). HiT-LBM integrates Chunked User Behavior Extraction (CUBE) and Hierarchical Tree Search for Interest (HTS) to capture diverse interests and interest evolution of user. CUBE divides user lifelong behaviors into multiple chunks and learns the interest and interest evolution within each chunk in a cascading manner. HTS generates candidate interests through hierarchical expansion and searches for the optimal interest with process rating model to ensure information gain for each behavior chunk. Additionally, we design Temporal-Ware Interest Fusion (TIF) to integrate interests from multiple behavior chunks, constructing a comprehensive representation of user lifelong interests. The representation can be embedded into any recommendation model to enhance performance. Extensive experiments demonstrate the effectiveness of our approach, showing that it surpasses state-of-the-art methods. We also deploy HiT-LBM on Kuaishou`s online advertising platform, showing 3.5\\% increase of revenue. We release the implementation code https://github.com/xiayu-cell/HiT-LBM.",
        "doi": "10.1145/3726302.3729995",
        "sheridan_id": "fp0640",
        "position": 3,
        "track_id": 1,
        "slot_id": 17
      }
    },
    {
      "paper": {
        "hashed_id": "fe8c15fed5f808006ce95eddb7366e35",
        "title": "AdSight: Scalable and Accurate Quantification of User Attention in Multi-Slot Sponsored Search",
        "abstract": "Modern Search Engine Results Pages (SERPs) present complex layouts where multiple elements compete for visibility. Attention modelling is crucial for optimising web design and computational advertising, whereas attention metrics can inform ad placement and revenue strategies. We introduce AdSight, a method leveraging mouse cursor trajectories to quantify in a scalable and accurate manner user attention in multi-slot environments like SERPs. AdSight uses a novel Transformer-based sequence-to-sequence architecture where the encoder processes cursor trajectory embeddings, and the decoder incorporates slot-specific features, enabling robust attention prediction across various SERP layouts. We evaluate our approach on two Machine Learning tasks: (1)~\\emph{regression}, to predict fixation times and counts; and (2)~\\emph{classification}, to determine some slot types were noticed. Our findings demonstrate the model`s ability to predict attention with unprecedented precision, offering actionable insights for researchers and practitioners.",
        "doi": "10.1145/3726302.3729891",
        "sheridan_id": "fp0849",
        "position": 5,
        "track_id": 1,
        "slot_id": 4
      }
    },
    {
      "paper": {
        "hashed_id": "d7657583058394c828ee150fada65345",
        "title": "Wrong Answers Can Also Be Useful: PlausibleQA \u2014 A Large-Scale QA Dataset with Answer Plausibility Scores",
        "abstract": "Large Language Models (LLMs) are revolutionizing information retrieval, with chatbots becoming an important source for answering user queries. As by their design, LLMs prioritize generating correct answers, the value of highly plausible yet incorrect answers (candidate answers) tends to be overlooked. However, such answers can still prove useful, for example, they can play a crucial role in tasks like Multiple-Choice Question Answering (MCQA) and QA Robustness Assessment (QARA). Existing QA datasets primarily focus on correct answers without explicit consideration of the plausibility of other candidate answers, limiting opportunity for more nuanced evaluations of models. To address this gap, we introduce PlausibleQA, a large-scale dataset comprising 10,000 questions and 100,000 candidate answers, each annotated with plausibility scores and justifications for their selection. Additionally, the dataset includes 900,000 justifications for pairwise comparisons between candidate answers, further refining plausibility assessments. We evaluate PlausibleQA through human assessments and empirical experiments, demonstrating its utility in MCQA and QARA analysis. Our findings show that plausibility-aware approaches are effective for MCQA distractor generation and QARA. We release PlausibleQA as a resource for advancing QA research and enhancing LLM performance in distinguishing plausible distractors from correct answers.",
        "doi": "10.1145/3726302.3730299",
        "sheridan_id": "rr1838",
        "position": 110,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "b4288d9c0ec0a1841b3b3728321e7088",
        "title": "Flow-guided Direct Preference Optimization for Knowledge Graph Reasoning with Trees",
        "abstract": "Recent advancements in knowledge graph question answering (KGQA) have shown promise, yet existing methods often fail to align with human reasoning patterns that involve continuous reflection and refinement. This paper proposes FD-PORT (flow-guided direct preference optimization for knowledge graph reasoning with trees), a novel approach that combines Monte Carlo Tree Search (MCTS) with flow-guided direct preference optimization (FDPO) for KGQA tasks. MCTS simulates human-like reasoning by systematically exploring multiple inference paths in knowledge graphs, while FDPO transforms the search feedback into fine-grained training signals through flow balance conditions. Unlike traditional methods focusing on end-to-end training or sequence-level preferences, FD-PORT establishes flow consistency between any states along the reasoning chain, enabling robust multi-hop reasoning that adapts to local decisions and long-range dependencies. Experimental results on three benchmark datasets demonstrate that FD-PORT significantly outperforms state-of-the-art methods, achieving up to 50.6% improvements over GPT-4 on complex multi-hop reasoning tasks with a smaller open-source language model. The framework is advanced in maintaining diverse reasoning paths while ensuring answer quality, closely mirroring human problem-solving strategies.",
        "doi": "10.1145/3726302.3729980",
        "sheridan_id": "fp0657",
        "position": 2,
        "track_id": 1,
        "slot_id": 8
      }
    },
    {
      "paper": {
        "hashed_id": "3a066bda8c96b9478bb0512f0a43028c",
        "title": "Segmentation Similarity Enhanced Semantic Related Entity Fusion for Multi-modal Knowledge Graph Completion",
        "abstract": "Multi-modal Knowledge Graph Completion (MKGC) aims at leveraging multi-modal information to infer missing objective facts in incomplete multi-modal knowledge graphs, thereby significantly enhancing their expressive capabilities. The segmentation of semantic data, including image segmentation and word-level descriptions, often contain implicit relationships between entities that are frequently overlooked by existing methodologies, thus limiting the effectiveness of reasoning tasks. Therefore, we propose a novel completion inference method based on fine-grained semantic segmentation, which enhances reasoning capability by utilizing implicit relationships between entities. Primarily, we introduce the concept of Semantic Related Entity (SRE) and a novel SRE selection algorithm, which captures the semantic neighboring relationships of entities based on segmentation semantic similarity to fully exploit the semantic association information.  Subsequently, we propose a Multi-modal Related Entity Fusion Transformer (M-REFT) model to effectively utilize SREs from semantic modalities and neighbors from structural modality for completion inference. The M-REFT employs a hierarchical Transformer architecture to encode the fusion modality representation between each entity and its SREs, and then decode the triplet representation with the neighbor information to identify missing entities in incomplete triplets. We conducted extensive comparative experiments with several state-of-the-art models on three datasets, demonstrating the significant performance advantages of M-REFT. A series of ablation experiments and case studies further validate the rationality and necessity of the SRE concept and the SRE selection algorithm.",
        "doi": "10.1145/3726302.3730082",
        "sheridan_id": "fp0661",
        "position": 3,
        "track_id": 1,
        "slot_id": 8
      }
    },
    {
      "paper": {
        "hashed_id": "8757150decbd89b0f5442ca3db4d0e0e",
        "title": "Towards Interest Drift-driven User Representation Learning in Sequential Recommendation",
        "abstract": "Sequential recommendation (SR) aims to infer users` future interests and suggest the next items for them. Most SR methods learn one single vector to represent a user`s recent interests, i.e., a user representation. Despite their great success, most of them do not explicitly consider the phenomenon of users` interest drift when learning user representations. Moreover, interest drift presents two critical challenges for these SR methods: (1) how to explore the potential distributions of the users` varying interest drift levels; and (2) how to capture the interest drift-aware collaborative knowledge among the users. In this paper, we delve into the issue of interest drift in SR and propose a novel and generic framework, i.e., Interest Drift-driven User Representation Learning (IDURL), to enhance SR methods to tackle the above two challenges. Specifically, our IDURL contains an interest drift quantization (IDQ) module to enable a quantitative measurement of the interest drift. Moreover, a drift representation generation module models the users` latent varying levels of interest drift, and an interest drift-guided representation disentanglement module optimizes the distributions of the interest drift levels under the guidance of IDQ. Furthermore, an interest drift-aware representation alignment module helps to capture the interest drift-aware collaborative knowledge among users. Finally, the users` overall interest representations are obtained to calculate the preference scores on the candidate items. Extensive experiments on four public datasets show the effectiveness of our IDURL. The source code of our IDURL is available at: https://github.com/xiaolLIN/IDURL.",
        "doi": "10.1145/3726302.3730099",
        "sheridan_id": "fp0663",
        "position": 1,
        "track_id": 1,
        "slot_id": 14
      }
    },
    {
      "paper": {
        "hashed_id": "84117275be999ff55a987b9381e01f96",
        "title": "Optimizing Compound Retrieval Systems",
        "abstract": "Modern retrieval systems do not rely on a single ranking model to construct their rankings. Instead, they generally take a cascading approach where a sequence of ranking models are applied in multiple re-ranking stages. Thereby, they balance the quality of the top-K ranking with computational costs by limiting the number of documents each model re-ranks. However, the cascading approach is not the only way models can interact to form a retrieval system. We propose the concept of compound retrieval systems as a broader class of retrieval systems that apply multiple prediction models. This encapsulates cascading models but also allows other types of interactions than top-K re-ranking. In particular, we enable interactions with large language models (LLMs) which can provide relative relevance comparisons. We focus on the optimization of compound retrieval system design which uniquely involves learning where to apply the component models and how to aggregate their predictions into a final ranking. This work shows how our compound approach can combine the classic BM25 retrieval model with state-of-the-art (pairwise) LLM relevance predictions, while optimizing a given ranking metric and efficiency target. Our experimental results show optimized compound retrieval systems provide better trade-offs between effectiveness and efficiency than cascading approaches, even when applied in a self-supervised manner. With the introduction of compound retrieval systems, we hope to inspire the information retrieval field to more out-of-the-box thinking on how prediction models can interact to form rankings.",
        "doi": "10.1145/3726302.3730051",
        "sheridan_id": "fp0665",
        "position": 4,
        "track_id": 1,
        "slot_id": 12
      }
    },
    {
      "paper": {
        "hashed_id": "5dd9db5e033da9c6fb5ba83c7a7ebea9",
        "title": "Query Smarter, Trust Better? Exploring Search Behaviours for Verifying News Accuracy",
        "abstract": "While it is often assumed that searching for information to evaluate misinformation will help identify false claims, recent work suggests that search behaviours can instead reinforce belief in misleading news, particularly when users generate queries using vocabulary from the source articles. Our research explores how different query generation strategies affect news verification and whether the way people search influences the accuracy of their information evaluation. A mixed-methods approach was used, consisting of three parts: (1) an analysis of existing data to understand how search behaviour influences trust in fake news, (2) a simulation of query generation strategies using a Large Language Model (LLM) to assess the impact of different query formulations on search result quality, and (3) a user study to examine how `Boost` interventions in interface design can guide users to adopt more effective query strategies. The results show that search behaviour significantly affects trust in news, with successful searches involving multiple queries and yielding higher-quality results. Queries inspired by different parts of a news article produced search results of varying quality, and weak initial queries improved when reformulated using full SERP information. Although `Boost` interventions had limited impact, the study suggests that interface design encouraging users to thoroughly review search results can enhance query formulation. This study highlights the importance of query strategies in evaluating news and proposes that interface design can play a key role in promoting more effective search practices, serving as one component of a broader set of interventions to combat misinformation.",
        "doi": "10.1145/3726302.3730067",
        "sheridan_id": "fp0671",
        "position": 8,
        "track_id": 1,
        "slot_id": 31
      }
    },
    {
      "paper": {
        "hashed_id": "ca9c267dad0305d1a6308d2a0cf1c39c",
        "title": "Ask and Retrieve Knowledge: Towards Proactive Asking with Imperfect Information in Medical Multi-turn Dialogues",
        "abstract": "Large language models (LLMs) cannot effectively collaborate with humans who provide imperfect information at the initial stage of the dialogue, unless they learn to proactively ask questions. Our core idea is to enable LLMs to decide whether to take the action of ``ask`` or ``tell`` at each turn by self-reasoning, with the belief of the decisions enhanced by retrieving knowledge related to the user input. Thus, we propose the ask and retrieve knowledge framework (Ark), where LLMs think through what to retrieve, when to stop retrieving, and then take actions accordingly. Ark is used to produce the action paths for model training. To mitigate the collapse of models trained on synthetic data, we propose a progressive training strategy: self-reason learning by supervised fine-tuning on produced paths and knowledge alignment through direct preference optimization on doctor response. To evaluate the information gain brought by the ask action, we design a method to calculate the ask utility value (AUV) based on the expected value of perfect information (EVPI) theory. Although MedArk is trained using synthetic data from GPT-4o-mini, it highly outperforms GPT-4o and other medical LLMs in six aspects: helpfulness, hallucination, action selection, BERTScore, AUV, and asking correctness. MedArk also achieves SOTA results in the perfect information scenario, i.e., medical examinations. We release our code, data and models at https://github.com/Bolin97/MedArk.",
        "doi": "10.1145/3726302.3729898",
        "sheridan_id": "fp0679",
        "position": 2,
        "track_id": 1,
        "slot_id": 24
      }
    },
    {
      "paper": {
        "hashed_id": "ba1b3eba322eab5d895aa3023fe78b9c",
        "title": "CoLoTa: A Dataset for Entity-based Commonsense Reasoning over Long-Tail Knowledge",
        "abstract": "The rise of Large Language Models (LLMs) has redefined the AI landscape, particularly due to their ability to encode factual and commonsense knowledge, and their outstanding performance in tasks requiring reasoning. Despite these advances, hallucinations and reasoning errors remain a significant barrier to their deployment in high-stakes settings. In this work, we observe that even the most prominent LLMs, such as OpenAI-o1, suffer from high rates of reasoning errors and hallucinations on tasks requiring commonsense reasoning over obscure, long-tail entities. To investigate this limitation, we present a new dataset for Commonsense reasoning over Long-Tail entities (CoLoTa), that consists of 3,300 queries from question answering and claim verification tasks and covers a diverse range of commonsense reasoning skills. We remark that CoLoTa can also serve as a Knowledge Graph Question Answering (KGQA) dataset since the support of knowledge required to answer its queries is present in the Wikidata knowledge graph. However, as opposed to existing KGQA benchmarks that merely focus on factoid questions, our CoLoTa queries also require commonsense reasoning. Our experiments with strong LLM-based KGQA methodologies indicate their severe inability to answer queries involving commonsense reasoning. Hence, we propose CoLoTa as a novel benchmark for assessing both (i) LLM commonsense reasoning capabilities and their robustness to hallucinations on long-tail entities and (ii) the commonsense reasoning capabilities of KGQA methods.",
        "doi": "10.1145/3726302.3730291",
        "sheridan_id": "rr1759",
        "position": 114,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "07c5807d0d927dcd0980f86024e5208b",
        "title": "Mitigating Source Bias with LLM Alignment",
        "abstract": "Recent studies have revealed a phenomenon known as source bias, where PLM-based retrievers assign higher relevance scores to LLM-generated content despite its semantic quality being comparable to human-written content. As LLMs rapidly advance and become more widely used, effectively counteracting source bias is crucial for the sustainable development of the information retrieval (IR) ecosystem. Existing methods primarily attempt to address source bias from the retriever side, adopting a ``passive defense`` approach that intervenes only after biased content has entered the retrieval pipeline. These solutions are limited by frequent retriever updates in industrial applications, high recurring costs, and their inability to address the root cause of source bias.In this paper, we propose a new perspective for mitigating source bias by actively aligning LLM outputs at the data generation stage. Specifically, we introduce LLM-SBM, a novel LLM alignment framework for source bias mitigation. First, we construct high-quality alignment datasets using an automatic preference data construction pipeline. This pipeline leverages LLMs to generate multiple rephrasings of content and employs a PLM-based retriever to assign corresponding specific preference values for each generated document, thereby forming preference pairs according to these preferences. Moreover, to fully utilize these scalar values of preference and enhance the efficiency of the alignment process, LLM-SBM incorporates these preference differences as weighting factors in the loss function during policy training. Extensive experiments across multiple datasets and PLM-based retrievers demonstrate that LLMs aligned with LLM-SBM successfully reduce source bias while preserving their general capabilities.",
        "doi": "10.1145/3726302.3730038",
        "sheridan_id": "fp0713",
        "position": 1,
        "track_id": 1,
        "slot_id": 22
      }
    },
    {
      "paper": {
        "hashed_id": "d14220ee66aeec73c49038385428ec4c",
        "title": "Generative Recommender with End-to-End Learnable Item Tokenization",
        "abstract": "Generative recommender systems have gained increasing attention as an innovative approach that directly generates item identifiers for recommendation tasks. Despite their potential, a major challenge is the effective construction of item identifiers that align well with recommender systems. Current approaches often treat item tokenization and generative recommendation training as separate processes, which can lead to suboptimal performance. To overcome this issue, we introduce \\textbf{ETEGRec}, a novel \\underline{E}nd-\\underline{T}o-\\underline{E}nd \\underline{G}enerative \\underline{Rec}ommender that unifies item tokenization and generative recommendation into a cohesive framework. Built on a dual encoder-decoder architecture, ETEGRec consists of an item tokenizer and a generative recommender. To enable synergistic interaction between these components, we propose a recommendation-oriented alignment strategy, which includes two key optimization objectives: sequence-item alignment and preference-semantic alignment. These objectives tightly couple the learning processes of the item tokenizer and the generative recommender, fostering mutual enhancement. Additionally, we develop an alternating optimization technique to ensure stable and efficient end-to-end training of the entire framework. Extensive experiments demonstrate the superior performance of our approach compared to traditional sequential recommendation models and existing generative recommendation baselines. Our code is available at \\href{https://github.com/RUCAIBox/ETEGRec}{{https://github.com/RUCAIBox/ETEGRec}}.",
        "doi": "10.1145/3726302.3729989",
        "sheridan_id": "fp0714",
        "position": 8,
        "track_id": 1,
        "slot_id": 16
      }
    },
    {
      "paper": {
        "hashed_id": "d63fbf8c3173730f82b150c5ef38b8ff",
        "title": "WARP: An Efficient Engine for Multi-Vector Retrieval",
        "abstract": "Multi-vector retrieval methods such as ColBERT and its recent variant, the ConteXtualized Token Retriever (XTR), offer high accuracy but face efficiency challenges at scale. To address this, we present WARP, a retrieval engine that substantially improves the efficiency of retrievers trained with the XTR objective through three key innovations: (1) WARPSELECT  for dynamic similarity imputation; (2) implicit decompression, avoiding costly vector reconstruction during retrieval; and (3) a two-stage reduction process for efficient score aggregation. Combined with highly-optimized C++ kernels, our system reduces end-to-end latency compared to XTR`s reference implementation by 41x, and achieves a 3x speedup over the ColBERTv2/PLAID engine, while preserving retrieval quality. WARP also reduces index sizes by a factor of 2x--4x compared to XTR, enabling deployment on memory-constrained devices.",
        "doi": "10.1145/3726302.3729904",
        "sheridan_id": "fp1534",
        "position": 3,
        "track_id": 1,
        "slot_id": 33
      }
    },
    {
      "paper": {
        "hashed_id": "c60d060b946d6dd6145dcbad5c4ccf6f",
        "title": "Comprehensive List Generation for Multi-Generator Reranking",
        "abstract": "Reranking models solve the final recommendation lists that best fulfill users` demands. While existing solutions focus on finding parametric models that approximate optimal policies, recent approaches find that it is better to generate multiple lists to compete for a ``pass`` ticket from an evaluator, where the evaluator serves as the supervisor who accurately estimates the performance of the candidate lists. In this work, we show that we can achieve a more efficient and effective list proposal with a multi-generator framework and provide empirical evidence on two public datasets and online A/B tests. More importantly, we verify that the effectiveness of a generator is closely related to how much it complements the views of other generators with sufficiently different rerankings, which derives the metric of list comprehensiveness. With this intuition, we design an automatic complementary generator-finding framework that learns a policy that simultaneously aligns the users` preferences and maximizes the list comprehensiveness metric. The experimental results indicate that the proposed framework can further improve the multi-generator reranking performance.",
        "doi": "10.1145/3726302.3729933",
        "sheridan_id": "fp1118",
        "position": 6,
        "track_id": 1,
        "slot_id": 29
      }
    },
    {
      "paper": {
        "hashed_id": "6bc24fc1ab650b25b4114e93a98f1eba",
        "title": "Intent-aware Diffusion with Contrastive Learning for Sequential Recommendation",
        "abstract": "Contrastive learning has proven effective in training sequential recommendation models by incorporating self-supervised signals from augmented views. Most existing methods generate multiple views from the same interaction sequence through stochastic data augmentation, aiming to align their representations in the embedding space. However, users typically have specific intents when purchasing items (e.g., buying clothes as gifts or cosmetics for beauty). Random data augmentation used in existing methods may introduce noise, disrupting the latent intent information implicit in the original interaction sequence. Moreover, using noisy augmented sequences in contrastive learning may mislead the model to focus on irrelevant features, distorting the embedding space and failing to capture users` true behavior patterns and intents. To address these issues, we propose Intent-aware Diffusion with contrastive learning for sequential Recommendation (InDiRec). The core idea is to generate item sequences aligned with users` purchasing intents, thus providing more reliable augmented views for contrastive learning. Specifically, InDiRec first performs intent clustering on sequence representations using K-means to build intent-guided signals. Next, it retrieves the intent representation of the target interaction sequence to guide a conditional diffusion model, generating positive views that share the same underlying intent. Finally, contrastive learning is applied to maximize representation consistency between these intent-aligned views and the original sequence. Extensive experiments on five public datasets demonstrate that InDiRec achieves superior performance compared to existing baselines, learning more robust representations even under noisy and sparse data conditions.",
        "doi": "10.1145/3726302.3730010",
        "sheridan_id": "fp0736",
        "position": 2,
        "track_id": 1,
        "slot_id": 14
      }
    },
    {
      "paper": {
        "hashed_id": "3a835d3215755c435ef4fe9965a3f2a0",
        "title": "Boosting Retrieval-Augmented Generation with Generation-Augmented Retrieval: A Co-Training Approach",
        "abstract": "Large language models (LLMs) have shown success in knowledge-intensive tasks, including closed-book question answering and entity linking. However, their susceptibility to hallucination undermines their reliability. Retrieval-augmented generation (RAG) partially addresses this issue by combining a retriever to locate relevant documents and a generator to produce responses grounded in the retrieved evidence. Despite its advantages, RAG faces challenges: (i) the structural gap between traditional dense retrievers and autoregressive generators, and (ii) limited generation performance due to insufficient contextual guidance returned by the retriever. To tackle these limitations, we propose MINT, a novel framework that enhances RAG by co-training Retrieval-augMented generatIon and geNeration-augmented reTrieval (GAR). MINT (i) bridges the gap between the retriever and generator using a unified encoder-decoder structure, (ii) incorporates an iterative co-training strategy between RAG and GAR, enabling mutual enhancement through pseudo-samples generation, and (iii) introduces three heuristic inference strategies to generate relevant document identifiers and answers. We conduct an empirical study on the KILT benchmark, and MINT is found to yield significant improvements in both retrieval and generation tasks compared with prevailing baselines.",
        "doi": "10.1145/3726302.3729907",
        "sheridan_id": "fp0768",
        "position": 3,
        "track_id": 1,
        "slot_id": 19
      }
    },
    {
      "paper": {
        "hashed_id": "2e65f2f2fdaf6c699b223c61b1b5ab89",
        "title": "Brain Image Reconstruction with Retrieval-Augmented Diffusion",
        "abstract": "Reconstructing visual images from brain signals is a rapidly evolving research with promising applications in brain-computer interfaces, cognitive neuroscience, and assistive technologies. While visual reconstruction based on functional Magnetic Resonance Imaging (fMRI) has previously achieved notable success, this paper explores cost-effective brain signals, i.e., electroencephalography (EEG) and magnetoencephalography (MEG). These signals are less precise than fMRI, which presents greater challenges for reconstruction. To address this problem, we propose BReAD (Brain Image Reconstruction with Retrieval-Augmented Diffusion), a novel framework that combines EEG/MEG signals with retrieval-augmented diffusion models to improve image reconstruction quality. BReAD utilizes the semantics decoded from brain signals for (1) retrieving semantic priors from a large-scale image database and (2) serving as a conditional constraint during the diffusion process. Extensive experiments demonstrate that BReAD significantly outperforms existing approaches in both qualitative and quantitative evaluations, paving the way for more robust and practical brain-to-image reconstruction systems. Our codes are available at https://github.com/Promise-Z5Q2SQ/BReAD.",
        "doi": "10.1145/3726302.3729909",
        "sheridan_id": "fp0741",
        "position": 1,
        "track_id": 1,
        "slot_id": 10
      }
    },
    {
      "paper": {
        "hashed_id": "2823f4797102ce1a1aec05359cc16dd9",
        "title": "CDC: Causal Domain Clustering for Multi-Domain Recommendation",
        "abstract": "Multi-domain recommendation leverages domain-general knowledge to improve recommendations across several domains. However, as platforms expand to dozens or hundreds of scenarios, training all domains in a unified model leads to performance degradation due to significant inter-domain differences. Existing domain grouping methods, based on business logic or data similarities, often fail to capture the true transfer relationships required for optimal grouping. To effectively cluster domains, we propose Causal Domain Clustering (CDC). CDC models domain transfer patterns within a large number of domains using two distinct effects: the Isolated Domain Affinity Matrix for modeling non-interactive domain transfers, and the Hybrid Domain Affinity Matrix for considering dynamic domain synergy or interference under joint training. To integrate these two transfer effects, we introduce causal discovery to calculate a cohesion-based coefficient that adaptively balances their contributions. A Co-Optimized Dynamic Clustering algorithm iteratively optimizes target domain clustering and source domain selection for training. CDC significantly enhances performance across over 50 domains on public datasets and in industrial settings, achieving a 4.9% increase in online eCPM. Code is available online: https://github.com/Chrissie-Law/Causal-Domain-Clustering-for-Multi-Domain-Recommendation.",
        "doi": "10.1145/3726302.3729919",
        "sheridan_id": "fp0756",
        "position": 3,
        "track_id": 1,
        "slot_id": 34
      }
    },
    {
      "paper": {
        "hashed_id": "88ae6372cfdc5df69a976e893f4d554b",
        "title": "Reason-to-Rank: Distilling Direct and Comparative Reasoning from Large Language Models for Document Reranking",
        "abstract": "Reranking documents in information retrieval often relies on black-box models that improve effectiveness but lack explainability. We introduce Reason-to-Rank (R2R), a novel framework that separates direct relevance reasoning from comparison reasoning to provide both direct and comparitive explanations. We first prompt a large language model to produce comprehensive rationales and a ranking order; then we distill both the ranking decisions and textual explanations into a smaller, open-source student model. Our approach not only improves retrieval performance, as demonstrated in MSMARCO, BEIR, and BRIGHT, but also provides interpretable justifications for why one document outranks another. We report NDCG@5 (and NDCG@10) for direct comparisons with prior work, and show that the distilled student model achieves competitive results while significantly reducing computational overhead. By unifying direct and comparative reasoning in a single pipeline, R2R bridges the gap between transparency and effectiveness in modern reranking systems.",
        "doi": "10.1145/3726302.3730070",
        "sheridan_id": "fp0761",
        "position": 8,
        "track_id": 1,
        "slot_id": 29
      }
    },
    {
      "paper": {
        "hashed_id": "eefc9e10ebdc4a2333b42b2dbb8f27b6",
        "title": "MELON: Learning Multi-Aspect Modality Preferences for Accurate Multimedia Recommendation",
        "abstract": "Existing multimedia recommender systems have made the best efforts to predict user preferences for items by utilizing behavioral similarities between users and the modality features of items a user has interacted with. However, we identify two key limitations in existing methods regarding preferences for modality features: (L1) although preferences for modality features is an important aspect of users` preferences, existing methods only leverage neighbors with similar interactions and do not consider the neighbors who may have similar preferences for modality features while having different interactions; (L2) although modality features of a user and an item may have a complex geometric relationship in the latent space, existing methods overlook and face challenges in precisely capturing this relationship. To address these two limitations, we propose a novel multimedia recommendation framework, named MELON, which is based on two core ideas: (Idea 1) Modality-cEntered embedding extraction; (Idea 2) reLatiOnship-ceNtered embedding extraction. We validate the effectiveness and validity of MELON through extensive experiments with four real-world datasets, showing 10.51% higher accuracy compared to the best competitor in terms of recall@10. The code and dataset of MELON is available at https://github.com/Bigdasgit/MELON.",
        "doi": "10.1145/3726302.3730031",
        "sheridan_id": "fp0763",
        "position": 4,
        "track_id": 1,
        "slot_id": 34
      }
    },
    {
      "paper": {
        "hashed_id": "959a557f5f6beb411fd954f3f34b21c3",
        "title": "Constrained Auto-Regressive Decoding Constrains Generative Retrieval",
        "abstract": "Generative retrieval seeks to replace traditional search index data structures with a single large-scale neural network, offering the potential for improved efficiency and seamless integration with generative large language models.As an end-to-end paradigm, generative retrieval adopts a learned differentiable search index to conduct retrieval by directly generating document identifiers through corpus-specific constrained decoding.The generalization capabilities of generative retrieval on out-of-distribution corpora have gathered significant attention.Recent advances primarily focus on the problems arising from training strategies, and addressing them through various learning techniques.However, the fundamental challenges of generalization arising from constrained auto-regressive decoding still remain unexplored and systematically understudied.In this paper, we examine the inherent limitations of constrained auto-regressive generation from two essential perspectives: constraints and beam search.We begin with the Bayes-optimal setting where the generative retrieval model exactly captures the underlying relevance distribution of all possible documents.Then we apply the model to specific corpora by simply adding corpus-specific constraints.Our main findings are two-fold:(i) For the effect of constraints, we derive a lower bound of the error, in terms of the KL divergence between the ground-truth and the model-predicted step-wise marginal distributions.This error arises due to the unawareness of future constraints during generation and is shown to depend on the average Simpson diversity index of the relevance distribution.(ii) For the beam search algorithm used during generation, we reveal that the usage of marginal distributions may not be an ideal approach.Specifically, we prove that for sparse relevance distributions, beam search can achieve perfect top-1 precision but suffer from poor top-k recall performance.To support our theoretical findings, we conduct experiments on synthetic and real-world datasets, validating the existence of the error from adding constraints and the recall performance drop due to beam search.This paper aims to improve our theoretical understanding of the generalization capabilities of the auto-regressive decoding retrieval paradigm, laying a foundation for its limitations and inspiring future advancements toward more robust and generalizable generative retrieval.",
        "doi": "10.1145/3726302.3729934",
        "sheridan_id": "fp0766",
        "position": 2,
        "track_id": 1,
        "slot_id": 19
      }
    },
    {
      "paper": {
        "hashed_id": "86b122d4358357d834a87ce618a55de0",
        "title": "Information Retrieval in the Age of Generative AI: The RGB Model",
        "abstract": "The advent of Large Language Models (LLMs) and generative AI is fundamentally transforming information retrieval and processing on the Internet, bringing both great potential and significant concerns regarding content authenticity and reliability. This paper presents a novel quantitative approach to shed light on the complex information dynamics arising from the growing use of generative AI tools. Despite their significant impact on the digital ecosystem, these dynamics remain largely uncharted and poorly understood.We propose a stochastic model to characterize the generation, indexing, and dissemination of information in response to new topics. This scenario particularly challenges current LLMs, which often rely on real-time Retrieval-Augmented Generation (RAG) techniques to overcome their static knowledge limitations. Our findings suggest that the rapid pace of generative AI adoption, combined with increasing user reliance, can outpace human verification, escalating the risk of inaccurate information proliferation across digital resources. An in-depth analysis of Stack Exchange data confirms that high-quality answers inevitably require substantial time and human effort to emerge. This underscores the considerable risks associated with generating persuasive text in response to new questions and highlights the critical need for responsible development and deployment of future generative AI tools.",
        "doi": "10.1145/3726302.3730008",
        "sheridan_id": "fp0773",
        "position": 3,
        "track_id": 1,
        "slot_id": 9
      }
    },
    {
      "paper": {
        "hashed_id": "7143d7fbadfa4693b9eec507d9d37443",
        "title": "CoMaPOI: A Collaborative Multi-Agent Framework for Next POI Prediction Bridging the Gap Between Trajectory and Language",
        "abstract": "Large Language Models (LLMs) offer new opportunities for the next Point-Of-Interest (POI) prediction task, leveraging their capabilities in semantic understanding of POI trajectories. However, previous LLM-based methods, which are superficially adapted to next POI prediction, largely overlook critical challenges associated with applying LLMs to this task. Specifically, LLMs encounter two critical challenges: (1) a lack of intrinsic understanding of numeric spatiotemporal data, which hinders accurate modeling of users` spatiotemporal distributions and preferences; and (2) an excessively large and unconstrained candidate POI space, which often results in random or irrelevant predictions. To address these issues, we propose a Collaborative Multi-Agent Framework for Next POI Prediction, named CoMaPOI. Through the close interaction of three specialized agents (Profiler, Forecaster, and Predictor), CoMaPOI collaboratively addresses the two critical challenges. The Profiler agent is responsible for converting numeric data into language descriptions, enhancing semantic understanding. The Forecaster agent focuses on dynamically constraining and refining the candidate POI space. The Predictor agent integrates this information to generate high-precision predictions. Extensive experiments on three benchmark datasets (NYC, TKY, and CA) demonstrate that CoMaPOI achieves state-of-the-art performance, improving all metrics by 5% to 10% compared to SOTA baselines. This work pioneers the investigation of challenges associated with applying LLMs to complex spatiotemporal tasks by leveraging tailored collaborative agents. Our source code is available at: https://github.com/Chips98/CoMaPOI.",
        "doi": "10.1145/3726302.3729930",
        "sheridan_id": "fp0781",
        "position": 4,
        "track_id": 1,
        "slot_id": 17
      }
    },
    {
      "paper": {
        "hashed_id": "61b4a64be663682e8cb037d9719ad8cd",
        "title": "The Viability of Crowdsourcing for RAG Evaluation",
        "abstract": "How good are humans at writing and judging responses in retrieval-augmented generation (RAG) scenarios? To answer this question, we investigate the efficacy of crowdsourcing for RAG through two complementary studies: response writing and response utility judgment. Our new Webis Crowd RAG Corpus 2025 (Webis-CrowdRAG-25) consists of 903 human-written and 903 LLM-generated responses for the 301 topics of the TREC 2024 RAG~track, with each response composed according to one of the three discourse styles `bullet list`, `essay`, or `news`. For a selection of 65 topics, the corpus further contains 47,320 pairwise human judgments and 10,556 pairwise LLM judgments across seven utility dimensions (e.g., coverage and coherence). Our analyses give insights into human writing behavior for RAG and the viability of crowdsourcing for RAG evaluation. We find that human pairwise judgments provide reliable and cost-effective results. This is much less the case for LLM-based pairwise and human/LLM-based pointwise judgments, nor for automated comparisons with human-written reference responses. All our data and tools are freely available.",
        "doi": "10.1145/3726302.3730093",
        "sheridan_id": "fp0786",
        "position": 2,
        "track_id": 1,
        "slot_id": 25
      }
    },
    {
      "paper": {
        "hashed_id": "3621f1454cacf995530ea53652ddf8fb",
        "title": "Hypencoder: Hypernetworks for Information Retrieval",
        "abstract": "Existing information retrieval systems are largely constrained by their reliance on vector inner products to assess query-document relevance, which naturally limits the expressiveness of the relevance score they can produce. We propose a new paradigm; instead of representing a query as a vector, we use a small neural network that acts as a learned query-specific relevance function. This small neural network takes a document representation as input (in this work we use a single vector) and produces a scalar relevance score. To produce the small neural network we use a hypernetwork, a network that produces the weights of other networks, as our query encoder. We name this category of encoder models Hypencoders. Experiments on in-domain search tasks show that Hypencoders significantly outperform strong dense retrieval models and even surpass reranking models and retrieval models with an order of magnitude more parameters. To assess the extent of Hypencoders` capabilities, we evaluate on a set of hard retrieval tasks including tip-of-the-tongue and instruction-following retrieval tasks. On harder tasks, we find that the performance gap widens substantially compared to standard retrieval tasks. Furthermore, to demonstrate the practicality of our method, we implement an approximate search algorithm and show that our model is able to retrieve from a corpus of 8.8M documents in under 60 milliseconds.",
        "doi": "10.1145/3726302.3729983",
        "sheridan_id": "fp0787",
        "position": 5,
        "track_id": 1,
        "slot_id": 12
      }
    },
    {
      "paper": {
        "hashed_id": "35cf8659cfcb13224cbd47863a34fc58",
        "title": "Efficient Recommendation with Millions of Items by Dynamic Pruning of Sub-Item Embeddings",
        "abstract": "A large item catalogue is a major challenge for deploying modern sequential recommender models, since it makes the memory footprint of the model large and increases inference latency. One promising approach to address this is RecJPQ, which replaces item embeddings with sub-item embeddings. However, slow inference remains problematic because finding the top highest-scored items usually requires scoring all items in the catalogue, which may not be feasible for large catalogues. By adapting dynamic pruning concepts from document retrieval, we propose the RecJPQPrune dynamic pruning algorithm to efficiently find the top highest-scored items without computing the scores of all items in the catalogue. Our RecJPQPrune algorithm is safe-up-to-rank K since it theoretically guarantees that no potentially high-scored item is excluded from the final top K recommendation list, thereby ensuring no impact on effectiveness. Our experiments on two large datasets and three recommendation models demonstrate the efficiency achievable using RecJPQPrune: for instance, on the Tmall dataset with 2.2M items, we can reduce the median model scoring time by 64\u00d7 compared to the Transformer Default baseline, and 5.3\u00d7 compared to a recent scoring approach called PQTopK. Overall, this paper demonstrates the effective and efficient inference of Transformer-based recommendation models at catalogue scales not previously reported in the literature. Indeed, our RecJPQPrune algorithm can score 2 million items in under 10 milliseconds without GPUs, and without relying on Approximate Nearest Neighbour (ANN) techniques.",
        "doi": "10.1145/3726302.3729963",
        "sheridan_id": "fp0796",
        "position": 2,
        "track_id": 1,
        "slot_id": 1
      }
    },
    {
      "paper": {
        "hashed_id": "9e3cfc48eccf81a0d57663e129aef3cb",
        "title": "Highly Efficient Disk-based Nearest Neighbor Search on Extended Neighborhood Graph",
        "abstract": "Nearest neighbor search (NN search) plays a fundamental role in many disciplines. According to recent studies, graph-based search methods show superior performance over other types of methods. In order to accommodate the high dimensionality as well as the growing data-scale, the disk-based NN search in which the index graph and the full-precision vectors are kept in SSD has become a promising direction. This paper optimizes the disk-based NN search from three perspectives. Firstly, an eXtended Neighborhood Graph (XN-Graph) structure is proposed. In contrast to the existing index graphs, the out-edges of the graph neighborhood are collected from much wider coverage of the data space. It therefore reduces the number of hops during NN search, which in turn reduces the search latency. Additionally, a dataset partitioning method called Boundary-adaptive Balanced Partition is proposed to facilitate the graph construction in cases where the system cannot handle large datasets in a single round. Moreover, an efficient hybrid NN search method called In-Memory First Search is proposed. Compared to the existing methods, it considerably reduces the CPU idle times. With the support of XN-Graph, it shows 1.5-3 times lower search latency than SOTA methods. On billion-scale datasets, its QPS is still above 4000 when Recall@10 is as high as 0.9.",
        "doi": "10.1145/3726302.3729996",
        "sheridan_id": "fp0798",
        "position": 6,
        "track_id": 1,
        "slot_id": 33
      }
    },
    {
      "paper": {
        "hashed_id": "846c260d715e5b854ffad5f70a516c88",
        "title": "Retrieval Augmented Generation with Collaborative Filtering for Personalized Text Generation",
        "abstract": "Recently, the personalization of Large Language Models (LLMs) to generate content that aligns with individual user preferences has garnered widespread attention. Personalized Retrieval-Augmented Generation (RAG), which retrieves relevant documents from the user`s history to reflect their preferences and enhance LLM generation, is one commonly used approach for personalization. However, existing personalized RAG methods do not consider that the histories of similar users can also assist in personalized generation for the current user, meaning that collaborative information between users can also benefit personalized generation. Inspired by the application of collaborative filtering in recommender systems, we propose a method called CFRAG, which adapts Collaborative Filtering to RAG for personalized text generation. However, this presents two challenges: (1) how to incorporate collaborative information without explicit user similarity labels? (2) how to retrieve documents that support personalized LLM generation? For Challenge 1, we use contrastive learning to train user embeddings to retrieve similar users and introduce collaborative information. For Challenge 2, we design a personalized retriever and reranker to retrieve the top-?? documents from these users` histories. We take into account the user`s preference during retrieval and reranking. Then we leverage feedback from the LLM to fine-tune the personalized retriever and reranker, enabling them to retrieve documents that meet the personalized generation needs of the LLM. Experimental results on the Language Model Personalization (LaMP) benchmark validate the effectiveness of CFRAG. Further analysis confirms the importance of incorporating collaborative information.",
        "doi": "10.1145/3726302.3730075",
        "sheridan_id": "fp0805",
        "position": 6,
        "track_id": 1,
        "slot_id": 3
      }
    },
    {
      "paper": {
        "hashed_id": "6e7b33fdea3adc80ebd648fffb665bb8",
        "title": "Adaptive Graph Integration for Cross-Domain Recommendation via Heterogeneous Graph Coordinators",
        "abstract": "In the digital era, users typically interact with diverse items across multiple domains (e.g., e-commerce, streaming platforms, and social networks), generating intricate heterogeneous interaction graphs. Leveraging multi-domain data can improve recommendation systems by enriching user insights and mitigating data sparsity in individual domains. However, integrating such multi-domain knowledge for cross-domain recommendation remains challenging due to inherent disparities in user behavior and item characteristics and the risk of negative transfer, where irrelevant or conflicting information from the source domains adversely impacts the target domain`s performance. To tackle these challenges, we propose HAGO, a novel framework with Heterogeneous Adaptive Graph coOrdinators, which dynamically integrates multi-domain graphs into a cohesive structure. HAGO adaptively adjusts the connections between coordinators and multi-domain graph nodes to enhance beneficial inter-domain interactions while alleviating negative transfer. Furthermore, we introduce a universal multi-domain graph pre-training strategy alongside HAGO to collaboratively learn high-quality node representations across domains. Being compatible with various graph-based models and pre-training techniques, HAGO demonstrates broad applicability and effectiveness. Extensive experiments show that our framework outperforms state-of-the-art methods in cross-domain recommendation scenarios, underscoring its potential for real-world applications. The source code is available at https://github.com/zhy99426/HAGO.",
        "doi": "10.1145/3726302.3729886",
        "sheridan_id": "fp0807",
        "position": 5,
        "track_id": 1,
        "slot_id": 34
      }
    },
    {
      "paper": {
        "hashed_id": "b75bd27b5a48a1b48987a18d831f6336",
        "title": "Advancing Chichewa IR",
        "abstract": "Malawi is home to over ten local languages, including Chichewa, yet many of these languages lack both printed and digital resources. Consequentially, access to information in these languages is limited, and this hinders knowledge sharing, which may potentially impact socio-economic development. In this paper, we discuss our work on developing language resources and tools for Chichewa. We begin by providing an overview of the Chichewa language, and highlight its inherent complexities that require new approaches to informa tion retrieval (IR) and natural language processing (NLP). We then present our past, current, and ongoing research and conclude with future directions. Our goal is to engage with the IR community to discuss how we can advance IR for low resource languages (LRLs) like Chichewa.",
        "doi": "10.1145/3726302.3730272",
        "sheridan_id": "lr2634",
        "position": 1,
        "track_id": 9,
        "slot_id": 26
      }
    },
    {
      "paper": {
        "hashed_id": "670e8a43b246801ca1eaca97b3e19189",
        "title": "Towards Brain Passage Retrieval: An Investigation of EEG Query Representations",
        "abstract": "Information Retrieval (IR) systems primarily rely on users` ability to translate their internal information needs into (text) queries. However, this translation process is often uncertain and cognitively demanding, leading to queries that incompletely or inaccurately represent users` true needs. This challenge is particularly acute for users with ill-defined information needs or physical impairments that limit traditional text input, where the gap between cognitive intent and query expression becomes even more pronounced. Recent neuroscientific studies have explored Brain-Machine Interfaces (BMIs) as a potential solution, aiming to bridge the gap between users` cognitive semantics and their search intentions. However, current approaches attempting to decode explicit text queries from brain signals have shown limited effectiveness in learning robust brain-to-text representations, often failing to capture the nuanced semantic information present in brain patterns. To address these limitations, we propose BPR -Brain Passage Retrieval, a novel framework that eliminates the need for intermediate query translation by enabling direct retrieval of relevant passages from users` brain signals. Our approach leverages dense retrieval architectures to map EEG signals and text passages into a shared semantic space. Through comprehensive experiments on the ZuCo dataset, we demonstrate that BPR achieves up to 8.81% improvement in precision@5 over existing EEG-to-text baselines, while maintaining effectiveness across 30 participants. Our ablation studies reveal the critical role of hard negative sampling and specialised brain encoders in achieving robust cross-modal alignment. These results establish the viability of direct brain-to-passage retrieval and provide a foundation for developing more natural interfaces between users` cognitive states and IR systems.",
        "doi": "10.1145/3726302.3730097",
        "sheridan_id": "fp0811",
        "position": 4,
        "track_id": 1,
        "slot_id": 9
      }
    },
    {
      "paper": {
        "hashed_id": "4558dbb6f6f8bb2e16d03b85bde76e2c",
        "title": "Lightweight and Direct Document Relevance Optimization for Generative Information Retrieval",
        "abstract": "Generative information retrieval (GenIR) is a promising neural retrieval paradigm that formulates document retrieval as a document identifier (docid) generation task, allowing for end-to-end optimization toward a unified global retrieval objective. However, existing GenIR models suffer from token-level misalignment, where models trained to predict the next token often fail to capture document-level relevance effectively. While reinforcement learning-based methods, such as reinforcement learning from relevance feedback (RLRF), aim to address this misalignment through reward modeling, they introduce significant complexity, requiring the optimization of an auxiliary reward function followed by reinforcement fine-tuning, which is computationally expensive and often unstable. To address these challenges, we propose direct document relevance optimization (DDRO), which aligns token-level docid generation with document-level relevance estimation through direct optimization via pairwise ranking, eliminating the need for explicit reward modeling and reinforcement learning. Experimental results on benchmark datasets, including MS MARCO document and Natural Questions, show that DDRO outperforms reinforcement learning-based methods, achieving a 7.4% improvement in MRR@10 for MS MARCO and a 19.9% improvement for Natural Questions. These findings highlight DDRO\u2019s potential to enhance retrieval effectiveness with a simplified optimization approach. By framing alignment as a direct optimization problem, DDRO simplifies the ranking optimization pipeline of GenIR models while offering a viable alternative to reinforcement learning-based methods",
        "doi": "10.1145/3726302.3730023",
        "sheridan_id": "fp0821",
        "position": 1,
        "track_id": 1,
        "slot_id": 23
      }
    },
    {
      "paper": {
        "hashed_id": "632cee946db83e7a52ce5e8d6f0fed35",
        "title": "Unsupervised Corpus Poisoning Attacks in Continuous Space for Dense Retrieval",
        "abstract": "This paper concerns corpus poisoning attacks in dense information retrieval, where an adversary attempts to compromise the ranking performance of a search algorithm by injecting a small number of maliciously generated documents into the corpus. Our work addresses two limitations in the current literature. First, attacks that perform adversarial gradient-based word substitution search do so in the discrete lexical space, while retrieval itself happens in the continuous embedding space. We thus propose an optimization method that operates in the embedding space directly. Specifically, we train a perturbation model with the objective of maintaining the geometric distance between the original and adversarial document embeddings, while also maximizing the token-level dissimilarity between the original and adversarial documents. Second, it is common for related work to have a strong assumption that the adversary has prior knowledge about the queries. In this paper, we focus on a more challenging variant of the problem where the adversary assumes no prior knowledge about the query distribution (hence, unsupervised). Our core contribution is an adversarial corpus attack that is fast and effective. We present comprehensive experimental results on both in- and out-of-domain datasets,  focusing on two related tasks: a top-1 attack and a corpus poisoning attack. We consider attacks under both a white-box and a black-box setting. Notably, our method can generate successful adversarial examples in under two minutes per target document; four times faster compared to the fastest gradient-based word substitution methods in the literature with the same hardware. Furthermore, our adversarial generation method generates text that is more likely to occur under the distribution of natural text (low perplexity), and is therefore more difficult to detect.",
        "doi": "10.1145/3726302.3730110",
        "sheridan_id": "fp0823",
        "position": 4,
        "track_id": 1,
        "slot_id": 19
      }
    },
    {
      "paper": {
        "hashed_id": "8f7d807e1f53eff5f9efbe5cb81090fb",
        "title": "MINTT: Memory Inductive Transfer for Temporal Graph Neural Networks",
        "abstract": "Interactions between entities are often time-dependent in real-world systems such as e-commerce, social networks, streaming platforms, finance, and healthcare, and are best modeled as temporal interaction graphs. The temporal dimension plays a crucial role in modern recommendation systems, which rely on future link predictions. Temporal Graph Neural Networks (TGNN) have demonstrated state-of-the-art performance in future link prediction tasks for temporal interaction graphs. However, these models often require substantial training data unavailable in real-world settings. A potential solution to data scarcity is model pre-training on semantically related datasets. Unfortunately, transferring the TGNN model from one dataset to another is not trivial, as it contains node-specific memory modules vital for performance, resulting in them being inherently non-transferable. To overcome this limitation, we propose a novel transfer method that effectively utilizes common attributes between source and target datasets by decoupling graph nodes and corresponding attributes via bipartite encoding. This decoupling facilitates the transfer of memories and other inductive biases from source datasets to a target dataset. We evaluate the proposed transfer technique on real-world datasets and establish that it improves the performance of TGNN on the target dataset by 56% compared to the no-transfer methods and 36% over the state-of-the-art baselines in data-scarce settings.",
        "doi": "10.1145/3726302.3730035",
        "sheridan_id": "fp0839",
        "position": 2,
        "track_id": 1,
        "slot_id": 20
      }
    },
    {
      "paper": {
        "hashed_id": "fc49306d97602c8ed1be1dfbf0835ead",
        "title": "A New HOPE: Domain-agnostic Automatic Evaluation of Text Chunking",
        "abstract": "Document chunking fundamentally impacts Retrieval-Augmented Generation (RAG) by determining how source materials are segmented before indexing. Despite evidence that Large Language Models (LLMs) are sensitive to the layout and structure of retrieved data, there is currently no framework to analyze the impact of different chunking methods. In this paper, we introduce a novel methodology that defines essential characteristics of the chunking process at three levels: intrinsic passage properties, extrinsic passage properties, and passages-document coherence. We propose HOPE (Holistic Passage Evaluation), a domain-agnostic, automatic evaluation metric that quantifies and aggregates these characteristics. Our empirical evaluations across seven domains demonstrate that the HOPE metric correlates significantly (p > 0.13) with various RAG performance indicators, revealing contrasts between the importance of extrinsic and intrinsic properties of passages. Semantic independence between passages proves essential for system performance with a performance gain of up to 56.2% in factual correctness and 21.1% in answer correctness. On the contrary, traditional assumptions about maintaining concept unity within passages show minimal impact. These findings provide actionable insights for optimizing chunking strategies, thus improving RAG system design to produce more factually correct responses.",
        "doi": "10.1145/3726302.3729882",
        "sheridan_id": "fp0860",
        "position": 3,
        "track_id": 1,
        "slot_id": 25
      }
    },
    {
      "paper": {
        "hashed_id": "1fc214004c9481e4c8073e85323bfd4b",
        "title": "CSRec: Rethinking Sequential Recommendation from A Causal Perspective.",
        "abstract": "The essence of sequential recommender systems (RecSys) lies in understanding how users make decisions. Most existing approaches frame the task as sequential prediction based on users` historical purchase records. Although effective in capturing users` natural preferences, this formulation falls short in accurately modeling actual recommendation scenarios, particularly in accounting for how unsuccessful recommendations influence future purchases. Furthermore, the impact of the RecSys itself on users` decisions has not been appropriately isolated and quantitatively analyzed. To address these challenges, we propose a novel formulation of sequential recommendation, called Causal Sequential Recommendation. Instead of merely predicting the next item in a sequence, CSRec distinguishes between a user`s natural preference and their actual purchasing decision. It predicts both aspects within a sequential context and traces how current decisions are formed and causally influenced by various factors. Applying such a causal framework can isolate the impact of recommender systems on user decisions, thereby opening new avenues for evaluation and design. This includes assessing how different strategies influence users` trust in the system and determining the optimal recommender system to maximize advertising benefits. CSRec can be seamlessly integrated into existing next-prediction-based methodologies. Experimental evaluations on both synthetic and real-world datasets demonstrate that the proposed implementation significantly improves upon state-of-the-art baselines.",
        "doi": "10.1145/3726302.3729940",
        "sheridan_id": "fp0864",
        "position": 3,
        "track_id": 1,
        "slot_id": 14
      }
    },
    {
      "paper": {
        "hashed_id": "22fb0cee7e1f3bde58293de743871417",
        "title": "A Generalised and Adaptable Reinforcement Learning Stopping Method",
        "abstract": "This paper presents a Technology Assisted Review (TAR) stopping approach based on Reinforcement Learning (RL). Previous such approaches offered limited control over stopping behaviour, such as fixing the target recall and tradeoff between preferring to maximise recall or cost. These limitations are overcome by introducing a novel RL environment, GRLStop, that allows a single model to be applied to multiple target recalls, balances the recall/cost tradeoff and integrates a classifier. Experiments were carried out on six benchmark datasets (CLEF e-Health datasets 2017-9, TREC Total Recall, TREC Legal and Reuters RCV1) at multiple target recall levels. Results showed that the proposed approach to be effective compared to multiple baselines in addition to offering greater flexibility.",
        "doi": "10.1145/3726302.3729879",
        "sheridan_id": "fp0870",
        "position": 3,
        "track_id": 1,
        "slot_id": 20
      }
    },
    {
      "paper": {
        "hashed_id": "51ef186e18dc00c2d31982567235c559",
        "title": "Towards Distribution Matching between Collaborative and Language Spaces for Generative Recommendation",
        "abstract": "Generative recommendation aims to learn the underlying generative process over the entire item set to produce recommendations for users. Although it leverages non-linear probabilistic models to surpass the limited modeling capacity of linear factor models, it is often constrained by a trade-off between representation ability and tractability. With the rise of a new generation of generative methods based on pre-trained language models (LMs), incorporating LMs into general recommendation with implicit feedback has gained considerable attention. However, adapting them to generative recommendation remains challenging. The core reason lies in the mismatch between the input-output formats and semantics of generative models and LMs, making it challenging to achieve optimal alignment in the feature space. This work addresses this issue by proposing a model-agnostic generative recommendation framework called DMRec, which introduces a probabilistic meta-network to bridge the outputs of LMs with user interactions, thereby enabling an equivalent probabilistic modeling process. Subsequently, we design three cross-space distribution matching processes aimed at maximizing shared information while preserving the unique semantics of each space and filtering out irrelevant information.   We apply DMRec to three different types of generative recommendation methods and conduct extensive experiments on three public datasets. The experimental results demonstrate that DMRec can effectively enhance the recommendation performance of these generative models, and it shows significant advantages over mainstream LM-enhanced recommendation methods.",
        "doi": "10.1145/3726302.3730098",
        "sheridan_id": "fp0874",
        "position": 6,
        "track_id": 1,
        "slot_id": 37
      }
    },
    {
      "paper": {
        "hashed_id": "4b0a59ddf11c58e7446c9df0da541a84",
        "title": "Continual Text-to-Video Retrieval with Frame Fusion and Task-Aware Routing",
        "abstract": "Text-to-Video Retrieval (TVR) aims to retrieve relevant videos based on textual queries. However, as video content evolves continuously, adapting TVR systems to new data remains a critical yet under-explored challenge. In this paper, we introduce the first benchmark for Continual Text-to-Video Retrieval (CTVR) to address the limitations of existing approaches. Current Pre-Trained Model (PTM)-based TVR methods struggle with maintaining model plasticity when adapting to new tasks, while existing Continual Learning (CL) methods suffer from catastrophic forgetting, leading to semantic misalignment between historical queries and stored video features. To address these two challenges, we propose FrameFusionMoE, a novel CTVR framework that comprises two key components: (1) the Frame Fusion Adapter (FFA), which captures temporal video dynamics while preserving model plasticity, and (2) the Task-Aware Mixture-of-Experts (TAME), which ensures consistent semantic alignment between queries across tasks and the stored video features. Thus, FrameFusionMoE enables effective adaptation to new video content while preserving historical text-video relevance to mitigate catastrophic forgetting. We comprehensively evaluate FrameFusionMoE on two benchmark datasets under various task settings. Results demonstrate that FrameFusionMoE outperforms existing CL and TVR methods, achieving superior retrieval performance with minimal degradation on earlier tasks when handling continuous video streams. Our code is available at: https://github.com/JasonCodeMaker/CTVR",
        "doi": "10.1145/3726302.3729936",
        "sheridan_id": "fp0875",
        "position": 6,
        "track_id": 1,
        "slot_id": 5
      }
    },
    {
      "paper": {
        "hashed_id": "67d16d00201083a2b118dd5128dd6f59",
        "title": "Collaborative Diffusion Models for Recommendation",
        "abstract": "Recently, recommendation models based on collaborative filtering have increasingly leveraged not only primary user-item interactions but also auxiliary information such as implicit relational structures (e.g., user-user or item-item graphs) and multimodal content (e.g., images and textual descriptions) to enhance recommendation performance. A key challenge in this context lies in effectively integrating auxiliary features derived from semantic structures or modality representations into user-item modeling, in a way that enhance performance without incurring detrimental effects. Furthermore, since these features often originate from heterogeneous semantic or modal spaces, they may include redundant or task-irrelevant information that can hinder the learning process. To address these issues, we propose the Collaborative Diffusion Models for Recommendation (CoDMR). CoDMR employs diffusion models in latent feature spaces to filter out task-irrelevant noise embedded in auxiliary features. It introduces task-relevant collaborative signals as conditional guidance during the denoising process, facilitating the generation of auxiliary representations aligned with the recommendation task. These refined features are then incorporated into user-item interaction modeling, resulting in enhanced representations for both users and items. Extensive experiments on three public datasets consistently demonstrate that our CoDMR method outperforms various competitive baselines. The source code of the model implementation is available at the link https://github.com/cmr123456/CoDMR.",
        "doi": "10.1145/3726302.3729929",
        "sheridan_id": "fp0876",
        "position": 3,
        "track_id": 1,
        "slot_id": 37
      }
    },
    {
      "paper": {
        "hashed_id": "d56b9fc4b0f1be8871f5e1c40c0067e7",
        "title": "Advancing Ship Re-Identification in the Wild: The ShipReID-2400 Benchmark Dataset and D2InterNet Baseline Method",
        "abstract": "Ship Re-Identification (ReID) aims to accurately identify ships with the same identity across different times and camera views, playing a crucial role in intelligent waterway transportation. However, compared to the widely researched pedestrian and vehicle ReID, Ship ReID has received much less attention, primarily due to the scarcity of large-scale and high-quality ship ReID datasets available for public access. Moreover, several unique challenges make ship ReID particularly difficult: ships are large objects that are hard to capture fully, and the visible area of ships vary significantly due to changes in cargo loading or water surface conditions.These challenges make it difficult to achieve ideal results by directly applying existing ReID methods. To address these challenges, in this paper, we introduce \\textit{ShipReID-2400}, a dataset for ship ReID compiled from a real-world intelligent waterway traffic monitoring system. It comprises 17,241 images of 2,400 distinct ship identities collected over 53 months, ensuring diversity and representativeness. Furthermore, we propose the Disentangle-to-Interact Network (\\textit{D2InterNet}), a simple but strong baseline for ship ReID designed to extract discriminative local features despite significant scale variations. Extensive experimental results show that D2InterNet achieves state-of-the-art performance on both the ShipReID-2400 and VesselReID datasets. In addition, despite being designed for ship ReID, D2InterNet also achieves competitive results on the MSMT17 pedestrian ReID dataset, showcasing its good generalization capability. Our dataset and code are publicly available at \\url{https://github.com/HuiGuanLab/ShipReID-2400}.",
        "doi": "10.1145/3726302.3729892",
        "sheridan_id": "fp0893",
        "position": 3,
        "track_id": 1,
        "slot_id": 41
      }
    },
    {
      "paper": {
        "hashed_id": "20aee3a5f4643755a79ee5f6a73050ac",
        "title": "Disentangled Graph Debiasing for Next POI Recommendation",
        "abstract": "Graph neural networks play a pivotal role in various location-based applications, showcasing their compelling ability to capture collaborative signals across user check-in sequences. Recent advancements in next POI recommendation have further leveraged spatio-temporal graphs to uncover the transitional and geographical regularities. However, these methods are usually vulnerable due to the presence of data biases in real-life scenarios, which may mislead the model to disproportionately favoring certain POIs. To this end, this paper proposes a new graph debiasing paradigm for POI recommendation, which disentangles causal and bias knowledge within spatio-temporal graphs, allowing for not only the mitigation of bias issues, but also the utilization of causal information from spatial and temporal perspectives. Specifically, to facilitate graph debiasing at its topological level, an adaptive edge mask generator is first designed to explicitly decompose an entangled graph into causal and bias subgraphs. We encourage the stable relationships between the causal subgraph and the prediction, while the bias subgraph targets at the skewed bias distribution. We further enhance the independence between such two parts by employing a causal-bias disagreement regularization to encourage their distribution in separate semantic spaces. In addition, an inter-view contrastive learning module is also applied to maintain the relation discriminability of transitional and geographical representations. Extensive experiments on three real-world datasets demonstrate the superiority of our proposed model on recommendation performance, as well as its robustness against data bias.",
        "doi": "10.1145/3726302.3729952",
        "sheridan_id": "fp0895",
        "position": 5,
        "track_id": 1,
        "slot_id": 17
      }
    },
    {
      "paper": {
        "hashed_id": "f47d0ad31c4c49061b9e505593e3db98",
        "title": "InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction Graphs for LLM-Based Task Planning",
        "abstract": "Recent advancements in large language models (LLMs) have enabled their use as agents for planning complex tasks. Existing methods typically rely on a thought-action-observation (TAO) process to enhance LLM performance, but these approaches are often constrained by the LLMs` limited knowledge of complex tasks. Retrieval-augmented generation (RAG) offers new opportunities by leveraging external databases to ground generation in retrieved information. In this paper, we identify two key challenges (enlargability and transferability) in applying RAG to task planning. We propose InstructRAG, a novel solution within a multi-agent meta-reinforcement learning framework, to address these challenges. InstructRAG includes a graph to organize past instruction paths (sequences of correct actions), an RL-Agent with Reinforcement Learning to expand graph coverage for enlargability, and an ML-Agent with Meta-Learning to improve task generalization for transferability. The two agents are trained end-to-end to optimize overall planning performance. Our experiments on four widely used task planning datasets demonstrate that InstructRAG significantly enhances performance and adapts efficiently to new tasks, achieving up to a 19.2% improvement over the best existing approach.",
        "doi": "10.1145/3726302.3730009",
        "sheridan_id": "fp0904",
        "position": 3,
        "track_id": 1,
        "slot_id": 40
      }
    },
    {
      "paper": {
        "hashed_id": "23ce1851341ec1fa9e0c259de10bf87c",
        "title": "Multi-Grained Patch Training for Efficient LLM-based Recommendation",
        "abstract": "Large Language Models (LLMs) have emerged as a new paradigm for recommendation by converting interacted item history into language modeling. However, constrained by the limited context length of LLMs, existing approaches have to truncate item history in the prompt, focusing only on recent interactions and sacrificing the ability to model long-term history. To enable LLMs to model long histories, we pursue a concise embedding representation for items and sessions. In the LLM embedding space, we construct an item`s embedding by aggregating its textual token embeddings; similarly, we construct a session`s embedding by aggregating its item embeddings. While efficient, this way poses two challenges since it ignores the temporal significance of user interactions and LLMs do not natively interpret our custom embeddings. To overcome these, we propose PatchRec, a multi-grained patch training method consisting of two stages: (1) Patch Pre-training, which familiarizes LLMs with aggregated embeddings -- patches, and (2) Patch Fine-tuning, which enables LLMs to capture time-aware significance in interaction history. Extensive experiments show that PatchRec effectively models longer behavior histories with improved efficiency. This work facilitates the practical use of LLMs for modeling long behavior histories.",
        "doi": "10.1145/3726302.3730042",
        "sheridan_id": "fp0916",
        "position": 4,
        "track_id": 1,
        "slot_id": 14
      }
    },
    {
      "paper": {
        "hashed_id": "6d0f846348a856321729a2f36734d1a7",
        "title": "Bridge the Domains: Large Language Models Enhanced Cross-domain Sequential Recommendation",
        "abstract": "Cross-domain Sequential Recommendation (CDSR) aims to extract the preference from the user`s historical interactions across various domains. Despite some progress in CDSR, two problems set the barrier for further advancements, i.e., overlap dilemma and transition complexity. The former means existing CDSR methods severely rely on users who own interactions on all domains to learn cross-domain item relationships, compromising the practicability. The latter refers to the difficulties in learning the complex transition patterns from the mixed behavior sequences. With powerful representation and reasoning abilities, Large Language Models (LLMs) are promising to address these two problems by bridging the items and capturing the user`s preferences from a semantic view. Therefore, we propose an LLMs Enhanced Cross-domain Sequential Recommendation model (LLM4CDSR). To obtain the semantic item relationships, we first propose an LLM-based unified representation module to represent items. Then, a trainable adapter with contrastive regularization is designed to adapt the CDSR task. Besides, a hierarchical LLMs profiling module is designed to summarize user cross-domain preferences. Finally, these two modules are integrated into the proposed tri-thread framework to derive recommendations. We have conducted extensive experiments on three public cross-domain datasets, validating the effectiveness of LLM4CDSR. We have released the code online.",
        "doi": "10.1145/3726302.3729911",
        "sheridan_id": "fp0920",
        "position": 5,
        "track_id": 1,
        "slot_id": 14
      }
    },
    {
      "paper": {
        "hashed_id": "430c3626b879b4005d41b8a46172e0c0",
        "title": "Comprehending Knowledge Graphs with Large Language Models for Recommender Systems",
        "abstract": "In recent years, the introduction of knowledge graphs (KGs) has significantly advanced recommender systems by facilitating the discovery of potential associations between items. However, existing methods still face several limitations. First, most KGs suffer from missing facts or limited scopes. Second, existing methods convert textual information in KGs into IDs, resulting in the loss of natural semantic connections between different items. Third, existing methods struggle to capture high-order connections in the global KG. To address these limitations, we propose a novel method called CoLaKG, which leverages large language models (LLMs) to improve KG-based recommendations. The extensive knowledge and remarkable reasoning capabilities of LLMs enable our method to supplement missing facts in KGs, and their powerful text understanding abilities allow for better utilization of semantic information. Specifically, CoLaKG extracts useful information from KGs at both local and global levels. By employing the item-centered subgraph extraction and prompt engineering, it can accurately understand the local information. In addition, through the semantic-based retrieval module, each item is enriched by related items from the entire knowledge graph, effectively harnessing global information. Furthermore, the local and global information are effectively integrated into the recommendation model through a representation fusion module and a retrieval-augmented representation learning module, respectively. Extensive experiments on four real-world datasets demonstrate the superiority of our method.",
        "doi": "10.1145/3726302.3729932",
        "sheridan_id": "fp0921",
        "position": 8,
        "track_id": 1,
        "slot_id": 8
      }
    },
    {
      "paper": {
        "hashed_id": "b55ec28c52d5f6205684a473a2193564",
        "title": "Intent Representation Learning with Large Language Model for Recommendation",
        "abstract": "Intent-based recommender systems have garnered significant attention for uncovering latent fine-grained preferences. Intents, as underlying factors of interactions, are crucial for improving recommendation interpretability. Most methods define intents as learnable parameters updated alongside interactions. However, existing frameworks often overlook textual information (e.g., user reviews, item descriptions), which is crucial for alleviating the sparsity of interaction intents. Exploring these multimodal intents, especially the inherent differences in representation spaces, poses two key challenges: i) How to align multimodal intents and effectively mitigate noise issues; ii) How to extract and match latent key intents across modalities. To tackle these challenges, we propose a model-agnostic framework, Intent Representation Learning with Large Language Model (IRLLRec), which leverages large language models (LLMs) to construct multimodal intents and enhance recommendations. Specifically, IRLLRec employs a dual-tower architecture to learn multimodal intent representations. Next, we propose pairwise and translation alignment to eliminate inter-modal differences and enhance robustness against noisy input features. Finally, to better match textual and interaction-based intents, we employ momentum distillation to perform teacher-student learning on fused intent representations. Empirical evaluations on three datasets show that our IRLLRec framework outperforms baselines.",
        "doi": "10.1145/3726302.3730011",
        "sheridan_id": "fp0942",
        "position": 6,
        "track_id": 1,
        "slot_id": 34
      }
    },
    {
      "paper": {
        "hashed_id": "c4015b7f368e6b4871809f49debe0579",
        "title": "Hierarchical Intent-guided Optimization with Pluggable LLM-Driven Semantics for Session-based Recommendation",
        "abstract": "Session-based Recommendation (SBR) aims to predict the next item a user will likely engage with, using their interaction sequence within an anonymous session. Existing SBR models often focus only on single-session information, ignoring inter-session relationships and valuable cross-session insights. Some methods try to include inter-session data but struggle with noise and irrelevant information, reducing performance. Additionally, most models rely on item ID co-occurrence and overlook rich semantic details, limiting their ability to capture fine-grained item features. To address these challenges, we propose a novel hierarchical intent-guided optimization approach with pluggable LLM-driven semantic learning for session-based recommendations, called HIPHOP. First, we introduce a pluggable embedding module based on large language models (LLMs) to generate high-quality semantic representations, enhancing item embeddings. Second, HIPHOP utilizes graph neural networks (GNNs) to model item transition relationships and incorporates a dynamic multi-intent capturing module to address users` diverse interests within a session. Additionally, we design a hierarchical inter-session similarity learning module, guided by user intent, to capture global and local session relationships, effectively exploring users` long-term and short-term interests. To mitigate noise, an intent-guided denoising strategy is applied during inter-session learning. Finally, we enhance the model`s discriminative capability by using contrastive learning to optimize session representations. Experiments on multiple datasets show that HIPHOP significantly outperforms existing methods, demonstrating its effectiveness in improving recommendation quality. Our code is available: https://github.com/hjx159/HIPHOP.",
        "doi": "10.1145/3726302.3729994",
        "sheridan_id": "fp0923",
        "position": 5,
        "track_id": 1,
        "slot_id": 21
      }
    },
    {
      "paper": {
        "hashed_id": "bea5955b308361a1b07bc55042e25e54",
        "title": "Unveiling Contrastive Learning`s Capability of Neighborhood Aggregation for Collaborative Filtering",
        "abstract": "Personalized recommendation is widely used in the web applications, and graph contrastive learning (GCL) has gradually become a dominant approach in recommender systems, primarily due to its ability to extract self-supervised signals from raw interaction data, effectively alleviating the problem of data sparsity. A classic GCL-based method typically uses data augmentation during graph convolution to generates more contrastive views, and performs contrast on these new views to obtain rich self-supervised signals. Despite this paradigm is effective, the reasons behind the performance gains remain a mystery. In this paper, we first reveal via theoretical derivation that the gradient descent process of the CL objective is formally equivalent to graph convolution, which implies that CL objective inherently supports neighborhood aggregation on interaction graphs. We further substantiate this capability through experimental validation and identify common misconceptions in the selection of positive samples in previous methods, which limit the potential of CL objective. Based on this discovery, we propose the Light Contrastive Collaborative Filtering (LightCCF) method, which introduces a novel neighborhood aggregation objective to bring users closer to all interacted items while pushing them away from other positive pairs, thus achieving high-quality neighborhood aggregation with very low time complexity. On three highly sparse public datasets, the proposed method effectively aggregate neighborhood information while preventing graph over-smoothing, demonstrating significant improvements over existing GCL-based counterparts in both training efficiency and recommendation accuracy. Our implementations are publicly accessible.",
        "doi": "10.1145/3726302.3730111",
        "sheridan_id": "fp0924",
        "position": 4,
        "track_id": 1,
        "slot_id": 37
      }
    },
    {
      "paper": {
        "hashed_id": "9f53d83ec0691550f7d2507d57f4f5a2",
        "title": "Towards Accurate Social User Geolocation: Mean Shift, Incremental Learning and Graph Convolutional Networks",
        "abstract": "The geolocation of social users is crucial for understanding user behavior, optimizing advertisement placement, and enhancing public safety. However, existing methods tend to show some deficiencies when handling sparse datasets and may not fully capture the natural clustering characteristics of user locations, thereby resulting in inadequate geolocation accuracy. This paper proposes a novel social user geolocation method (MILGCN) that innovatively integrates Mean Shift Clustering, Incremental Learning, and Graph Convolutional Networks. Specifically, Mean Shift performs fine-grained clustering of user locations based on density peak characteristics, ensuring that geographically close users are grouped into the same cluster. Introducing an incremental learning mechanism into graph convolutional networks enables MILGCN to have progressive learning ability. As a result, the problem of incomplete feature extraction from sparse data is alleviated, resulting in more comprehensive user features and improved geolocation accuracy. Extensive experiments proved that the proposed method significantly outperforms the state-of-the-art baselines on the real Twitter datasets, demonstrating a substantial improvement in geolocation performance.",
        "doi": "10.1145/3726302.3730095",
        "sheridan_id": "fp0931",
        "position": 7,
        "track_id": 1,
        "slot_id": 4
      }
    },
    {
      "paper": {
        "hashed_id": "3df1d4b96d8976ff5986393e8767f5b2",
        "title": "Multi-Modal Multi-Behavior Sequential Recommendation with Conditional Diffusion-Based Feature Denoising",
        "abstract": "The sequential recommendation system utilizes historical user interactions to predict preferences. Effectively integrating diverse user behavior patterns with rich multimodal information of items to enhance the accuracy of sequential recommendations is an emerging and challenging research direction. This paper focuses on the problem of multi-modal multi-behavior sequential recommendation, aiming to address the following challenges: (1) the lack of effective characterization of modal preferences across different behaviors, as user attention to different item modalities varies depending on the behavior; (2) the difficulty of effectively mitigating implicit noise in user behavior, such as unintended actions like accidental clicks; (3) the inability to handle modality noise in multi-modal representations, which further impacts the accurate modeling of user preferences. To tackle these issues, we propose a novel Multi-Modal Multi-Behavior Sequential Recommendation model (M3BSR). This model first removes noise in multi-modal representations using a Conditional Diffusion Modality Denoising Layer. Subsequently, it utilizes deep behavioral information to guide the denoising of shallow behavioral data, thereby alleviating the impact of noise in implicit feedback through Conditional Diffusion Behavior Denoising. Finally, by introducing a Multi-Expert Interest Extraction Layer, M3BSR explicitly models the common and specific interests across behaviors and modalities to enhance recommendation performance. Experimental results indicate that M3BSR significantly outperforms existing state-of-the-art methods on benchmark datasets.",
        "doi": "10.1145/3726302.3730044",
        "sheridan_id": "fp0939",
        "position": 6,
        "track_id": 1,
        "slot_id": 14
      }
    },
    {
      "paper": {
        "hashed_id": "2f885d0fbe2e131bfc9d98363e55d1d4",
        "title": "Short Video Segment-level User Dynamic Interests Modeling in Personalized Recommendation",
        "abstract": "The rapid growth of short videos has necessitated effective recommender systems to match users with content tailored to their evolving preferences. Current video recommendation models primarily treat each video as a whole, overlooking the dynamic nature of user preferences with specific video segments. In contrast, our research focuses on segment-level user interest modeling, which is crucial for understanding how users` preferences evolve during video browsing. To capture users` dynamic segment interests, we propose an innovative model that integrates a hybrid representation module, a multi-modal user-video encoder, and a segment interest decoder. Our model addresses the challenges of capturing dynamic interest patterns, missing segment-level labels, and fusing different modalities, achieving precise segment-level interest prediction. We present two downstream tasks to evaluate the effectiveness of our segment interest modeling approach: video-skip prediction and short video recommendation. Our experiments on real-world short video datasets with diverse modalities show promising results on both tasks. It demonstrates that segment-level interest modeling brings a deep understanding of user engagement and enhances video recommendations. We also release a unique dataset that includes segment-level video data and diverse user behaviors, enabling further research in segment-level interest modeling. This work pioneers a novel perspective on understanding user segment-level preference, offering the potential for more personalized and engaging short video experiences.",
        "doi": "10.1145/3726302.3730083",
        "sheridan_id": "fp0943",
        "position": 7,
        "track_id": 1,
        "slot_id": 34
      }
    },
    {
      "paper": {
        "hashed_id": "4b6538a44a1dfdc2b83477cd76dee98e",
        "title": "Are Generative AI Agents Effective Personalized Financial Advisors?",
        "abstract": "Large language model-based agents are becoming increasingly popular as a low-cost mechanism to provide personalized, conversational advice, and have demonstrated impressive capabilities in relatively simple scenarios, such as movie recommendations. But how do these agents perform in complex high-stakes domains, where domain expertise is essential and mistakes carry substantial risk? This paper investigates the effectiveness of LLM-advisors in the finance domain, focusing on three distinct challenges: (1) eliciting user preferences when users themselves may be unsure of their needs, (2) providing personalized guidance for diverse investment preferences, and (3) leveraging advisor personality to build relationships and foster trust. Via a lab-based user study with 64 participants, we show that LLM-advisors often match human advisor performance when eliciting preferences, although they can struggle to resolve conflicting user needs. When providing personalized advice, the LLM was able to positively influence user behavior, but demonstrated clear failure modes. Our results show that accurate preference elicitation is key, otherwise, the LLM-advisor has little impact, or can even direct the investor toward unsuitable assets. More worryingly, users appear insensitive to the quality of advice being given, or worse these can have an inverse relationship. Indeed, users reported a preference for and increased satisfaction as well as emotional trust with LLMs adopting an extroverted persona, even though those agents provided worse advice.",
        "doi": "10.1145/3726302.3729897",
        "sheridan_id": "fp0945",
        "position": 8,
        "track_id": 1,
        "slot_id": 4
      }
    },
    {
      "paper": {
        "hashed_id": "ef4e3b775c934dada217712d76f3d51f",
        "title": "PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of applications, e.g., medical question-answering, mathematical sciences, and code generation. However, they also exhibit inherent limitations, such as outdated knowledge and susceptibility to hallucinations. Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to address these issues, but it also introduces new vulnerabilities. Recent efforts have focused on the security of RAG-based LLMs, yet existing attack methods face three critical challenges: (1) their effectiveness declines sharply when only a limited number of poisoned texts can be injected into the knowledge database, (2) they lack sufficient stealth, as the attacks are often detectable by anomaly detection systems, which compromises their effectiveness, and (3) they rely on heuristic approaches to generate poisoned texts, lacking formal optimization frameworks and theoretic guarantees, which limits their effectiveness and applicability. To address these issues, we propose coordinated Prompt-RAG attack (PR-attack), a novel optimization-driven attack that introduces a small number of poisoned texts into the knowledge database while embedding a backdoor trigger within the prompt. When activated, the trigger causes the LLM to generate pre-designed responses to targeted queries, while maintaining normal behavior in other contexts. This ensures both high effectiveness and stealth. We formulate the attack generation process as a bilevel optimization problem leveraging a principled optimization framework to develop optimal poisoned texts and triggers. Extensive experiments across diverse LLMs and datasets demonstrate the effectiveness of PR-Attack, achieving a high attack success rate even with a limited number of poisoned texts and significantly improved stealth compared to existing methods. These results highlight the potential risks posed by PR-Attack and emphasize the importance of securing RAG-based LLMs against such threats.",
        "doi": "10.1145/3726302.3730058",
        "sheridan_id": "fp0955",
        "position": 1,
        "track_id": 1,
        "slot_id": 16
      }
    },
    {
      "paper": {
        "hashed_id": "d79aac075930c83c2f1e369a511148fe",
        "title": "Heterogeneous Graph Embedding Made More Practical",
        "abstract": "Heterogeneous graphs are prevalent in the real-world applications, and a key analytical task for such graphs is heterogeneous graph embedding, which seeks to represent each heterogeneous graph as a low-dimensional feature vector while preserving its inherent heterogeneity. Although the traditional methods have achieved significant advancements, they predominantly rely on modeling basic pairwise relationships between nodes, limiting their ability to capture the intricate structures and interactions present in heterogeneous graphs. Recent studies have begun incorporating simplicial complexes, which effectively encode higher-order interactions, into the Graph Neural Network (GNN) framework. However, these GNN-based approaches are computationally intensive due to the substantial parameter training involved. To address these challenges, we propose HGSketch, a practical heterogeneous graph embedding algorithm that balances performance and temporal efficiency without the powerful workhorses. By leveraging the Locality Sensitive Hashing (LSH) technique, HGSketch efficiently captures higher-order information from simplicial complexes locally and globally without the need for parameter learning. The extensive experiment results display that HGSketch achieves performance comparable to the state-of-the-art learning-based methods, while significantly reducing runtime by a factor of up to 1223.86; also, HGSketch generally outperforms the state-of-the-art LSH-based methods. We have released the source code and the datasets in https://github.com/AIandBD/graph-hashing/tree/main/HGSketch.",
        "doi": "10.1145/3726302.3729993",
        "sheridan_id": "fp0980",
        "position": 4,
        "track_id": 1,
        "slot_id": 16
      }
    },
    {
      "paper": {
        "hashed_id": "358aee4cc897452c00244351e4d91f69",
        "title": "Small Data, Big Impact: Navigating Resource Limitations in Point-of-Interest Recommendation for Individuals with Autism",
        "abstract": "Autism Spectrum Disorder (ASD) affects sensory perception, making spatial exploration difficult. Recommender systems can assist ASD users by suggesting Points of Interest (POIs) aligned with their sensory preferences. However, demographic constraints, difficulties in engaging ASD users, and the complexity of obtaining sensory data position POI recommendation for ASD people as a low-resource problem. In this paper, we identify key challenges in developing such systems and present our ongoing efforts. Using a local ASD center as a use case, we are developing a structured user involvement protocol. From the limited data, we are deriving knowledge graphs (KGs) to model preferences and sensory aspects. We are then exploring KG-based techniques to generate paths from users to POIs to suggest. With psychologists, we are refining the paths structure to match varying complexity levels and translate them into natural language accessible for people with ASD.",
        "doi": "10.1145/3726302.3730269",
        "sheridan_id": "lr2659",
        "position": 5,
        "track_id": 9,
        "slot_id": 35
      }
    },
    {
      "paper": {
        "hashed_id": "fec8d47d412bcbeece3d9128ae855a7a",
        "title": "IVCR-200K: A Large-Scale Multi-turn Dialogue Benchmark for Interactive Video Corpus Retrieval",
        "abstract": "In recent years, significant developments have been made in both video retrieval and video moment retrieval tasks, which respectively retrieve complete videos or moments for a given text query. These advancements have greatly improved user satisfaction during the search process. However, previous work has failed to establish meaningful ``interaction`` between the retrieval system and the user, and its one-way retrieval paradigm can no longer fully meet the personalization and dynamic needs of at least 80.8% of users. In this paper, we introduce the Interactive Video Corpus Retrieval (IVCR) task, a more realistic setting that enables multi-turn, conversational, and realistic interactions between the user and the retrieval system. To facilitate research on this challenging task, we introduce IVCR-200K, a high-quality, bilingual, multi-turn, conversational, and abstract semantic dataset that supports video retrieval and even moment retrieval. Furthermore, we propose a comprehensive framework based on multi-modal large language models (MLLMs) to help users interact in several modes with more explainable solutions. The extensive experiments demonstrate the effectiveness of our dataset and framework. The datasets, codes, and leaderboards are available at: https://ivcr200k.github.io/IVCR.",
        "doi": "10.1145/3726302.3730015",
        "sheridan_id": "fp0982",
        "position": 5,
        "track_id": 1,
        "slot_id": 41
      }
    },
    {
      "paper": {
        "hashed_id": "df6d2338b2b8fce1ec2f6dda0a630eb0",
        "title": "MSL: Not All Tokens Are What You Need for Tuning LLM as a Recommender",
        "abstract": "Large language models (LLMs), known for their comprehension capabilities and extensive knowledge, have been increasingly applied to recommendation systems (RS). Given the fundamental gap between the mechanism of LLMs and the requirement of RS, researchers have focused on fine-tuning LLMs with recommendation-specific data to enhance their performance. Language Modeling Loss (LML),  originally designed for language generation tasks, is commonly adopted. However, we identify two critical limitations of LML: 1) it exhibits significant divergence from the recommendation objective; 2) it erroneously treats all fictitious item descriptions as negative samples, introducing misleading training signals.To address these limitations, we propose a novel \\textbf{Masked Softmax Loss (MSL)} tailored for fine-tuning LLMs on recommendation. MSL improves LML by identifying and masking invalid tokens that could lead to fictitious item descriptions during loss computation. This strategy can effectively avoid the interference from erroneous negative signals and ensure well alignment with the recommendation objective supported by theoretical guarantees. During implementation, we identify a potential challenge related to gradient vanishing of MSL. To overcome this, we further introduce the temperature coefficient and propose an \\textbf{Adaptive Temperature Strategy (ATS)} that adaptively adjusts the temperature without requiring extensive hyperparameter tuning. Extensive experiments conducted on four public datasets further validate the effectiveness of MSL, achieving an average improvement of 42.24\\% in NDCG@10. The code is available at \\url{https://github.com/WANGBohaO-jpg/MSL}.",
        "doi": "10.1145/3726302.3730041",
        "sheridan_id": "fp0987",
        "position": 3,
        "track_id": 1,
        "slot_id": 38
      }
    },
    {
      "paper": {
        "hashed_id": "934815ad542a4a7c5e8a2dfa04fea9f5",
        "title": "Enhancing New-item Fairness in Dynamic Recommender Systems",
        "abstract": "New-items play a crucial role in recommender systems (RSs) for delivering fresh and engaging user experiences. However, traditional methods struggle to effectively recommend new-items due to their short exposure time and limited interaction records, especially in dynamic recommender systems (DRSs) where new-items get continuously introduced and users` preferences evolve over time. This leads to significant unfairness towards new-items, which could accumulate over the successive model updates, ultimately compromising the stability of the entire system. Therefore, we propose FairAgent, a reinforcement learning (RL)-based new-item fairness enhancement framework specifically designed for DRSs. It leverages knowledge distillation to extract collaborative signals from traditional models, retaining strong recommendation capabilities for old-items. In addition, FairAgent introduces a novel reward mechanism for recommendation tailored to the characteristics of DRSs, which consists of three components: 1) a new-item exploration reward to promote the exposure of dynamically introduced new-items, 2) a fairness reward to adapt to users` personalized fairness requirements for new-items, and 3) an accuracy reward which leverages users` dynamic feedback to enhance recommendation accuracy. Extensive experiments on three public datasets and backbone models demonstrate the superior performance of FairAgent. The results present that FairAgent can effectively boost new-item exposure, achieve personalized new-item fairness, while maintaining high recommendation accuracy.",
        "doi": "10.1145/3726302.3729969",
        "sheridan_id": "fp0994",
        "position": 4,
        "track_id": 1,
        "slot_id": 15
      }
    },
    {
      "paper": {
        "hashed_id": "f22e4747da1aa27e363d86d40ff442fe",
        "title": "A Flexible Resource for Top-Weighted Comparisons Between Sets and Rankings",
        "abstract": "We describe rbstar a toolkit of software for carrying out  measurements when the goal is to determine how similar a system  observation is to a gold-standard reference output.  The resource covers all four combinations that arise when each of  observation and reference can be either an unordered finite set in  which element ordering is unimportant, or a finite prefix of an  arbitrarily long ranking in which early elements are more important  than later ones.  Specifically, the package realizes four ``rank-biased`` measurement  approaches that have been presented in a sequence of papers over a  15-year span, bringing them together into a single location with a  uniform interface and efficient reference implementations.  The provision of all of rank-biased precision, rank-biased overlap,  rank-biased recall, and rank-biased alignment, with the latter two  recent additions to the family, allows a wide range of measurement  scenarios to be handled in a consistent manner.",
        "doi": "10.1145/3726302.3730306",
        "sheridan_id": "rr1939",
        "position": 112,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "b706835de79a2b4e80506f582af3676a",
        "title": "CD-CDR: Conditional Diffusion-based Item Generation for Cross-Domain Recommendation",
        "abstract": "Cross-domain recommendation (CDR) has emerged as a promising direction for expanding the applicability of recommendation systems. Recent advances in CDR have demonstrated the effectiveness of the unified distribution paradigm, which leverages shared distributions to transfer knowledge across domains and employs domain-specific adapters for targeted recommendations. While this well-designed paradigm shows promising performance, existing methods require extra supervision signals (e.g. contrastive learning on domain-masked embeddings) to maintain unified distributions across domains, leading to an inherent trade-off between unified objectives and domain-specific preference modeling. To address these limitations, we propose CD-CDR (Conditional Diffusion-CDR), a novel approach that leverages a shared conditional diffusion model to learn unified item distributions and facilitate knowledge transfer across domains. The key insight is to utilize the powerful generative capabilities of diffusion models to learn a shared distribution while naturally incorporating domain-specific characteristics through conditional generation. This design enables CD-CDR to replace traditional adapters with generation conditions as an integral part of the distribution model, thereby eliminating extra supervision signals and fundamentally resolving the trade-off between unified and domain-specific objectives. Extensive experiments on six domain pairs from two real-world datasets demonstrate that CD-CDR significantly outperforms existing methods for both normal and cold-start settings. To the best of our knowledge, this is the first work to explore the unified distribution paradigm in CDR using conditional diffusion models.",
        "doi": "10.1145/3726302.3729918",
        "sheridan_id": "fp0999",
        "position": 6,
        "track_id": 1,
        "slot_id": 17
      }
    },
    {
      "paper": {
        "hashed_id": "fba9d88164f3e2d9109ee770223212a0",
        "title": "Gaming for Boundary: Elastic Localization for Frame-Supervised Video Moment Retrieval",
        "abstract": "Video moment retrieval aims to determine the temporal boundaries of moments within a video that are most relevant to textual queries. Unlike fully-supervised and weakly-supervised methods, frame-supervised methods use a single annotated frame to model the similarities between the target moment and queries. This task is still in its infancy due to the following challenges: 1) indiscernible intra-modal information and 2) inflexible inter-modal information interaction. In light of these challenges, we introduce the Gaming fOr elAstic Localization (GOAL) method for frame-supervised video moment retrieval. It enables target moment boundary localization from a novel strategic game perspective. GOAL encompasses two core components: a game-based paradigm to find the most reliable moment and a Dynamic Updating Technique (DUT) to continuously optimize moment retrieval through dynamic gradients, thereby refining boundary predictions with different feedback. Extensive experiments on Charades-STA, ActivityNet Captions, and TACoS have validated the effectiveness of GOAL.",
        "doi": "10.1145/3726302.3729984",
        "sheridan_id": "fp1002",
        "position": 5,
        "track_id": 1,
        "slot_id": 11
      }
    },
    {
      "paper": {
        "hashed_id": "08fe2621d8e716b02ec0da35256a998d",
        "title": "\u03bcDS: Multi-Objective Data Snippet Extraction for Dataset Search",
        "abstract": "With the continuous growth of open data on the Web, dataset search has become a prominent specialized retrieval problem to find datasets relevant to a query. Recent solutions rank datasets based on not only their metadata, but also data snippets extracted from their actual data. While the goodness of a data snippet has been studied from various aspects, in this paper we propose to, for the first time, jointly optimize compactness, relevance, representativeness, and cohesiveness in snippet extraction. To extract such multi-objective data snippets, we formulate a new combinatorial optimization problem and design an efficient algorithm with a proved worst-case approximation ratio. We evaluate the data snippets extracted by our algorithm intrinsically through a set of quality metrics and extrinsically by applying them to dataset search.",
        "doi": "10.1145/3726302.3730120",
        "sheridan_id": "fp1016",
        "position": 4,
        "track_id": 1,
        "slot_id": 41
      }
    },
    {
      "paper": {
        "hashed_id": "5d616dd38211ebb5d6ec52986674b6e4",
        "title": "Fair Recommendation with Biased-Limited Sensitive Attribute",
        "abstract": "Ensuring fair recommendations for users with different sensitive attributes is essential for building trustworthy recommender systems. A significant challenge in achieving this in the real world is that some users are unwilling to disclose their sensitive attributes, limiting the applicability of traditional approaches. Recent efforts have attempted to address this challenge by reconstructing sensitive attributes based on the observed data. However, the observed data often does not represent an unbiased sample of the true distribution, rendering the reconstructed results unreliable. Moreover, it is difficult to select a debiasing method to achieve unbiased reconstruction, due to lacking sufficient prior knowledge about the bias. This motivates us to develop new fairness approaches. This work proposes a new method, Multiple Prior-Guided Robust Optimization (MPR), to achieve fair recommendations under biased observations of sensitive attributes, without requiring real sensitive attribute distribution. MPR begins by estimating various potential distributions of sensitive attributes using multiple randomly set priors, and then ensures fairness by minimizing the worst-case unfairness across all estimations. Thus, MPR can ensure fairness optimization under the real distribution approximately once one of the estimates approaches the true distribution. Both theoretical and empirical evidence demonstrate that MPR effectively ensures fairness in recommender systems when sensitive attribute observations are limited and biased. The code and data are released at https://github.com/jizhi-zhang/MPR.",
        "doi": "10.1145/3726302.3729974",
        "sheridan_id": "fp1017",
        "position": 5,
        "track_id": 1,
        "slot_id": 15
      }
    },
    {
      "paper": {
        "hashed_id": "93d65641ff3f1586614cf2c1ad240b6c",
        "title": "ProtChatGPT: Towards Understanding Proteins with Hybrid Representation and Large Language Models",
        "abstract": "Protein research is crucial in various scientific disciplines, but understanding their intricate structure-function relationships remains challenging. Recent advancements in Large Language Models (LLMs) have significantly improved the comprehension of task-specific knowledge, suggesting the potential for specialized ChatGPT-like systems in protein research to aid fundamental investigations. In this work, we introduce ProtChatGPT, which aims to learn and understand protein structures using natural language.ProtChatGPT enables users to upload proteins, ask questions, and engage in interactive conversations to produce comprehensive answers. The system comprises multi-level protein encoding, protein-language alignment, and instruction tuning of LLMs. A protein first undergoes multiple protein encoders and PLP-former to produce multi-level hybrid protein embeddings, which are then aligned through a Protein Context Gating (PCG) module with contrastive learning, and projected by an adapter to conform with the LLM. The LLM finally combines user questions with projected protein embeddings to generate informative answers. Experiments show that ProtChatGPT can produce promising responses to proteins and the corresponding user questions. We hope that ProtChatGPT could form the basis for further exploration and application in protein research. Code and our pre-trained model will be publicly available.",
        "doi": "10.1145/3726302.3730064",
        "sheridan_id": "fp1022",
        "position": 5,
        "track_id": 1,
        "slot_id": 24
      }
    },
    {
      "paper": {
        "hashed_id": "a34bacf839b923770b2c360eefa26748",
        "title": "Leveraging Large Language Models for Effective Label-free Node Classification in Text-Attributed Graphs",
        "abstract": "Graph neural networks (GNNs) have become the preferred models for node classification in graph data due to their robust capabilities in integrating graph structures and attributes. However, these models heavily depend on a substantial amount of high-quality labeled data for training, which is often costly to obtain. With the rise of large language models (LLMs), a promising approach is to utilize their exceptional zero-shot capabilities and extensive knowledge for node labeling. Despite encouraging results, this approach either requires numerous queries to LLMs or suffers from reduced performance due to noisy labels generated by LLMs. To address these challenges, we introduce \\textbf{Locle}, an active self-training framework that does \\underline{\\textbf{L}}abel-free n\\underline{\\textbf{O}}de \\underline{\\textbf{C}}lassification with \\underline{\\textbf{L}}LMs cost-\\underline{\\textbf{E}}ffectively. Locle iteratively identifies small sets of \"critical\" samples using GNNs and extracts informative pseudo-labels for them with both LLMs and GNNs, serving as additional supervision signals to enhance model training. Specifically, Locle comprises three key components: (i) an effective active node selection strategy for initial annotations; (ii) a careful sample selection scheme to identify \"critical\" nodes based on label disharmonicity and entropy; and (iii) a label refinement module that combines LLMs and GNNs with a rewired topology. Extensive experiments on five benchmark text-attributed graph datasets demonstrate that Locle significantly outperforms state-of-the-art methods under the same query budget to LLMs in terms of label-free node classification. Notably, on the DBLP dataset with 14.3k nodes, Locle achieves an 8.08\\% improvement in accuracy over the state-of-the-art at a cost of less than one cent. Our code is available at \\url{https://github.com/HKBU-LAGAS/Locle}.",
        "doi": "10.1145/3726302.3730021",
        "sheridan_id": "fp1035",
        "position": 5,
        "track_id": 1,
        "slot_id": 16
      }
    },
    {
      "paper": {
        "hashed_id": "537d9b6c927223c796cac288cced29df",
        "title": "DAR: Dimension-Adaptive Recommendation with Multi-Granular Noise Control",
        "abstract": "Implicit feedback has become the primary source of training data for modern recommender systems due to its abundance and ease of collection. However, the inherent noise in implicit feedback poses significant challenges to model training. Existing denoising approaches either completely remove suspected noisy interactions (re-sampling) or uniformly adjust their importance (re-weighting). Such coarse-grained treatments fail to capture the complex nature of noise in real-world scenarios, where different aspects of an interaction may have varying noise levels.In this paper, we propose a novel perspective on fine-grained denoising. Our key insight is that noisy interactions often result from simple, impulsive decisions triggered by surface-level aspects and thus require less information to represent, while genuine preferences involve more complex considerations of aspects that need richer representations. Based on this insight, we propose DAR, a dimension-adaptive recommendation framework that dynamically adjusts each interaction`s representation dimension to achieve fine-grained denoising control (re-scaling). Grounded on the Information Bottleneck theory, we establish that this dimension-adaptive approach provides a principled solution for preserving useful signals while limiting noise propagation. DAR implements this theoretical insight through three key components: (1) multi-granular noise estimation that considers interaction-level, user-level, and item-level signals, (2) dimension adaptation that determines appropriate representation dimensions based on estimated noise levels, and (3) temporal smoothing that ensures stable training. Extensive experiments on real-world datasets demonstrate that DAR consistently outperforms state-of-the-art denoising methods, while providing interpretable insights about interaction noise. The source code is publicly available at https://github.com/Riwei-HEU/DAR.",
        "doi": "10.1145/3726302.3729941",
        "sheridan_id": "fp1040",
        "position": 5,
        "track_id": 1,
        "slot_id": 30
      }
    },
    {
      "paper": {
        "hashed_id": "4a08142c38dbe374195d41c04562d9f8",
        "title": "Efficient Re-ranking with Cross-encoders via Early Exit",
        "abstract": "Pre-trained language models based on transformer networks are highly effective for document re-ranking in ad-hoc search. Among these, cross-encoders stand out for their effectiveness, as they process query-document pairs through the entire transformer network to compute ranking scores. However, this traversal is computationally expensive. To address this, prior work has explored early-exit strategies, enabling the model to terminate the traversal of query-document pairs. These techniques rely on learned classifiers, placed after each transformer block, that decide if a query-document pair can be dropped. Diverging from previous approaches, we propose Similarity-based Early Exit (SEE), a novel\u2014non-learned\u2014strategy that exploits the similarities between query and document token embeddings to early-terminate the inference of documents that will most likely be non-relevant to the query. Even though SEE can be used after every transformer block, we show that the best advantage is achieved when applied before the first transformer block, thus saving most of the inference cost for the query-document pairs. Reproducible experiments on 17 public datasets covering in-domain and out-of-domain evaluation show that SEE can be effectively applied to four different cross-encoders, achieving speedups of up to 3.5\u00d7 with a limited loss in ranking effectiveness.",
        "doi": "10.1145/3726302.3729962",
        "sheridan_id": "fp1059",
        "position": 8,
        "track_id": 1,
        "slot_id": 33
      }
    },
    {
      "paper": {
        "hashed_id": "522a9ae9a99880d39e5daec35375e999",
        "title": "An Empirical Study of Evaluating Long-form Question Answering",
        "abstract": "\\Ac{LFQA} aims to generate lengthy answers to complex questions. This scenario presents great flexibility as well as significant challenges for evaluation. Most evaluations rely on deterministic metrics that depend on string or n-gram matching, while the reliability of large language model-based evaluations for long-form answers remains relatively unexplored. We address this gap by conducting an in-depth study of long-form answer evaluation with the following research questions: (i) To what extent do existing automatic evaluation metrics serve as a substitute for human evaluations? (ii) What are the limitations of existing evaluation metrics compared to human evaluations? (iii) How can the effectiveness and robustness of existing evaluation methods be improved? We collect 5,236 factoid and non-factoid long-form answers generated by different large language models and conduct a human evaluation on 2,079 of them, focusing on correctness and informativeness. Subsequently, we investigated the performance of automatic evaluation metrics by evaluating these answers, analyzing the consistency between these metrics and human evaluations. We find that the style, length of the answers, and the category of questions can bias the automatic evaluation metrics. However, fine-grained evaluation helps mitigate this issue on some metrics. Our findings have important implications for the use of large language models for evaluating long-form question answering. All code and datasets are available at \\url{https://github.com/bugtig6351/lfqa_evaluation}.",
        "doi": "10.1145/3726302.3729895",
        "sheridan_id": "fp1078",
        "position": 5,
        "track_id": 1,
        "slot_id": 42
      }
    },
    {
      "paper": {
        "hashed_id": "69a5b5995110b36a9a347898d97a610e",
        "title": "Diversity-aware Dual-promotion Poisoning Attack on Sequential Recommendation",
        "abstract": "Sequential recommender systems (SRSs) excel in capturing users` dynamic interests, thus playing a key role in various industrial applications. The popularity of SRSs has also driven emerging research on their security aspects, where data poisoning attack for targeted item promotion is a typical example. Existing attack mechanisms primarily focus on increasing the ranks of target items in the recommendation list by injecting carefully crafted interactions (i.e., poisoning sequences), which comes at the cost of demoting users` real preferences. Consequently, noticeable recommendation accuracy drops are observed, restricting the stealthiness of the attack. Additionally, the generated poisoning sequences are prone to substantial repetition of target items, which is a result of the unitary objective of boosting their overall exposure and lack of effective diversity regularizations. Such homogeneity not only compromises the authenticity of these sequences, but also limits the attack effectiveness, as it ignores the opportunity to establish sequential dependencies between the target and many more items in the SRS. To address the issues outlined, we propose a Diversity-aware Dual-promotion Sequential Poisoning attack method named DDSP for SRSs. Specifically, by theoretically revealing the conflict between recommendation and existing attack objectives, we design a revamped attack objective that promotes the target item while maintaining the relevance of preferred items in a user`s ranking list. We further develop a diversity-aware, auto-regressive poisoning sequence generator, where a re-ranking method is in place to sequentially pick the optimal items by integrating diversity constraints. By attacking two representative SRSs on three real-world datasets, comprehensive experimental results demonstrate that DDSP outperforms state-of-the-art attack methods in attack effectiveness. Moreover, DDSP achieves the strongest stealthiness with its lowest impact on recommendation accuracy.",
        "doi": "10.1145/3726302.3729955",
        "sheridan_id": "fp1129",
        "position": 2,
        "track_id": 1,
        "slot_id": 21
      }
    },
    {
      "paper": {
        "hashed_id": "47a658229eb2368a99f1d032c8848542",
        "title": "DLF: Enhancing Explicit-Implicit Interaction via Dynamic Low-Order-Aware Fusion for CTR Prediction",
        "abstract": "Click-through rate (CTR) prediction is a critical task in online advertising and recommender systems, relying on effective modeling of feature interactions. Explicit interactions capture predefined relationships, such as inner products, but often suffer from data sparsity, while implicit interactions excel at learning complex patterns through non-linear transformations but lack inductive biases for efficient low-order modeling. Existing two-stream architectures integrate these paradigms but face challenges such as limited information sharing, gradient imbalance, and difficulty preserving low-order signals in sparse CTR data.We propose a novel framework, Dynamic Low-Order-Aware Fusion (DLF), which addresses these limitations through two key components: a Residual-Aware Low-Order Interaction Network (RLI) and a Network-Aware Attention Fusion Module (NAF). RLI explicitly preserves low-order signals while mitigating redundancy from residual connections, and NAF dynamically integrates explicit and implicit representations at each layer, enhancing information sharing and alleviating gradient imbalance. Together, these innovations balance low-order and high-order interactions, improving model expressiveness.Extensive experiments on public datasets demonstrate that DLF achieves state-of-the-art performance in CTR prediction, addressing key limitations of existing models. The implementation is publicly available at https://github.com/USTC-StarTeam/DLF.",
        "doi": "10.1145/3726302.3729956",
        "sheridan_id": "fp1136",
        "position": 6,
        "track_id": 1,
        "slot_id": 30
      }
    },
    {
      "paper": {
        "hashed_id": "c3e0c62ee91db8dc7382bde7419bb573",
        "title": "A Unified Retrieval Framework with Document Ranking and EDU Filtering for Multi-document Summarization",
        "abstract": "In the field of multi-document summarization (MDS), transformer-based models have demonstrated remarkable success, yet they suffer an input length limitation. Current methods apply truncation after the retrieval process to fit the context length; however, they heavily depend on manually well-crafted queries, which are impractical to create for each document set for MDS. Additionally, these methods retrieve information at a coarse granularity, leading to the inclusion of irrelevant content. To address these issues, we propose a novel retrieval-based framework that integrates query selection and document ranking and shortening into a unified process. Our approach identifies the most salient elementary discourse units (EDUs) from input documents and utilizes them as latent queries. These queries guide the document ranking by calculating relevance scores. Instead of traditional truncation, our approach filters out irrelevant EDUs to fit the context length, ensuring that only critical information is preserved for summarization. We evaluate our framework on multiple MDS datasets, demonstrating consistent improvements in ROUGE metrics while confirming its scalability and flexibility across diverse model architectures. Additionally, we validate its effectiveness through an in-depth analysis, emphasizing its ability to dynamically select appropriate queries and accurately rank documents based on their relevance scores. These results demonstrate that our framework effectively addresses context-length constraints, establishing it as a robust and reliable solution for MDS.",
        "doi": "10.1145/3726302.3729884",
        "sheridan_id": "fp1138",
        "position": 4,
        "track_id": 1,
        "slot_id": 40
      }
    },
    {
      "paper": {
        "hashed_id": "2cfd4560539f887a5e420412b370b361",
        "title": "How Cohesive Are Community Search Results on Online Social Networks?: An Experimental Evaluation",
        "abstract": "Recently, numerous community search methods for large graphs have been proposed, at the core of which is defining and measuring cohesion. This paper experimentally evaluates the effectiveness of these community search algorithms \\wrt cohesiveness in the context of online social networks. Social communities are formed and developed under the influence of group cohesion theory, which has been extensively studied in social psychology. However, current generic methods typically measure cohesiveness using structural or attribute-based approaches and overlook domain-specific concepts such as group cohesion. We introduce five novel psychology-informed cohesiveness measures, based on the concept of group cohesion from social psychology, and propose a novel framework called CHASE for evaluating eight representative community search algorithms w.r.t. these measures on online social networks. Our analysis reveals that there is no clear correlation between structural and psychological cohesiveness, and no algorithm effectively identifies psychologically cohesive communities in online social networks. This study provides new insights that could guide the development of future community search methods.",
        "doi": "10.1145/3726302.3729997",
        "sheridan_id": "fp1123",
        "position": 6,
        "track_id": 1,
        "slot_id": 10
      }
    },
    {
      "paper": {
        "hashed_id": "8ce6790cc6a94e65f17f908f462fae85",
        "title": "Hybrid Advertising in the Sponsored Search",
        "abstract": "Online advertisements are a primary revenue source for e-commerce platforms. Traditional advertising models are store-centric, selecting winning stores through auction mechanisms. Recently, a new approach known as joint advertising has emerged, which presents sponsored bundles combining one store and one brand in ad slots. Unlike traditional models, joint advertising allows platforms to collect payments from both brands and stores. However, each of these two advertising models appeals to distinct user groups, leading to low click-through rates when users encounter an undesirable advertising model. To address this limitation and enhance generality, we propose a novel advertising model called ``Hybrid Advertising``. In this model, each ad slot can be allocated to either an independent store or a bundle. To find the optimal auction mechanisms in hybrid advertising, while ensuring nearly dominant strategy incentive compatibility and individual rationality, we introduce the Hybrid Regret Network (HRegNet), a neural network architecture designed for this purpose. Extensive experiments on both synthetic and real-world data demonstrate that the mechanisms generated by HRegNet significantly improve platform revenue compared to established baseline methods.",
        "doi": "10.1145/3726302.3729999",
        "sheridan_id": "fp1142",
        "position": 5,
        "track_id": 1,
        "slot_id": 19
      }
    },
    {
      "paper": {
        "hashed_id": "208e43f0e45c4c78cafadb83d2888cb6",
        "title": "Killing Two Birds with One Stone: Unifying Retrieval and Ranking with a Single Generative Recommendation Model",
        "abstract": "In recommendation systems, the traditional multi-stage paradigm, which includes retrieval and ranking, often suffers from information loss between stages and diminishes performance. Recent advances in generative models, inspired by natural language processing, suggest the potential for unifying these stages to mitigate such loss. This paper presents the Unified Generative Recommendation Framework (UniGRF), a novel approach that integrates retrieval and ranking into a single generative model. By treating both stages as sequence generation tasks, UniGRF enables sufficient information sharing without additional computational costs, while remaining model-agnostic. To enhance inter-stage collaboration, UniGRF introduces a ranking-driven enhancer module that leverages the precision of the ranking stage to refine retrieval processes, creating an enhancement loop. Besides, a gradient-guided adaptive weighter is incorporated to dynamically balance the optimization of retrieval and ranking, ensuring synchronized performance improvements. Extensive experiments demonstrate that UniGRF significantly outperforms existing models on benchmark datasets, confirming its effectiveness in facilitating information transfer. Ablation studies and further experiments reveal that UniGRF not only promotes efficient collaboration between stages but also achieves synchronized optimization. UniGRF provides an effective, scalable, and compatible framework for generative recommendation systems.",
        "doi": "10.1145/3726302.3730017",
        "sheridan_id": "fp1143",
        "position": 7,
        "track_id": 1,
        "slot_id": 30
      }
    },
    {
      "paper": {
        "hashed_id": "0c048b3a434e49e655c1247efb389cec",
        "title": "Why is Normalization Necessary for Linear Recommenders?",
        "abstract": "Despite their simplicity, linear autoencoder (LAE)-based models have shown comparable or even better performance with faster inference speed than neural recommender models. However, LAEs face two critical challenges: (i) popularity bias, which tends to recommend popular items, and (ii) neighborhood bias, which overly focuses on capturing local item correlations. To address these issues, this paper first analyzes the effects of two existing normalization methods for LAEs, i.e., random-walk and symmetric normalization. Our theoretical analysis reveals that normalization highly affects the degree of popularity and neighborhood biases among items. Inspired by this analysis, we propose a versatile normalization solution, called Data-Adaptive Normalization (DAN), which flexibly controls the popularity and neighborhood biases by adjusting item- and user-side normalization to align with unique dataset characteristics. Owing to its model-agnostic property, DAN can be easily applied to various LAE-based models. Experimental results show that DAN-equipped LAEs consistently improve existing LAE-based models across six benchmark datasets, with significant gains of up to 128.57% and 12.36% for long-tail items and unbiased evaluations, respectively. Refer to our code in https://github.com/psm1206/DAN.",
        "doi": "10.1145/3726302.3730116",
        "sheridan_id": "fp1158",
        "position": 7,
        "track_id": 1,
        "slot_id": 1
      }
    },
    {
      "paper": {
        "hashed_id": "0a0a0c8aaa00ade50f74a3f0ca981ed7",
        "title": "Rethinking Continual Knowledge Graph Embedding: Benchmarks and Analysis",
        "abstract": "Continual knowledge graph embedding (CKGE) has gained wide attention for managing dynamic knowledge graphs (KGs), which are continuously updated with new facts. Unlike traditional methods designed for static KGs, CKGE enables incremental updates to KG embeddings to accommodate new facts while retaining previously learned knowledge. Despite these advancements, current CKGE studies and benchmarks primarily focus on handling the increasing scale of data while overlooking changes in graph patterns. These changes, altering the graph structure of KGs, are referred to as pattern shifts in this paper. Pattern shifts frequently arise as new facts are added, introducing significant challenges to the stability and adaptability of CKGE methods. To address this gap, we introduce a suite of novel and challenging benchmarks, called PS-CKGE, specifically designed to evaluate CKGE methods under pattern shifts, where logic rules are utilized to capture and manage structural changes in dynamic KGs. Through these benchmarks, we comprehensively evaluate current CKGE methods in terms of their overall performance, resistance to catastrophic forgetting, and adaptability to new knowledge. The results show that pattern shifts not only exacerbate their risk of catastrophic forgetting but also impair their adaptability, usually with greater performance degradation over triples associated with more significant changes.",
        "doi": "10.1145/3726302.3730073",
        "sheridan_id": "fp1173",
        "position": 6,
        "track_id": 1,
        "slot_id": 41
      }
    },
    {
      "paper": {
        "hashed_id": "16e6a3326dd7d868cbc926602a61e4d0",
        "title": "Social Relation-Level Privacy Risks and Preservation in Social Recommender Systems",
        "abstract": "The integration of social information into recommender systems (RSs) has gained significant popularity for enhancing recommendation performance and user experience. However, this practice introduces substantial privacy risks, particularly concerning the leakage of sensitive social relationships. While prior research has primarily focused on user-level and interaction-level privacy risks, the social relation-level privacy risks remain largely unexplored. To fill this gap, we investigate social privacy risks through membership inference attacks (MIA) and propose a Social relation-level MIA (SMIA) framework. Two key challenges arise: (1) the adversary can only access the recommended item IDs, which provide indirect and limited information about social relationships, and (2) extracting socially relevant preferences from recommendation results is inherently difficult. To tackle the first challenge, we leverage shadow models to transform sparse item IDs into dense features, enabling adversaries to effectively utilize recommendation outputs. For the second challenge, SMIA employs a dual-branch learning approach that disentangles social and behavioral preferences. Therefore, we can extract socially relevant signals from the disentangled preferences.Extensive experiments on real-world datasets demonstrate that both social and general RSs are highly vulnerable to such attacks, highlighting the urgent need for robust privacy protection mechanisms. To defend against these attacks, we introduce a Socially Adversarial Learning (SAL) defense mechanism that selectively obscures sensitive social information in user representations during training, effectively reducing privacy leakage. We further evaluate the effectiveness of our defense and discuss future directions for developing privacy-preserving mechanisms in social RSs.",
        "doi": "10.1145/3726302.3730086",
        "sheridan_id": "fp1159",
        "position": 6,
        "track_id": 1,
        "slot_id": 15
      }
    },
    {
      "paper": {
        "hashed_id": "6e7d2da6d3953058db75714ac400b584",
        "title": "Generating Difficulty-aware Negative Samples via Conditional Diffusion for Multi-modal Recommendation",
        "abstract": "Designing effective negative sampling strategies is crucial for training Multi-Modal Recommendation (MMRec) models, as it helps address the issues of sparse user-item interactions and facilitates the learning of high-dimensional modality features. However, most existing methods randomly sample non-interacted items as negative ones, which frequently result in easy  negatives. They limit the model`s ability to accurately capture user preferences.  In this paper, we propose to Generate Difficulty-aware Negative Samples via conditional diffusion for MMRec (denoted as GDNSM). Leveraging the rich semantic and contextual  information from multi-modal features, our method generates hard negative samples with varying difficulty levels, tailored to user preferences. They force the  model to learn finer-grained distinctions between positive and negative samples, enhancing its ability to inferring user preferences. To avoid unstable training, we design a dynamic difficulty scheduling mechanism that schedules the negative samples from easy to hard for model training, ensuring both stability and effectiveness.  Extensive experiments on three real-world datasets demonstrate that the effectiveness of our models.",
        "doi": "10.1145/3726302.3729986",
        "sheridan_id": "fp1163",
        "position": 3,
        "track_id": 1,
        "slot_id": 5
      }
    },
    {
      "paper": {
        "hashed_id": "a113c1ecd3cace2237256f4c712f61b5",
        "title": "Boosting Discriminability for Robust Multimodal Entity Linking with Visual Modality Missing",
        "abstract": "Multimodal Entity Linking (MEL) aims to retrieve ambiguous mentions within multimodal contexts to the referent entities in a multimodal knowledge base, typically based on the assumption of modality completeness. However, when deployed in open-world applications, MEL systems may encounter uncertainly missing of visual modalities from user-proposed mentions. In this paper, we propose a novel setting dubbed MEL-MM to simulate the practical challenge, and reveal that the semantic discriminability is a crucial factor to enhance the anti-missingness resilience. To this end, we introduce an innovative yet efficient approach termed Cross-View Introspective Ranking Distillation (CVIRD), which seeks to sufficiently align the linking similarities between teacher and student models trained from modality-complete and incomplete data. To be specific, as the first concept in CVIRD, Missing-Aware Ranking Distillation (MARD) focuses on modeling the discriminability by formulating the similarity rankings between mention and entities in a missing-sensitive and differentiable manner. Moreover, the second concept of Cross-View Distillation with Introspection (CVDI) aims to improve discriminability extraction in MARD through multi-level distillation, considering both cross-view retrieval and self-consistency.  Experiments verify the effectiveness and model-agnostic ability of our method, which achieves superior performance in contrast to competitive missingness-resilient strategies.",
        "doi": "10.1145/3726302.3729906",
        "sheridan_id": "fp1171",
        "position": 4,
        "track_id": 1,
        "slot_id": 5
      }
    },
    {
      "paper": {
        "hashed_id": "36a1694bce9815b7e38a9dad05ad42e0",
        "title": "Reverse-Engineering the Retrieval Process in GenIR Models",
        "abstract": "Generative Information Retrieval (GenIR) is a novel paradigm in which a transformer encoder-decoder model predicts document rankings based on a query in an end-to-end fashion. These GenIR models have received significant attention due to their simple retrieval architecture while maintaining high retrieval effectiveness. However, in contrast to established retrieval architectures like cross-encoders or bi-encoders, their internal computations remain largely unknown. In this work, we investigate this retrieval mechanism and uncover the roles played by different model components (self-attention, cross-attention, MLPs) and their interaction to generate the document identifier. First, we show that the pre-trained encoder, which was not fine-tuned for retrieval, is sufficient for the retrieval process.  Then, we find that the pass through the decoder can be divided into three stages: (I) the priming stage in which no component contributes query-specific information, (II) the bridging stage where cross-attention transfers query information from the encoder to the decoder, and (III) the interaction stage where MLPs process this transferred information to predict the document identifier in the last layer. Our results indicate that document-specific information is only stored in a few components in the final stage of the retrieval process. We hope that our findings will motivate the development of more effective GenIR models and facilitate their improvements.",
        "doi": "10.1145/3726302.3730076",
        "sheridan_id": "fp1172",
        "position": 2,
        "track_id": 1,
        "slot_id": 16
      }
    },
    {
      "paper": {
        "hashed_id": "0e095e054ee94774d6a496099eb1cf6a",
        "title": "Mitigating Distribution Shifts in Sequential Recommendation: An Invariance Perspective",
        "abstract": "Sequential recommendation aims to learn users` dynamic preferences from their historical interactions and predict the next item they are most likely to engage with. In real-world scenarios, time-varying factors (e.g., product promotions, seasonal changes) induce distribution shifts in user interactions. Despite the demonstrated success of existing models, their generalization capability remains limited under such dynamic conditions.Current methods tackle this challenge by leveraging distributionally robust optimization (DRO) to optimize the \"worst-case\" loss or by employing manually designed data augmentation to enrich the training distribution. Despite their effectiveness, DRO-based approaches are inherently constrained by the sparsity of training data, limiting the range of distributions they can model, while manually designed augmentations risk introducing noise or irrelevant information that could distort user preference learning. Furthermore, these methods often overlook the sensitivity of user interactions to distribution shifts, which is essential for capturing the stable factors in the evolution of user preferences in real-world settings.In this work, we tackle the distribution shifting problem from the perspective of invariant learning. We propose a novel framework called \\textit{\\textbf{I}nvariant Learning for \\textbf{D}istribution Shifts in S\\textbf{E}quential Recommend\\textbf{A}tion (\\textbf{IDEA})} to develop robust sequential recommendation. The key of \\shortname~lies on learning stable preferences across various distribution-aware environments. Since explicit environments are unavailable, we first extract multiple subsequences by dropping potential noise items, then extend environments with our proposed subsequence mixup. Given the simulated environments, \\shortname~then learns stable user preferences through invariant risk minimization (IRM) across various environments. To encourage the diversity of simulated environments, \\shortname~employs an adversarial training strategy to explore potential diverse environments, and further enhance the model`s generalization to unseen test distributions. It is worth mentioning that \\shortname~is a flexible model-agnostic framework, which is applicable to various sequential recommendation models. Extensive experimental results on three public datasets clearly demonstrate the effectiveness of the proposed framework. Our code is available at: \\url{https://github.com/hermione314/IDEA}.",
        "doi": "10.1145/3726302.3730036",
        "sheridan_id": "fp1183",
        "position": 7,
        "track_id": 1,
        "slot_id": 14
      }
    },
    {
      "paper": {
        "hashed_id": "5680522b8e2bb01943234bce7bf84534",
        "title": "The Great Nugget Recall: Automating Fact Extraction and RAG Evaluation with Large Language Models",
        "abstract": "Large Language Models (LLMs) have significantly enhanced the capabilities of information access systems, especially with retrieval-augmented generation (RAG). Nevertheless, the evaluation of RAG systems remains a barrier to continued progress, a challenge we tackle in this work by proposing an automatic evaluation framework that is validated against human annotations. We believe that the nugget evaluation methodology provides a solid foundation for evaluating RAG systems. This approach, originally developed for the TREC Question Answering (QA) Track in 2003, evaluates systems based on atomic facts that should be present in good answers. Our efforts focus on \"refactoring\" this methodology, where we describe the AutoNuggetizer framework that specifically applies LLMs to both automatically create nuggets and automatically assign nuggets to system answers. In the context of the TREC 2024 RAG Track, we calibrate a fully automatic approach against strategies where nuggets are created manually or semi-manually by human assessors and then assigned manually to system answers. Based on results from a community-wide evaluation, we observe strong agreement at the run level between scores derived from fully automatic nugget evaluation and human-based variants. The agreement is stronger when individual framework components such as nugget assignment are automated independently. This suggests that our evaluation framework provides tradeoffs between effort and quality that can be used to guide the development of future RAG systems. However, further research is necessary to refine our approach, particularly in establishing robust per-topic agreement to diagnose system failures effectively.",
        "doi": "10.1145/3726302.3730090",
        "sheridan_id": "fp1185",
        "position": 4,
        "track_id": 1,
        "slot_id": 25
      }
    },
    {
      "paper": {
        "hashed_id": "82c2559140b95ccda9c6ca4a8b981f1e",
        "title": "Bridging Interests and Truth: Towards Mitigating Fake News with Personalized and Truthful Recommendations",
        "abstract": "While the proliferation of fake news poses a significant threat to information integrity, existing efforts to counter it, especially within personalized news recommendation systems, have proven inadequate. Traditional methods, which often rely on classifiers to filter out fake content, are limited by their accuracy and their inability to fully capture the diverse interests of users. To address these challenges, we proposed PRISM\u2014Protection-enhanced Recommendation with Interest-aware Sequential Modeling\u2014a novel framework based on diffusion models. PRISM harnesses the generative and control capabilities of diffusion models to progressively learn the implicit distribution of user interests from their reading history, thereby generating personalized recommendations that align with both their linguistic preferences and interest domains. Furthermore, PRISM incorporates pre-trained authenticity representations as constraints during content generation, ensuring the credibility of the recommended news and effectively curbing the spread of fake news. Comprehensive evaluations from multiple dimensions demonstrate the superiority of our model.",
        "doi": "10.1145/3726302.3729912",
        "sheridan_id": "fp1189",
        "position": 6,
        "track_id": 1,
        "slot_id": 31
      }
    },
    {
      "paper": {
        "hashed_id": "160c88652d47d0be60bfbfed25111412",
        "title": "Joint Item Embedding Dual-view Exploration and Adaptive Local-Global Fusion for Federated Recommendation",
        "abstract": "Federated Recommendation (FedRec) enables joint training across a large number of clients without centralizing user interaction data. However, existing FedRec methods overlook two key challenges, i.e., (1) sufficiently explore the global item embedding space, and (2) effectively achieve local and global collaboration. The former is caused by client sparsity, which leads to suboptimal item embeddings and subsequently impacts the global item embedding in both the dimension and sample views. The latter arises from the lack of modeling the relative importance of local and global contributions to personalized user preferences. To address the above challenges, we propose FedIAR which contains two modules, i.e., item embedding dual-view exploration and adaptive local-global fusion. The first module enhances the global item embedding by reducing redundancy in the dimension view and capturing latent item relationships in the sample view, improving representational capacity. The second module enables the adaptive fusion of local and global item embeddings based on the user preference representation, achieving personalized optimum for recommendation. Extensive experiments on six datasets demonstrate the effectiveness of FedIAR in improving federated recommendation performance.",
        "doi": "10.1145/3726302.3730016",
        "sheridan_id": "fp1190",
        "position": 6,
        "track_id": 1,
        "slot_id": 22
      }
    },
    {
      "paper": {
        "hashed_id": "a4d2f0d23dcc84ce983ff9157f8b7f88",
        "title": "Mitigating Modality Bias in Multi-modal Entity Alignment from a Causal Perspective",
        "abstract": "Multi-Modal Entity Alignment (MMEA) aims to retrieve equivalent entities from different Multi-Modal Knowledge Graphs (MMKGs), a critical information retrieval task. Existing studies have explored various fusion paradigms and consistency constraints to improve the alignment of equivalent entities, while overlooking that the visual modality may not always contribute positively. Empirically, entities with low-similarity images usually generate unsatisfactory performance, highlighting the limitation of overly relying on visual features. We believe the model can be biased toward the visual modality, leading to a shortcut image-matching task. To address this, we propose a counterfactual debiasing framework for MMEA, termed CDMEA, which investigates visual modality bias from a causal perspective. Our approach aims to leverage both visual and graph modalities to enhance MMEA while suppressing the direct causal effect of the visual modality on model predictions. By estimating the Total Effect (TE) of both modalities and excluding the Natural Direct Effect (NDE) of the visual modality, we ensure that the model predicts based on the Total Indirect Effect (TIE), effectively utilizing both modalities and reducing visual modality bias. Extensive experiments on 9 benchmark datasets show that CDMEA outperforms 14 state-of-the-art methods, especially in low-similarity, high-noise, and low-resource data scenarios.",
        "doi": "10.1145/3726302.3730037",
        "sheridan_id": "fp1215",
        "position": 4,
        "track_id": 1,
        "slot_id": 8
      }
    },
    {
      "paper": {
        "hashed_id": "6a61d423d02a1c56250dc23ae7ff12f3",
        "title": "PATFinger: Prompt-Adapted Transferable Fingerprinting against Unauthorized Multimodal Dataset Usage",
        "abstract": "The multimodal datasets can be leveraged to pre-train large-scale vision-language models by providing cross-modal semantics. Current endeavors for determining the usage of datasets mainly focus on single-modal dataset ownership verification through intrusive methods and non-intrusive techniques, while cross-modal approaches remain under-explored. Intrusive methods can adapt to multimodal datasets but degrade model accuracy, while non-intrusive methods rely on label-driven decision boundaries that fail to guarantee stable behaviors for verification. To address these issues, we propose a novel prompt-adapted transferable fingerprinting scheme from a training-free perspective, called PATFinger, which incorporates the global optimal perturbation (GOP) and the adaptive prompts to capture dataset-specific distribution characteristics. Our scheme utilizes inherent dataset attributes as fingerprints instead of compelling the model to learn triggers. The GOP is derived from the sample distribution to maximize embedding drifts between different modalities. Subsequently, our PATFinger re-aligns the adaptive prompt with GOP samples to capture the cross-modal interactions on the carefully crafted surrogate model. This allows the dataset owner to check the usage of datasets by observing specific prediction behaviors linked to the PATFinger during retrieval queries. Extensive experiments demonstrate the effectiveness of our scheme against unauthorized multimodal dataset usage on various cross-modal retrieval architectures by 30% over state-of-the-art baselines.",
        "doi": "10.1145/3726302.3730054",
        "sheridan_id": "fp1217",
        "position": 4,
        "track_id": 1,
        "slot_id": 22
      }
    },
    {
      "paper": {
        "hashed_id": "1d72310edc006dadf2190caad5802983",
        "title": "Precise Zero-Shot Pointwise Ranking with LLMs through Post-Aggregated Global Context Information",
        "abstract": "Recent advancements have successfully harnessed the power of Large Language Models (LLMs) for zero-shot document ranking, exploring a variety of prompting strategies. Comparative approaches like pairwise and listwise achieve high effectiveness but are computationally intensive and thus less practical for larger-scale applications. Scoring-based pointwise approaches exhibit superior efficiency by independently and simultaneously generating the relevance scores for each candidate document. However, this independence ignores critical comparative insights between documents, resulting in inconsistent scoring and suboptimal performance. In this paper, we aim to improve the effectiveness of pointwise methods while preserving their efficiency through two key innovations: (1) We propose a novel Global-Consistent Comparative Pointwise Ranking (GCCP) strategy that incorporates global reference comparisons between each candidate and an anchor document to generate contrastive relevance scores. We strategically design the anchor document as a query-focused summary of pseudo-relevant candidates, which serves as an effective reference point by capturing the global context for document comparison. (2) These contrastive relevance scores can be efficiently Post-Aggregated with existing pointwise methods, seamlessly integrating essential Global Context information in a training-free manner (PAGC). Extensive experiments on the TREC DL and BEIR benchmark demonstrate that our approach significantly outperforms previous pointwise methods while maintaining comparable efficiency. Our method also achieves competitive performance against comparative methods that require substantially more computational resources. More analyses further validate the efficacy of our anchor construction strategy.",
        "doi": "10.1145/3726302.3730061",
        "sheridan_id": "fp1221",
        "position": 6,
        "track_id": 1,
        "slot_id": 12
      }
    },
    {
      "paper": {
        "hashed_id": "3a029f04d76d32e79367c4b3255dda4d",
        "title": "Combining Evidence and Reasoning for Biomedical Fact-Checking",
        "abstract": "Misinformation in healthcare, from vaccine hesitancy to unproven treatments, poses  risks to public health and trust in medical systems. While machine learning and natural language processing have advanced automated fact-checking, validating biomedical claims remains uniquely challenging due to complex terminology, the need for domain expertise, and the critical importance of grounding in scientific evidence. We introduce CER (Combining Evidence and Reasoning), a novel framework for biomedical fact-checking that integrates scientific evidence retrieval, reasoning via large language models, and supervised veracity prediction. By integrating the text-generation capabilities of large language models with advanced retrieval techniques for high-quality biomedical scientific evidence, CER effectively mitigates the risk of hallucinations, ensuring that generated outputs are grounded in verifiable, evidence-based sources. Evaluations on expert-annotated datasets (HealthFC, BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising cross-dataset generalization. Code and data are released for transparency and reproducibility: https://github.com/PRAISELab-PicusLab/CER",
        "doi": "10.1145/3726302.3729931",
        "sheridan_id": "fp1222",
        "position": 6,
        "track_id": 1,
        "slot_id": 24
      }
    },
    {
      "paper": {
        "hashed_id": "7bccfde7714a1ebadf06c5f4cea752c1",
        "title": "Order-agnostic Identifier for Large Language Model-based Generative Recommendation",
        "abstract": "Leveraging Large Language Models (LLMs) for generative recommendation has attracted significant research interest, where item tokenization is a critical step. It involves assigning item identifiers for LLMs to encode user history and generate the next item. Existing approaches leverage either token-sequence identifiers, representing items as discrete token sequences, or single-token identifiers, using ID or semantic embeddings. Token-sequence identifiers face issues such as the local optima problem in beam search and low generation efficiency due to step-by-step generation. In contrast, single-token identifiers fail to capture rich semantics or encode Collaborative Filtering (CF) information, resulting in suboptimal performance.To address these issues, we propose two fundamental principles for item identifier design: 1) integrating both CF and semantic information to fully capture multi-dimensional item information, and 2) designing order-agnostic identifiers without token dependency, mitigating the local optima issue and achieving simultaneous generation for generation efficiency. Accordingly, we introduce a novel set identifier paradigm for LLM-based generative recommendation, representing each item as a set of order-agnostic tokens. To implement this paradigm, we propose SETRec, which leverages CF and semantic tokenizers to obtain order-agnostic multi-dimensional tokens. To eliminate token dependency, SETRec uses a sparse attention mask for user history encoding and a query-guided generation mechanism for simultaneous token generation. We instantiate SETRec on T5 and Qwen (from 1.5B to 7B). Extensive experiments on four datasets demonstrate its effectiveness across various scenarios (e.g., full ranking, warm- and cold-start ranking, and various item popularity groups). Moreover, results validate SETRec`s superior efficiency and show promising scalability on cold-start items as model sizes increase.",
        "doi": "10.1145/3726302.3730053",
        "sheridan_id": "fp1236",
        "position": 4,
        "track_id": 1,
        "slot_id": 38
      }
    },
    {
      "paper": {
        "hashed_id": "792c7b5aae4a79e78aaeda80516ae2ac",
        "title": "Enhancing Homophily in Heterogeneous Graph Contrastive Learning via Connection Strength and Multi-view Self-Expression",
        "abstract": "Heterogeneous graph pre-training (HGP) has demonstrated remarkable performance across various domains. However, the issue of heterophily in real-world heterogeneous graphs (HGs) has been largely neglected. To bridge this research gap, we proposed a novel heterogeneous graph contrastive learning framework, termed HGMS, which leverages connection strength and multi-view self-expression to learn homophilous node representations. Specifically, we design a heterogeneous edge dropping augmentation strategy, which preferentially preserves metapath-based edges with strong connection strength, thereby improving the homophily of augmented views. Moreover, we propose a multi-view self-expressive learning method to infer the homophily between nodes from the subspace. In practice, we develop two approaches to solve the self-expressive matrix. The solved self-expressive matrix serves as an additional augmented view to provide homophilous information and is used to mitigate false negatives in contrastive loss. Extensive experimental results demonstrate the superiority of HGMS across different downstream tasks. The code is available at https://github.com/senllh/HGMS/tree/main.",
        "doi": "10.1145/3726302.3729968",
        "sheridan_id": "fp1374",
        "position": 6,
        "track_id": 1,
        "slot_id": 16
      }
    },
    {
      "paper": {
        "hashed_id": "a9eb812238f753132652ae09963a05e9",
        "title": "From Knowledge Forgetting to Accumulation: Evolutionary Relation Path Passing for Lifelong Knowledge Graph Embedding",
        "abstract": "The continual emergence of new entities and relations drives the dynamic expansion of knowledge graphs (KG). In the face of such growing KG, relearning from scratch wastes acquired knowledge, while learning solely from new snapshots leads to model forgetting of old knowledge. Existing methods focus on lifelong learning in growing KG through transfer and regularize embeddings. However, extensive entity updates to adapt to new snapshots introduce conflicts between old and new knowledge, thereby resulting in the inevitable occurrence of knowledge forgetting. To address these challenges, we propose the Evolutionary Relation Path Passing (ERPP) model for lifelong knowledge graph embedding, aiming to shift from knowledge forgetting to knowledge accumulation, thereby achieving accurate long-term prediction. Specifically, we propose a snapshot conditional relation path passing strategy to generate expressive representations that better adapt to snapshots compared to the transferred embeddings in existing methods. Subsequently, we propose a relation inheritance and evolution mechanism across snapshots and continue relation path passing in next snapshots. This allows ERPP to avoid inevitable catastrophic forgetting from frequent entity embedding updates. ERPP outperforms SOTA models in 35 scenarios, with average improvements of 11.1% in long-term prediction and 12.9% in knowledge transfer. Moreover, ERPP makes a breakthrough in achieving knowledge positive accumulation, in contrast to the negative forgetting of existing models. To the best of our knowledge, ERPP is the first model to realize knowledge accumulation. Our code is available at https://anonymous.4open.science/r/ERPP-6D66.",
        "doi": "10.1145/3726302.3729982",
        "sheridan_id": "fp1237",
        "position": 5,
        "track_id": 1,
        "slot_id": 8
      }
    },
    {
      "paper": {
        "hashed_id": "2de5d16682c3c35007e4e92982f1a2ba",
        "title": "Multi-level Encoding with Hierarchical Alignment for Sketch-Based 3D Shape Retrieval",
        "abstract": "Sketch-based 3D shape retrieval (SBSR) aims to retrieve 3D shapes using hand-drawn sketches as query inputs. Although existing SBSR methods have achieved promising results, several challenges still require further investigation. First, most existing approaches usually leverage simple aggregation schemes, often failing to capture the intrinsic relationships between views, which limits the effectiveness of 3D shape feature extraction. Second, conventional SBSR primarily focuses on instance-level alignment while ignoring multi-level alignment, which may neglect complex hierarchical relationships. To address these limitations, we propose a novel Multi-level Encoding with Hierarchical Alignment (MEHA) method for SBSR. Specifically, we adopt spatial encoding and view encoding for multiple views of 3D shapes. The proposed aggregation scheme then integrates these multi-level embedded local features to enhance the representation of 3D shape features. Considering the complexity of 3D shapes, MEHA adopts a two-stage training process: the first stage focuses on learning 3D shape features, while the second stage emphasizes modality alignment. Furthermore, we introduce a hierarchical alignment strategy that bridges the modality gap through instance-level, prototype-level, and centre-level alignment. Extensive experiments on two public benchmark datasets demonstrate the superiority of our method, showing that MEHA outperforms the state-of-the-art baselines.",
        "doi": "10.1145/3726302.3730043",
        "sheridan_id": "fp1242",
        "position": 8,
        "track_id": 1,
        "slot_id": 5
      }
    },
    {
      "paper": {
        "hashed_id": "81e5f81db77c596492e6f1a5a792ed53",
        "title": "TITE: Token-Independent Text Encoder for Information Retrieval",
        "abstract": "Transformer-based retrieval approaches typically use the contextualized embedding of the first input token as a dense vector representation for queries and documents. The embeddings of all other tokens are also computed but then discarded, wasting resources. In this paper, we propose the Token-Independent Text Encoder (TITE) as a more efficient modification of the backbone encoder model. Using an attention-based pooling technique, TITE iteratively reduces the sequence length of hidden states layer by layer so that the final output is already a single sequence representation vector. Our empirical analyses on the TREC 2019 and 2020 Deep Learning tracks and the BEIR benchmark show that TITE is on par in terms of effectiveness compared to standard bi-encoder retrieval models while being up to 3.3 times faster at encoding queries and documents. Our code is available at: https://github.com/webis-de/SIGIR-25.",
        "doi": "10.1145/3726302.3730094",
        "sheridan_id": "fp1250",
        "position": 2,
        "track_id": 1,
        "slot_id": 33
      }
    },
    {
      "paper": {
        "hashed_id": "c850371fda6892fbfd1c5a5b457e5777",
        "title": "Process-Supervised LLM Recommenders via Flow-guided Tuning",
        "abstract": "While large language models (LLMs) are increasingly adapted for recommendation systems via supervised fine-tuning (SFT), this approach amplifies popularity bias due to its likelihood maximization objective, compromising recommendation diversity and fairness. To address this, we present Flow-guided fine-tuning recommender (Flower), which replaces SFT with a Generative Flow Network (GFlowNet) [6] framework that enacts process supervision through token-level reward propagation. Flower`s key innovation lies in decomposing item-level rewards into constituent token rewards, enabling direct alignment between token generation probabilities and their reward signals. This mechanism achieves three critical advancements: (1) popularity bias mitigation and fairness enhancement through empirical distribution matching, (2) preservation of diversity through GFlowNet`s proportional sampling, and (3) flexible integration of personalized preferences via adaptable token rewards. Experiments demonstrate Flower`s superior distribution-fitting capability and its significant advantages over traditional SFT in terms of accuracy, fairness, and diversity, highlighting its potential to improve LLM-based recommendation systems. The implementation is available via https://github.com/MrPeach0301/Flower.",
        "doi": "10.1145/3726302.3729981",
        "sheridan_id": "fp1270",
        "position": 5,
        "track_id": 1,
        "slot_id": 38
      }
    },
    {
      "paper": {
        "hashed_id": "4079016d940210b4ae9ae7d41c4a2065",
        "title": "Designing Search Engine Result Pages for Immersive Virtual Reality: Insights from Eye-Tracking and User Perception Data",
        "abstract": "Extensive research exists on user interactions with search engine result pages (SERPs) in desktop and mobile environments. However, relatively little work has focused on understanding how virtual reality (VR) users interact with SERPs in 3D immersive virtual environments (IVEs). Unlike 2D displays with established paradigms (e.g., ranked lists), 3D IVEs lack standardized methods for presenting search results. This work explores how different information arrangements in 3D virtual space impact users` search behaviors and preferences.This paper presents the results of an exploratory within-subjects user study that investigated search behaviors, perceptions, and eye-tracking behaviors for four different spatial arrangements of search results (``list`` - 2D list; ``curve3`` - 3x3 curved grid; ``curve4`` - 4x4 curved grid; and ``sphere`` - 4x4 semi-spherical grid) in a virtual reality across two different task types (Find All relevant, Pick 3 best). Thirty-two (32) participants completed 5 search trials in 8 experimental conditions (4 displays x 2 task types) for 40 total search trials. The findings from our analysis show: (1) participants were accepting of and more often preferred using the more immersive displays than the conventional list display, (2) they generally preferred turning their heads (``physical navigation``) to scrolling (``virtual navigation``) for viewing results, (3) they perceived scrolling back up a display as an act of backtracking but did not perceived head movements to previously viewed results as backtracking, and (4) they spent less time gazing at the right-most columns in the exhaustive search task. We discuss the implications of the results on designs for SERPs in 3D IVEs.",
        "doi": "10.1145/3726302.3729947",
        "sheridan_id": "fp1287",
        "position": 5,
        "track_id": 1,
        "slot_id": 9
      }
    },
    {
      "paper": {
        "hashed_id": "dc87c13749315c7217cdc4ac692e704c",
        "title": "The Truth Becomes Clearer Through Debate! Multi-Agent Systems with Large Language Models Unmask Fake News",
        "abstract": "In today`s digital environment, the rapid propagation of fake news via social networks poses significant social challenges.   Most existing detection methods either employ traditional classification models, which suffer from low interpretability and limited generalization capabilities, or craft specific prompts for large language models (LLMs) to produce explanations and results directly, failing to leverage LLMs` reasoning abilities fully.  Inspired by the saying that ``truth becomes clearer through debate,`` our study introduces a novel multi-agent system with LLMs named TruEDebate (TED) to enhance the interpretability and effectiveness of fake news detection.   TED employs a rigorous debate process inspired by formal debate settings.  Central to our approach are two innovative components: the DebateFlow Agents and the InsightFlow Agents.  The DebateFlow Agents organize agents into two teams, where one supports and the other challenges the truth of the news. These agents engage in opening statements, cross-examination, rebuttal, and closing statements, simulating a rigorous debate process akin to human discourse analysis, allowing for a thorough evaluation of news content.  Concurrently, the InsightFlow Agents consist of two specialized sub-agents: the Synthesis Agent and the Analysis Agent. The Synthesis Agent summarizes the debates and provides an overarching viewpoint, ensuring a coherent and comprehensive evaluation.  The Analysis Agent, which includes a role-aware encoder and a debate graph, integrates role embeddings and models the interactions between debate roles and arguments using an attention mechanism, providing the final judgment.Our extensive experiments on two datasets, ARG-EN and ARG-CN, demonstrate that the TED framework surpasses traditional methods across various metrics and, more importantly, enhances interpretable fake news detection by illuminating logical reasoning and structured debate processes leading to accurate conclusions.We release our code to support Information systems that use structured debate within responsible information systems for improved decision-making.",
        "doi": "10.1145/3726302.3730092",
        "sheridan_id": "fp1295",
        "position": 7,
        "track_id": 1,
        "slot_id": 31
      }
    },
    {
      "paper": {
        "hashed_id": "05311655a15b75fab86956663e1819cd",
        "title": "UPPR+: Scaling Uncertain Personalised PageRank Computation on Billion-Sized Graphs with Mutually Exclusive Edges",
        "abstract": "While Personalised PageRank (PPR) is widely used for ranking nodes in certain graphs, research on PPR for uncertain graphs remains limited. Real-world graphs often exhibit uncertainty in some edges with interdependent probabilities. The best-of-breed work by Kim et al. proposed a fast approximate algorithm, UPPR, leveraging the Sherman-Morrison formula with singular value decomposition. However, UPPR lacks error guarantees, and struggles to scale on large graphs due to the high cost to precompute block matrix inverses over the certain part of the graph. To address these problems, we propose UPPR+, an efficient scheme to retrieve PPR on billion-scale uncertain graphs. 1) We first propose an efficient approach that groupifies uncertain edges to remove duplicates of source node set and maps uncertainties into a small subspace using low-dimensional embeddings. 2) To further accelerate the computation, we devise a novel uncertain subspace reduction method and advance the aggregation of PPRs over all possible worlds within the subspace via ``subset embedding``. 3) We provide theoretical guarantees on the exactness of UPPR+ and analyse its time and space complexities. Extensive empirical studies on various real datasets validate that UPPR+ is 23\u2013106x faster than state-of-the-art competitors, and scales well on billion-edge graphs without compromising accuracy.",
        "doi": "10.1145/3726302.3730113",
        "sheridan_id": "fp1338",
        "position": 6,
        "track_id": 1,
        "slot_id": 19
      }
    },
    {
      "paper": {
        "hashed_id": "861dc9bd7f4e7dd3cccd534d0ae2a2e9",
        "title": "AlphaFuse: Learn ID Embeddings for Sequential Recommendation in Null Space of Language Embeddings",
        "abstract": "Recent advancements in sequential recommendation have underscored the potential of Large Language Models (LLMs) for enhancing item embeddings. However, existing approaches face three key limitations: 1) the degradation of the semantic space when high-dimensional language embeddings are mapped to lower-dimensional ID embeddings, 2) the underutilization of language embeddings, and 3) the reliance on additional trainable parameters, such as an adapter, to bridge the gap between the semantic and behavior spaces. In this paper, we introduce AlphaFuse, a simple but effective language-guided learning strategy that addresses these challenges by learning ID embeddings within the null space of language embeddings. Specifically, we decompose the semantic space of language embeddings via Singular Value Decomposition (SVD), distinguishing it into a semantic-rich row space and a semantic-sparse null space. Collaborative signals are then injected into the null space, while preserving the rich semantics of the row space. AlphaFuse prevents degradation of the semantic space, integrates the retained language embeddings into the final item embeddings, and eliminates the need for auxiliary trainable modules, enabling seamless adaptation to any sequential recommendation framework. We validate the effectiveness and flexibility of AlphaFuse through extensive experiments on three benchmark datasets, including cold-start user and long-tail settings, showcasing significant improvements in both discriminative and diffusion-based generative sequential recommenders.",
        "doi": "10.1145/3726302.3729894",
        "sheridan_id": "fp1350",
        "position": 8,
        "track_id": 1,
        "slot_id": 14
      }
    },
    {
      "paper": {
        "hashed_id": "3e313b9badf12632cdae5452d20e1af6",
        "title": "Linear Item-Item Models with Neural Knowledge for Session-based Recommendation",
        "abstract": "Session-based recommendation (SBR) aims to predict users` subsequent actions by modeling short-term interactions within sessions. Existing neural models primarily focus on capturing complex dependencies for sequential item transitions. As an alternative solution, linear item-item models mainly identify strong co-occurrence patterns across items and support faster inference speed. Although each paradigm has been actively studied in SBR, their fundamental differences in capturing item relationships and how to bridge these distinct modeling paradigms effectively remain unexplored. In this paper, we propose a novel SBR model, namely Linear Item-Item model with Neural Knowledge (LINK), which integrates both types of knowledge into a unified linear framework. Specifically, we design two specialized components of LINK: (i) Linear knowledge-enhanced Item-item Similarity model (LIS), which refines the item similarity correlation via self-distillation, and (ii) Neural knowledge-enhanced Item-item Transition model (NIT), which seamlessly incorporates complicated neural knowledge distilled from the off-the-shelf neural model. Extensive experiments demonstrate that LINK outperforms state-of-the-art linear SBR models across six real-world datasets, achieving improvements of up to 14.78% and 11.04% in Recall@20 and MRR@20 while showing up to 813x fewer inference FLOPs. Our code is available at https://github.com/jin530/LINK.",
        "doi": "10.1145/3726302.3730024",
        "sheridan_id": "fp1351",
        "position": 6,
        "track_id": 1,
        "slot_id": 21
      }
    },
    {
      "paper": {
        "hashed_id": "ee8374ec4e4ad797d42350c904d73077",
        "title": "Enhancing Cross-Domain Recommendation with Plug-In Contrastive Representations from Large Language Models",
        "abstract": "Cross-Domain Recommendation (CDR) leverages auxiliary information from extra domains to enhance performance by learning domain-invariant and domain-specific representations. However, existing methods primarily rely on ID information of users and items, resulting in the entanglement of these two representations and hindering effective knowledge transfer. Therefore, we present a novel plug-in contrastive learning for CDR (PicCDR), which utilizes textual semantics to disentangle and enhance domain-invariant and domain-specific representations via LLMs. First, PicCDR introduces the CoT prompting to generate and encode content-independent domain-invariant and domain-specific texts. Next, a contrastive domain-disentangled augmentation strategy is used to align domain-invariant and domain-specific representations in the semantic space with those of ID space via MI estimation. To further enhance representations, we present contrastive MI lower-bound and upper-bound approximations to optimize MI maximization and minimization terms. We also provide theoretical proof to reveal the superiority of our contrastive strategy. Lastly, we encapsulate PicCDR into a plug-and-play framework. This allows PicCDR to be plugged into any existing CDR model. Extensive experiments show the efficiency, robustness, and generalization of PicCDR.",
        "doi": "10.1145/3726302.3729967",
        "sheridan_id": "fp1353",
        "position": 7,
        "track_id": 1,
        "slot_id": 17
      }
    },
    {
      "paper": {
        "hashed_id": "cf9a242b70f45317ffd281241fa66502",
        "title": "Knowing You Don`t Know: Learning When to Continue Search in Multi-round RAG through Self-Practicing",
        "abstract": "Retrieval Augmented Generation (RAG) has shown strong capability in enhancing language models` knowledge and reducing AI generative hallucinations, driving its widespread use. However, complex tasks requiring multi-round retrieval remain challenging, and early attempts tend to be overly optimistic without a good sense of self-skepticism. Current multi-round RAG systems may continue searching even when enough information has already been retrieved, or they may provide incorrect answers without having sufficient information or knowledge. Existing solutions either require large amounts of expensive human-labeled process supervision data or lead to subpar performance.  This paper aims to address these limitations by introducing a new framework, SIM-RAG, to explicitly enhance RAG systems` self-awareness and multi-round retrieval capabilities. To train SIM-RAG, we first let a RAG system self-practice multi-round retrieval, augmenting existing question-answer pairs with intermediate inner monologue reasoning steps to generate synthetic training data. For each pair, the system may explore multiple retrieval paths, which are labeled as successful if they reach the correct answer and unsuccessful otherwise. Using this data, we train a lightweight information sufficiency Critic. At inference time, the Critic evaluates whether the RAG system has retrieved sufficient information at each round, guiding retrieval decisions and improving system-level self-awareness through in-context reinforcement learning. Experiments across multiple prominent RAG benchmarks show that SIM-RAG is an effective multi-round RAG solution. Furthermore, this framework is system-efficient, adding a lightweight component to RAG without requiring modifications to existing LLMs or search engines, and data-efficient, eliminating the need for costly human-annotated mid-step retrieval process supervision data.",
        "doi": "10.1145/3726302.3730018",
        "sheridan_id": "fp1361",
        "position": 7,
        "track_id": 1,
        "slot_id": 3
      }
    },
    {
      "paper": {
        "hashed_id": "a223c6b3710f85df22e9377d6c4f7553",
        "title": "CG-RAG: Research Question Answering by Citation Graph Retrieval-Augmented LLMs",
        "abstract": "Research question answering requires accurate retrieval and contextual understanding of scientific literature. However, current Retrieval-Augmented Generation (RAG) methods often struggle to balance complex document relationships with precise information retrieval. In this paper, we introduce Contextualized Graph Retrieval-Augmented Generation (CG-RAG), a novel framework that integrates sparse and dense retrieval signals within graph structures to enhance retrieval efficiency and subsequently improve generation quality for research question answering. First, we propose a contextual graph representation for citation graphs, effectively capturing both explicit and implicit connections within and across documents. Next, we introduce Lexical-Semantic Graph Retrieval (LeSeGR), which seamlessly integrates sparse and dense retrieval signals with graph encoding. It bridges the gap between lexical precision and semantic understanding in citation graph retrieval, demonstrating generalizability to existing graph retrieval and hybrid retrieval methods. Finally, we present a context-aware generation strategy that utilizes the retrieved graph-structured information to generate precise and contextually enriched responses using large language models (LLMs). Extensive experiments on research question answering benchmarks across multiple domains demonstrate that our CG-RAG framework significantly outperforms RAG methods combined with various state-of-the-art retrieval approaches, delivering superior retrieval accuracy and generation quality.",
        "doi": "10.1145/3726302.3729920",
        "sheridan_id": "fp1367",
        "position": 3,
        "track_id": 1,
        "slot_id": 16
      }
    },
    {
      "paper": {
        "hashed_id": "8d9a0adb7c204239c9635426f35c9522",
        "title": "Bridging Personalization and Control in Scientific Personalized Search",
        "abstract": "Personalized search is a problem where models benefit from learning user preferences from per-user historical interaction data. The inferred preferences enable personalized ranking models to improve the relevance of documents to users. However, personalization is also seen as opaque in its use of historical interactions and is not amenable to users` control. Further, personalization limits the diversity of information users are exposed to. While search results may be automatically diversified this does little to address the lack of control over personalization. In response, we introduce a model for personalized search that enables users to control personalized rankings proactively. Our model, CtrlCE, is a novel cross-encoder model augmented with an editable memory built from users` historical interactions. The editable memory allows cross-encoders to be personalized efficiently and enables users to control personalized ranking. Next, because all queries do not require personalization, we introduce a calibrated mixing model which determines when personalization is necessary. This enables users to control personalization via their editable memory only when necessary. To thoroughly evaluate CtrlCE, we demonstrate its empirical performance in four domains of science, its ability to selectively request user control in a calibration evaluation of the mixing model, and the control provided by its editable memory in a user study.",
        "doi": "10.1145/3726302.3729913",
        "sheridan_id": "fp1378",
        "position": 7,
        "track_id": 1,
        "slot_id": 29
      }
    },
    {
      "paper": {
        "hashed_id": "cd0dce8fca267bf1fb86cf43e18d5598",
        "title": "Is Having Rationales Enough? Rethinking Knowledge Enhancement for Multimodal Hateful Meme Detection",
        "abstract": "Hateful memes are prevalent on the Internet, raising the urgent need for effective detection. Given their implicit nature, incorporating rationales with background knowledge is crucial for enhancing model understanding. However, existing methods often suffer from limited quality of external rationales and misalignment with original meme information. These challenges hinder model comprehension, leading to reduced accuracy and explainability. To address these challenges, we propose a Multimodal Multi-agent Knowledge Enhanced (M2KE) framework for hateful meme detection. M2KE introduces a multi-agent rationale discovery mechanism to extract high-quality rationales relevant to meme content and an adaptive knowledge interaction mechanism to ensure alignment between original meme information and external rationales. Specifically, multi-agent rationale discovery mechanism improves the reliability of rationales by collaboratively verifying and refining them with multiple agents, supported by large language models (LLMs) due to their extensive knowledge. And adaptive knowledge interaction mechanism uses information entropy to dynamically balance the model`s attention between original meme information and external rationales, preventing over-reliance on rationales and enabling a more comprehensive understanding. Experimental results on three datasets demonstrate that M2KE significantly outperforms existing models. Further analysis underscores the importance of effectively integrating accurate rationales to enhance model performance.",
        "doi": "10.1145/3726302.3730014",
        "sheridan_id": "fp1383",
        "position": 4,
        "track_id": 1,
        "slot_id": 39
      }
    },
    {
      "paper": {
        "hashed_id": "2bd7f907b7f5b6bbd91822c0c7b835f6",
        "title": "SAFT: Structure-aware Transformers for Textual Interaction Classification",
        "abstract": "Textual interaction networks (TINs) are an omnipresent data structure used to model the interplay between users and items on e-commerce websites, social networks, etc., where each interaction is associated with a text description. Classifying such textual interactions (TIC) finds extensive use in detecting spam reviews in e-commerce, fraudulent transactions in finance, and so on. Existing TIC solutions either (i) fail to capture the rich text semantics due to the use of context-free text embeddings, and/or (ii) disregard the bipartite structure and node heterogeneity of TINs, leading to compromised TIC performance. In this work, we propose SAFT, a new architecture that integrates language- and graph-based modules for the effective fusion of textual and structural semantics in the representation learning of interactions. In particular, line graph attention (LGA)/gated attention units (GAUs) and pretrained language models (PLMs) are capitalized on to model the interaction-level and token-level signals, which are further coupled via the proxy token in an iterative and contextualized fashion. Additionally, an efficient and theoretically-grounded approach is developed to encode the local and global topology information pertaining to interactions into structural embeddings. The resulting embeddings not only inject the structural features underlying TINs into the textual interaction encoding but also facilitate the design of graph sampling strategies. Extensive empirical evaluations on multiple real TIN datasets demonstrate the superiority of SAFT over the state-of-the-art baselines in TIC accuracy.",
        "doi": "10.1145/3726302.3730079",
        "sheridan_id": "fp1389",
        "position": 4,
        "track_id": 1,
        "slot_id": 20
      }
    },
    {
      "paper": {
        "hashed_id": "ad3019b856147c17e82a5bead782d2a8",
        "title": "DIFF: Dual Side-Information Filtering and Fusion for Sequential Recommendation",
        "abstract": "Side-information Integrated Sequential Recommendation (SISR) benefits from auxiliary item information to infer hidden user preferences, which is particularly effective for sparse interactions and cold-start scenarios. However, existing studies face two main challenges. (i) They fail to remove noisy signals in item sequence and (ii) they underutilize the potential of side-information integration. To tackle these issues, we propose a novel SISR model, \\textit{\\textbf{Dual Side-Information Filtering and Fusion (DIFF)}}, which employs frequency-based noise filtering and dual multi-sequence fusion. Specifically, we convert the item sequence to the frequency domain to filter out noisy short-term fluctuations in user interests. We then combine early and intermediate fusion to capture diverse relationships across item IDs and attributes. Thanks to our innovative filtering and fusion strategy, DIFF is more robust in learning subtle and complex item correlations in the sequence. DIFF outperforms state-of-the-art SISR models, achieving improvements of up to 14.1% and 12.5% in Recall@20 and NDCG@20 across four benchmark datasets.",
        "doi": "10.1145/3726302.3729948",
        "sheridan_id": "fp1393",
        "position": 1,
        "track_id": 1,
        "slot_id": 21
      }
    },
    {
      "paper": {
        "hashed_id": "d9731321ef4e063ebbee79298fa36f56",
        "title": "ARC: Approximate Relevant Clip Query in Large-Scale Video Repositories",
        "abstract": "The exponential growth of video data highlights the necessity of exploring large-scale video repositories to extract valuable insights. Querying video clips based on content and temporal attributes is a critical task. However, existing solutions face two major challenges: insufficient flexibility in handling complex query conditions involving statistical reasoning and temporal constraints, and low efficiency under high query quality requirements and resource constraints. In this paper, we formally introduce the concept of relevant clip queries for the first time, providing a framework for querying relevant clips in a much more flexible way. To answer such queries efficiently, we propose the approximate query processing system ARC, which aims to maximize the recall and minimize the query overhead while ensuring the confidence of the query results. ARC adopts a proxy model to prune the original video repositories and uses an oracle model to refine the pruned results. Evaluation on real-world video datasets shows that ARC achieves an average speedup of 32.57\u00d7 compared to naive baselines, while significantly outperforming state-of-the-art methods in almost all performance metrics. Sensitivity and ablation analysis further validate the robustness and effectiveness of the ARC components.",
        "doi": "10.1145/3726302.3729896",
        "sheridan_id": "fp1398",
        "position": 6,
        "track_id": 1,
        "slot_id": 11
      }
    },
    {
      "paper": {
        "hashed_id": "602d1305678a8d5fdb372271e980da6a",
        "title": "Retrieval Augmented Generation for Dynamic Graph Modeling",
        "abstract": "Modeling dynamic graphs, such as those found in social networks, recommendation systems, and e-commerce platforms, is crucial for capturing evolving relationships and delivering relevant insights over time. Traditional approaches primarily rely on graph neural networks with temporal components or sequence generation models, which often focus narrowly on the historical context of target nodes. This limitation restricts the ability to adapt to new and emerging patterns in dynamic graphs. To address this challenge, we propose a novel framework, Retrieval-Augmented Generation for Dy namic Graph modeling (RAG4DyG ), which enhances dynamic graph predictions by incorporating contextually and temporally relevant examples from broader graph structures. Our approach includes a time- and context-aware contrastive learning module to identify high-quality demonstrations and a graph fusion strategy to effectively integrate these examples with historical contexts. The proposed framework is designed to be effective in both transductive and inductive scenarios, ensuring adaptability to previously unseen nodes and evolving graph structures. Extensive experiments across multiple real-world datasets demonstrate the effectiveness of RAG4DyG in improving predictive accuracy and adaptability for dynamic graph modeling. The code and datasets are publicly available at https://github.com/YuxiaWu/RAG4DyG.",
        "doi": "10.1145/3726302.3729958",
        "sheridan_id": "fp1399",
        "position": 5,
        "track_id": 1,
        "slot_id": 40
      }
    },
    {
      "paper": {
        "hashed_id": "46771d1f432b42343f56f791422a4991",
        "title": "Seeing Beyond Hallucinations: LLM-based Compositional Information Extraction for Multimodal Reasoning",
        "abstract": "Advancements in Multimodal Large Language Models (MLLMs) have significantly improved information extraction and retrieval performance. Despite these achievements, MLLMs still suffer from the visual object hallucination problem, where models produce plausible, yet incorrect, or irrelevant content not present in the input data. This issue arises from an over-reliance on ``bag-of-objects`` representations and language priors, leading to inadequate extraction of visual objects, along with their attributes and relationships. Existing methods to mitigate these hallucinations are limited by the significant human labor required and the coarse-grained nature. To overcome these challenges, we introduce Multimodal Contrastive Decoding (MMCD), a novel decoding approach that integrates graph-structured reasoning paths with contrastive decoding. MMCD mitigates object hallucinations induced by language priors and enhances the ability of MLLMs to extract and understand compositional information, without additional training or the usage of external tools. This is achieved by masking key objects in images, constructing perturbed scene graphs of attributes and relationships, then contrasting these with the original image and scene graph. Extensive evaluation across three distinct multimodal compositional reasoning tasks: spatial relationship reasoning, alignment of synthetic image and caption, and fine-grained object attribute understanding, show that MMCD consistently surpasses existing decoding methods when applied to various MLLMs. Moreover, MMCD achieves state-of-the-art performance on multiple benchmarks, including the What`s Up, SeeTrue and SugarCrepe datasets.",
        "doi": "10.1145/3726302.3730081",
        "sheridan_id": "fp1407",
        "position": 5,
        "track_id": 1,
        "slot_id": 5
      }
    },
    {
      "paper": {
        "hashed_id": "9aa42b31882ec039965f3c4923ce901b",
        "title": "You Are What You Bought: Generating Customer Personas for E-commerce Applications",
        "abstract": "In e-commerce, user representations are essential for various applications. Existing methods often use deep learning techniques to convert customer behaviors into implicit embeddings. However, these embeddings are difficult to understand and integrate with external knowledge, limiting the effectiveness of applications such as customer segmentation, search navigation, and product recommendations. To address this, our paper introduces the concept of the \\textit{customer persona}. Condensed from a customer`s numerous purchasing histories, a customer persona provides a multi-faceted and human-readable characterization of specific purchase behaviors and preferences, such as \\textit{Busy Parents} or \\textit{Bargain Hunters}.    This work then focuses on representing each customer by multiple personas from a predefined set, achieving readable and informative explicit user representations. To this end, we propose an effective and efficient solution GPLR. To ensure effectiveness, GPLR leverages pre-trained LLMs and few-shot learning to infer personas for customers. To reduce overhead, GPLR applies LLM-based labeling to only a fraction of users and utilizes a random walk technique to predict personas for the remaining customers. To further enhance efficiency, we propose an approximate solution called RevAff for this random walk-based computation. RevAff provides an absolute error $\\epsilon$ guarantee while improving the time complexity of the exact solution by a factor of at least $O\\left(\\frac{\\epsilon \\cdot |E| N}{|E| + N \\log N} \\right)$, where $N$ represents the number of customers and products, and $E$ represents the interactions between them. We evaluate the performance of our persona-based representation in terms of accuracy and robustness for recommendation and customer segmentation tasks using three real-world e-commerce datasets. Most notably, we find that integrating customer persona representations improves the state-of-the-art graph convolution-based recommendation model by up to 12\\% in terms of NDCG@K and F1-Score@K.",
        "doi": "10.1145/3726302.3730118",
        "sheridan_id": "fp1421",
        "position": 8,
        "track_id": 1,
        "slot_id": 17
      }
    },
    {
      "paper": {
        "hashed_id": "56352739f59643540a3a6e16985f62c7",
        "title": "CIRAG: Retrieval-Augmented Language Model with Collective Intelligence",
        "abstract": "Retrieval-augmented generation (RAG) paradigms can integrate external knowledge to enhance and validate the output of Large Language Models (LLMs) thereby mitigating generative hallucinations and broadening the model`s knowledge scope. Despite advancements, existing RAG methods still suffer from uncertainty of prediction during the multi-round retrieval-generation process, and a lack of the ability to balance the adequacy and redundancy of retrieved information. To address these challenges, we propose CIRAG, an approach that combines the RAG process with collective intelligence. Inspired by the crowd of wisdom, CIRAG simulates individual independent decision-making and information aggregation within a crowd. Specifically, CIRAG first enhances retrieval diversity by expanding queries based on extracted entities, then combines frequency-based and semantic-based reranking to form a multi granularity fusion reranking thereby assessing better relevance, and integrate multiple information sources for accurate content generation. By undertaking these steps in an integrated manner, CIRAG enables the model to acquire comprehensive and non-redundant information for generating responses. We conduct extensive experiments with HotPotQA and 2WikiMultihopQA datasets, popular benchmark for retrieval-based, multi-step question-answering. Experimental results show that our approach surpasses existing advanced RAG framework while providing high portability in query expansion as well as strong comprehensiveness exhibited in the collective intelligence.",
        "doi": "10.1145/3726302.3729921",
        "sheridan_id": "fp1429",
        "position": 8,
        "track_id": 1,
        "slot_id": 3
      }
    },
    {
      "paper": {
        "hashed_id": "540ae6b0f6ac6e155062f3dd4f0b2b01",
        "title": "InfoNCE is a Free Lunch for Semantically guided Graph Contrastive Learning",
        "abstract": "As an important graph pre-training method, Graph Contrastive Learning (GCL) continues to play a crucial role in the ongoing surge of research on graph foundation models or LLM as enhancer for graphs. Traditional GCL optimizes InfoNCE by using augmentations to define self-supervised tasks, treating augmented pairs as positive samples and others as negative. However, this leads to semantically similar pairs being classified as negative, causing significant sampling bias and limiting performance. In this paper, we argue that GCL is essentially a Positive-Unlabeled (PU) learning problem, where the definition of self-supervised tasks should be semantically guided, i.e., augmented samples with similar semantics are considered positive, while others, with unknown semantics, are treated as unlabeled. From this perspective, the key lies in how to extract semantic information. To achieve this, we propose IFL-GCL, using InfoNCE as a ``free lunch`` to extract semantic information. Specifically, We first prove that under InfoNCE, the representation similarity of node pairs aligns with the probability that the corresponding contrastive sample is positive. Then we redefine the maximum likelihood objective based on the corrected samples, leading to a new InfoNCE loss function. Extensive experiments on both the graph pretraining framework and LLM as an enhancer show significantly improvements of IFL-GCL in both IID and OOD scenarios, achieving up to a 9.05% improvement, validating the effectiveness of semantically guided. Code for IFL-GCL is publicly available at: https://github.com/Camel-Prince/IFL-GCL.",
        "doi": "10.1145/3726302.3730007",
        "sheridan_id": "fp1439",
        "position": 7,
        "track_id": 1,
        "slot_id": 16
      }
    },
    {
      "paper": {
        "hashed_id": "8fb5f8be2aa9d6c64a04e3ab9f63feee",
        "title": "Can LLMs Enhance Fairness in Recommendation Systems? A Data Augmentation Approach",
        "abstract": "Despite the vital role of recommendation systems (RS) in delivering personalized services tailored to users` needs, user fairness issues have increasingly emerged in recent years, especially differentiated treatments caused by user sensitive attributes. This not only undermines both user experience and platform revenues, but also leads to potential social unfairness. Although many fairness-aware methods have been developed and achieved some success, many of them filter out sensitive attribute information while ignoring the potential loss of personalized information, leading to suboptimal results. Large language models (LLMs) have demonstrated remarkable capabilities across various tasks, while their potential in fairness-aware recommendation remains further unexplored. In this paper, we propose a new exploration of fairness-aware RS by prompting LLMs with the user`s personalized fairness degrees to augment fair user-item interaction for training. Specifically, to estimate the fairness degree of each user, we first design a personalized unfairness modelling module, consisting of a replaceable fairness-aware representation learning model. Moreover, to enable LLMs to perceive fairness from semantic information and adapt to various scenarios, we propose a prompt tuning mechanism to optimize user-shared prompt templates with the objective of maximizing the consistency with users` preferences and the diversity of augmented data. Finally, we utilize LLMs to augment fair interaction data with the optimal prompts and integrate it with the raw data to re-train the recommendation model. Extensive experiments on two real-world datasets demonstrate the superiority of our approach in terms of recommendation performance, fairness, and robustness.",
        "doi": "10.1145/3726302.3729917",
        "sheridan_id": "fp1443",
        "position": 5,
        "track_id": 1,
        "slot_id": 39
      }
    },
    {
      "paper": {
        "hashed_id": "b265ce60fe4c5384e622b09eb829b8df",
        "title": "Large Language Models Enhanced Hyperbolic Space Recommender Systems",
        "abstract": "Large Language Models (LLMs) have attracted significant attention in recommender systems for their excellent world knowledge capabilities. However, existing methods that rely on Euclidean space struggle to capture the rich hierarchical information inherent in textual and semantic data, which is essential for capturing user preferences. The geometric properties of hyperbolic space offer a promising solution to address this issue. Nevertheless, integrating LLMs-based methods with hyperbolic space to effectively extract and incorporate diverse hierarchical information is non-trivial. To this end, we propose a model-agnostic framework, named \\textbf{HyperLLM}, which extracts and integrates hierarchical information from both structural and semantic perspectives. Structurally, HyperLLM uses LLMs to generate multi-level classification tags with hierarchical parent-child relationships for each item. Then, tag-item and user-item interactions are jointly learned and aligned through contrastive learning, thereby providing the model with clear hierarchical information. Semantically, HyperLLM introduces a novel meta-optimized strategy to extract hierarchical information from semantic embeddings and bridge the gap between the semantic and collaborative spaces for seamless integration. Extensive experiments show that HyperLLM significantly outperforms recommender systems based on hyperbolic space and LLMs, achieving performance improvements of over 40\\%. Furthermore, HyperLLM not only improves recommender performance but also enhances training stability, highlighting the critical role of hierarchical information in recommender systems.",
        "doi": "10.1145/3726302.3730019",
        "sheridan_id": "fp1445",
        "position": 6,
        "track_id": 1,
        "slot_id": 38
      }
    },
    {
      "paper": {
        "hashed_id": "c5cc17e395d3049b03e0f1ccebb02b4d",
        "title": "Agentic Feedback Loop Modeling Improves Recommendation and User Simulation",
        "abstract": "Large language model-based agents are increasingly applied in the recommendation field due to their extensive knowledge and strong planning capabilities. While prior research has primarily focused on enhancing either the recommendation agent or the user agent individually, the collaborative interaction between the two has often been overlooked. Towards this research gap, we propose a novel framework that emphasizes the feedback loop process to facilitate the collaboration between the recommendation agent and the user agent. Specifically, the recommendation agent refines its understanding of user preferences by analyzing the feedback from the user agent on the item recommendation. Conversely, the user agent further identifies potential user interests based on the items and recommendation reasons provided by the recommendation agent. This iterative process enhances the ability of both agents to infer user behaviors, enabling more effective item recommendations and more accurate user simulations. Extensive experiments on three datasets demonstrate the effectiveness of the agentic feedback loop: the agentic feedback loop yields an average improvement of 11.52% over the single recommendation agent and 21.12% over the single user agent. Furthermore, the results show that the agentic feedback loop does not exacerbate popularity or position bias, which are typically amplified by the real-world feedback loop, highlighting its robustness. The source code is available at https://github.com/Lanyu0303/AFL.",
        "doi": "10.1145/3726302.3729893",
        "sheridan_id": "fp1450",
        "position": 8,
        "track_id": 1,
        "slot_id": 30
      }
    },
    {
      "paper": {
        "hashed_id": "01d8bae291b1e4724443375634ccfa0e",
        "title": "Preference-Strength-Aware Self-Improving Alignment with Generative Preference Models",
        "abstract": "Self-improving alignment leveraging large language models (LLMs) to automatically generate synthetic preference data has garnered significant attention as a means of reducing reliance on human labelers. These methods typically employ the LLM-as-a-judge mechanism, where the LLM generates responses and then employs itself to judge which response best aligns with the given prompt for curating the binary self-preferred dataset. However, these methods encounter two major challenges: (1) LLM-as-a-judge often produces error-prone evaluations, resulting in low-quality preference annotation, and (2) their optimization strategies often overlook the strength of preferences within binary pairs, leading to overfitting. This paper proposes a novel method, Preference-Strength-aware Optimization (PSO), to address these issues. Specifically, PSO frames the preference annotation process as a judgment token prediction task using the generative preference model to produce reliable judgments. The predicted judgment token indicates the preferred response and its corresponding probability reflects the disparity between responses, referred to as preference strength. Based on this strength, we introduce a new preference-strength-aware loss to adaptively reweight the impact of different response pairs on optimization, concentrating the model`s learning on high-quality response pairs. Our experiments demonstrate that PSO significantly improves performance in preference benchmarks, achieving stronger alignment with human preferences, reducing verbose responses, and mitigating overfitting. Furthermore, PSO exhibits robust generalization and sample efficiency, offering a scalable and promising solution for LLM alignment without relying on human-annotated preferences.",
        "doi": "10.1145/3726302.3730063",
        "sheridan_id": "fp1457",
        "position": 5,
        "track_id": 1,
        "slot_id": 25
      }
    },
    {
      "paper": {
        "hashed_id": "1abb1e1ea5f481b589da52303b091cbb",
        "title": "Document Screenshot Retrievers are Vulnerable to Pixel Poisoning Attacks",
        "abstract": "Recent advancements in dense retrieval have introduced vision-language model (VLM)-based retrievers, such as DSE and ColPali, which leverage document screenshots embedded as vectors to enable effective search and offer a simplified pipeline over traditional text-only methods. In this study, we propose three pixel poisoning attack methods designed to compromise VLM-based retrievers and evaluate their effectiveness under various attack settings and parameter configurations. Our empirical results demonstrate that injecting even a single adversarial screenshot into the retrieval corpus can significantly disrupt search results, poisoning the top-10 retrieved documents for 41.9% of queries in the case of DSE and 26.4% for ColPali. These vulnerability rates notably exceed those observed with equivalent attacks on text-only retrievers. Moreover, when targeting a small set of known queries, the attack success rate raises, achieving complete success in certain cases. By exposing the vulnerabilities inherent in vision-language models, this work highlights the potential risks associated with their deployment.",
        "doi": "10.1145/3726302.3730056",
        "sheridan_id": "fp1459",
        "position": 5,
        "track_id": 1,
        "slot_id": 22
      }
    },
    {
      "paper": {
        "hashed_id": "6d9cb7de5e8ac30bd5e8734bc96a35c1",
        "title": "Empowering Large Language Model Agent through Step-Level Self-Critique and Self-Training",
        "abstract": "Large Language Model (LLM) agents frequently produce sub-optimal actions when tackling complex, multi-step decision-making tasks. Employing self-critique to identify flaws and suggest enhancements is an effective strategy for refining actions. Although trajectory-level critique is commonly employed, it often fails to identify flawed steps accurately. In this paper, we introduce SLSC-MCTS, a method that integrates Monte Carlo Tree Search with Step-Level Self-Critique to enhance LLM agents during both testing and self-training phases. During decision tree expansion with SLSC-MCTS, the LLM agent initially generates an action, receives environmental feedback, and subsequently generates further actions via self-critique and refinement. Through multiple episodes of SLSC-MCTS, LLM agents can effectively utilize step-level critiques while disregarding ineffective ones based on node values, thereby incorporating the critiques more robustly. Additionally, our method further empowers LLM agents in a self-training manner, collecting training data from the constructed decision tree to iteratively fine-tune the LLM agents. The self-training data gathered via SLSC-MCTS is diverse and high-quality, which further enhances the reasoning, critiquing, and refining abilities of LLM agents. Experimental results demonstrate that SLSC-MCTS significantly improves LLM agents during testing, surpassing state-of-the-art baselines and achieving shorter task completion trajectories across information retrieval benchmarks such as WebShop and HotPotQA. After three iterations of self-training, LLM agents established by Llama-3.1-8B-Instruct show substantial improvement, even surpassing human experts in WebShop.",
        "doi": "10.1145/3726302.3729965",
        "sheridan_id": "fp1466",
        "position": 6,
        "track_id": 1,
        "slot_id": 40
      }
    },
    {
      "paper": {
        "hashed_id": "42ffcf057e133f94c1b7b5cf543ef3bd",
        "title": "HCDS: Hierarchical Clustering for Cold-Start Few-Shot Data Selection",
        "abstract": "Deep learning models usually require large labeled datasets to generalize well, but this is computationally and financially costly. Cold-start few-shot data selection enables fast model generalization by selecting a few diverse, representative samples from an unlabeled data pool. To achieve this goal, previous work usually divides the training data into several clusters and performs sampling from these clusters. Yet, such a way tends to have two issues. First, imbalanced data distribution in the training data pool still exists in the selected subset, causing models` performance biases and suboptimal generalization ability. Second, these methods improve sample diversity in each cluster by considering either the feature dissimilarity among instances, or model uncertainty for individual instance. They ignore the entire representativeness of samples within a cluster. To tackle these challenges, we propose a novel framework HCDS : Hierarchical Clustering for Cold-Start Few-Shot Data Selection. Specifically, we first perform class-level clustering, using pseudo-labels for class supervision and applying contrastive clustering to derive class-rich features. We then refine these features within the class-level clusters into semantically meaningful features and perform representation-level clustering. Finally, we sample data from the representation-level clusters based on global similarity to ensure representativeness. Experimental results on six public datasets, including both balanced and imbalanced ones, show that HCDS achieves state-of-the-art performance, particularly with limited and imbalanced data.",
        "doi": "10.1145/3726302.3729992",
        "sheridan_id": "fp1470",
        "position": 5,
        "track_id": 1,
        "slot_id": 20
      }
    },
    {
      "paper": {
        "hashed_id": "ab541d874c7bc19ab77642849e02b89f",
        "title": "Classifying Term Variants in Query Formulation",
        "abstract": "Formulating queries is a challenging stage of the search process. This study investigates how crowd workers formulate an initial query for a common information need described in a backstory, resulting in diverse query variations. Using the UQV100 dataset of information need backstories and corresponding queries, we analyze the variations. Our findings show that 70% of the query terms used in crowd worker queries did not appear in the backstory text. Examining such terms we developed a taxonomy of search strategies, with the most common being semantic variations of backstory terms, followed by information type specifications. Additionally, we categorized the backstories by cognitive complexity, showing that higher complexity led to greater diversity in query variations and a wider range of term variant categories. This study highlights the importance of accounting for query variations, term variants, user strategies, and cognitive complexity in designing search systems and test collections to better align with users` information needs, influenced by the cognitive demands of a task, and enhance system performance and usability.",
        "doi": "10.1145/3726302.3729924",
        "sheridan_id": "fp1482",
        "position": 7,
        "track_id": 1,
        "slot_id": 12
      }
    },
    {
      "paper": {
        "hashed_id": "0f3d014eead934bbdbacb62a01dc4831",
        "title": "Unconstrained Monotonic Calibration of Predictions in Deep Ranking Systems",
        "abstract": "Ranking models primarily focus on modeling the relative order of predictions while often neglecting the significance of the accuracy of their absolute values. However, accurate absolute values are essential for certain downstream tasks, necessitating the calibration of the original predictions. To address this, existing calibration approaches typically employ predefined transformation functions with order-preserving properties to adjust the original predictions. Unfortunately, these functions often adhere to fixed forms, such as piece-wise linear functions, which exhibit limited expressiveness and flexibility, thereby constraining their effectiveness in complex calibration scenarios. To mitigate this issue, we propose implementing a calibrator using an Unconstrained Monotonic Neural Network (UMNN), which can learn arbitrary monotonic functions with great modeling power. This approach significantly relaxes the constraints on the calibrator, improving its flexibility and expressiveness while avoiding excessively distorting the original predictions by requiring monotonicity. Furthermore, to optimize this highly flexible network for calibration, we introduce a novel additional loss function termed Smooth Calibration Loss (SCLoss), which aims to fulfill a necessary condition for achieving the ideal calibration state. Extensive offline experiments confirm the effectiveness of our method in achieving superior calibration performance. Moreover, deployment in Kuaishou`s large-scale online video ranking system demonstrates that the method`s calibration improvements translate into enhanced business metrics. The source code is available at https://github.com/baiyimeng/UMC.",
        "doi": "10.1145/3726302.3730105",
        "sheridan_id": "fp1512",
        "position": 7,
        "track_id": 1,
        "slot_id": 11
      }
    },
    {
      "paper": {
        "hashed_id": "98986c005e5def2da341b4e0627d4712",
        "title": "Multi-scenario Instance Embedding Learning for Deep Recommender Systems",
        "abstract": "Multi-scenario recommendation (MSR) has become a core component of various online platforms, but its increasing model size has also brought attention to its efficiency optimization. An important effort is to find effective and efficient feature embedding layers for MSR, and existing work focuses on scenario-level feature selection, i.e., all instance embeddings in the same scenario get the same filtering results on the feature set, and the filtering results are different for different scenarios. However, this ignores the information redundancy of the dimension set and the individuality of different instances in the same scenario. To address these limitations, we propose a multi-scenario instance embedding learning (MultiEmb) framework that implements exclusive feature-dimension redundant information removal for different instances within a scenario to obtain the optimal individual embeddings. The core of our MultiEmb is to introduce an instance embedding selection network to effectively complete the above challenging tasks, in which a set of feature selection and dimension selection adaptive components are equipped for each scenario, and their combination completes the optimal embedding selection for each instance. Finally, we evaluate MultiEmb through extensive experiments on two public multi-scenario benchmarks and demonstrate its effectiveness, compatibility, transferability, etc.",
        "doi": "10.1145/3726302.3730045",
        "sheridan_id": "fp1554",
        "position": 6,
        "track_id": 1,
        "slot_id": 1
      }
    },
    {
      "paper": {
        "hashed_id": "42d6c7d61481d1c21bd1635f59edae05",
        "title": "Adaptive Structure Learning with Partial Parameter Sharing for Post-Click Conversion Rate Prediction",
        "abstract": "The post-click conversion rate (CVR) prediction task aims to predict the probability of a conversion after a click, which is essential in many fields. There are two widely-recognized challenges for CVR prediction: selection bias and data sparsity. Many previous methods focus on addressing selection bias by unbiasedly estimating the ideal loss based on the doubly robust estimator, which incorporates the error imputation model and propensity model to help CVR prediction model learning. However, they struggle with unreasonable knowledge transfer between the prediction model and imputation model and inflexible network structure design under sparse data. To this end, we introduce a novel principled adaptive structure learning approach, named Adap-SL, to adaptively learn the optimal network structure, adjust the number of activated (non-zero) parameters, and determine which knowledge needs to be transferred between the prediction model and the imputation model. Specifically, we start with an over-parameterized base network, where we adaptively extract partially overlapped subnetworks for the imputation model and the prediction model. Extensive experiments are conducted on three real-world recommendation datasets, demonstrating that our method consistently improves performance while requiring fewer parameters. The code is available at https://github.com/ChunyuanZheng/sigir25-sparse-sharing.",
        "doi": "10.1145/3726302.3729887",
        "sheridan_id": "fp1518",
        "position": 3,
        "track_id": 1,
        "slot_id": 4
      }
    },
    {
      "paper": {
        "hashed_id": "748ba69d3e8d1af87f84fee909eef339",
        "title": "Rating-Aware Homogeneous Review Graphs and User Likes/Dislikes Differentiation for Effective Recommendations",
        "abstract": "The goal of Review-Based Recommendation System (RBRS) is toeffectively learn the representations of users and items by utilizingreview texts in addition to user-item interactions. From user-iteminteraction graphs widely employed in recommendation systems,recent RBRS methods using graph neural networks (GNNs) obtainthe representations by associating each edge between a user and anitem with the review information of the user for that item. However,these GNN-based RBRS methods present two main issues: (1) by con-verting each review text into the weight, i.e., single value, of a edgebetween a user node and an item node, they lose the rich informa-tion about users and items inherent in the review; and (2) by creatingonly a single general representation for each user, they cannot repre-sent the individual effects of users\u2019 likes and dislikes on their ratingsfor items they have interacted with. To address these problems, wepropose a novel GNN-based RBRS, named LETTER, utilizing homo-geneous graphs, i.e., user-user graphs and an item-item graph, tolearn general representations of users and items along with users\u2019like and dislike representations. LETTER can learn user and itemrepresentations without losing review information by utilizing theproposed homogeneous graphs. Furthermore, LETTER explicitlydesigns the influence of users\u2019 like and dislike representations ontheir ratings to perform accurate rating predictions. Through ex-periments on six datasets, we verify that the proposed LETTER out-performs nine state-of-the-art RBRSs by up to 23.1%. Our sourcecode is available at https://github.com/Bigdasgit/LETTER.",
        "doi": "10.1145/3726302.3730069",
        "sheridan_id": "fp1535",
        "position": 6,
        "track_id": 1,
        "slot_id": 2
      }
    },
    {
      "paper": {
        "hashed_id": "17e23e50bedc63b4095e3d8204ce063b",
        "title": "How Users Interact with Generative Information Retrieval Systems: A Study of User Behavior and Search Experience",
        "abstract": "The development of LLM has facilitated the emergence of generative information retrieval (IR) systems, such as ``Bing Chat``. Generative IR systems return generated text with citations rather than a list of ranked search results. User studies on IR systems are essential for understanding users` interaction patterns, evaluating and optimizing systems, and improving search experience, particularly in the context of generative IR systems with novel conversational interfaces and responses. However, systematic investigations into user behavior and search experience on generative IR systems are notably lacking. To address this gap, we conducted a user study using Bing Chat to explore user behavior and feedback on generative IR systems. The participants were required to accomplish three types of tasks using Bing Chat. During the search process, we collected their various behavior (e.g., click, query reformulation) and explicit feedback (e.g., satisfaction, credibility, and success). Additionally, the same study was conducted on traditional IR systems Bing for comparison. Analyses of these data show that Bing Chat can reduce the user`s search effort and lead to a better search experience without any decrease in credibility compared with Bing. We believe that this work provides valuable insight into the design and evaluation of generative information retrieval systems.",
        "doi": "10.1145/3726302.3729998",
        "sheridan_id": "fp1539",
        "position": 6,
        "track_id": 1,
        "slot_id": 9
      }
    },
    {
      "paper": {
        "hashed_id": "c88d8d0a6097754525e02c2246d8d27f",
        "title": "Adaptive User Dynamic Interest Guidance for Generative Sequential Recommendation",
        "abstract": "Recently, diffusion model-based methods have utilized user interest features as guidance conditions to achieve stable generation results in sequential recommendation tasks. However, these models struggle to capture users` dynamic interests, as the interests of different users are often inconsistent. Moreover, the fixed number of interests predefined by existing models cannot adapt to the diverse preferences of users, making it difficult to further improve recommendation performance. To address these issues, we propose a novel generative sequential recommendation framework named ADIGRec (Adaptive User Dynamic Interest Guidance for Generative Sequential Recommendation), which adaptively focuses on users` dynamic interest features. Specifically, our framework combines users` dynamic features and inherent interest features encoded from historical sequences as new guidance conditions. Furthermore, we introduce a module that injects dynamic interest features into the noise item embeddings, enabling explicit interaction with the guidance conditions during the generation phase. This approach essentially fits the noise in the target space rather than the user preference space, leading to improved recommendation diversity. Additionally, we propose a novel regularization method to mitigate the impact of user interest routing collapse on the generation results. Extensive experiments on three publicly available datasets demonstrate that our method achieves superior performance compared to established baseline methods.",
        "doi": "10.1145/3726302.3729888",
        "sheridan_id": "fp1549",
        "position": 3,
        "track_id": 1,
        "slot_id": 21
      }
    },
    {
      "paper": {
        "hashed_id": "3430095c577593aad3c39c701712bcfe",
        "title": "Leveraging Artificial Intelligence-Powered Virtual Assistant for Information Retrieval in Indigenous Agriculture: Insights from Nigeria",
        "abstract": "This study examines the use of an AI-powered Virtual Assistant (VA) to aid information retrieval in the cultivation of indigenous vegetables in Nigeria. A two-phase approach involved a needs assessment with 240 youth and the deployment of a bilingual web-based VA using a Large Language Model. The results show a strong youth interest in the tool, despite infrastructure and financial challenges. The VA achieved a high Precision@3 score (0.87), indicating its potential to improve agricultural decision-making in low-resource areas. The use of the VA can improve access to timely and context-specific agricultural knowledge, thereby supporting climate change adaptation and contributing to global food security.",
        "doi": "10.1145/3726302.3730265",
        "sheridan_id": "lr2489",
        "position": 4,
        "track_id": 9,
        "slot_id": 26
      }
    },
    {
      "paper": {
        "hashed_id": "8cff9bf6694dccfc3b6a613d05d51d16",
        "title": "Dense Retrieval for Low Resource languages - the Case of Amharic Language",
        "abstract": "This paper presents our investigation into dense retrieval models for Amharic, a low-resource language spoken by more than 120 million people. We constructed training datasets tailored to dense retrieval models and evaluated model performance by comparing dense and sparse retrieval approaches on Amharic information retrieval. The study also highlights the challenges and efforts involved in advancing retrieval systems for low-resource languages.",
        "doi": "10.1145/3726302.3730274",
        "sheridan_id": "lr2629",
        "position": 5,
        "track_id": 9,
        "slot_id": 26
      }
    },
    {
      "paper": {
        "hashed_id": "f12f2b34a0c3174269c19e21c07dee68",
        "title": "Towards Enhanced Agricultural Information Access in Kiswahili: Integrating Knowledge Graphs and Retrieval-Augmented Generation",
        "abstract": "Access to and consumption of agricultural research findings remains a challenge for Kiswahili-speaking farmers and extension officers in Tanzania due to the predominance of English in agriculture scholarly publications. To address this challenge, the Mkulima repository, a digital collection of over 600 Swahili agricultural publications, was developed at the Sokoine University of Agriculture to provide agriculture knowledge in Kiswahili. However, its current structure limits effective retrieval and accessibility, given the type of its intended audience, smallholder farmers. This work-in-progress aims to improve access to agricultural knowledge in Kiswahili through a hybrid model that integrates a domain-specific Knowledge Graph (KG) with Retrieval-Augmented Generation (RAG), an approach that combines traditional retrieval with generative language models for producing informed answers. The project`s findings are aimed to contribute to AI-driven retrieval systems for low-resource languages, with results targeted for submission as a paper to SIGIR 2026.",
        "doi": "10.1145/3726302.3730271",
        "sheridan_id": "lr2642",
        "position": 3,
        "track_id": 9,
        "slot_id": 26
      }
    },
    {
      "paper": {
        "hashed_id": "f35a2bc72dfdc2aae569a0c7370bd7f5",
        "title": "Some Things Never Change: Overcoming Persistent Challenges in Children IR",
        "abstract": "There is a lack of a steady and solid influx of information retrieval (IR) research that has children (as the user group) as the protagonist. Existing work is scattered, conducted by only a few research groups, and often based on small-scale user studies or data that cannot be widely shared. Moreover, much of the current research focuses on specific age ranges and abilities, neglecting the broader spectrum of children\u2019s needs. Consequently, the paucity of IR research on how search and recommender systems serve and/or ultimately affect children translates into one of many \u2018Low-resource environments\u2019 in IR. Drawing from the literature and our experience in this area, we highlight key challenges and encourage greater attention from the IR community to address this critical gap.",
        "doi": "10.1145/3726302.3730270",
        "sheridan_id": "lr2644",
        "position": 4,
        "track_id": 9,
        "slot_id": 35
      }
    },
    {
      "paper": {
        "hashed_id": "908a6f6a6c131a850ecb0e3f11b08189",
        "title": "IR for AAC Users: A Hyperdimensional Computing (Vector Symbolic Architectures) Approach",
        "abstract": "This work proposes Hyperdimensional Computing (HDC) as a design paradigm [13] to facilitate search and recommendation activities for disabled users employing symbolic augmentative and alternative communication (AAC) systems. Such a context necessitates flexibility and composability in item and query representations as a consequence of vocabularies being tailored to an individual user. HDC is suggested to meet these needs in an efficient manner. However, construction and empirical evaluation are left to additional research.  Project development for symbolic AAC supports a small but highly diverse user base. This creates a ``low resource environment`` from both an economic and technical perspective. The heterogeneity of user communication abilities, preferences, and symbolic interpretation limits the generalisability of datasets and presents a cold start problem. Furthermore, countries with underdeveloped social welfare and health infrastructure, the Philippines serving as an illustrative example, have few practitioners able to fine-tune AAC devices or support inclusive decision making. Consequently, this exacerbates resource constraints, which motivates systems to offer consumer-level ease of use. Rural areas, in any socioeconomic setting, lack reliable network connectivity: designers should anticipate regular on-device computation, leaving networked tasks to limited occasions. Technologies for disabilities, broadly speaking, are related to all 17 UN Sustainable Development Goals [21]. Additionally, AAC is a focus area of UNICEF`s work on disabilities and inclusion for marginalised children [2].  By proposing HDC as a way to mediate diverse feature spaces, search and recommendation applications are able to reuse semantic components and process structures --- reducing costs. This flexibility enables adaptation to underserved cultures, where localised symbol interpretations are particularly needed [3]. A similar approach has been taken to circulate open access symbols [2]. HDC`s development comes from an interdisciplinary perspective, implementing cognitive and linguistic science precepts computationally [8]. Building on this idea, AAC for search requires wider collaboration with entities outside the traditional information retrieval (IR) community, such as speech pathologists, disability support workers, and end users with disabilities.",
        "doi": "10.1145/3726302.3730273",
        "sheridan_id": "lr2663",
        "position": 3,
        "track_id": 9,
        "slot_id": 35
      }
    },
    {
      "paper": {
        "hashed_id": "7edccc661418aeb5761dbcdc06ad490c",
        "title": "Efficient Approximate Nearest Neighbor Search on a Raspberry Pi",
        "abstract": "Approximate Nearest Neighbors (ANN) search is a core task in Information Retrieval. However, the high computational demands and reliance on expensive infrastructures limit broader contributions to ANN research. Enabling efficient and effective ANN search on low-resource devices would allow researchers in low-income countries to participate in the ANN community, thereby democratizing the field. Despite its potential, the IR literature offers little work on the feasibility of ANN search under resource constraints. In this proposal, we explore efficient solutions for large-scale ANN search on low-resource devices. We report a preliminary experimentation highlighting current limitations and outlining future challenges.",
        "doi": "10.1145/3726302.3730268",
        "sheridan_id": "lr2667",
        "position": 2,
        "track_id": 9,
        "slot_id": 35
      }
    },
    {
      "paper": {
        "hashed_id": "0e900ad84f63618452210ab8baae0218",
        "title": "When Less is Enough: Optimizations for Low-Cost Recommendation Systems",
        "abstract": "Social media platforms rely heavily on ad revenue, making cost-efficient recommendation systems essential for sustaining profitability while preserving user satisfaction, especially in regions with low Average Revenue Per User (ARPU). We present a comprehensive approach that combines model-side optimizations (e.g., fused operations, reducing system responsiveness) with system-side enhancements (e.g., improved load balancing, half precision) to lower infrastructure costs without significantly compromising user engagement. Some of the optimizations below were deployed in production to serve 180M users, these optimizations deliver 57% cloud cost savings with less than 0.4% drop in retention and increase net profitability. This work provides a scalable blueprint for cost-efficient recommendation systems and offers actionable insights for deploying such systems in resource-constrained environments.",
        "doi": "10.1145/3726302.3730267",
        "sheridan_id": "lr2672",
        "position": 1,
        "track_id": 9,
        "slot_id": 35
      }
    },
    {
      "paper": {
        "hashed_id": "d89a66c7c80a29b1bdbab0f2a1a94af8",
        "title": "Fair Access to Food Data in Africa: An Approach Based on Retrieval-Augmented Generation",
        "abstract": "In this paper, we propose a Retrieval-Augmented Generation-based (RAG) approach for fair access to food data in developing countries. This work also contributes to achieving sustainable development goals, specifically goal 2: Zero hunger and goal 3: Ensure healthy lives and promote well-being for all at all ages. Actually, given that a lot of African food data is accessible only in PDF format, we firstly extracted and organized these data using the Open Research Knowledge Graph (ORKG) and the image data using the Firebase database, with the link to the corresponding food description in the ORKG. Currently, more than 1000 foods eaten in around 50 African countries are already documented. Given that Large Language Models necessitate a lot of data and resources to be train/fine-tuned, which we do not have in our university, our idea is to use the food data stored in the ORKG to build a Retrieval-Augmented Generation system (RAG) for improving access to food data in Africa. Its implementation involved the use of multi-embedding models, vector databases (Pinecone), Falcon3 and LangChain. Because we do not have enough resources, this work is made possible thanks to a collaboration with TIB-Hannover who provide access to remote computers.",
        "doi": "10.1145/3726302.3730266",
        "sheridan_id": "lr2676",
        "position": 2,
        "track_id": 9,
        "slot_id": 26
      }
    },
    {
      "paper": {
        "hashed_id": "92af93f73faf3cefc129b6bc55a748a9",
        "title": "An Instruction-Response Perspective on Large Language Models in Information Retrieval Tasks",
        "abstract": "The increasing use of retrieval-augmented applications, where large language models (LLMs) are instructed to generate queries, assess relevance, and synthesise responses, has introduced new challenges in Information Retrieval (IR). The lack of transparency in LLMs means that even subtle variations in instructions can significantly impact the quality, consistency, and reliability of their responses. To address this issue, we propose Instruction-Response Study, an experimental framework for systematically analysing how task instructions influence LLM-generated responses in IR tasks. This paper presents the core components of the framework and demonstrates its utility through four case studies, examining 1) the effect of IR tasks on query formulation, 2) the impact of topic information size on retrieval effectiveness, 3) the reproducibility of LLM-generated queries, and 4) the role of meta-instructions in diversifying instruction design. The findings highlight how the proposed framework enables controlled experimentation on instruction design and its effects, offering a foundation for optimising prompt engineering and enhancing retrieval-augmented applications.",
        "doi": "10.1145/3726302.3730346",
        "sheridan_id": "per1562",
        "position": 3,
        "track_id": 8,
        "slot_id": 36
      }
    },
    {
      "paper": {
        "hashed_id": "b0f2ad44d26e1a6f244201fe0fd864d1",
        "title": "From Query to Conscience: The Importance of Information Retrieval in Empowering Socially Responsible Consumerism",
        "abstract": "Millions of consumers search for products online each day, aiming to find items that meet their needs at an acceptable price. While price and quality are major factors in purchasing decisions, ethical considerations increasingly influence consumer behavior -giving rise to the socially responsible consumer. Insights from a recent survey of over 600 consumers reveal that many barriers to ethical shopping stem from information-seeking challenges, often leading to decisions made under uncertainty. These challenges contribute to the intention\u2013behaviour gap, where consumers` desire to make ethical choices is undermined by limited or inaccessible information and inefficacy of search systems in supporting responsible decision-making. In this perspectives paper, we argue that the field of Information Retrieval (IR) has a critical role to play by empowering consumers to make more informed and more responsible choices. We present three interrelated perspectives: (1) reframing ethical consumption as an information extraction problem aimed at reducing information asymmetries; (2) redefining product search as a complex task requiring interfaces that lower the cost and burden of responsible search; and (3) reimagining search as a process of knowledge calibration that helps consumers bridge gaps in awareness when making purchasing decisions. Taken together, these perspectives outline a path from query to conscience - one where IR systems help transform everyday product searches into opportunities for more ethical and informed choices. We advocate for the development of new and novel IR systems and interfaces that address the intricacies of socially responsible consumerism, and call on the IR community to build technologies that make ethical decisions more informed, convenient, and aligned with economic realities.",
        "doi": "10.1145/3726302.3730347",
        "sheridan_id": "per1668",
        "position": 2,
        "track_id": 8,
        "slot_id": 36
      }
    },
    {
      "paper": {
        "hashed_id": "3214a6d842cc69597f9edf26df552e43",
        "title": "Rankers, Judges, and Assistants: Towards Understanding the Interplay of LLMs in Information Retrieval Evaluation",
        "abstract": "Large language models (LLMs) are increasingly integral to information retrieval (IR), powering ranking, evaluation, and AI-assisted content creation. This widespread adoption necessitates a critical examination of potential biases arising from the interplay between these LLM-based components. This paper synthesizes existing research and presents novel experiment designs that explore how LLM-based rankers and assistants influence LLM-based judges. We provide the first empirical evidence of LLM judges exhibiting significant bias towards LLM-based rankers. Furthermore, we observe limitations in LLM judges` ability to discern subtle system performance differences. Contrary to some previous findings, our preliminary study does not find evidence of bias against AI-generated content. These results highlight the need for a more holistic view of the LLM-driven information ecosystem. To this end, we offer initial guidelines and a research agenda to ensure the reliable use of LLMs in IR evaluation.",
        "doi": "10.1145/3726302.3730348",
        "sheridan_id": "per1880",
        "position": 1,
        "track_id": 8,
        "slot_id": 36
      }
    },
    {
      "paper": {
        "hashed_id": "a9813e9550fee3110373c21fa012eee7",
        "title": "Information Retrieval for Artificial General Intelligence: A New Perspective of Information Retrieval Research",
        "abstract": "Traditionally, the users of an information retrieval (IR) system have been human users. We present a new perspective on IR research in which the users of an IR system are intelligent agents instead of human users. Extending the current work on retrieval-augmented generation (RAG), we identify five novel IR tasks that an intelligent agent must be able to perform in order to achieve Human-Level Artificial Intelligence, or Artificial General Intelligence (AGI), including 1) External Information Retrieval (EIR) to access new information unseen by the agent, 2) Provenance Information Retrieval (PIR) to trace the provenance of information, 3) Curriculum Information Retrieval (CIR) to actively acquire the most useful new data and information for lifelong learning, 4) Rule Information Retrieval (RIR) to perform reasoning and problem solving, and 5) Scenario Information Retrieval (SIR) to leverage past scenarios for problem solving and decision making. We compare these new IR tasks with the traditional IR tasks performed by an IR system that serves human users and systematically examine the challenges involved in the five new IR tasks, providing a roadmap for new IR research within the broader context of AGI development.",
        "doi": "10.1145/3726302.3730349",
        "sheridan_id": "per2051",
        "position": 3,
        "track_id": 8,
        "slot_id": 28
      }
    },
    {
      "paper": {
        "hashed_id": "fca0789e7891cbc0583298a238316122",
        "title": "Brain-Machine Interfaces & Information Retrieval Challenges and Opportunities",
        "abstract": "The fundamental goal of Information Retrieval (IR) systems lies in their capacity to effectively satisfy human information needs - a challenge that encompasses not just the technical delivery of information, but the nuanced understanding of human cognition during information seeking. Contemporary IR platforms rely primarily on observable interaction signals, creating a fundamental gap between system capabilities and users` cognitive processes. Brain-Machine Interface (BMI) technologies now offer unprecedented potential to bridge this gap through direct measurement of previously inaccessible aspects of information-seeking behaviour. This perspective paper offers a broad examination of the IR landscape, providing a comprehensive analysis of how BMI technology could transform IR systems, drawing from advances at the intersection of both neuroscience and IR research. We present our analysis through three identified fundamental vertices: (1) understanding the neural correlates of core IR concepts to advance theoretical models of search behaviour, (2) enhancing existing IR systems through contextual integration of neurophysiological signals, and (3) developing proactive IR capabilities through direct neurophysiological measurement. For each vertex, we identify specific research opportunities and propose concrete directions for developing BMI-enhanced IR systems. We conclude by examining critical technical and ethical challenges in implementing these advances, providing a structured roadmap for future research at the intersection of neuroscience and IR.",
        "doi": "10.1145/3726302.3730350",
        "sheridan_id": "per2134",
        "position": 5,
        "track_id": 8,
        "slot_id": 36
      }
    },
    {
      "paper": {
        "hashed_id": "936a40b7e8eea0dc537e5f2edee1387a",
        "title": "Adaptive Orchestration of Modular Generative Information Access Systems",
        "abstract": "Advancements in large language models (LLMs) have driven the emergence of complex new systems to provide access to information, that we will collectively refer to as modular generative information access (GenIA) systems. They integrate a broad and evolving range of specialized components, including LLMs, retrieval models, and a heterogeneous set of sources and tools. While modularity offers flexibility, it also raises critical challenges: How can we systematically characterize the space of possible modules and their interactions? How can we automate and optimize interactions among these heterogeneous components? And, how do we enable this modular system to dynamically adapt to varying user query requirements and evolving module capabilities?  In this perspective paper, we argue that the architecture of future modular generative information access systems will not just assemble powerful components, but enable a self-organizing system through real-time adaptive orchestration -- where components` interactions are dynamically configured for each user input, maximizing information relevance while minimizing computational overhead. We give provisional answers to the questions raised above with a roadmap that depicts the key principles and methods for designing such an adaptive modular system. We identify pressing challenges, and propose avenues for addressing them in the years ahead. This perspective urges the IR community to rethink modular system designs for developing adaptive, self-optimizing, and future-ready architectures that evolve alongside their rapidly advancing underlying technologies.",
        "doi": "10.1145/3726302.3730351",
        "sheridan_id": "per2146",
        "position": 4,
        "track_id": 8,
        "slot_id": 28
      }
    },
    {
      "paper": {
        "hashed_id": "86e78499eeb33fb9cac16b7555b50767",
        "title": "From To-Do to Ta-Da: Transforming Task-Focused IR with Generative AI",
        "abstract": "For decades, scholars have emphasized that tasks should be the central focus in Information Retrieval (IR). This point of view holds even more significance with the advent of Generative Artificial Intelligence (GenAI) models, which can, among other capabilities, understand natural language, engage in dialog with users, generate bespoke user interfaces, and power agents to help complete tasks. GenAI presents an unprecedented opportunity to finally realize the potential of tasks in IR, enhance task-focused retrieval and interaction, and create ``magical`` task completion moments for users. In this paper, we explore the rationale and methodology behind this argument. Traditional IR systems support mostly simple tasks. The emergence of GenAI creates an opportunity for IR systems to help users achieve complex tasks and for the IR community to rekindle its interest and demonstrate leadership in this sizable and significant problem space. We underscore the pivotal role of tasks in IR and introduce new evidence supporting the notion that task-centric approaches, abstracted from specific modalities, represent the future of IR. Building on this foundation, we envision the development, utilization, and evaluation of next-generation IR systems. We propose a promising future where IR agents prioritize users, their tasks, and their situations. However, despite their potential to address task-focused and modality-independent IR, agents alone are insufficient. We propose a robust ecosystem around these agents that transcends traditional queries, questions, prompts, and modalities to address users` fundamental needs, tasks, and goals.",
        "doi": "10.1145/3726302.3730352",
        "sheridan_id": "per2162",
        "position": 1,
        "track_id": 8,
        "slot_id": 28
      }
    },
    {
      "paper": {
        "hashed_id": "40b5f25a228570053bc64a043c3f1833",
        "title": "NExT-Search: Rebuilding User Feedback Ecosystem for Generative AI Search",
        "abstract": "Generative AI search driven by large language models (LLMs) is reshaping information retrieval by offering end-to-end answers to complex queries, reducing users` reliance on manually browsing and summarizing multiple web pages. However, while this paradigm enhances convenience, it disrupts the feedback-driven improvement loop that has historically powered the evolution of traditional Web search. Web search can continuously improve their ranking models by collecting large-scale, fine-grained user feedback (e.g., clicks, dwell time) at the document level. In contrast, generative AI search operates through a much longer search pipeline\u2014spanning query decomposition, document retrieval, and answer generation\u2014yet typically receives only coarse-grained feedback on the final answer. This introduces a feedback loop disconnect, where user feedback for the final output cannot be effectively mapped back to specific system components, making it difficult to improve each intermediate stage and sustain the feedback loop. To address this limitation, we envision NExT-Search, a next-generation paradigm designed to reintroduce fine-grained, process-level feedback into generative AI search. NExT-Search integrates two complementary modes: User Debug Mode, which allows engaged users to intervene at key stages\u2014such as refining query decomposition, rating retrieved documents, and editing initial generated responses\u2014and Shadow User Mode, where a personalized user agent simulates user preferences and provides AI-assisted feedback for less interactive users. As these feedback signals serve as valuable resources for refining the whole search pipeline, we also introduce a feedback store mechanism that encourages users to share and monetize their debugging efforts, further incentivizing participation. Furthermore, we envision how these feedback signals can be leveraged through online adaptation, which refines current search outputs in real-time, and offline update, which aggregates interaction logs to periodically fine-tune query decomposition, retrieval, and generation models. By restoring human control over key stages of the generative AI search pipeline, we believe NExT-Search offers a promising direction for building feedback-rich AI search systems that can evolve continuously alongside human feedback.",
        "doi": "10.1145/3726302.3730353",
        "sheridan_id": "per2299",
        "position": 4,
        "track_id": 8,
        "slot_id": 36
      }
    },
    {
      "paper": {
        "hashed_id": "d254c8a084d4545bd80577481aa03076",
        "title": "Toward Holistic Evaluation of Recommender Systems Powered by Generative Models",
        "abstract": "Recommender systems powered by generative models (Gen-RecSys) extend beyond classical item-ranking by producing open-ended content, which simultaneously unlocks richer user experiences and introduces new risks. On one hand, these systems can enhance personalization and appeal through dynamic explanations and multi-turn dialogues. On the other hand, they might venture into unknown territory\u2014hallucinating nonexistent items, amplifying bias, or leaking private information. Traditional accuracy metrics cannot fully capture these challenges, as they fail to measure factual correctness, content safety, or alignment with user intent. This paper makes two main contributions. First, we categorize the evaluation challenges of Gen-RecSys into two groups: (i) existing concerns that are exacerbated by generative outputs (e.g., bias, privacy) and (ii) entirely new risks (e.g., item hallucinations, contradictory explanations). Second, we propose a holistic evaluation approach that includes scenario-based assessments and multi-metric checks\u2014incorporating relevance, factual grounding, bias detection, and policy compliance. Our goal is to provide a guiding framework so that researchers and practitioners can thoroughly assess Gen-RecSys, ensuring both effective personalization and responsible deployment.",
        "doi": "10.1145/3726302.3730354",
        "sheridan_id": "per2354",
        "position": 2,
        "track_id": 8,
        "slot_id": 28
      }
    },
    {
      "paper": {
        "hashed_id": "f670ef5d2d6bdf8f29450a970494dd64",
        "title": "Gosling Grows Up: Retrieval with Learned Dense and Sparse Representations Using Anserini",
        "abstract": "The Anserini IR toolkit has come a long way since efforts began in 2015. Although the goals of the project \u2014 to bridge research and practice in information retrieval, and to provide reproducible, easy-to-use baselines \u2014 have remained constant, the world has changed quite a bit. We discuss how Anserini has evolved in response to this changing environment, the most significant of which is the advent of transformer-based retrieval models that did not exist when the project started. The bi-encoder architecture provides a framework for understanding retrieval models based on dense and sparse vector representations, and offers a reference for conveying the capabilities of our toolkit. Anserini provides end-to-end first-stage retrieval based on single-vector learned dense and sparse representations, directly building on the open-source Lucene search library and the ONNX runtime. This minimal design accelerates the pace of research and fosters reproducibility, enabling ``two-click reproductions``. By better aligning research and practice, we increase the potential real-world impact of research innovations.",
        "doi": "10.1145/3726302.3730281",
        "sheridan_id": "rr1643",
        "position": 2,
        "track_id": 5,
        "slot_id": 27
      }
    },
    {
      "paper": {
        "hashed_id": "d86ea612dec96096c5e0fcc8dd42ab6d",
        "title": "My System Is As Effective As Yours: Reproducibility, Sustainability, and More",
        "abstract": "When a paired or two-sample t-test shows that a difference is not statistically significant (i.e., the null hypothesis H is \"accepted\"), all we obtain as a \"conclusion\" is: \" we cannot conclude from the data whether the difference is real or not. \" In general, statistical significance tests with a significance level of \u03b1 give us a proper conclusion with 100(1-\u03b1)% confidence only if the H is rejected. Hence, for example, in a reproducibility study in IR, traditional significance tests like the t-test are not adequate if one wishes to claim that the reproduced run is as good as the target run. In this paper, we show that the equivalence test, which has been gaining popularity in the medical domain for comparing new drugs with standard drugs, is applicable to IR research in situations such as above. We also discuss the less ambitious noninferiority test, which can be used, for example, when an IR researcher wants to claim that their system performs no worse than a state-of-the-art system that is computationally much more expensive and therefore earth-unfriendly. The equivalence and noninferiority tests require researchers to pre-define an indifference zone, which defines how much difference is \"practically negligible\"; hence we also discuss one possible approach to establishing an indifference zone for a given IR effectiveness measure. In addition, we provide recommendations for IR researchers who wish to conduct equivalence/noninferiority tests involving more than two systems. It is hoped that equivalence and noninferiority tests will become standard practices in IR, so that we can avoid making claims based on lack of statistical significance.",
        "doi": "10.1145/3726302.3730345",
        "sheridan_id": "per603",
        "position": 6,
        "track_id": 8,
        "slot_id": 36
      }
    },
    {
      "paper": {
        "hashed_id": "a14ac55a4f27472c5d894ec1c3c743d2",
        "title": "Benchmarking Recommendation, Classification, and Tracing Based on Hugging Face Knowledge Graph",
        "abstract": "The rapid growth of open source machine learning (ML) resources, such as models and datasets, has accelerated IR research. However, existing platforms like Hugging Face do not explicitly utilize structured representations, limiting advanced queries and analyses such as tracing model evolution and recommending relevant datasets. To fill the gap, we construct HuggingKG, the first large-scale knowledge graph built from the Hugging Face community for ML resource management. With 2.6 million nodes and 6.2 million edges, HuggingKG captures domain-specific relations and rich textual attributes. It enables us to further present HuggingBench, a multi-task benchmark with three novel test collections for IR tasks including resource recommendation, classification, and tracing. Our experiments reveal unique characteristics of HuggingKG and the derived tasks. Both resources are publicly available, expected to advance research in open source resource sharing and management.",
        "doi": "10.1145/3726302.3730277",
        "sheridan_id": "rr1610",
        "position": 98,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "b618c3210e934362ac261db280128c22",
        "title": "Reproducibility, Replicability, and Insights into Visual Document Retrieval with Late Interaction",
        "abstract": "Visual Document Retrieval (VDR) is an emerging research area that focuses on encoding and retrieving document images directly, bypassing the dependence on Optical Character Recognition (OCR) for document search. A recent advance in VDR was introduced by ColPali, which significantly improved retrieval effectiveness through a late interaction mechanism. ColPali`s approach demonstrated substantial performance gains over existing baselines that do not use late interaction on an established benchmark. In this study, we investigate the reproducibility and replicability of VDR methods with and without late interaction mechanisms by systematically evaluating their performance across multiple pre-trained vision-language models. Our findings confirm that late interaction yields considerable improvements in retrieval effectiveness; however, it also introduces computational inefficiencies during inference. Additionally, we examine the adaptability of VDR models to textual inputs and assess their robustness across text-intensive datasets within the proposed benchmark, particularly when scaling the indexing mechanism. Furthermore, our research investigates the specific contributions of late interaction by looking into query-patch matching in the context of visual document retrieval. We find that although query tokens cannot explicitly match image patches as in the text retrieval scenario, they tend to match the patch contains visually similar tokens or their surrounding patches.",
        "doi": "10.1145/3726302.3730285",
        "sheridan_id": "rr1686",
        "position": 3,
        "track_id": 6,
        "slot_id": 177
      }
    },
    {
      "paper": {
        "hashed_id": "fc6709bfdf0572f183c1a84ce5276e96",
        "title": "Accelerating Listwise Reranking: Reproducing and Enhancing FIRST",
        "abstract": "Large language models (LLMs) have emerged as powerful listwise rerankers but remain prohibitively slow for many real-world applications. What`s more, training on the language modeling (LM) objective is not intrinsically aligned with reranking tasks. To address these challenges, FIRST, a novel approach for listwise reranking, integrates a learning-to-rank objective and leverages only the logits of the first generated token for reranking, significantly reducing computational overhead while preserving effectiveness. We systematically evaluate the capabilities and limitations of FIRST. By extending its evaluation to TREC Deep Learning collections (DL19-23), we show that FIRST achieves robust out-of-domain effectiveness. Through training FIRST on a variety of backbone models, we demonstrate its generalizability across different model architectures, and achieve effectiveness surpassing the original implementation. Further analysis of the interaction between FIRST and various first-stage retrievers reveals diminishing returns akin to traditional LLM rerankers. A comprehensive latency study confirms that FIRST consistently delivers a 40% efficiency gain over traditional rerankers without sacrificing effectiveness. Notably, while LM training implicitly improves zero-shot single-token reranking, our experiments also highlight potential conflicts between LM pre-training and subsequent fine-tuning on the FIRST objective. These findings pave the way for more efficient and effective listwise reranking in future applications. Our code is available at: https://rankllm.ai.",
        "doi": "10.1145/3726302.3730287",
        "sheridan_id": "rr1718",
        "position": 2,
        "track_id": 6,
        "slot_id": 13
      }
    },
    {
      "paper": {
        "hashed_id": "2647c1dba23bc0e0f9cdf75339e120d2",
        "title": "nlcTables: A Dataset for Marrying Natural Language Conditions with Table Discovery",
        "abstract": "With the growing abundance of repositories containing tabular data, discovering relevant tables for in-depth analysis remains a challenging task. Existing table discovery methods primarily retrieve desired tables based on a query table or several vague keywords, leaving users to manually filter large result sets. To address this limitation, we propose a new task: NL-conditional table discovery (nlcTD), where users combine a query table with natural language (NL) requirements to refine search results. To advance research in this area, we present nlcTables, a comprehensive benchmark dataset comprising 627 diverse queries spanning NL-only, union, join, and fuzzy conditions, 22,080 candidate tables, and 21,200 relevance annotations. Our evaluation of six state-of-the-art table discovery methods on nlcTables reveals substantial performance gaps, highlighting the need for advanced techniques to tackle this challenging nlcTD scenario. The dataset, construction framework, and baseline implementations are publicly available at https://github.com/SuDIS-ZJU/nlcTables to foster future research.",
        "doi": "10.1145/3726302.3730296",
        "sheridan_id": "rr1824",
        "position": 102,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "01e00f2f4bfcbb7505cb641066f2859b",
        "title": "Doctron: A Web-based Collaborative Annotation Tool for Ground Truth Creation in IR",
        "abstract": "In Information Retrieval (IR), ground truth creation is a crucial yet resource-intensive task that relies on human experts to build test collections -- essential for training and evaluating retrieval models. Large-scale evaluation campaigns, such as TREC and CLEF, demand significant human effort to produce reliable, high-quality annotations. To ease this process, tailored annotation tools are pivotal to supporting assessors and streamlining their workload. To this end, we introduce Doctron, a web-based, dockerized annotation tool designed to streamline ground truth creation for IR tasks. Doctron enables the annotation of both textual documents and images. It supports annotating textual passages, identifying relationships, tagging and linking entities, evaluating document relevance to a topic with graded labels, and performing object detection. It offers a collaborative environment where teams can work with defined user roles and permissions. The integration of Inter Annotator Agreement (IAA) measures helps to identify inconsistencies between annotators, thereby ensuring the reliability and high quality of the annotated ground truth data.",
        "doi": "10.1145/3726302.3730286",
        "sheridan_id": "rr1700",
        "position": 69,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "5d79099fcdf499f12b79770834c0164a",
        "title": "WikiHint: A Human-Annotated Dataset for Hint Ranking and Generation",
        "abstract": "The use of Large Language Models (LLMs) has increased significantly with users frequently asking questions to chatbots. In the time when information is readily accessible, it is crucial to stimulate and preserve human cognitive abilities and maintain strong reasoning skills. This paper addresses such challenges by promoting the use of hints as an alternative or a supplement to direct answers. We first introduce a manually constructed hint dataset, WikiHint, which is based on Wikipedia and includes 5,000 hints created for 1,000 questions. We then finetune open-source LLMs for hint generation in answer-aware and answer-agnostic contexts. We assess the effectiveness of the hints with human participants who answer questions with and without the aid of hints. Additionally, we introduce a lightweight evaluation method, HintRank, to evaluate and rank hints in both answer-aware and answer-agnostic settings. Our findings show that (a) the dataset helps generate more effective hints, (b) including answer information along with questions generally improves the quality of generated hints, and (c) encoder-based models perform better than decoder-based models in hint ranking.",
        "doi": "10.1145/3726302.3730284",
        "sheridan_id": "rr1685",
        "position": 72,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "08e6bea8e90ba87af3c9554d94db6579",
        "title": "RE-AdaptIR: Improving Information Retrieval through Reverse Engineered Adaptation",
        "abstract": "Large language models (LLMs) fine-tuned for text-retrieval have demonstrated state-of-the-art results across several information retrieval (IR) benchmarks. However, supervised training for improving these models requires numerous labeled examples, which are generally unavailable or expensive to acquire. In this work, we explore the effectiveness of extending reverse engineered adaptation to the context of information retrieval (RE-AdaptIR). We use RE-AdaptIR to improve LLM-based IR models using only unlabeled data. We demonstrate improved performance in both training domains and in zero-shot domains where the models have seen no queries. We analyze performance changes in various fine-tuning scenarios and offer findings of immediate use to IR practitioners.",
        "doi": "10.1145/3726302.3730240",
        "sheridan_id": "sp1677",
        "position": 18,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "db957c626a8cd7a27231adfbf51e20eb",
        "title": "Revisiting Algorithmic Audits of TikTok: Poor Reproducibility and Short-term Validity of Findings",
        "abstract": "Social media platforms are constantly shifting towards algorithmically curated content based on implicit or explicit user feedback. Regulators, as well as researchers, are calling for systematic social media algorithmic audits as this shift leads to enclosing users in filter bubbles and leading them to more problematic content. An important aspect of such audits is the reproducibility and generalisability of their findings, as it allows to draw verifiable conclusions and audit potential changes in algorithms over time. In this work, we study the reproducibility of the existing sockpuppeting audits of TikTok recommender systems, and the generalizability of their findings. In our efforts to reproduce the previous works, we find multiple challenges stemming from social media platform changes and content evolution, but also the research works themselves. These drawbacks limit the audit reproducibility and require an extensive effort altogether with inevitable adjustments to the auditing methodology. Our experiments also reveal that these one-shot audit findings often hold only in the short term, implying that the reproducibility and generalizability of the audits heavily depend on the methodological choices and the state of algorithms and content on the platform. This highlights the importance of reproducible audits that allow us to determine how the situation changes in time.",
        "doi": "10.1145/3726302.3730293",
        "sheridan_id": "rr1788",
        "position": 7,
        "track_id": 6,
        "slot_id": 177
      }
    },
    {
      "paper": {
        "hashed_id": "8c3039bd5842dca3d944faab91447818",
        "title": "WebFAQ: A Multilingual Collection of Natural Q&A Datasets for Dense Retrieval",
        "abstract": "We present WebFAQ, a large-scale collection of open-domain question answering datasets derived from FAQ-style schema.org annotations. In total, the data collection consists of 96 million natural question-answer (QA) pairs across 75 languages, including 47 million (49%) non-English samples. WebFAQ further serves as the foundation for 49 monolingual retrieval benchmarks with a total size of 11.2 million QA pairs (5.9 million non-English). These datasets are carefully curated through refined filtering and near-duplicate detection, yielding high-quality resources for training and evaluating multilingual dense retrieval models. To empirically confirm WebFAQ`s efficacy, we use the collected QAs to fine-tune an in-domain pretrained XLM-RoBERTa model. Through this process of dataset-specific fine-tuning, the model achieves significant retrieval performance gains, which generalize - beyond WebFAQ - to other multilingual retrieval benchmarks evaluated in zero-shot setting. Last but not least, we utilize WebFAQ to construct a set of QA-aligned bilingual corpora spanning over 1000 language pairs using state-of-the-art bitext mining and automated LLM-assessed translation evaluation. Due to our advanced, automated method of bitext dataset generation, the resulting bilingual corpora demonstrate higher translation quality compared to similar datasets. WebFAQ and all associated resources are publicly available on GitHub and HuggingFace.",
        "doi": "10.1145/3726302.3731934",
        "sheridan_id": "rr1850",
        "position": 65,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "f542eae1949358e25d8bfeefe5b199f1",
        "title": "JuDGE: Benchmarking Judgment Document Generation for Chinese Legal System",
        "abstract": "This paper introduces JuDGE (Judgment Document Generation Evaluation), a novel benchmark for evaluating the performance of judgment document generation in the Chinese legal system. We define the task as generating a complete legal judgment document from the given factual description of the case. To facilitate this benchmark, we construct a comprehensive dataset consisting of factual descriptions from real legal cases, paired with their corresponding full judgment documents, which serve as the ground truth for evaluating the quality of generated documents. This dataset is further augmented by two external legal corpora that provide additional legal knowledge for the task: one comprising statutes and regulations, and the other consisting of a large collection of past judgment documents. In collaboration with legal professionals, we establish a comprehensive automated evaluation framework to assess the quality of generated judgment documents across various dimensions. We evaluate various baseline approaches, including few-shot in-context learning, fine-tuning, and a multi-source retrieval-augmented generation (RAG) approach, using both general and legal-domain LLMs. The experimental results demonstrate that, while RAG approaches can effectively improve performance in this task, there is still substantial room for further improvement. All the codes and datasets are available at: https://github.com/oneal2000/JuDGE",
        "doi": "10.1145/3726302.3730295",
        "sheridan_id": "rr1813",
        "position": 75,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "cd63a3eec3319fd9c84c942a08316e00",
        "title": "IDAT: A Multi-Modal Dataset and Toolkit for Building and Evaluating Interactive Task-Solving Agents",
        "abstract": "Seamless interaction between AI agents and humans using natural language remains a key goal in AI research. This paper addresses the challenges of developing interactive agents capable of understanding and executing grounded natural language instructions through the IGLU competition. Despite advancements, challenges such as a scarcity of appropriate datasets and the need for effective evaluation platforms persist. We introduce a scalable data collection tool for gathering interactive grounded language instructions within a Minecraft-like environment, resulting in a Multi-Modal dataset with around 9,000 utterances and over 1,000 clarification questions. Additionally, we present a Human-in-the-Loop interactive evaluation platform for qualitative analysis and comparison of agent performance through multi-turn communication with human annotators. We offer to the community these assets referred to as IDAT (IGLU Dataset And Toolkit) which aim to advance the development of intelligent, interactive AI agents and provide essential resources for further research.",
        "doi": "10.1145/3726302.3730300",
        "sheridan_id": "rr1849",
        "position": 96,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "958adb57686c2fdec5796398de5f317a",
        "title": "Information Leakage of Sentence Embeddings via Generative Embedding Inversion Attacks",
        "abstract": "Text data are often encoded as dense vectors, known as embeddings, which capture semantic, syntactic, contextual, and domain-specific information. These embeddings, widely adopted in various applications, inherently contain rich information that may be susceptible to leakage under certain attacks. The GEIA framework highlights vulnerabilities in sentence embeddings, demonstrating that they can reveal the original sentences they represent. In this study, we reproduce GEIA`s findings across various neural sentence embedding models. Additionally, we contribute new analysis to examine whether these models leak sensitive information from their training datasets. We propose a simple yet effective method without any modification to the attacker`s architecture proposed in GEIA. The key idea is to examine differences between log-likelihood for masked and original variants of data that sentence embedding models have been pre-trained on, calculated on the embedding space of the attacker. Our findings indicate that following our approach, an adversary party can recover meaningful sensitive information related to the pre-training knowledge of the popular models used for creating sentence embeddings, seriously undermining their security. Our code is available on: https://github.com/taslanidis/GEIA",
        "doi": "10.1145/3726302.3730303",
        "sheridan_id": "rr1874",
        "position": 8,
        "track_id": 6,
        "slot_id": 13
      }
    },
    {
      "paper": {
        "hashed_id": "65699726a3c601b9f31bf04019c8593c",
        "title": "Benchmarking LLM-based Relevance Judgment Methods",
        "abstract": "Large Language Models (LLMs) are increasingly deployed in both academic and industry settings to automate the evaluation of information seeking systems, particularly by generating graded relevance judgments. Several studies report Kendall $\\tau$ correlations exceeding $0.85$ when comparing system rankings derived from human versus LLM-generated relevance labels. Previous work on LLM-based relevance assessment has primarily focused on replicating graded human relevance judgments through various prompting strategies. However, there has been limited exploration of alternative assessment methods or comprehensive comparative studies. In this paper, we systematically compare multiple LLM-based relevance assessment methods, including binary relevance judgments, graded relevance assessments, pairwise preference-based methods, and two nugget-based evaluation methods~--~document-agnostic and document-dependent. Wherever possible, we employ state-of-the-art tools and optimized prompts tailored for these methods. In addition to a traditional comparison based on system rankings using Kendall correlations, we also examine how well LLM judgments align with human preferences, as inferred from relevance grades. We conduct extensive experiments on datasets from three TREC Deep Learning tracks 2019, 2020 and 2021 as well as the ANTIQUE dataset, which focuses on non-factoid open-domain question answering. Beyond dataset-specific results, our work offers a practical methodology for evaluating diverse LLM-based relevance assessment methods. As part of our data release, we include relevance judgments generated by both an open-source (Llama3.2b) and a commercial (gpt-4o)  model.  Our goal is to \\textit{reproduce} various LLM-based relevance judgment methods to provide a comprehensive comparison. We release all the relevance judgments as a \\textit{resource} that establishes a baseline for future work, ensuring a level playing field for evaluation of LLM-based relevance judgments. All code, data, and resources are publicly available in our GitHub Repository at \\url{https://github.com/Narabzad/llm-relevance-judgement-comparison}",
        "doi": "10.1145/3726302.3730305",
        "sheridan_id": "rr1908",
        "position": 3,
        "track_id": 5,
        "slot_id": 13
      }
    },
    {
      "paper": {
        "hashed_id": "8038da89e49ac5eabb489cfc6cea9fc1",
        "title": "Investigating the Robustness of Counterfactual Learning to Rank Models: A Reproducibility Study",
        "abstract": "Counterfactual learning to rank (CLTR) has attracted extensive attention in the IR community for its ability to leverage massive logged user interaction data to train ranking models. While the CLTR models can be theoretically unbiased when the user behavior assumption is correct and the propensity estimation is accurate, their effectiveness is usually empirically evaluated via simulation-based experiments due to a lack of widely available, large-scale, real click logs. However, many previous simulation-based experiments are somewhat limited because they may have one or more of the following deficiencies: 1) using a weak production ranker to generate initial ranked lists, 2) relying on a simplified user simulation model to simulate user clicks, and 3) generating a fixed number of synthetic click logs. As a result, the robustness of CLTR models in complex and diverse situations is largely unknown and needs further investigation. To address this problem, in this paper, we aim to investigate the robustness of existing CLTR models in a reproducibility study with extensive simulation-based experiments that (1) use production rankers with different ranking performance, (2) leverage multiple user simulation models with different user behavior assumptions, and (3) generate different numbers of synthetic sessions for the training queries. We find that the IPS-DCM, DLA-PBM, and UPE models show better robustness under various simulation settings than other CLTR models. Moreover, existing CLTR models often fail to outperform naive click baselines when the production ranker is strong and the number of training sessions is limited, indicating a pressing need for new CLTR algorithms tailored to these conditions.",
        "doi": "10.1145/3726302.3730310",
        "sheridan_id": "rr2013",
        "position": 1,
        "track_id": 6,
        "slot_id": 6
      }
    },
    {
      "paper": {
        "hashed_id": "051928341be67dcba03f0e04104d9047",
        "title": "Inside Out 2: Make Room for New Emotions & LLM: A Reproducibility Study of the Emotional Side of Search in the Classroom",
        "abstract": "In an existing study, the InsideOut Framework is used to produce and explore the emotional profiles of search engines (SE) in response to queries formulated by children aged 9 to 11 in the classroom context, revealing the emotional diversity of SE responses. Since then, there have been significant technological advances in emotion detection and information access. In this work, we conduct a comprehensive reproducibility study where we probe today`s emotional profile of SE using both a lexicon-based and a language-model based approach tailored to the Italian language, thus addressing an acknowledged limitation of the original study. Additionally, considering the prevalence of agents based on Large Language Models (LLM) as information access systems among children, we extend the analysis to capture the emotional undertones of LLM responses and juxtapose them to those of SE. Our findings emphasize the importance of leveraging the appropriate emotion detection technique to produce and explore emotional profiles and lead us to reflect on the interplay of emotions on children`s search-as-learning experience.",
        "doi": "10.1145/3726302.3730315",
        "sheridan_id": "rr2048",
        "position": 5,
        "track_id": 6,
        "slot_id": 13
      }
    },
    {
      "paper": {
        "hashed_id": "801272ee79cfde7fa5960571fee36b9b",
        "title": "Does UMBRELA work on other LLMs?",
        "abstract": "We reproduce the UMBRELA LLM Judge evaluation framework across a range of large language models (LLMs) to assess its generalizability beyond the original study. Our investigation evaluates how LLM choice affects relevance assessment accuracy, focusing on leaderboard rank correlation and per-label agreement metrics. Results demonstrate that UMBRELA with DeepSeek V3 obtains very comparable performance to GPT-4o (used in original work). For LLaMA-3.3-70B we obtain slightly lower performance, which further degrades with smaller LLMs.",
        "doi": "10.1145/3726302.3730317",
        "sheridan_id": "rr2092",
        "position": 4,
        "track_id": 6,
        "slot_id": 13
      }
    },
    {
      "paper": {
        "hashed_id": "cf2226ddd41b1a2d0ae51dab54d32c36",
        "title": "Unveiling DIME: Reproducibility, Generalizability, and Formal Analysis of Dimension Importance Estimation for Dense Retrieval",
        "abstract": "Dimension IMportance Estimation (DIME) is a recently proposed technique to enhance ranking effectiveness of dense retrieval models by pruning irrelevant embedding dimensions through Pseudo Relevance Feedback (PRF DIME) or exploiting dense representations of Large Language Model-generated answers (LLM DIME). Despite strong empirical performance, its theoretical foundations and generalizability remain open questions.  In this paper, we propose four key contributions. First, we provide a rigorous theoretical analysis of DIME, framing it as a denoising mechanism that mitigates embedding noise while preserving the salient information. Second, we conduct a comprehensive reproducibility study, confirming previously reported gains for both PRF DIME and LLM DIME. Third, we extend the evaluations of PRF DIME by applying it to a broader set of embedding models with distinct characteristics, such as matryoshka embeddings, cosine similarity-optimized models, and architectures that produce high-dimensional representations, while also testing it on diverse retrieval datasets. For LLM DIME, we expand the analysis across a range of LLMs, comparing high-parameter proprietary models with cheaper open-source alternatives. Finally, we refine DIME by introducing an attention-inspired PRF mechanism and propose to leverage dimension importance as a reranking technique.",
        "doi": "10.1145/3726302.3730318",
        "sheridan_id": "rr2094",
        "position": 3,
        "track_id": 6,
        "slot_id": 27
      }
    },
    {
      "paper": {
        "hashed_id": "8208974663db80265e9bfe7b222dcb18",
        "title": "Wiki-TabNER: Integrating Named Entity Recognition into Wikipedia Tables",
        "abstract": "Interest in solving table interpretation tasks has grown over the years, yet it still relies on existing datasets that may be overly simplified. This is potentially reducing the effectiveness of the dataset for thorough evaluation and failing to accurately represent tables as they appear in the real-world. To enrich the existing benchmark datasets, we extract and annotate a new, more challenging dataset. The proposed Wiki-TabNER dataset features complex tables containing several entities per cell, with named entities labeled using DBpedia classes. This dataset is specifically designed to address named entity recognition (NER) task within tables, but it can also be used as a more challenging dataset for evaluating the entity linking task. In this paper we describe the distinguishing features of the Wiki-TabNER dataset and the labeling process. In addition, we propose a prompting framework for evaluating the new large language models on the within tables NER task. Finally, we perform qualitative analysis to gain insights into the challenges encountered by the models and to understand the limitations of the proposed~dataset.",
        "doi": "10.1145/3726302.3730344",
        "sheridan_id": "rr2404",
        "position": 108,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "ea119a40c1592979f51819b0bd38d39d",
        "title": "A Versatile Dataset of Mouse and Eye Movements on Search Engine Results Pages",
        "abstract": "We contribute a comprehensive dataset to study user attention and purchasing behavior on Search Engine Result Pages (SERPs).Previous work has relied on mouse movements as a low-cost large-scale behavioral proxybut also has relied on self-reported ground-truth labels, collected at post-task,which can be inaccurate and prone to biases. To address this limitation, we use an eye tracker to construct an \\emph{objective} ground-truth of \\emph{continuous} visual attention.Our dataset comprises 2,776 transactional queries on Google SERPs, collected from 47 participants, and includes:(1)~HTML source files, with CSS and images; (2)~rendered SERP screenshots; (3)~eye movement data; (4)~mouse movement data; (5)~bounding boxes of direct display and organic advertisements;and (6)~scripts for further preprocessing the data.In this paper we provide an overview of the dataset and baseline experiments (classification tasks)that can inspire researchers about the different possibilities for future work.",
        "doi": "10.1145/3726302.3730325",
        "sheridan_id": "rr2197",
        "position": 74,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "df1f1d20ee86704251795841e6a9405a",
        "title": "2D Matryoshka Training for Information Retrieval",
        "abstract": "2D Matryoshka Training is an advanced embedding representation training approach designed to train an encoder model simultaneously across various layer-dimension setups. This method has demonstrated higher effectiveness in Semantic Text Similarity (STS) tasks over traditional training approaches when using sub-layers for embeddings. Despite its success, discrepancies exist between two published implementations, leading to varied comparative results with baseline models. In this reproducibility study, we implement and evaluate both versions of 2D Matryoshka Training on STS tasks and extend our analysis to retrieval tasks. Our findings indicate that while both versions achieve higher effectiveness than traditional Matryoshka training on sub-dimensions, and traditional full-sized model training approaches, they do not outperform models trained separately on specific sub-layer and sub-dimension setups. Moreover, these results generalize well to retrieval tasks, both in supervised (MSMARCO) and zero-shot (BEIR) settings. Further explorations of different loss computations reveals more suitable implementations for retrieval tasks, such as incorporating full-dimension loss and training on a broader range of target dimensions. Conversely, some intuitive approaches, such as fixing document encoders to full model outputs, do not yield improvements. Our reproduction code is available at https://github.com/ielab/2DMSE-Reproduce.",
        "doi": "10.1145/3726302.3730330",
        "sheridan_id": "rr2247",
        "position": 7,
        "track_id": 6,
        "slot_id": 6
      }
    },
    {
      "paper": {
        "hashed_id": "ddd9dda6bfaf0bb1525a8a27c3ee6131",
        "title": "Beyond Reproducibility: Advancing Zero-shot LLM Reranking Efficiency with Setwise Insertion",
        "abstract": "This study presents a comprehensive reproducibility analysis and extension of the Setwise prompting method for zero-shot ranking with Large Language Models (LLMs), as proposed by Zhuang et al.. We evaluate the method`s effectiveness and efficiency compared to traditional Pointwise, Pairwise, and Listwise approaches in document ranking tasks. Our reproduction confirms the findings of Zhuang et al., highlighting the trade-offs between computational efficiency and ranking effectiveness in Setwise methods. Building on these insights, we introduce Setwise Insertion, a novel approach that leverages the initial document ranking as prior knowledge, reducing unnecessary comparisons and uncertainty by prioritizing candidates more likely to improve the ranking results. Experimental results across multiple LLM architectures - Flan-T5, Vicuna, and Llama - show that Setwise Insertion yields a 31% reduction in query time, a 23% reduction in model inferences, and a slight improvement in reranking effectiveness compared to the original Setwise method. These findings highlight the practical advantage of incorporating prior ranking knowledge into Setwise prompting for efficient and accurate zero-shot document reranking.",
        "doi": "10.1145/3726302.3730323",
        "sheridan_id": "rr2159",
        "position": 8,
        "track_id": 6,
        "slot_id": 177
      }
    },
    {
      "paper": {
        "hashed_id": "3147da8ab4a0437c15ef51a5cc7f2dc4",
        "title": "Reassessing Large Language Model Boolean Query Generation for Systematic Reviews",
        "abstract": "Systematic reviews are comprehensive literature reviews that address highly focused research questions and represent the highest form of evidence in medicine. A critical step in this process is the development of complex Boolean queries to retrieve relevant literature. Given the difficulty of manually constructing these queries, recent efforts have explored Large Language Models (LLMs) to assist in their formulation. One of the first studies, Wang et al. [21], investigated ChatGPT for this task, followed by Staudinger et al. [14], which evaluated multiple LLMs in a reproducibility study. However, the latter overlooked several key aspects of the original work, including (i) validation of generated queries, (ii) output formatting constraints, and (iii) selection of examples for chainof- thought (Guided) prompting. As a result, its findings diverged significantly from the original study. In this work, we systematically reproduce both studies while addressing these overlooked factors. Our results show that query effectiveness varies significantly across models and prompt designs, with guided query formulation benefiting from well-chosen seed studies. Overall, prompt design and model selection are key drivers of successful query formulation. Our findings provide a clearer understanding of LLMs\u2019 potential in Boolean query generation and highlight the importance of modeland prompt-specific optimisations. The complex nature of systematic reviews adds to challenges in both developing and reproducing methods but also highlights the importance of reproducibility studies in this domain.",
        "doi": "10.1145/3726302.3730329",
        "sheridan_id": "rr2244",
        "position": 6,
        "track_id": 6,
        "slot_id": 177
      }
    },
    {
      "paper": {
        "hashed_id": "38651c4450f87348fcbe1f992746a954",
        "title": "Pre-training vs. Fine-tuning: A Reproducibility Study on Dense Retrieval Knowledge Acquisition",
        "abstract": "Dense retrievers utilize pre-trained backbone language models (e.g., BERT, LLaMA) that are fine-tuned via contrastive learning to perform the task of encoding text into sense representations that can be then compared via a shallow similarity operation, e.g. inner product. Recent research has questioned the role of fine-tuning vs. that of pre-training within dense retrievers, specifically arguing that retrieval knowledge is primarily gained during pre-training, meaning knowledge not acquired during pre-training cannot be sub-sequentially acquired via fine-tuning. We revisit this idea here as the claim was only studied in the context of a BERT-based encoder using DPR as representative dense retriever. We extend the previous analysis by testing other representation approaches (comparing the use of CLS tokens with that of mean pooling), backbone architectures (encoder-only BERT vs. decoder-only LLaMA), and additional datasets (MSMARCO in addition to Natural Questions). Our study confirms that in DPR tuning, pre-trained knowledge underpins retrieval performance, with fine-tuning primarily adjusting neuron activation rather than reorganizing knowledge. However, this pattern does not hold universally, such as in mean-pooled (Contriever) and decoder-based (LLaMA) models. We ensure full reproducibility and make our implementation publicly available at https://github.com/ielab/DenseRetriever-Knowledge-Acquisition.",
        "doi": "10.1145/3726302.3730332",
        "sheridan_id": "rr2254",
        "position": 1,
        "track_id": 6,
        "slot_id": 27
      }
    },
    {
      "paper": {
        "hashed_id": "26505e0494662534f633586941b77d0c",
        "title": "ELOQ: Resources for Enhancing LLM Detection of Out-of-Scope Questions",
        "abstract": "Retrieval-augmented generation (RAG) has become integral to large language models (LLMs), particularly for conversational AI systems where user questions may reference knowledge beyond the LLMs\u2019 training cutoff. However, many natural user questions lack well-defined answers, either due to limited domain knowledge or because the retrieval system returns documents that are relevant in appearance but uninformative in content. In such cases, LLMs often produce hallucinated answers without flagging them. While recent work has largely focused on questions with false premises, we study out-of-scope questions, where the retrieved document appears semantically similar to the question but lacks the necessary information to answer it. In this paper, we propose a guided hallucination-based approach ELOQ \\footnote{\\url{https://github.com/zhiyuanpeng/ELOQ.git}}, for automatically generating a diverse set of out-of-scope questions from post-cutoff documents, followed by human verification to ensure quality. We use this dataset to evaluate several LLMs on their ability to detect out-of-scope questions and generate appropriate responses. Finally, we introduce an improved detection method that enhances the reliability of LLM-based question-answering systems in handling out-of-scope questions.",
        "doi": "10.1145/3726302.3730333",
        "sheridan_id": "rr2263",
        "position": 71,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "b166b57d195370cd41f80dd29ed523d9",
        "title": "Extending MovieLens-32M to Provide New Evaluation Objectives",
        "abstract": "Offline evaluation of recommender systems has traditionally treated the problem as a machine learning problem.  In the classic case of recommending movies, where the user has provided explicit ratings of which movies they like and don`t like, each user`s ratings are split into test and train sets, and the evaluation task becomes to predict the held out test data using the training data.  This machine learning style of evaluation makes the objective to recommend the movies that a user has watched and rated highly, which is not the same task as helping the user find movies that they would enjoy if they watched them. This mismatch in objective between evaluation and task is a compromise to avoid the cost of asking a user to evaluate recommendations by watching each movie.  As a resource available for download, we offer an extension to the MovieLens-32M dataset that provides for new evaluation objectives. Our primary objective is to predict the movies that a user would be interested in watching, i.e. predict their watchlist.  To construct this extension, we recruited MovieLens users, collected their profiles, made recommendations with a diverse set of algorithms, pooled the recommendations, and had the users assess the pools.  This paper demonstrates the feasibility of using pooling to construct a test collection for recommender systems.  Notably, we found that the traditional machine learning style of evaluation ranks the Popular algorithm, which recommends movies based on total number of ratings in the system, in the middle of the twenty-two recommendation runs we used to build the pools.  In contrast, when we rank the runs by users` interest in watching movies, we find that recommending popular movies as a recommendation algorithm becomes one of the worst performing runs.  It appears that by asking users to assess their personal recommendations, we can alleviate the issue of popularity bias in the evaluation of top-n recommendation.",
        "doi": "10.1145/3726302.3730328",
        "sheridan_id": "rr2237",
        "position": 119,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "add217938e07bb1fd8796e0315b88c10",
        "title": "REANIMATOR: Reanimate Retrieval Test Collections with Extracted and Synthetic Resources",
        "abstract": "Retrieval test collections are essential for evaluating information retrieval systems, yet they often lack generalizability across tasks.To overcome this limitation, we introduce REANIMATOR, a versatile framework designed to enable the repurposing of existing test collections by enriching them with extracted and synthetic resources.REANIMATOR enhances test collections from PDF files by parsing full texts and machine-readable tables, as well as related contextual information.It then employs state-of-the-art large language models to produce synthetic relevance labels. Including an optional human-in-the-loop step can help validate the resources that have been extracted and generated.We demonstrate its potential with a revitalized version of the TREC-COVID test collection, showcasing the development of a retrieval-augmented generation system and evaluating the impact of tables on retrieval-augmented generation.REANIMATOR enables the reuse of test collections for new applications, lowering costs and broadening the utility of legacy resources.",
        "doi": "10.1145/3726302.3730342",
        "sheridan_id": "rr2379",
        "position": 101,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "2d2ca7eedf739ef4c3800713ec482e1a",
        "title": "RARR Unraveled: Component-Level Insights into Hallucination Detection and Mitigation",
        "abstract": "Large Language Models (LLMs) often exhibit hallucinations, which makes detecting and mitigating these errors a critical challenge. The Retrofit Attribution using Research and Revision (RARR) framework addresses this challenge by extracting key aspects of an LLM response, verifying them against retrieved evidence, and resolving errors through re-prompting. In this work, we critically examine RARR and adapt its framework to incorporate publicly available evidence retrieval systems and generative models, thereby operationalizing the approach. We focus on hallucination detection, analyzing how each pipeline component contributes to this task. We also conduct a sentence-level analysis of hallucinations to provide a more granular assessment of RARR`s performance. A key finding is that while query generation and retrieval are effective, the agreement module emerges as the weakest link in the RARR pipeline. We offer deeper insights into RARR`s strengths, limitations, and potential areas for improvement, thereby broadening our understanding of hallucination detection in LLMs.",
        "doi": "10.1145/3726302.3730337",
        "sheridan_id": "rr2305",
        "position": 1,
        "track_id": 6,
        "slot_id": 13
      }
    },
    {
      "paper": {
        "hashed_id": "6211080fa89981f66b1a0c9d55c61d0f",
        "title": "A Reproducibility Study of LLM Setwise Reranker with Heapsort",
        "abstract": "Large language models (LLMs) can be effective at retrievalbut are generally too expensive to use as first-stage rankers.As a consequence, several approaches to their use as rerankers of less expensive first-stage retrieval resultshave been suggested.Zhuang et al. recommend setwise approaches.In particular, they use heapsort to efficiently return top-ranked documentsby obtaining a partial order from each LLM call. Utilizing rerankers requires setting parameterssuch as %window size,number of input documents,number of documents to be reranked,evaluation depth,number of tokens per document, and selection of LLM, all of which contribute to latency and effectiveness. In this work, we reproduce the batching and reranking of Zhuang et al. with a larger comparison window size.Furthermore, we determine that the document truncation used in the original implementation is suboptimal.By providing more context to the LLM, we show that the reranker is more effective than originally reported.",
        "doi": "10.1145/3726302.3730338",
        "sheridan_id": "rr2307",
        "position": 6,
        "track_id": 6,
        "slot_id": 13
      }
    },
    {
      "paper": {
        "hashed_id": "20d135f0f28185b84a4cf7aa51f29500",
        "title": "Private Preferences, Public Rankings: A Privacy-Preserving Framework for Marketplace Recommendations",
        "abstract": "Protecting user privacy in recommender systems is crucial for fostering trust in marketplaces. In this paper, we propose a privacy-preserving framework that integrates public seller rankings into personalized recommendations without exposing sensitive user preferences. By utilizing ``seller representative users`` (encoding seller item rankings) and a novel recommendation mechanism, the framework preserves privacy while ensuring robust ranking accuracy. Our approach is validated on multiple use cases extracted from real-world datasets, showing its effectiveness across varying marketplace configurations. This framework is suited for real-world applications, such as e-commerce platforms, where it can enhance user trust, protect sensitive data, and improve engagement by transparently balancing personalization and privacy.",
        "doi": "10.1145/3726302.3730237",
        "sheridan_id": "sp1112",
        "position": 4,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "565030e1fce4e481f9823a7de3b8a047",
        "title": "ir_explain: A Python Library of Explainable IR Methods",
        "abstract": "While recent advancements in Neural Ranking Models have resulted in significant improvements over traditional statistical retrieval models, it is generally acknowledged that the use of large neural architectures and the application of complex language models in Information Retrieval (IR) have reduced the transparency of retrieval methods. Consequently, Explainability and Interpretability have emerged as important research topics in IR. Several axiomatic and post-hoc explanation methods, as well as approaches that attempt to be interpretable-by-design, have been proposed. We present ir_explain, an open-source Python library that implements a variety of well-known techniques for Explainable IR (ExIR) within a common, extensible framework. It supports the three standard categories of post-hoc explanations, namely pointwise, pairwise, and listwise explanations. The library is designed to make it easy to reproduce state-of-the-art ExIR baselines on standard test collections, as well as to explore new approaches to explaining IR models and methods. To facilitate adoption, ir_explain is well-integrated with widely-used toolkits such as Pyserini, PyTerrier (work in progress) and ir_datasets. Downstream applications of ir_explain include explaining the Retrieval-Augmented Generation (RAG) pipeline. The development version of the library is available on GitHub. We release the library as a pip package (https://pypi.org/project/ir-explain/); source code is available from https://github.com/souravsaha/ir_explain.",
        "doi": "10.1145/3726302.3730343",
        "sheridan_id": "rr2398",
        "position": 97,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "07a9d3fed4c5ea6b17e80258dee231fa",
        "title": "Negative Exclusion Filtering: Optimizing Ad Delivery Efficiency for Large-Scale Social Media Platforms",
        "abstract": "The volume of ads ranked impacts the performance of ad ranking systems. To enhance efficiency, multi-stage ranking systems are widely studied in academia and adopted across industry. However, as large-scale deep learning recommendation models gain prevalence, resource constraints---especially CPU and GPU limitations---have become a significant bottleneck. These constraints can hinder model iteration and lead to incomplete ranking, causing regressions in user experience and ad performance.To address these issues, we analyzed ad ranking metrics and found that ad rankings for individual users remain relatively stable over short periods. Based on this insight, we introduce Negative Exclusion Filtering, a framework that optimizes the balance between ranked ad volume and computing resources. By skipping re-ranking of consistently low-ranked ads for each user request, it reduces computing cost in large-scale social media environments.Negative Exclusion Filtering has achieved CPU reductions of 3.7-7.4\\% and GPU reductions of 4.0-7.9\\% in power consumption across various Meta products, along with a 0.5-2.0\\% reduction in latency, all while maintaining recommendation quality and performance.",
        "doi": "10.1145/3726302.3731940",
        "sheridan_id": "sir2448",
        "position": 3,
        "track_id": 12,
        "slot_id": 183
      }
    },
    {
      "paper": {
        "hashed_id": "3cf2559725a9fdfa602ec8c887440f32",
        "title": "MO-LightGBM: A Library for Multi-objective Learning to Rank with LightGBM",
        "abstract": "This paper introduces MO-LightGBM, an open-source library built upon LightGBM, specifically designed to offer an integrated, versatile, and easily adaptable framework for Multi-objective Learning to Rank (MOLTR).  MO-LightGBM supports diverse Multi-objective optimization (MOO) settings and incorporates 12 state-of-the-art optimization strategies. Its modular architecture enhances usability and flexibility, allowing researchers and practitioners to easily develop new MOO methodologies, perform rigorous comparisons with existing techniques, and effectively deploy MOO algorithms in practical ranking applications. We illustrate the utility of MO-LightGBM through a Bi-objective Learning to Rank example and present visualizations of the results.MO-LightGBM is available at https://github.com/amazon-science/MO-LightGBM.",
        "doi": "10.1145/3726302.3731937",
        "sheridan_id": "sir2438",
        "position": 4,
        "track_id": 12,
        "slot_id": 183
      }
    },
    {
      "paper": {
        "hashed_id": "020bf2c45e7bb322f89a226bd2c5d41b",
        "title": "Graph Isomorphism Network-Based Cohort Modeling In Click-Through Rate Prediction",
        "abstract": "Accurate Click-Through Rate (CTR) prediction is vital for search engines and recommendation systems, yet it is often hindered by the \"cold start problem\", which arises from insufficient historical data for new users. Recent approaches have sought to tackle this by training encoder-decoder networks on data from warm users to generate virtual behavior embeddings for cold users. However, these methods have shortcomings in terms of simplistic encoding techniques for warm user behaviors and direct utilization of virtual behavior embeddings, leading to limitations in user interest expression and generalization. To address these challenges, we propose a novel method that leverages Graph Isomorphism Networks (GIN) for cohort modeling within CTR prediction. GIN effectively captures high-order user-item interactions, providing a more nuanced understanding of users` diverse interests. Additionally, the cohort modeling strategy minimizes deviations in constructed embeddings, enhancing the model`s generalization abilities. We validate our approach through experiments on public and industrial datasets, demonstrating significant improvements for both warm and cold users compared to existing methodologies. Furthermore, we implemented the GIN Cohort Modeling (GINCM) in a large-scale online advertising system, optimizing for both pre-computation and real-time processing to reduce latency. The implementation yields notable enhancements of 2.13% in CTR and Revenue Per Mille(RPM), showcasing the practical effectiveness and real-world applicability of our model.",
        "doi": "10.1145/3726302.3731936",
        "sheridan_id": "sir2419",
        "position": 3,
        "track_id": 12,
        "slot_id": 184
      }
    },
    {
      "paper": {
        "hashed_id": "7cf64379eb6f29a4d25c4b6a2df713e4",
        "title": "Examples as the Prompt: A Scalable Approach for Efficient LLM Adaptation in E-Commerce",
        "abstract": "Prompting LLMs offers an efficient way to guide output generation without explicit model training. In the e-commerce domain, prompt-based applications are widely used in query understanding, recommender systems, and customer support. However, adapting LLMs to different tasks often requires extensive prompt engineering by domain experts, along with frequent updates to align with evolving business needs. Additionally, crafting fully unbiased natural language prompts remains a challenge for humans. To address these challenges, we propose a novel framework, Examples as the Prompt (EaP). Specifically, EaP automatically selects the most representative examples to maximize the few-shot capability of LLMs. It is efficient due to its unsupervised example selection and adaptive to potential data distribution shifts. We validate EaP on four real-world production use cases, demonstrating that it achieves comparable or even superior performance comparing to hand-crafted prompts designed by domain experts. Additionally, we introduce EaP_lite, which entirely replaces the natural language components of prompts with labeled examples. EaP_lite improves LLM inference speed by up to 70% without compromising performance. The online A/B test shows that using EaP and EaP_lite for data labeling can bring significant composite revenue gain by 0.06%.",
        "doi": "10.1145/3726302.3731941",
        "sheridan_id": "sir2456",
        "position": 4,
        "track_id": 12,
        "slot_id": 185
      }
    },
    {
      "paper": {
        "hashed_id": "1f34004ebcb05f9acda6016d5cc52d5e",
        "title": "PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time Retrieval",
        "abstract": "Social chatbots have become essential companions in daily scenarios ranging from emotional support to personal interaction. However, conventional chatbots with passive response mechanisms usually rely on users to initiate or sustain dialogues by bringing up new topics, resulting in diminished engagement and shortened dialogue duration. In this paper, we present PaRT, a novel framework enabling context-aware proactive dialogues for social chatbots through personalized real-time retrieval and generation. Specifically, PaRT first integrates user profiles and dialogue context into a large language model (LLM), which is initially prompted to refine user queries and recognize underlying intents for the upcoming conversation. Guided by refined intents, the LLM generates personalized dialogue topics as targeted queries to retrieve relevant passages from RedNote. Finally, we prompt LLMs with summarized passages to generate knowledge-grounded and engagement-optimized responses. Our approach has been running stably in a real-world production environment for more than 30 days, achieving a 21.77% improvement in the average duration of dialogues.",
        "doi": "10.1145/3726302.3731946",
        "sheridan_id": "sir2479",
        "position": 2,
        "track_id": 12,
        "slot_id": 182
      }
    },
    {
      "paper": {
        "hashed_id": "2c6ae45a3e88aee548c0714fad7f8269",
        "title": "From Keywords to Concepts: A Late Interaction Approach to Semantic Product Search on IKEA.com",
        "abstract": "Modern e-commerce platforms require search engines that go beyond simple keyword matching to accurately capture customer intent. Traditional keyword-based retrieval struggles with complex, multi-attribute queries, potentially leading to suboptimal results and poor customer experience. To address these challenges, we introduce a late interaction-based semantic search engine designed for IKEA product search. This approach significantly improves retrieval quality while maintaining low latency, ensuring a more effective and seamless search experience for customers.Our approach departs from single-vector embeddings by leveraging token-level late interaction scoring, enabling fine-grained alignment between search queries and product descriptions. To enhance search effectiveness, we introduce three key contributions: (1) large-scale synthetic query generation using LLMs to diversify training data, (2) strong negative sampling to improve contrastive learning, and (3) adaptive thresholding to dynamically refine ranking cutoffs and prevent over-retrieval biases.In live A/B testing on IKEA.com for long tail queries in the U.S. market, our system outperforms IKEA Boolean search with a 3.1% increase in click-through rate, a 1.96% boost in conversions, 1.78% increase in search interaction rate, and a 2.18% rise in add-to-cart actions. These results validate the effectiveness of efficient token-level retrieval and adaptive ranking in large-scale commercial search.",
        "doi": "10.1145/3726302.3731948",
        "sheridan_id": "sir2483",
        "position": 3,
        "track_id": 12,
        "slot_id": 186
      }
    },
    {
      "paper": {
        "hashed_id": "c8067ad1937f728f51288b3eb986afaa",
        "title": "Embedding-based Retrieval in Multi-Modal Content Moderation",
        "abstract": "Video understanding plays a fundamental role for content moderation on short video platforms, enabling the detection of inappropriate content. While classification remains the dominant approach for content moderation, it often struggles in scenarios requiring rapid and cost-efficient responses, such as trend adaptation and urgent escalations. To address this issue, we introduce an Embedding-Based Retrieval (EBR) method designed to complement traditional classification approaches. We first leverage a Supervised Contrastive Learning (SCL) framework to train a suite of foundation embedding models, including both single-modal and multi-modal architectures. Our models demonstrate superior performance over established contrastive learning methods such as CLIP and MoCo. Building on these embedding models, we design and implement the embedding-based retrieval system that integrates embedding generation and video retrieval to enable efficient and effective trend handling. Comprehensive offline experiments on 25 diverse emerging trends show that EBR improves ROC-AUC from 0.85 to 0.99 and PR-AUC from 0.35 to 0.95. Further online experiments reveal that EBR increases action rates by 10.32% and reduces operational costs by over 80%, while also enhancing interpretability and flexibility compared to classification-based solutions.",
        "doi": "10.1145/3726302.3731945",
        "sheridan_id": "sir2476",
        "position": 3,
        "track_id": 12,
        "slot_id": 187
      }
    },
    {
      "paper": {
        "hashed_id": "8db9264228dc48fbf47535e888c02ae0",
        "title": "Inquiry Assistant Using LLM-Generated Knowledge Graphs",
        "abstract": "Businesses are increasingly overwhelmed by inquiries related to their services or products. Relying on human agents to handle inquiries via email results in higher costs and delayed responses, contributing to customer dissatisfaction.  In response to these challenges, this pilot study leverages advancements in Large Language Models (LLMs) by proposing a fully automated method for generating a knowledge graph from unstructured data in help pages, which is then utilized to power a fully automated dialogue management system.  By transitioning to a chat-based approach, our method aims to handle ambiguous, incomplete, or nonspecific inquiries more effectively and enhance customer satisfaction with tailored, natural responses. We also implement explicit safeguards to improve intent identification and prevent response hallucinations.  We validate our proposal in the hotel industry, demonstrating that our knowledge graph based AI agent outperforms the baseline Retrieval-Augmented Generation (RAG) model in accuracy while facilitating more natural and coherent dialogues.",
        "doi": "10.1145/3726302.3731956",
        "sheridan_id": "sir2509",
        "position": 1,
        "track_id": 12,
        "slot_id": 185
      }
    },
    {
      "paper": {
        "hashed_id": "33bb83720ba9d2b6da87114380314af5",
        "title": "Alleviating LLM-based Generative Retrieval Hallucination in Alipay Search",
        "abstract": "Generative retrieval (GR) has revolutionized document retrieval with the advent of large language models (LLMs), and LLM-based GR is gradually being adopted by the industry. Despite its remarkable advantages and potential, LLM-based GR suffers from hallucination and generates documents that are irrelevant to the query in some instances, severely challenging its credibility in practical applications. We thereby propose an optimized GR framework designed to alleviate retrieval hallucination, which integrates knowledge distillation reasoning in model training and incorporate decision agent to further improve retrieval precision. Specifically, we employ LLMs to assess and reason GR retrieved query-document (q-d) pairs, and then distill the reasoning data as transferred knowledge to the GR model. Moreover, we utilize a decision agent as post-processing to extend the GR retrieved documents through retrieval model and select the most relevant ones from multi perspectives as the final generative retrieval result. Extensive offline experiments on real-world datasets and online A/B tests on Fund Search and Insurance Search in Alipay demonstrate our framework`s superiority and effectiveness in improving search quality and conversion gains.",
        "doi": "10.1145/3726302.3731951",
        "sheridan_id": "sir2495",
        "position": 2,
        "track_id": 12,
        "slot_id": 185
      }
    },
    {
      "paper": {
        "hashed_id": "87682805257e619d49b8e0dfdc14affa",
        "title": "Defining & Optimizing Quality of LinkedIn`s Content Search",
        "abstract": "Most search engines optimize for quality metrics in addition to engagement metrics. Quality metrics require an explicit definition of the relevance of a document for a query. Defining relevance is a non-trivial problem. Simple definitions such as on-topicness of a document to a query may not adequately capture all aspects of quality, such as document originality, depth and recency. These aspects can have an impact on the value provided by a search engine to searchers, which in-turn drives engagement metrics in the long-term. So, a more thoughtful definition can be very beneficial. However, a complex definition necessitates the need for a search system that has a deep understanding of language. In this paper we present our definition of relevance for content search, and the design of our content search system that enables optimization of Precision based on that definition.",
        "doi": "10.1145/3726302.3731954",
        "sheridan_id": "sir2506",
        "position": 1,
        "track_id": 12,
        "slot_id": 186
      }
    },
    {
      "paper": {
        "hashed_id": "e71e5cd119bbc5797164fb0cd7fd94a4",
        "title": "A System for Triggering Sports Instant Answers on Search Engines",
        "abstract": "Bing Sports serves Instant Answers to sports-related queries from hundreds of millions of users every day with a latency of < 100ms. Answering sports-related factual questions is challenging because of the dynamic nature of the domain, contextual nature of queries, and a large variety of possible intents. In this paper, we discuss various blocks of our scalable multilingual sports answer triggering pipeline. The pipeline mainly comprises of two main stages: Query Understanding (QU) and Ranking. QU leverages blocks like domain classifier, named entity recognizer, intent classifier, and entity linker to detect queries for which a sports answer should get triggered and also accurately identify user intent and entities in queries. The ranking stage is driven using blocks like pre-web ranker, answer lookup, and post-web suppression and reranking for ranking various candidates and choose the best one to be shown as the final triggered sports answer. We leverage various heuristics, deep learning models like UniLM and large language models like GPT-4o for both QU and ranking. Lastly, we present evaluation results for various blocks in our pipeline on a set of $\\sim$80K Bing queries from May 2024.",
        "doi": "10.1145/3726302.3731953",
        "sheridan_id": "sir2503",
        "position": 2,
        "track_id": 12,
        "slot_id": 186
      }
    },
    {
      "paper": {
        "hashed_id": "84b20b1f5a0d103f5710bb67a043cd78",
        "title": "Insight Agents: An LLM-Based Multi-Agent System for Data Insights",
        "abstract": "Today, E-commerce sellers face several key challenges, including difficulties in discovering and effectively utilizing available programs and tools, and struggling to understand and utilize rich data from various tools. We therefore aim to develop Insight Agents (IA), a conversational multi-agent Data Insight system, to provide E-commerce sellers with personalized data and business insights through automated information retrieval. Our hypothesis is that IA will serve as a force multiplier for sellers, thereby driving incremental seller adoption by reducing the effort required and increase speed at which sellers make good business decisions. In this paper, we introduce this new LLM-backed end-to-end agentic workflow designed for comprehensive coverage, high accuracy, and low latency. It features a hierarchical multi-agent structure, consisting of manager agent and two worker agents: data presentation and insight generation, for efficient information retrieval and problem-solving. We design a simple yet effective ML solution for manager agent that combines Out-of-Domain (OOD) detection using a lightweight encoder-decoder model and agent routing through a BERT-based classifier, optimizing both accuracy and latency. Within the two worker agents, a strategic planning is designed for API-based data model that breaks down queries into granular components to generate more accurate responses, and domain knowledge is dynamically injected to to enhance the insight generator. IA has been launched for Amazon sellers in US, which has achieved high accuracy of 89.5% based on human evaluation, with latency of P90 below 15s.",
        "doi": "10.1145/3726302.3731959",
        "sheridan_id": "sir2513",
        "position": 4,
        "track_id": 12,
        "slot_id": 179
      }
    },
    {
      "paper": {
        "hashed_id": "9657c1fffd38824e5ab0472e022e577e",
        "title": "Towards More Relevant Product Search Ranking with Fulfillment Intent Understanding",
        "abstract": "E-commerce retailers increasingly offer diverse fulfillment options (e.g., in-store pickup, same-day delivery from store, standard shipping from fulfillment centers and marketplace sellers), creating a need for search systems that understand and cater to individual customer preferences. This paper addresses the challenge of incorporating fulfillment intent into product search ranking. We propose a model that predicts customer fulfillment intent based on the search query, past user interactions, and other contextual information. A {\\it fulfillment match signal} is introduced to quantify the alignment between a product`s available fulfillment methods and the predicted customer intent. Integrating this signal into the ranking process ensures that search results prioritize products matching the user`s preferred fulfillment type. Offline and online experiments demonstrate the efficacy of our approach and highlight the importance of fulfillment-aware ranking in omnichannel e-commerce.",
        "doi": "10.1145/3726302.3731963",
        "sheridan_id": "sir2540",
        "position": 2,
        "track_id": 12,
        "slot_id": 181
      }
    },
    {
      "paper": {
        "hashed_id": "9824f9c1543628a85bb51d2dd6fcf8a3",
        "title": "Learning Universal User Representations Leveraging Cross-domain User Intent at Snapchat",
        "abstract": "The development of powerful user representations is a key factor in the success of recommender systems (RecSys). Online platforms employ a range of RecSys techniques to personalize user experience across diverse in-app surfaces. User representations are often learned individually through user`s historical interactions within each surface and user representations across different surfaces can be shared post-hoc as auxiliary features or additional retrieval sources. While effective, such schemes cannot directly encode collaborative filtering signals across different surfaces, hindering its capacity to discover complex relationships between user behaviors and preferences across the whole platform. To bridge this gap at Snapchat, we seek to conduct universal user modeling (UUM) across different in-app surfaces, learning general-purpose user representations which encode behaviors across surfaces. Instead of replacing domain-specific representations, UUM representations capture cross-domain trends, enriching existing representations with complementary information. This work discusses our efforts in developing initial UUM versions, practical challenges, technical choices and modeling and research directions with promising offline performance. Following successful A/B testing, UUM representations have been launched in production, powering multiple use cases and demonstrating their value. UUM embedding has been incorporated into (i) Long-form Video embedding-based retrieval, leading to 2.78% increase in Long-form Video Open Rate, (ii) Long-form Video L2 ranking, with 19.2% increase in Long-form Video View Time sum, (iii) Lens L2 ranking, leading to 1.76% increase in Lens play time, and (iv) Notification L2 ranking, with 0.87% increase in Notification Open Rate.",
        "doi": "10.1145/3726302.3731961",
        "sheridan_id": "sir2532",
        "position": 1,
        "track_id": 12,
        "slot_id": 184
      }
    },
    {
      "paper": {
        "hashed_id": "2288f691b58edecadcc9a8691762b4fd",
        "title": "Progressive Refinement of E-commerce Search Ranking Based on Short-Term Activities of the Buyer",
        "abstract": "In e-commerce shopping, aligning search results with a buyer\u2019s immediate needs and preferences presents a significant challenge, particularly in adapting search results throughout the buyer`s shopping journey as they move from the initial stages of browsing to making a purchase decision or shift from one intent to another. This study presents a systematic approach to adapting e-commerce search results based on the current context. We start with basic methods and incrementally incorporate more contextual information and state-of-the-art techniques to improve the search outcomes. By applying this evolving contextual framework to items displayed on the search engine results page (SERP), we progressively align search outcomes more closely with the buyer\u2019s interests and current search intentions. Our findings demonstrate that this incremental enhancement, from simple heuristic autoregressive features to advanced sequence models, significantly improves ranker performance. The integration of contextual techniques enhances the performance of our production ranker, leading to improved search results in both offline and online A/B testing in terms of Mean Reciprocal Rank (MRR). Overall, the paper details iterative methodologies and their substantial contributions to search result contextualization on e-commerce platforms.",
        "doi": "10.1145/3726302.3731966",
        "sheridan_id": "sir2558",
        "position": 1,
        "track_id": 12,
        "slot_id": 180
      }
    },
    {
      "paper": {
        "hashed_id": "e92d74ccacdc984afa0c517ad0d557a6",
        "title": "Ontology-Guided Knowledge Graph Retrieval for Multi-Hop and Cross-Granularity Store Fulfillment Queries",
        "abstract": "Answering complex queries in store fulfillment, such as \"What percentage of employee-assigned actions remain unresolved?\" or \"How many worklists for a specific product type were completed within a timeframe at each location?\" requires precise, multi-hop reasoning across datasets with varying granularities. This paper introduces an ontology-based knowledge graph (KG) approach integrated with a structured text-to-Cypher generation pipeline, enabling accurate retrieval for such queries. Benchmarking against a robust hybrid search baseline combining BM25 and semantic search, our method demonstrates superior performance in addressing multi-hop and cross-granularity questions. Leveraging a KG schema designed to capture intricate relationships (e.g., (OrderLineItem)-[:INVOLVES_ACTION]->(Action)-[:INVOLVES]->(BatchProcess)-[:IS_COMPLETED_AT]->(Location)), we reveal universal patterns for constructing and querying highly relational data. This work highlights the transformative potential of ontology-driven KGs to improve reasoning, data aggregation, and decision-making, with broader implications for any domain requiring structured, multi-relational data analysis.",
        "doi": "10.1145/3726302.3731964",
        "sheridan_id": "sir2541",
        "position": 1,
        "track_id": 12,
        "slot_id": 181
      }
    },
    {
      "paper": {
        "hashed_id": "e6acf4b0f69f6f6e60e9a815938aa1ff",
        "title": "Pyramid Mixer: Multi-dimensional Multi-period Interest Modeling for Sequential Recommendation",
        "abstract": "Sequential recommendation, a critical task in recommendation systems, predicts the next user action based on the understanding of the user`s historical behaviors. Conventional studies mainly focus on cross-behavior modeling with self-attention based methods while neglecting comprehensive user interest modeling for more dimensions. In this study, we propose a novel sequential recommendation model, Pyramid Mixer, which leverages the MLP-Mixer architecture to achieve efficient and complete modeling of user interests. Our method learns comprehensive user interests via cross-behavior and cross-feature user sequence modeling. The mixer layers are stacked in a pyramid way for cross-period user temporal interest learning. Through extensive offline and online experiments, we demonstrate the effectiveness and efficiency of our method, and we obtain a +0.106% improvement in user stay duration and a +0.0113% increase in user active days in the online A/B test. The Pyramid Mixer has been successfully deployed on the industrial platform, demonstrating its scalability and impact in real-world applications.",
        "doi": "10.1145/3726302.3731968",
        "sheridan_id": "sir2565",
        "position": 1,
        "track_id": 12,
        "slot_id": 182
      }
    },
    {
      "paper": {
        "hashed_id": "8169e05e2a0debcb15458f2cc1eff0ea",
        "title": "Robust Inverse Retrieval in Online Advertising with Contrastive Learning",
        "abstract": "Sponsored product plays a key role at advertising business whichattracts an increasing number of advertisers seeking better platformsto promote their products. Connecting advertiser\u2019s products(demand) to the customer interests (supply) becomes a crucial factorin forecasting advertising campaign success. In this work, we proposea general framework for learning the inverse product retrievalprocess, a more complex procedure compared to the conventionalforward approach. The first set of challenges arise due to a significantlevel of noise in the retrieval data caused by users who deviatefrom the intended platform usage. To address this, we propose acontrastive learning approach that minimizes the effect of suchnoise in data, ensuring robustness against false positives and falsenegatives. In addition, we propose a calibration procedure for theinverse retrieval that handles dynamic size of a set of queries thatmay retrieve any particular product of interest. Our frameworkis universally applicable across various contexts of an advertisingplatform, including but not limited to search pages, item pages,and browsing pages. We showcase the efficacy of the proposedapproach using Walmart\u2019s advertising data in ten product domains.",
        "doi": "10.1145/3726302.3731967",
        "sheridan_id": "sir2564",
        "position": 1,
        "track_id": 12,
        "slot_id": 183
      }
    },
    {
      "paper": {
        "hashed_id": "7c4ede33a62160a19586f6e26eaefacf",
        "title": "Dynamic Margin-based Contrastive Learning for Robust Negative Sampling in Information Retrieval",
        "abstract": "Modern information retrieval (IR) systems, powered by bi-encoder architectures and pretrained language models, rely on effective negative sampling for contrastive learning.While easy negatives are computationally simple, they fail to challenge the model, whereas hard negatives---selected via methods like BM25, ANCE, or ADORE---can be overly difficult and misleading.To this end, this paper proposes dynamic margin-based contrastive learning (DMCL), which adaptively adjusts the decision boundary based on query-negative similarity, ensuring consistent exposure to moderately hard negatives. Experiments across diverse datasets and models show that DMCL outperforms traditional methods, achieving state-of-the-art retrieval performance with minimal computational cost.",
        "doi": "10.1145/3726302.3730182",
        "sheridan_id": "sp1689",
        "position": 22,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "82cec96096d4281b7c95cd7e74623496",
        "title": "Limitations of Automatic Relevance Assessments with Large Language Models for Fair and Reliable Retrieval Evaluation",
        "abstract": "Offline evaluation of search systems depends on test collections. These benchmarks provide the researchers with a corpus of documents, topics and relevance judgements indicating which documents are relevant for each topic. While test collections are an integral part of Information Retrieval (IR) research, their creation involves significant efforts in manual annotation. Large language models (LLMs) are gaining much attention as tools for automatic relevance assessment. Recent research has shown that LLM-based assessments yield high systems ranking correlation with human-made judgements. These correlations are helpful in large-scale experiments but less informative if we want to focus on top-performing systems. Moreover, these correlations ignore whether and how LLM-based judgements impact the statistically significant differences among systems with respect to human assessments. In this work, we look at how LLM-generated judgements preserve ranking differences among top-performing systems and also how they preserve pairwise significance evaluation as human judgements. Our results show that LLM-based judgements are unfair at ranking top-performing systems. Moreover, we observe an exceedingly high rate of false positives regarding statistical differences.",
        "doi": "10.1145/3726302.3730221",
        "sheridan_id": "sp0355",
        "position": 1,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "cdf1035c34ec380218a8cc9a43d438f9",
        "title": "Generating Effective Health-Related Queries for Promoting Reliable Search Results",
        "abstract": "Misinformation on the Internet poses significant risks to users seeking health information. This paper addresses the challenge of generating effective health-related queries to promote reliable search results. We propose a method leveraging Large Language Models to generate synthetic narratives that guide the creation of alternative queries. These queries are designed to retrieve more helpful and fewer harmful documents compared to those retrieved by the original user queries. We evaluate the effectiveness of these queries using classic and neural retrieval models across multiple datasets, demonstrating promising improvements in retrieving reputable content.",
        "doi": "10.1145/3726302.3730202",
        "sheridan_id": "sp1669",
        "position": 16,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "207f88018f72237565570f8a9e5ca240",
        "title": "Multi-Interest Matching for Personalized News Recommendation with Large Language Models",
        "abstract": "Personalized news recommendation plays a vital role in mitigating information overload, yet challenges persist in accurately capturing user preferences and fine-grained interests. Leveraging the semantic understanding and extraction capabilities of large language models (LLMs), we propose a Multi-Interest Personalized News Recommendation (MIPNR) model to address these issues. MIPNR separately models user interests at the user, news, and entity levels. Specifically, we introduce a Category-Guided Interest-News Matching (CGIN-Matching) method to identify potential interests, a Local News Entity Graph (LNEG) to model subtle entity relationships, and an entity-wise attention mechanism to extract fine-grained interests. In addition, LLMs are used to generate explicit textual descriptions of user preferences. Extensive experiments on real-world datasets demonstrate the effectiveness of our approach.",
        "doi": "10.1145/3726302.3730233",
        "sheridan_id": "sp1652",
        "position": 8,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "b147a61c1d07c1c999560f62add6dbc7",
        "title": "Score-Fitted Indexes and Constant Length Indexes for Information Retrieval",
        "abstract": "We present two novel inverted index approaches and corresponding query processing strategies for information retrieval: 1) score-fitted indexes and 2) constant length indexes. These indexes do not store document lengths and document priors, but nevertheless support popular rankers like BM25 and language models by approximating their results. We answer the question: What is the effect of score-fitted indexes and constant length indexes, and the combination of both approaches, on the search quality? We show on three diverse datasets that the two indexes perform on par with approaches that use a standard inverted index in almost all cases. Our work suggests that it is possible to develop search engines that are more efficient than engines that store document lengths and/or document priors, such as Lucene and Terrier.",
        "doi": "10.1145/3726302.3730248",
        "sheridan_id": "sp1653",
        "position": 9,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "42a3964579017f3cb42b26605b9ae8ef",
        "title": "Counterfactual Model Selection in Contextual Bandits",
        "abstract": "Contextual bandit algorithms are crucial in various decision-making applications, such as personalized content recommendation, online advertising, and e-commerce banner placement. Despite their successful applications in various domains, contextual bandit algorithms still face significant challenges with exploration efficiency compared to non-contextual bandit algorithms due to exploration in feature spaces. To overcome this issue, model selection policies such as MetaEXP and MetaCORRAL have been proposed to interactively explore base policies. In this paper, we introduce a novel counterfactual approach to address the model selection problem in contextual bandits. Unlike previous methods, our approach leverages unbiased Off-Policy Evaluation (OPE) to dynamically select base policies, making it more robust to model misspecification. We present two new algorithms, MetaEXP-OPE and MetaGreedy-OPE, which utilize OPE for model selection policy.We also provide theoretical analysis on regret bounds and evaluate the impact of different OPE estimators.We evaluated our model on synthetic data and a semi-synthetic simulator using a real-world dataset, and the results show that MetaEXP-OPE and MetaGreedy-OPE significantly outperform existing policies, including MetaEXP and MetaCORRAL.",
        "doi": "10.1145/3726302.3730176",
        "sheridan_id": "sp1635",
        "position": 8,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "02f039058bd48307e6f653a2005c9dd2",
        "title": "Graph-Based Multimodal Contrastive Learning for Chart Question Answering",
        "abstract": "Chart question answering (ChartQA) is challenged by the heterogeneous composition of chart elements and the subtle data patterns they encode. This work introduces a novel joint multimodal scene graph framework that explicitly models the relationships among chart components and their underlying structures. The framework integrates both visual and textual graphs to capture structural and semantic characteristics, while a graph contrastive learning strategy aligns node representations across modalities\u2014enabling their seamless incorporation into a transformer decoder as soft prompts. Moreover, a set of tailored Chain-of-Thought (CoT) prompts is proposed to enhance multimodal large language models (MLLMs) in zero-shot scenarios by mitigating hallucinations. Extensive evaluations on benchmarks including ChartQA, OpenCQA, and ChartX demonstrate significant performance improvements and validate the efficacy of the proposed approach.",
        "doi": "10.1145/3726302.3730204",
        "sheridan_id": "sp1707",
        "position": 12,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "70ece1e1e0931919438fcfc6bd5f199c",
        "title": "Exploring Human-Like Thinking in Search Simulations with Large Language Models",
        "abstract": "Simulating user search behavior is a critical task in information retrieval, which can be employed for user behavior modeling, data augmentation, and system evaluation. Recent advancements in large language models (LLMs) have opened up new possibilities for generating human-like actions including querying, browsing, and clicking. In this work, we explore the integration of human-like thinking into search simulations by leveraging LLMs to simulate users` hidden cognitive processes. Specifically, given a search task and context, we prompt LLMs to first think like a human before executing the corresponding action. As existing search datasets do not include users` thought processes, we conducted a user study to collect a new dataset enriched with users` explicit thinking. We investigate the impact of incorporating such human-like thinking on simulation performance and apply supervised fine-tuning (SFT) to teach LLMs to emulate both human thinking and actions. Our experiments span two dimensions in leveraging LLMs for user simulation: (1) with or without explicit thinking, and (2) with or without fine-tuning on the thinking-augmented dataset. The results demonstrate the feasibility and potential of incorporating human-like thinking in user simulations, though performance improvements on some metrics remain modest. We believe this exploration provides new avenues and inspirations for advancing user behavior modeling in search simulations.",
        "doi": "10.1145/3726302.3730193",
        "sheridan_id": "sp1737",
        "position": 14,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "df9028fcb6b065e000ffe8a4f03eeb38",
        "title": "Dual Debiasing in LLM-based Recommendation",
        "abstract": "Large language models (LLMs) have been widely applied in recommender systems, achieving remarkable success. However, LLM-based recommendation (LR) suffers from more severe popularity bias than conventional recommendation (CR), stemming from both training and inference stages. In this paper, we propose a novel debiasing method for LR, which performs debiasing in such two stages, so termed as Dual Debiasing in LR (D\u00b2LR). Concretely, in the training stage, we conduct token-wise inverse propensity score weighting to force the LLM to pay more attention on unpopular tokens. In the inference stage, we train a more biased CR model by increasing the weights of popular items, which adjusts the generation probability of corresponding tokens according to its scores for items, hoping to suppress the excessive generation of popular tokens. Experiments conducted on three real-world datasets validate the effectiveness of our D\u00b2LR in mitigating popularity bias in LR.",
        "doi": "10.1145/3726302.3730181",
        "sheridan_id": "sp1763",
        "position": 24,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "f0bbac6fa079f1e00b2c14c1d3c6ccf0",
        "title": "From Monolith to Mosaic: Uncovering Behavioral Differences for Choice Models in Recommender Systems Simulations",
        "abstract": "Simulation is widely used in recommender systems research to study algorithm behavior and its impact on users. A common strategy involves adopting a universal choice model to represent users, assuming all follow the same consumption patterns. This one-size-fits-all approach overlooks the diversity in user preferences and decision-making patterns. In this work, we scrutinize whether this universal view fails to account for unique user behavior, thus harming realism and reliability of simulation outcomes. We conduct multiple simulations with various recommendation algorithms and choice models in the movie domain, comparing outcomes to users` organic consumption patterns. Further, we evaluate whether a holistic model that captures users` differences in behavior would better reflect a wide user base. Our findings highlight the limitations of using a naive, universal choice model and emphasize the need for more nuanced, user-specific approaches to make contributions from simulation studies more reflective of real-world effects.",
        "doi": "10.1145/3726302.3730199",
        "sheridan_id": "sp1815",
        "position": 30,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "7dd0240cd412efde8bc165e864d3644f",
        "title": "Learning Resistant Binary Descriptors Against Noise for Efficient Image Retrieval",
        "abstract": "Hashing aims to learn a binary-output function that maps an image to a binary vector, which has received increasing attention with its potential in large-scale visual similarity search. Recently, supervised hashing methods have shown remarkable performance, but they assume that all examples are properly labeled. While in reality, it is unsurprising that we may encounter a range of label noise, which may significantly degrade retrieval performance. In response, we propose a noise-resistant Hashing Contrastive learning with hybrid selection (STAR). Specifically, STAR first develops noise-resistant hashing contrastive learning to preserve the similarity structure against label noise. In addition, we propose a hybrid sample selection strategy from the view of both Hamming distance and output uncertainty, which identifies reliable clean examples. Finally, to get rid of potential memorizing of noisy data, we incorporate both clean samples and noisy samples into selective centroid learning, which minimizes distances between clean samples and their centroids while pushing noisy samples away from negative centroids. Extensive experiments validate the efficacy of STAR.",
        "doi": "10.1145/3726302.3730220",
        "sheridan_id": "sp1776",
        "position": 26,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "7503cfacd12053d309b6bed5c89de212",
        "title": "Retrieving Tables via Inter- and Intra-Content Contrastive Representation Learning",
        "abstract": "Contrastive learning has emerged as a highly effective and versatile technique in information retrieval. However, its application within table retrieval remains limited, and often neglecting a typical phenomenon in table retrieval: one table can be associated with multiple, distinct queries. Directly applying traditional contrastive learning strategies may lead to semantic contrast conflicts during training, potentially impairing the quality of learned representations. Additionally, many current table retrieval methods still operate on query-table joint encoding, which introduces notable inefficiencies during both the training and retrieval processes. For this issue, this paper proposes ConTR, a tabular semantic contrastive learning method that simultaneously considers both inter-table and intra-table differences. By segmenting table into multiple vector representations and enabling the matching of diverse queries through differentiated vectors, thereby facilitating a more focused contrastive learning process. Retrieval experiments based on two typical table-related tasks validate the feasibility and effectiveness of proposed method.",
        "doi": "10.1145/3726302.3730245",
        "sheridan_id": "sp1853",
        "position": 36,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "1f1baa5b8edac74eb4eaa329f14a0361",
        "title": "A Comparative Study of Large Language Models and Traditional Privacy Measures to Evaluate Query Obfuscation Approaches",
        "abstract": "When interacting with an Information Retrieval (IR) system, users might disclose personal information, such as medical details, through their queries. Thus, assessing the level of privacy granted to users when querying an IR system is essential to determine the confidentiality of submitted sensitive data. Query obfuscation protocols have traditionally been employed to obscure a user`s real information need when retrieving documents. In these protocols, the query is modified employing \u03b5-Differential Privacy (DP) obfuscation mechanisms, which alter query terms according to a predefined privacy budget \u03b5. While this budget ensures formal mathematical guarantees, it provides only limited guarantees of the privacy experienced by the user and calls for empirical privacy evaluation to be carried out. Such privacy assessments employ lexical and semantic similarity measures between the original and obfuscated queries. In this study, we explore the role of Large Language Models (LLMs) in privacy evaluation, simulating a scenario where users employ such models to determine whether their input has been effectively privatized. Our primary research objective is to determine whether LLMs provide a novel perspective on privacy estimation and if their assessments serve as a proxy for traditional similarity metrics, such as the Jaccard and cosine similarity derived from Transformer-based sentence embeddings. Our findings reveal a positive correlation between LLMs-generated privacy scores and cosine similarity computed using different Transformer architectures. This suggests that LLM assessments act as a proxy for similarity-based measures.",
        "doi": "10.1145/3726302.3730158",
        "sheridan_id": "sp1807",
        "position": 14,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "110eec23201d80e40d0c4a48954e2ff5",
        "title": "Psychological Aspects in Retrieval and Recommendation",
        "abstract": "Psychological processes play a critical role in shaping users` interactions with information retrieval (IR) and recommender systems (RS). Therefore, understanding human cognition, decision-making, and emotions is vital to enable user-centric retrieval and recommendation systems. Vice versa, understanding whether these aspects are also present in the systems themselves (e.g., in training data, ranking models, or outputs), or even injecting them on purpose, can inform the development of psychology-inspired systems. The purpose of this tutorial is to provide its attendees with an introduction to psychological concepts that are important in the ecosystem of search, retrieval, and recommendation, in particular, cognitive architectures, cognitive effects and biases, as well as personality and affect. Leveraging corresponding models allows its audience to build or refine psychology-informed IR and RS technology. The interdisciplinary tutorial requires intermediate expertise in terms of IR and RS, while we do not assume knowledge in psychology.",
        "doi": "10.1145/3726302.3731691",
        "sheridan_id": "tut2691",
        "position": 0,
        "track_id": 14,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "537de305e941fccdbba5627e3eefbb24",
        "title": "Efficient Conversational Search via Topical Locality in Dense Retrieval",
        "abstract": "Pre-trained language models have been widely exploited to learn dense representations of documents and queries for information retrieval.While previous efforts have primarily focused on improving effectiveness and user satisfaction, response time remains a critical bottleneck of conversational search systems. To address this, we exploit the topical locality inherent in conversational queries, i.e., the tendency of queries within a conversation to focus on related topics. By leveraging query embedding similarities, we dynamically restrict the search space to semantically relevant document clusters, reducing computational complexity without compromising retrieval quality.We evaluate our approach on the TREC CAsT, 2019 and 2020 datasets using multiple embedding models and vector indexes, achieving improvements in processing speed of up to 10.3X with little loss in performance (4.3X without any loss).Our results show that the proposed system effectively handles complex, multi-turn queries with high precision and efficiency, offering a practical solution for real-time conversational search.",
        "doi": "10.1145/3726302.3730186",
        "sheridan_id": "sp1859",
        "position": 20,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "c164bbc9d6c72a52c599bbb43d8db8e1",
        "title": "SMMR: Sampling-Based MMR Reranking for Faster, More Diverse, and Balanced Recommendations and Retrieval",
        "abstract": "Relevance and diversity are critical objectives in modern information retrieval (IR), particularly in recommender systems. Achieving a balance between relevance (exploitation) and diversity (exploration) optimizes user satisfaction and business goals such as catalog coverage and novelty. While existing post-processing reranking methods address this trade-off, they usually rely on greedy strategies, leading to suboptimal outcomes for large-scale tasks.\tTo this end, we propose Sampled Maximal Marginal Relevance (SMMR), a novel sampling-based extension of MMR that introduces randomness into item selection to improve relevance-diversity trade-offs. SMMR avoids the rigidity of greedy and deterministic reranking, and achieves a logarithmic computational speedup, which allows it to scale on large candidate sets. Our evaluations on multiple real-world open-source datasets demonstrate that SMMR consistently outperforms existing state-of-the-art approaches, offering superior performance in balancing relevance and diversity. Our implementation of the proposed method is made available to support future research.",
        "doi": "10.1145/3726302.3730250",
        "sheridan_id": "sp1868",
        "position": 21,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "68c694de94e6c110f42e587e8e48d852",
        "title": "Assessing Support for the TREC 2024 RAG Track: A Large-Scale Comparative Study of LLM and Human Evaluations",
        "abstract": "Retrieval-augmented generation (RAG) enables large language models (LLMs) to generate answers with citations from source documents containing ``ground truth``. A crucial factor in RAG evaluation is ``support``, or whether the information in the cited documents supports the answer. We conducted a comparative study of submissions to the TREC 2024 RAG Track, evaluating an automatic LLM judge (GPT-4o) against human judges for support assessment. We considered two conditions: (1) fully manual assessments from scratch and (2) manual assessments with post-editing of LLM predictions. Our results indicate good agreement between human and GPT-4o predictions. Further analysis of the disagreements shows that an independent human judge correlates better with GPT-4o than a human judge, suggesting that LLM judges can be a reliable alternative for support assessment. We provide a qualitative analysis of human and GPT-4o errors to help guide future evaluations.",
        "doi": "10.1145/3726302.3730165",
        "sheridan_id": "sp1869",
        "position": 22,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "5fa9e41bfec0725742cc9d15ef594120",
        "title": "Automatic Document Editing for Improved Ranking",
        "abstract": "We present a study of using large language models (LLMs) to modify adocument so as to have it highly ranked for a query by an undisclosedranking function. We present different prompting methods inspired by work onusing LLMs to induce ranking. Empirical evaluation attests to the merits of the best performing methods with respect to humanmodifications and a highly effective feature-based modification method.",
        "doi": "10.1145/3726302.3730168",
        "sheridan_id": "sp1894",
        "position": 43,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "73e0f7487b8e5297182c5a711d20bf26",
        "title": "VAP3: Variation-Aware Prompt Performance Prediction",
        "abstract": "Large Language Models (LLMs) exhibit strong capabilities across various Information Retrieval (IR) and natural language processing tasks. However, they are highly sensitive to prompt variations, where slight rephrasings can significantly alter responses, leading to inconsistent or incorrect outputs. This variability poses challenges for response reliability in real-world applications. Inspired by Query Performance Prediction (QPP) in IR, we focus on Prompt Performance Prediction (PPP), which estimates whether an LLM will generate a correct response for a given prompt before execution. We propose VAP3 (Variation-Aware Prompt Performance Prediction), a novel pre-generation PPP approach that integrates prompt variations with adversarial training to enhance robustness against trivial modifications and better capture prompt sensitivity. Evaluating VAP3 against LLM-based self-evaluation, QPP-inspired baselines, and supervised classification models on the PromptSET-HotpotQA and PromptSET-TriviaQA datasets, we demonstrate that VAP3 consistently outperforms all baselines, achieving stable and reliable performance across datasets.",
        "doi": "10.1145/3726302.3730264",
        "sheridan_id": "sp1905",
        "position": 46,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "d305281faf947ca7acade9ad5c8c818c",
        "title": "Large Models are Good Annotators for Zero-Shot Learning",
        "abstract": "Human-annotated attributes serve as effective semantic label embeddings for zero-shot learning (ZSL); however, their annotation is labor-intensive and difficult to scale. Recent studies have explored weakly supervised semantic label embeddings to reduce human effort, but these methods often fail to capture visual similarity and underperform compared to human-annotated semantics. In this work, we propose a minimally supervised yet effective approach: GPT- and CLIP-powered attributes (GCAtt). Specifically, we introduce a three-step interaction process with ChatGPT\u2014comprising preliminary design, hierarchical refinement, and specific value determination\u2014to generate attributes that are both category-shared and discriminative for classification. Additionally, we develop a method that encodes attributes and their values as potential text pairings, leveraging CLIP`s retrieval capabilities for annotation. Experimental results on four widely used benchmarks demonstrate that GCAtt consistently outperforms human-annotated semantics. Code and data are available at https://github.com/RowenaHe/GCAtt.",
        "doi": "10.1145/3726302.3730219",
        "sheridan_id": "sp1870",
        "position": 40,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "7302e3f5e7c072aea8801faf8a492be0",
        "title": "Bias-Aware Curriculum Sampling For Fair Ranking",
        "abstract": "Neural ranking models are widely used to retrieve and rank relevant documents. However, these models may inherit and amplify biases present in the training data, posing challenges for fairness and relevance in ranking outputs. In this paper, we propose a novel curriculum-based training approach that manages bias exposure throughout the training process. We design a bias-aware curriculum that stages the exposure of the model to biased samples during the training stages, allowing the model to establish a fair relevance baseline. We conduct extensive experiments across different LLMs and datasets to evaluate the effectiveness of our approach. Our results demonstrate that our proposed strategy outperforms other bias reduction methods in terms of both fairness and relevance, without sacrificing retrieval effectiveness.",
        "doi": "10.1145/3726302.3730171",
        "sheridan_id": "sp1887",
        "position": 42,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "3f088ebeda03513be71d34d214291986",
        "title": "Axiomatic Re-Ranking for Argument Retrieval",
        "abstract": "Information retrieval axioms are formalized constraints that retrieval systems should ideally satisfy (e.g., to rank documents higher that contain the query terms more often). In this paper, we propose new axioms that focus on the scenario of argument retrieval: retrieval for queries that need arguments in the results. Our underlying axiomatic idea is that in such scenarios, documents should be prioritized with argumentative units that are similar to the query. We test our new axioms in re-ranking experiments on the data of the Touch\u00e9 ~2020 and~2021 shared task on argument retrieval for controversial questions, and show that the new axioms can improve the effectiveness of Touch\u00e9`s strong DirichletLM baseline model and even of the top-performing system from Touch\u00e9 ~2021, a system already specifically optimized for argument retrieval. Finally, we also propose a new method for visualizing the relationships between axioms based on their effects in re-ranking settings.",
        "doi": "10.1145/3726302.3730169",
        "sheridan_id": "sp1995",
        "position": 56,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "519c84155964659375821f7ca576f095",
        "title": "Text Obsoleteness Detection using Large Language Models",
        "abstract": "Maintaining accurate and up-to-date information is a persistent challenge for large-scale knowledge repositories, where outdated content can compromise their value. In this paper, we present a Multitask learning framework that uses Large Language Models (LLMs) for two tasks: semantic update detection and semantic update necessity prediction. The update detection task identifies obsoleteness by comparing older and newer text versions, while the update necessity prediction task determines whether an update is required based on a given context.   To support these tasks, we curate a specialized dataset from Wikipedia called SEMUPDATES, focusing on frequently updated articles. Our experiments with five LLMs across four datasets in zero-shot, few-shot, and fine-tuned settings demonstrate that fine-tuning significantly enhances performance. In the multitask learning setup, Qwen delivers the best overall performance, while Mistral achieves the highest accuracy on individual tasks when fine-tuned separately. However, the performance differences across models are not substantial, suggesting that multiple LLMs can be effectively adapted for content update automation. These findings highlight the potential of LLMs in detecting and predicting obsolescence, providing a scalable solution for maintaining the timeliness of digital knowledge repositories.",
        "doi": "10.1145/3726302.3730254",
        "sheridan_id": "sp1942",
        "position": 52,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "333222170ab9edca4785c39f55221fe7",
        "title": "Dual-perspective Data Augmentation and Curriculum Learning Framework for Low-resource Complex Named Entity Recognition",
        "abstract": "Low-resource complex named entity recognition focuses on identifying complex entities such as creative work, product name and so on, in scenarios where annotated training data is limited. Recent advanced works deal with this task through data augmentation and make substantial progress. However, existing methods ignore the influence of different types or levels of augmented data on model optimization in different learning stages. To address it, we propose a dual-perspective data augmentation and curriculum learning framework. Specifically, we first employ the large language model (LLM) to construct two kinds of augmented datasets from context-perspective and entity-perspective, respectively. Then, we present a multi-stage curriculum learning strategy including a novel adaptive curriculum arrangement algorithm to automatically select the most suitable kind of augmented set to optimize the target model at each training epoch, thus using the augmented data more effectively and controllably. Experimental results on the public benchmark across various low-resource settings show that our framework outperforms previous works.",
        "doi": "10.1145/3726302.3730180",
        "sheridan_id": "sp1922",
        "position": 25,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "1e913e1b06ead0b66e30b6867bf63549",
        "title": "FROG: Effective Friend Recommendation in Online Games via Modality-aware User Preferences",
        "abstract": "Due to the convenience of mobile devices, the online games have become an important part for user entertainments in reality, creating a demand for friend recommendation in online games. However, none of existing approaches can effectively incorporate the multi-modal user features (\\emph{e.g.}, images and texts) with the structural information in the friendship graph, due to the following limitations: (1) some of them ignore the high-order structural proximity between users, (2) some fail to learn the pairwise relevance between users at modality-specific level, and (3) some cannot capture both the local and global user preferences on different modalities. By addressing these issues, in this paper, we propose an end-to-end model \\textsc{FROG} that better models the user preferences on potential friends. Comprehensive experiments on both offline evaluation and online deployment at \\kw{Tencent} have demonstrated the superiority of \\textsc{FROG} over existing approaches. The source code of this paper can be found at \\url{https://github.com/socialalgo/FROG}.",
        "doi": "10.1145/3726302.3730198",
        "sheridan_id": "sp1933",
        "position": 26,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "2d00f43f07911355d4151f13925ff292",
        "title": "Conversational Argument Search Under Selective Exposure: Strategies for Balanced Perspective Access",
        "abstract": "Conversational argument search systems influence how users access diverse perspectives but are prone to selective exposure. To address this, we propose two strategies: an interface-level multi-agent framework that structures perspective presentation and an interaction-level questioning strategy that encourages deeper engagement. We evaluate these strategies through a 2 x 2 factorial user study, examining their impact on selective exposure. Results show that the multi-agent setup facilitates broader perspective comparison, while agent-initiated questioning fosters deeper reflection; together, they promote more balanced argument access. Based on these findings, we discuss conversational search systems to mitigate selective exposure by implementing multi-agent interactions and questioning mechanisms.",
        "doi": "10.1145/3726302.3730175",
        "sheridan_id": "sp1945",
        "position": 28,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "5531a5834816222280f20d1ef9e95f69",
        "title": "Training-free Periodic Interest Augmentation in Incremental Recommendation",
        "abstract": "Industrial recommender systems usually train models incrementally to grasp recent interests of users. However, a fundamental issue of these incremental updated models is their tendency to overfit current data while neglecting past information. Specifically, we have observed that the data distribution of real systems exhibits periodic drifts, leading to periodic fluctuations of prediction bias. To alleviate the above bias fluctuations while minimizing the loss of recent interests, we propose TPIA, a Training-free approach for Periodic Interest Augmentation in incremental recommendation. Specifically, after the latest model is trained, we first calculate the importance score of each model in the previous period. Then, we merge these models based on the importance scores. To minimize information loss due to interference of parameters during model merging, we further develop a method for trimming redundant and abnormal parameters. Offline experiments on both public and private datasets demonstrate the effectiveness of TPIA. It has also been deployed on a large-scale industrial recommender system, and has shown a notable 1.61% increase in CVR and a 1.97% increase in CPM, along with enhanced stability in prediction bias.",
        "doi": "10.1145/3726302.3730258",
        "sheridan_id": "sp2023",
        "position": 58,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "757b505cfd34c64c85ca5b5690ee5293",
        "title": "Workshop on Explainability in Information Retrieval",
        "abstract": "As models grow more complex and societal demands for transparency increase with emerging regulations, explainability has become an even more important research area. However, despite its recognized relevance, explainability research in IR has seen slower progress than in related fields. This full day workshop aims to advance research in explainable information retrieval by providing a more in-depth platform to reflect on recent developments and facilitate discussions to address new and persistent challenges. Our goal is to bring together a diverse group of researchers to build a shared understanding of key tasks and challenges that will lay the foundation for the future of explainable IR research.",
        "doi": "10.1145/3726302.3730361",
        "sheridan_id": "wk0201",
        "position": 0,
        "track_id": 18,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "98c7242894844ecd6ec94af67ac8247d",
        "title": "Multilingual Evaluation of Main Content Extractors for Web Pages",
        "abstract": "Tools designed to extract main content from web pages require thorough evaluation, yet existing benchmarks disproportionately focus on English-language datasets. Consequently, previous studies have shown that while these extractors are well-optimized for English, their effectiveness partially or entirely diminishes in other languages. This study reproduces and extends recent benchmarks by incorporating multilingual datasets as a key factor. We analyze extractor performance across five languages\u2014Greek, English, Polish, Russian, and Chinese\u2014highlighting the need to adapt extraction models to linguistic variations. Our results show that while some extractors maintain stable performance, others suffer significant drops in precision and recall on non-English or structurally irregular pages.",
        "doi": "10.1145/3726302.3730234",
        "sheridan_id": "sp1968",
        "position": 31,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "7b7a53e239400a13bd6be6c91c4f6c4e",
        "title": "Hierarchical User Long-term Behavior Modeling for Click-Through Rate Prediction",
        "abstract": "State-of-the-art approaches for click-through rate (CTR) prediction in industry predominantly rely on transformer-based networks or their variants. However, as user behavior sequences become longer, employing self-attention networks for CTR prediction within a constrained inference time presents a significant challenge. To address this, mainstream methods adopt a classical two-stage paradigm: a General Search Unit (GSU) for quickly retrieving relevant items from long-term behaviors, and an Exact Search Unit (ESU) for applying effective Multi-Head Target Attention (MHTA) over the items selected by the GSU. These two-stage algorithms have certain limitations. Firstly, the GSU needs to retrieve different target subsequences for different target items, restricting the ESU to a suboptimal MHTA network rather than a more effective transformer-based network. Secondly, the GSU retrieves only a subset of items from the user`s behavior sequence, ignoring the evolution of user interests and the interrelationships between different points of interest. To overcome these challenges, we propose a novel end-to-end hierarchical user long-term behavior modeling network for CTR prediction (HBM). Specifically, we employ the multi-interest routing layer to channel the user`s long-term behavior to several aggregated interest clusters. Furthermore, we introduce a fine interest learning network that selects the top-k interests from the initial aggregated representations. Subsequently, we employ a transformer network to model the user`s behavior sequence associated with these top-k interests in a detailed manner, while also capturing the inherent correlations between different user interests at a coarse level. Finally, we integrate the coarse and fine interests. Extensive experiments on two real-world datasets demonstrate the effectiveness of our proposed methods. In addition, an online A/B test on the JD recommendation platform shows promising improvements, with a 2.15% increase in CTR and a 0.98% increase in CVR, accompanied by lower online inference latency.",
        "doi": "10.1145/3726302.3730207",
        "sheridan_id": "sp2020",
        "position": 34,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "955cb567b6e38f4c6b3f28cc857fc38c",
        "title": "Lost in Transliteration: Bridging the Script Gap in Neural IR",
        "abstract": "Most human languages use scripts other than the Latin alphabet. Search users in these languages often formulate their information needs in a transliterated --usually Latinized-- form for ease of typing. For example, Greek speakers might use Greeklish, and Arabic speakers might use Arabizi. This paper shows that current search systems, including those that use multilingual dense embeddings such as BGE-M3, do not generalise to this setting, and their performance rapidly deteriorates when exposed to transliterated queries. This creates a ``script gap`` between the performance of the same queries when written in their native or transliterated form. We explore whether adapting the popular ``translate-train`` paradigm to transliterations can enhance the robustness of multilingual Information Retrieval (IR) methods and bridge the gap between native and transliterated scripts. https://github.com/andreaschari/transliterations By exploring various combinations of non-Latin and Latinized query text for training, we investigate whether we can enhance the capacity of existing neural retrieval techniques and enable them to apply to this important setting. We show that by further fine-tuning IR models on an even mixture of native and Latinized text, they can perform this cross-script matching at nearly the same performance as when the query was formulated in the native script. Out-of-domain evaluation and further qualitative analysis show that transliterations can also cause queries to lose some of their nuances, motivating further research.",
        "doi": "10.1145/3726302.3730226",
        "sheridan_id": "sp2054",
        "position": 62,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "6f4920ea25403ec77bee9efce43ea25e",
        "title": "Document Similarity Enhanced IPS Estimation for Unbiased Learning to Rank",
        "abstract": "Learning to Rank (LTR) models learn from historical user interactions, such as user clicks. However, there is an inherent bias in the clicks of users due to position bias, i.e., users are more likely to click highly-ranked documents than low-ranked documents. To address this bias when training LTR models, many approaches from the literature re-weight the users` click data using Inverse Propensity Scoring (IPS). IPS re-weights the user`s clicks proportionately to the position in the historical ranking that a document was placed when it was clicked since low-ranked documents are less likely to be seen by a user. In this paper, we argue that low-ranked documents that are similar to highly-ranked relevant documents are also likely to be relevant. Moreover, accounting for the similarity of low-ranked documents to highly ranked relevant documents when calculating IPS can more effectively mitigate the effects of position bias. Therefore, we propose an extension to IPS, called IPSsim, that takes into consideration the similarity of documents when estimating IPS. We evaluate our IPSsim estimator using two large publicly available LTR datasets under a number of simulated user click settings, and with different numbers of training clicks. Our experiments show that our IPSsim estimator is more effective than the existing IPS estimators for learning an unbiased LTR model, particularly in top-n settings when n >= 30. For example, when n = 50, our IPSsim estimator achieves a statistically significant ~3% improvement (p < 0.05) in terms of NDCG compared to the Doubly Robust estimator from the literature.",
        "doi": "10.1145/3726302.3730179",
        "sheridan_id": "sp2066",
        "position": 37,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "89885ff2c83a10305ee08bd507c1049c",
        "title": "In-Context Learning as an Effective Estimator of Functional Correctness of LLM-Generated Code",
        "abstract": "When applying LLM-based code generation to software development projects that follow a feature-driven or rapid application development approach, it becomes necessary to estimate the functional correctness of the generated code in the absence of test cases. Just as a user selects a relevant document from a ranked list of retrieved ones, a software generation workflow requires a developer to choose (and potentially refine) a generated solution from a ranked list of alternative solutions, ordered by their posterior likelihoods. This implies that estimating the quality of a ranked list -- akin to estimating ``relevance`` for query performance prediction (QPP) in IR -- is also crucial for generative software development, where quality is defined in terms of ``functional correctness``. In this paper, we propose an in-context learning (ICL) based approachfor code quality estimation. Our findings demonstrate that providing few-shot examples of functionally correct code from a training set enhances the performance of existing QPP approaches as well as a zero-shot-based approach for code quality estimation.",
        "doi": "10.1145/3726302.3730212",
        "sheridan_id": "sp2041",
        "position": 60,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "0070d23b06b1486a538c0eaa45dd167a",
        "title": "Effective Inference-Free Retrieval for Learned Sparse Representations",
        "abstract": "Learned Sparse Retrieval (LSR) is an effective IR approach that exploits pre-trained language models for encoding text into a learned bag of words. Several efforts in the literature have shown that sparsity is key to enabling a good trade-off between the efficiency and effectiveness of the query processor. To induce the right degree of sparsity, researchers typically use regularization techniques when training LSR models. Recently, new efficient\u2014inverted index-based\u2014retrieval engines have been proposed, leading to a natural question: has the role of regularization changed in training LSR models? In this paper, we conduct an extended evaluation of regularization approaches for LSR where we discuss their effectiveness, efficiency, and out-of-domain generalization capabilities. We first show that regularization can be relaxed to produce more effective LSR en- coders. We also show that query encoding is now the bottleneck limiting the overall query processor performance. To remove this bottleneck, we advance the state-of-the-art of inference-free LSR by proposing Learned Inference-free Retrieval (Li-Lsr). At training time, Li-Lsr learns a score for each token, casting the query encoding step into a seamless table lookup. Our approach yields state-of-the-art effectiveness for both in-domain and out-of-domain evaluation,surpassing Splade-v3-Doc by 1 point of mRR@10 on MsMarco and 1.8 points of nDCG@10 on Beir.",
        "doi": "10.1145/3726302.3730185",
        "sheridan_id": "sp2081",
        "position": 65,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "b0df2270be9cb16c14537e5bc2f2d37b",
        "title": "Aligning Web Query Generation with Ranking Objectives via Direct Preference Optimization",
        "abstract": "Neural retrieval models excel in Web search, but their training requires substantial amounts of labeled query-document pairs, which are costly to obtain. With the widespread availability of Web document collections like ClueWeb22, synthetic queries generated by large language models offer a scalable alternative. Still, synthetic training queries often vary in quality, which leads to suboptimal downstream retrieval performance. Existing methods typically filter out noisy query-document pairs based on signals from an external re-ranker. In contrast, we propose a framework that leverages Direct Preference Optimization (DPO) to integrate ranking signals into the query generation process, aiming to directly optimize the model towards generating high-quality queries that maximize downstream retrieval effectiveness. Experiments show higher ranker-assessed relevance between query-document pairs after DPO, leading to stronger downstream performance on the MS~MARCO benchmark when compared to baseline models trained with synthetic data.",
        "doi": "10.1145/3726302.3730162",
        "sheridan_id": "sp2218",
        "position": 73,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "931af583573227f0220bc568c65ce104",
        "title": "Retrieving the Right Law: Enhancing Legal Search with Style Translation",
        "abstract": "Legal question answering requires accurate retrieval of relevant laws, yet the significant writing style gap between user queries and legal provisions poses a major challenge. Existing datasets and retrieval methods often struggle to capture the complexity of legal language, limiting retrieval effectiveness. In this study, we introduce the Legal Query-to-Provision Retrieval (LQPR) task and construct Query2Provision (Q2P), a dataset designed to enhance law retrieval by incorporating diverse case scenarios and linguistic structures representative of real-world legal inquiries. To address the style disparity, we propose a style translation approach that transforms informal user queries into a more formal legal tone and simplifies complex legal provisions for better alignment. Our experiments demonstrate that integrating writing style transformation significantly improves retrieval performance. The dataset is available at https://github.com/ntunlplab/Query2Provision",
        "doi": "10.1145/3726302.3730246",
        "sheridan_id": "sp2108",
        "position": 40,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "e21e4e58ad9ab56e8a4634046da90113",
        "title": "Refining Fidelity Metrics for Explainable Recommendations",
        "abstract": "Counterfactual evaluation provides a promising framework for assessing explanation fidelity in recommender systems, but per- turbation metrics adapted from computer vision suffer three key limitations: (1) they conflate explaining and contradictory features, (2) they average over entire user histories instead of prioritizing concise, high-impact explanations, and (3) they use fixed-percentage perturbations, leading to inconsistencies across users. We introduce refined counterfactual metrics that focus on the most relevant explaining features, exclude contradictory elements, and assess fidelity at a fixed explanation length, ensuring a more consistent and interpretable evaluation. Our code is at: https:// github.com/DeltaLabTLV/FidelityMetrics4XRec",
        "doi": "10.1145/3726302.3730242",
        "sheridan_id": "sp2148",
        "position": 41,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "bb1662b7c5f22a0f905fd59e718ca05e",
        "title": "In a Few Words: Comparing Weak Supervision and LLMs for Short Query Intent Classification",
        "abstract": "User intent classification is an important task in information retrieval. Previously, user intents were classified manually and automatically; the latter helped to avoid hand labelling of large datasets. Recent studies explored whether LLMs can reliably determine user intent. However, researchers have recognized the limitations of using generative LLMs for classification tasks. In this study, we empirically compare user intent classification into informational, navigational, and transactional categories, using weak supervision and LLMs. Specifically, we evaluate LLaMA-3.1-8B-Instruct and LLaMA-3.1-70B-Instruct for in-context learning and LLaMA-3.1-8B-Instruct for fine-tuning, comparing their performance to an established baseline classifier trained using weak supervision (ORCAS-I). Our results indicate that while LLMs outperform weak supervision in recall, they continue to struggle with precision, which shows the need for improved methods to balance both metrics effectively.",
        "doi": "10.1145/3726302.3730213",
        "sheridan_id": "sp2177",
        "position": 43,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "3e6260b81898beacda3d16db379ed329",
        "title": "KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking",
        "abstract": "Entity linking (EL) aligns textual mentions with their corresponding entities in a knowledge base, facilitating various applications such as semantic search and question answering. Recent advances in multimodal entity linking (MEL) have shown that combining text and images can reduce ambiguity and improve alignment accuracy. However, most existing MEL methods overlook the rich structural information available in the form of knowledge-graph (KG) triples. In this paper, we propose KGMEL, a novel framework that leverages KG triples to enhance MEL. Specifically, it operates in three stages: (1) Generation: Produces high-quality triples for each mention by employing vision-language models based on its text and images. (2) Retrieval: Learns joint mention-entity representations, via contrastive learning, that integrate text, images, and (generated or KG) triples to retrieve candidate entities for each mention. (3) Reranking: Refines the KG triples of the candidate entities and employs large language models to identify the best-matching entity for the mention. Extensive experiments on benchmark datasets demonstrate that KGMEL outperforms existing methods. Our code, datasets, and online appendix are available at: https://github.com/juyeonnn/KGMEL.",
        "doi": "10.1145/3726302.3730217",
        "sheridan_id": "sp2232",
        "position": 79,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "16026d60ff9b54410b3435b403afd226",
        "title": "The Effects of Demographic Instructions on LLM Personas",
        "abstract": "Social media platforms must filter sexist content in compliance with governmental regulations. Current machine learning approaches can reliably detect sexism based on standardized definitions, but often neglect the subjective nature of sexist language and fail to consider individual users` perspectives. To address this gap, we adopt a perspectivist approach, retaining diverse annotations rather than enforcing gold-standard labels or their aggregations, allowing models to account for personal or group-specific views of sexism. Using demographic data from Twitter, we employ large language models (LLMs) to personalize the identification of sexism.  Our empirical results show that OpenAI`s LLMs (GPT-3.5, GPT-4, and GPT-4o) and two open-source LLMs (Mistral and Qwen) exhibit higher Krippendorff`s alpha label agreement with female annotators than with male annotators. As well, each LLM presents higher Krippendorff`s alpha agreement with a specific annotator age group. We then sought to counter these trends by providing ``persona`` instructions as part of the LLM prompt, with somewhat surprising outcomes, highlighting the potential of user-centered perspectivist methods to improve content moderation systems.",
        "doi": "10.1145/3726302.3730255",
        "sheridan_id": "sp2295",
        "position": 48,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "a376033f78e144f494bfc743c0be3330",
        "title": "Towards Principled Learning for Re-ranking in Recommender Systems",
        "abstract": "As the final stage of recommender systems, re-ranking presents ordered item lists to users that best match their interests. It plays such a critical role and has become a trending research topic with much attention from both academia and industry. Recent advances of re-ranking are focused on attentive listwise modeling of interactions and mutual influences among items to be re-ranked. However, principles to guide the learning process of a re-ranker, and to measure the quality of the output of the re-ranker, have been always missing. In this paper, we study such principles to learn a good re-ranker. Two principles are proposed, including convergence consistency and adversarial consistency. These two principles can be applied in the learning of a generic re-ranker and improve its performance. We validate such a finding by various baseline methods over different datasets.",
        "doi": "10.1145/3726302.3730257",
        "sheridan_id": "sp2271",
        "position": 82,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "04048aeca2c0f5d84639358008ed2ae7",
        "title": "Measuring the Fairness Gap Between Retrieval and Generation in RAG Systems using a Cognitive Complexity Framework",
        "abstract": "In this paper, we investigate the problem of quantifying fairness in Retrieval-Augmented Generation (RAG) systems, particularly for complex cognitive tasks that go beyond factual question-answering. While RAG systems have demonstrated effectiveness in information extraction tasks, their fairness implications for cognitively complex tasks - including ideation, content creation, and analytical reasoning \u2014 remain under-explored. We propose a novel evaluation framework that extends IR fairness metrics by incorporating centrality-based measures to account for influence of retrieved documents on generated output beyond ranking. Our framework evaluates RAG systems across various cognitive dimensions using two ranking approaches: lexical (BM25) and dense (BGE), and language models of varying sizes. Our findings provide insights into: (1) the propagation of fairness disparities from retrieval to generation phases, and (2) the variation in system performance across different cognitive dimensions.",
        "doi": "10.1145/3726302.3730230",
        "sheridan_id": "sp2223",
        "position": 75,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "4cb811134b9d39fc3104bd06ce75abad",
        "title": "Understanding Large Language Model Performance in Software Engineering: A Large-scale Question Answering Benchmark",
        "abstract": "In this work, we introduce CodeRepoQA, a large-scale benchmark specifically designed for evaluating repository-level question-answering capabilities in the field of software engineering. CodeRepoQA encompasses five programming languages and covers a wide range of scenarios, enabling comprehensive evaluation of language models.To construct this dataset, we crawl data from 30 well-known repositories in GitHub, the largest platform for hosting and collaborating on code, and carefully filter the raw data.In total, CodeRepoQA is a multi-turn question-answering benchmark with 585,687 entries. It covers a diverse array of software engineering scenarios, with an average of 6.62 dialogue turns per entry. We evaluate ten popular large language models on our dataset and provide in-depth analysis. We find that LLMs still have limitations in question-answering capabilities in the field of software engineering, and medium-length contexts are more conducive to their performance.  The entire benchmark and details are publicly available at https://github.com/kinesiatricssxilm14/CodeRepoQA.",
        "doi": "10.1145/3726302.3730262",
        "sheridan_id": "sp2260",
        "position": 81,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "0a65e195cb51418279b6fa8d96847a60",
        "title": "HiLTV: Hierarchical Multi-Distribution Modeling for Lifetime Value Prediction in Online Games",
        "abstract": "Customer Lifetime Value (LTV) prediction is a critical task in online games, as it helps with the formulation of refined game operation strategies, resource allocation, and personalized recommendation.Accurate LTV values enable to identify and target high-value users, enhance user retention and further long-term revenue growth.However, LTV prediction in online games faces unique challenges.Most in-app purchases (IAP) games have various fixed recharge levels, and users with different payment preferences show distinct LTV distributions.Moreover, existing methods fail to capture the multi-modal distribution of LTV values, and suffer from bias when predicting LTV values of games that users have not registered, i.e., new users.To address these challenges, we propose HiLTV, a novel hierarchical framework for LTV prediction in online games. We devise hierarchical modules to align with real-world user recharge behaviors, and a Zero-Inflated Mixture-of-Logistic (ZIMoL) loss instead of a unimodal distribution loss is adopted to better model various segments of users.We also introduce a calibration module that enables more robust predictions for new users.Both offline evaluation on real-world industrial datasets over state-of-the-art baselines and online A/B test from a leading game platform demonstrate the superior performance of our method.",
        "doi": "10.1145/3726302.3730208",
        "sheridan_id": "sp2371",
        "position": 85,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "e8dfff4676a47048d6f0c4ef899593dd",
        "title": "NLQxform-UI: An Interactive and Intuitive Scholarly Question Answering System",
        "abstract": "Most scholarly search services only provide basic text-matching or similarity-based searches, with limited operations that require manual configuration, such as sorting and filtering by specific metadata attributes. These capabilities are insufficient for researchers who often have queries that involve complex constraints and operations, such as ``enumerating the authors of a given paper along with the venues where they have published other papers.`` In this work, we develop an interactive and intuitive scholarly question answering system called NLQxform-UI, which allows users to pose complex queries in the form of natural language questions. It is capable of automatically translating these questions into SPARQL queries that can be executed over the DBLP knowledge graph to retrieve expected answers. Furthermore, the users can interact with each step of the answering process and browse the final results in a web-based interface. A video recording of our system is available at https://youtu.be/elq8CPykiyk Additionally, the system has been completely open-sourced: https://github.com/ruijie-wang-uzh/NLQxform-UI",
        "doi": "10.1145/3726302.3730153",
        "sheridan_id": "de1841",
        "position": 7,
        "track_id": 10,
        "slot_id": 104
      }
    },
    {
      "paper": {
        "hashed_id": "0fe473396242072e84af286632d3f0ff",
        "title": "Deep Multiple Quantization Network on Long Behavior Sequence for Click-Through Rate Prediction",
        "abstract": "In Click-Through Rate (CTR) prediction, the long behavior sequence, comprising the user`s long period of historical interactions with items has a vital influence on assessing the user`s interest in the candidate item. Existing approaches strike efficiency and effectiveness through a two-stage paradigm: first retrieving hundreds of candidate-related items and then extracting interest intensity vector through target attention. However, we argue that the discrepancy in target attention`s relevance distribution between the retrieved items and the full long behavior sequence inevitably leads to a performance decline. To alleviate the discrepancy, we propose the Deep Multiple Quantization Network (DMQN) to process long behavior sequence end-to-end through compressing the long behavior sequence. Firstly, the entire spectrum of long behavior sequence will be quantized into multiple codeword sequences based on multiple independent codebooks. Hierarchical Sequential Transduction Unit is incorporated to facilitate the interaction of reduced codeword sequences. Then, attention between the candidate and multiple codeword sequences will output the interest vector. To enable online serving, intermediate representations of the codeword sequences are cached, significantly reducing latency. Our extensive experiments on both industrial and public datasets confirm the effectiveness and efficiency of DMQN. The A/B test in our advertising system shows that DMQN improves CTR by 3.5\\% and RPM by 2.0\\%.",
        "doi": "10.1145/3726302.3730177",
        "sheridan_id": "sp2433",
        "position": 89,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "8420d359404024567b5aefda1231af24",
        "title": "Unveiling Knowledge Boundary of Large Language Models for Trustworthy Information Access",
        "abstract": "Large Language Models (LLMs) have emerged as powerful tools for generating content and facilitating information seeking across diverse domains. While their integration into conversational systems opens new avenues for interactive information-seeking experiences, their effectiveness is constrained by their knowledge boundaries\u2014the limits of what they know and their ability to provide reliable, truthful, and contextually appropriate information. Understanding these boundaries is essential for maximizing the utility of LLMs for real-time information seeking while ensuring their reliability and trustworthiness. In this tutorial, we will explore the taxonomy of knowledge boundary in LLMs, addressing their handling of uncertainty, response calibration, and mitigation of unintended behaviors that can arise during interaction with users. We will also present advanced techniques for optimizing LLM behavior in generative information-seeking tasks, ensuring that models align with user expectations of accuracy and transparency. Attendees will gain insights into research trends and practical methods for enhancing the reliability and utility of LLMs for trustworthy information access.",
        "doi": "10.1145/3726302.3731684",
        "sheridan_id": "tut2683",
        "position": 0,
        "track_id": 14,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "7c4bf50b715509a963ce81b168ca674b",
        "title": "Information Retrieval in Finance: Industry and Academic Perspectives on Innovation",
        "abstract": "Information retrieval (IR) plays a critical role in financial decision-making across investment research, trading, risk management, and reporting. With the rise of large language models (LLMs), IR systems have evolved to support more natural, context-aware workflows. In this tutorial, we survey recent advances in applying IR and LLM technologies in finance, covering agent-based simulations, investor recommender systems, retrieval-augmented research management, and LLM-driven portfolio construction. We highlight practical challenges and propose future research directions at the intersection of IR, LLMs, and financial innovation. More materials can be found at http://irfin.nlpfin.com/.",
        "doi": "10.1145/3726302.3731685",
        "sheridan_id": "tut2684",
        "position": 0,
        "track_id": 15,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "3a0844cee4fcf57de0c71e9ad3035478",
        "title": "Conversational Search: From Fundamentals to Frontiers in the LLM Era",
        "abstract": "Conversational search enables multi-turn interactions between users and systems to fulfill users` complex information needs. During this interaction, the system should understand the users` search intent within the conversational context and then return the relevant information through a flexible, dialogue-based interface.The recent powerful large language models (LLMs) with capacities of instruction following, content generation, and reasoning, attract significant attention and advancements, providing new opportunities and challenges for building up intelligent conversational search systems.This tutorial aims to introduce the connection between fundamentals and the emerging topics revolutionized by LLMs in the context of conversational search.It is designed for students, researchers, and practitioners from both academia and industry.Participants will gain a comprehensive understanding of both the core principles and cutting-edge developments driven by LLMs in conversational search, equipping them with the knowledge needed to contribute to the development of next-generation conversational search systems.",
        "doi": "10.1145/3726302.3731686",
        "sheridan_id": "tut2686",
        "position": 0,
        "track_id": 14,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "573eec40e4ef4f2089531dd5cbf629f8",
        "title": "Query Understanding in LLM-based Conversational Information Seeking",
        "abstract": "Query understanding in CIS involves accurately interpreting user intent through context-aware interactions. This includes resolving ambiguities, refining queries, and adapting to evolving information needs. LLM enhance this process by interpreting nuanced language and adapting dynamically, improving the relevance and precision of search results in real-time. In this tutorial, we explore advanced techniques to enhance query understanding in LLM-based CIS systems. We delve into LLM-driven methods for developing robust evaluation metrics to assess query understanding quality in multi-turn interactions, strategies for building more interactive systems, and applications like proactive query management and query reformulation. We also discuss key challenges in integrating LLM for query understanding in conversational search systems and outline future research directions. Our goal is to deepen the audience`s understanding of LLM-based conversational query understanding and inspire discussions to drive ongoing advancements in this field.",
        "doi": "10.1145/3726302.3731687",
        "sheridan_id": "tut2687",
        "position": 0,
        "track_id": 14,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "b38e5ff5f816ac6e4169bce9314b2996",
        "title": "Efficient In-Memory Inverted Indexes: Theory and Practice",
        "abstract": "Inverted indexes are the backbone of most large-scale information retrieval systems. Although conceptually simple, high-performance inverted indexes require a deep understanding of low-level system optimizations, compression techniques, and traversal strategies. With the widespread adoption of in-memory search engines, the rise of learned sparse retrieval (LSR), and the increasing complexity of ranking pipelines, the design space for efficient indexing and retrieval systems has expanded significantly. This tutorial addresses a critical knowledge gap between textbook-style explanations and advanced techniques required for efficient and optimized retrieval. It aims to equip researchers and practitioners with a comprehensive understanding of how modern in-memory search systems are designed, built, and optimized for high-performance retrieval across large-scale document collections.",
        "doi": "10.1145/3726302.3731688",
        "sheridan_id": "tut2688",
        "position": 0,
        "track_id": 14,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "f6185f0ef02dcaec414a3171cd01c697",
        "title": "Long Context vs. RAG: Strategies for Processing Long Documents in LLMs",
        "abstract": "Large Language Models (LLMs) excel at zero- and few-shot learning but are restricted by the length of context windows when processing long documents. Two strategies have emerged to overcome this limitation: (1) Long Context (LC) methods, which extend or compress transformer architectures to input more text; and (2) Retrieval-Augmented Generation (RAG), which integrates external knowledge sources via embedding- or index-based retrieval. This half-day tutorial offers a unified, beginner-friendly introduction to both approaches. We first review transformer fundamentals\u2014positional encoding, attention complexity, and common LC techniques. Next, we explain the classic RAG pipeline and recent RAG strategies, alongside evaluation metrics and benchmarks.  We also analyze recent empirical studies to highlight strengths, limitations, and trade-offs of LC vs. RAG in terms of scalability, computational cost, and retrieval effectiveness. We conclude with best practices for real-world deployments, emerging hybrid architectures, and open research directions, equipping IR researchers and practitioners with actionable guidelines for processing long documents in LLMs.",
        "doi": "10.1145/3726302.3731690",
        "sheridan_id": "tut2690",
        "position": 0,
        "track_id": 14,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "d790c9e6c0b5e02c87b375e782ac01bc",
        "title": "Dynamic and Parametric Retrieval-Augmented Generation",
        "abstract": "Retrieval-Augmented Generation (RAG) has become a foundational paradigm for enhancing large language models (LLMs) with external knowledge, playing an important role in modern information retrieval and knowledge-intensive NLP applications. Standard RAG systems typically adopt a static retrieve-then-generate pipeline and rely on in-context knowledge injection, which can be suboptimal for complex tasks that require multihop reasoning, adaptive information access, and deeper integration of external knowledge. Motivated by these limitations, the research community has moved beyond static retrieval and in-context knowledge injection. Among the emerging directions, this tutorial delves into two rapidly growing and complementary research directions on RAG: Dynamic RAG and Parametric RAG. Dynamic RAG explores how LLMs can actively decide when and what to retrieve during generation, enabling real-time adaptation to evolving information needs. Parametric RAG rethinks how the retrieved knowledge should be incorporated, moving from input-level to parameter-level knowledge injection for improved efficiency and effectiveness. This tutorial offers a comprehensive overview of recent advances in both directions. It provides participants with the theoretical foundations and actionable insights needed to build flexible and scalable RAG systems.",
        "doi": "10.1145/3726302.3731692",
        "sheridan_id": "tut2692",
        "position": 0,
        "track_id": 14,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "3bd4017318837e92a66298c7855f4427",
        "title": "Neural Lexical Search with Learned Sparse Retrieval",
        "abstract": "Learned Sparse Retrieval (LSR) techniques use neural machinery to represent queries and documents as learned bags of words. In contrast with other neural retrieval techniques, such as generative retrieval and dense retrieval, LSR has been shown to be a remarkably robust, transferable, and efficient family of methods for retrieving high-quality search results. This half-day tutorial aims to provide an extensive overview of LSR, ranging from its fundamentals to the latest emerging techniques. By the end of the tutorial, attendees will be familiar with the important design decisions of an LSR system, know how to apply them to text and other modalities, and understand the latest techniques for retrieving with them efficiently. Website: https://lsr-tutorial.github.io",
        "doi": "10.1145/3726302.3731693",
        "sheridan_id": "tut2693",
        "position": 0,
        "track_id": 14,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "cf9b2d0406020c56599f9a93708832b5",
        "title": "Fairness in Information Retrieval from an Economic Perspective",
        "abstract": "Recently, fairness-aware information retrieval (IR) systems have been receiving much attention. Numerous fairness metrics and algorithms have been proposed. The complexity of fairness and IR systems makes it challenging to provide a systematic summary of the progress that has been made. This complexity calls for a more structured framework to navigate future fairness-aware IR research directions. The field of economics has long explored fairness, offering a strong theoretical and empirical foundation. Its system-oriented perspective enables the integration of IR fairness into a broader framework that considers societal and intertemporal trade-offs. In this tutorial, we first highlight that IR systems can be understood as a specialized economic market. Then, we re-organize fairness algorithms through three key economic dimensions\u2014macro vs. micro, demand vs supply, and short-term vs. long-term. We effectively view most fairness categories in IR from an economic perspective. Finally, we illustrate how this economic framework can be applied to various real-world IR applications and we demonstrate its benefits in industrial scenarios. Different from other fairness-aware tutorials, our tutorial not only provides a new and clear perspective to re-frame fairness-aware IR but also inspires the use of economic tools to solve fairness problems in IR. We hope this tutorial provides a fresh, broad perspective on fairness in IR, highlighting open problems and future research directions.",
        "doi": "10.1145/3726302.3731694",
        "sheridan_id": "tut2694",
        "position": 0,
        "track_id": 14,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "dbbf603ff0e99629dda5d75b6f75f966",
        "title": "The Second Tutorial on Retrieval-Enhanced Machine Learning: Synthesis and Opportunities",
        "abstract": "Retrieval-Enhanced Machine Learning (REML) refers to the use of information retrieval (IR) methods to support reasoning and inference in machine learning tasks. Although relatively recent, these approaches can substantially improve model performance. This includes improved generalization, knowledge grounding, scalability, freshness, attribution, interpretability, and on-device learning. To date, despite being influenced by work in the information retrieval community, REML research has predominantly been presented in natural language processing (NLP) conferences. Our tutorial addresses this disconnect by introducing core REML concepts and synthesizing the literature from various domains in machine learning (ML), including, but not limited to, NLP. What is unique to our approach is the use of consistent notations to provide researchers with a unified and expandable framework. The tutorial will be presented in lecture format based on an existing manuscript, with supporting materials and a comprehensive reading list available at a website. Building on the momentum of our successful workshop at SIGIR 2023 and our tutorial at SIGIR-AP 2024, this year`s tutorial features updated content with an emphasis on retrieval technologies used across the broader ML community. We also highlight their role in emerging, future-facing applications such as language agents and evolving scenarios where the extensive body of knowledge from IR can provide critical insights and capabilities.",
        "doi": "10.1145/3726302.3731695",
        "sheridan_id": "tut2695",
        "position": 0,
        "track_id": 14,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "4c5bde74a8f110656874902f07378009",
        "title": "SIGIR 2025 Workshop on eCommerce (ECOM25)",
        "abstract": "The eCommerce search and recommendations space is a unique and dynamic domain within information retrieval (IR), characterized by its multimodality and industry-driven challenges. While the basic task of fulfilling a user`s information need aligns with web search, the methodologies employed are distinct. On eCommerce platforms (e.g. Alibaba, Amazon, eBay, Etsy, Flipkart, Walmart), the data available for retrieval and ranking differs significantly, as do the success signals (e.g. adding items to a cart, purchasing). Our focus for 2025 is on fostering deeper engagement through interactive discussions, exploring crucial topics such as navigating irreproducibility in research-to-product pipelines, and addressing emerging topics such as evaluation metrics for LLMs, multimodality, and the interplay between organic and sponsored search. With our discussion-heavy format and structured facilitation, we aim to spark conversation among all participants.",
        "doi": "10.1145/3726302.3730359",
        "sheridan_id": "wk0182",
        "position": 0,
        "track_id": 18,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "fb4ab556bc42d6f0ee0f9e24ec4d1af0",
        "title": "Navigating Large Language Models for Recommendation: From Architecture to Learning Paradigms and Deployment",
        "abstract": "Large Language Models (LLMs) are reshaping the landscape of recommender systems, giving rise to the emerging field of LLM4Rec that attracts both academia and industry. Unlike earlier approaches that simply borrowed model architectures or learning paradigms from language models, recent advances have led to a dedicated and evolving technical stack for LLM4Rec, spanning architecture design, pre-training and post-training strategies, inference techniques, and real-world deployment. This tutorial offers a systematic and in-depth overview of LLM4Rec through the lens of this technical stack. We will examine how LLMs are being adapted to recommendation tasks across different stages, empowering them with capabilities such reasoning, planning, and in-context learning. Moreover, we will highlight practical challenges including complex user modeling, trustworthiness, and evaluation. Distilling insights from recent research and identifying open problems, this tutorial aims to equip participants with a comprehensive understanding of LLM4Rec and inspire continued innovation in this rapidly evolving field.",
        "doi": "10.1145/3726302.3731696",
        "sheridan_id": "tut2698",
        "position": 0,
        "track_id": 14,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "0415740eaa4d9decbc8da001d3fd805f",
        "title": "Theory and Toolkits for User Simulation in the Era of Generative AI: User Modeling, Synthetic Data Generation, and System Evaluation",
        "abstract": "Interactive AI systems, including search engines, recommender systems, conversational agents, and generative AI applications, are increasingly central to user experiences. However, rigorously evaluating their performance, training them effectively with interaction data, and modeling user behavior for personalization remain significant challenges, often difficult to address reproducibly and at scale. User simulation, which employs intelligent agents to mimic human interaction patterns, offers a powerful and versatile methodology to tackle these interconnected issues. This half-day tutorial provides a comprehensive overview of modern user simulation techniques for interactive AI systems. We will explore the theoretical foundations and practical applications of simulation for system evaluation, algorithm training, and user modeling, emphasizing the crucial connections between these uses. The tutorial covers key simulation methodologies, with a particular focus on recent advancements leveraging large language models, discussing both the opportunities they present and the open challenges they entail. Crucially, we will also provide practical guidance, highlighting relevant toolkits, libraries, and datasets available to researchers and practitioners.",
        "doi": "10.1145/3726302.3731697",
        "sheridan_id": "tut2699",
        "position": 0,
        "track_id": 14,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "02522a2b2726fb0a03bb19f2d8d9524d",
        "title": "Robust-IR @ SIGIR 2025: The First Workshop on Robust Information Retrieval",
        "abstract": "With the advancement of information retrieval (IR) technologies, robustness is increasingly attracting attention. When deploying technology into practice, we consider not only its average performance under normal conditions but, more importantly, its ability to maintain functionality across a variety of exceptional situations. In recent years, the research on IR robustness covers theory, evaluation, methodology, and application, and all of them show a growing trend. The purpose of this workshop is to systematize the latest results of each research aspect, to foster comprehensive communication within this niche domain while also bridging robust IR research with the broader community, and to promote further future development of robust IR. To avoid the one-sided talk of mini-conferences, this workshop adopts a highly interactive format, including round-table and panel discussion sessions, to encourage active participation and meaningful exchange among attendees.",
        "doi": "10.1145/3726302.3730355",
        "sheridan_id": "wk0134",
        "position": 0,
        "track_id": 18,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "a5e00132373a7031000fd987a3c9f87b",
        "title": "2nd Workshop on Information Retrieval for Understudied Users (IR4U2) - Bridging User-centered AI with IR: Making Information Retrieval Accessible for All",
        "abstract": "The Workshop on Information Retrieval for Understudied Users (IR4U2) serves as a platform to highlight information retrieval (IR) research that directly impacts often understudied user groups. The second (IR4U2) workshop focuses on a user-centred AI perspective, which is vital for informing the design, development, and assessment of information retrieval systems that thoughtfully address the diverse needs of understudied populations, ensuring genuine accessibility and inclusivity. The objectives of IR4U2 are: (1) to build community and awareness by sharing AI and IR developments that serve underrepresented user groups in this research area; (2) to identify challenges and open issues along with lessons learned and challenges inherent to this area of research; and (3) to spark discussions that establish common frameworks for future research.",
        "doi": "10.1145/3726302.3730356",
        "sheridan_id": "wk0146",
        "position": 0,
        "track_id": 18,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "8d5e957f297893487bd98fa830fa6413",
        "title": "International Workshop on Algorithmic Bias in Search and Recommendation (BIAS 2025)",
        "abstract": "Designing search and recommendation models that are both efficient and effective has long been a central objective for both industry professionals and academic researchers. Yet, growing evidence highlights how models trained on historical data can reinforce pre-existing biases, potentially leading to harmful outcomes. Addressing these challenges by defining, evaluating, and mitigating bias across development workflows is a crucial step toward the responsible deployment of search and recommendation models in practice. The BIAS 2025 workshop seeks to gather innovative research and foster a shared space for dialogue among researchers and practitioners committed to advancing this fundamental direction. Workshop website: https://biasinrecsys.github.io/sigir2025/.",
        "doi": "10.1145/3726302.3730357",
        "sheridan_id": "wk0147",
        "position": 0,
        "track_id": 18,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "06409663226af2f3114485aa4e0a23b4",
        "title": "ReNeuIR at SIGIR 2025: The Fourth Workshop on Reaching Efficiency in Neural Information Retrieval",
        "abstract": "Measuring effectiveness and efficiency in information retrieval has a strong empirical background. While modern retrieval systems substantially improve effectiveness, the community has not yet agreed on how to measure efficiency, making it difficult to contrast effectiveness and efficiency fairly. Efficiency-oriented system comparisons are difficult due to factors such as hardware configurations, software versioning, and experimental settings. Efficiency affects users, researchers, and the environment and can be measured in many dimensions beyond time and space, such as resource consumption, water usage, and sample efficiency. Analyzing the efficiency of algorithms and their trade-off with effectiveness requires revisiting and establishing new standards and principles, from defining relevant concepts to designing new measures and guidelines to assess the findings` significance. ReNeuIR`s fourth iteration aims to bring the community together to debate these questions and collaboratively test and improve benchmarking frameworks for efficiency based on discussions and collaborations of its previous iterations, including a shared task focused on efficiency and reproducibility.",
        "doi": "10.1145/3726302.3730358",
        "sheridan_id": "wk0158",
        "position": 0,
        "track_id": 18,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "84d9ee44e457ddef7f2c4f25dc8fa865",
        "title": "6th Workshop on Patent Text Mining and Semantic Technologies (PatentSemTech2025)",
        "abstract": "Information retrieval systems for the patent domain have a long and evolving history, serving as effective tools to support patent experts in a variety of daily tasks. They facilitate patent landscape analysis, help in the drafting and evaluation tasks in the patenting process, and enable efficient information extraction to gain practical insights into new technologies and innovations. Moreover, they assist in identifying existing solutions, knowledge gaps, trends, and persistent challenges within specific technological fields, thereby informing strategic decision-making and innovation management.Advances in machine learning and natural language processing allow to further automate such tasks, e.g. paragraph retrieval, question answering (QA) or patent text generation. The exploration of semantic technologies for the intellectual property (IP) industry is still in its early stages, with significant potential yet to be unlocked. Investigating the use of artificial intelligence (AI) methods for the patent domain is therefore not only of academic interest, but also highly relevant for practitioners. Compared to other domains, high quality, semi-structured, annotated data is available in large volumes (a requirement for supervised machine learning models), making training large models easier. On the other hand, domain-specific challenges arise, such as very technical language or legal requirements for patent documents, and data from various disciplines and technological areas. With the 6th edition of this workshop we will provide a platform for researchers and industry to discuss recent developments for semantic patent retrieval and analysis employing sophisticated methods ranging from patent text mining, domain-specific information retrieval to large language models (LLMs) targeting next generation applications and use cases for the IP and related domains.",
        "doi": "10.1145/3726302.3730360",
        "sheridan_id": "wk0199",
        "position": 0,
        "track_id": 18,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "1534b76d325a8f591b52d302e7181331",
        "title": "IR-RAG @SIGIR25: The Second Edition of the Workshop on Information Retrieval`s Role in RAG Systems",
        "abstract": "In recent years, Retrieval-Augmented Generation (RAG) systems have become a cornerstone of artificial intelligence, attracting considerable attention in a variety of fields. By integrating the strengths of information retrieval and generative models, these systems have shown immense potential to push the boundaries of machine learning applications. Nevertheless, RAG systems still face significant challenges and offer ample room for advancement and innovation. This workshop aims to highlight the central role of information retrieval within RAG frameworks, which we believe has often been overshadowed by the emphasis on the generative components. While the generative models are integral to these systems, the quality and effectiveness of the retrieval mechanism is equally critical, as it has a direct impact on the overall system performance and outcomes.  We invite papers that rethink and prioritise the fundamental aspects of RAG systems, particularly in strengthening the information retrieval component. Through this workshop, we aim to gain deeper insights into how improved retrieval methods can enhance the performance and reliability of RAG systems.  The event will bring together leading experts, researchers and practitioners to provide a collaborative platform for exchanging ideas, sharing results and fostering innovation. Our aim is to stimulate research and discussion that reaffirms the essential role of information retrieval in shaping the next generation of generative systems.",
        "doi": "10.1145/3726302.3730362",
        "sheridan_id": "wk0212",
        "position": 0,
        "track_id": 18,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "979d472a84804b9f647bc185a877a8b5",
        "title": "Second SIGIR Workshop on Simulations for Information Access (Sim4IA 2025)",
        "abstract": "Simulations in information access (IA) have recently gained interest, as shown by various tutorials and workshops around that topic.   Simulations can be key contributors to central IA research and evaluation questions, especially around interactive settings when real users are unavailable, or their participation is impossible due to ethical reasons. In addition, simulations in IA can help contribute to a better understanding of users, reduce complexity of evaluation experiments, and improve reproducibility.   Building on recent developments in methods and toolkits, the second iteration of our Sim4IA workshop aims to again bring together researchers and practitioners to form an interactive and engaging forum for discussions on the future perspectives of the field. An additional aim is to plan an upcoming TREC/CLEF campaign.",
        "doi": "10.1145/3726302.3730363",
        "sheridan_id": "wk0213",
        "position": 0,
        "track_id": 18,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "45fbc6d3e05ebd93369ce542e8f2322d",
        "title": "The 1st NIP@IR Workshop on New Interaction Paradigms for Information Retrieval in the Era of Generative AI",
        "abstract": "The advent of generative artificial intelligence (AI), driven by advancements in large language models (LLMs), has unlocked transformative possibilities for information retrieval (IR), giving rise to a new wave of interactive and conversational paradigms. This workshop, titled New Interaction Paradigms for Information Retrieval in the Era of Generative AI, aims to serve as a collaborative platform for researchers and practitioners to explore the challenges and opportunities of integrating generative AI into IR systems. By focusing on tasks such as multi-turn conversational search, adaptive retrieval interfaces, and context-aware response generation, this workshop will address key areas including system design, user engagement, and evaluation methodologies. The workshop will also delve into broader concerns such as trust, transparency, and fairness, emphasizing the ethical implications of deploying generative AI in IR systems. Through panel discussions, poster sessions, and interactive roundtables, this workshop will foster critical dialogue and innovation, paving the way for a new era of user-centric, generative AI-powered IR systems.",
        "doi": "10.1145/3726302.3730364",
        "sheridan_id": "wk0216",
        "position": 0,
        "track_id": 17,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "312351bff07989769097660a56395065",
        "title": "The LiveRAG Challenge at SIGIR 2025",
        "abstract": "The LiveRAG Challenge at SIGIR 2025 provides a competitive platform for advancing Retrieval-Augmented Generation (RAG) technologies. Participants from academia and industry have been invited to build a RAG-based question answering system using a fixed  corpus (Fineweb-10BT) and a common open-source LLM (Falcon3-10B-Instruct). The goal is to enable fair, focused comparisons on retrieval and prompting strategies. During the Live Challenge Day, the competing teams must provide answers and supportive information to 500 unseen questions within a strict two-hour window. Evaluation is conducted in two stages: automated LLM-as-a-judge scoring mechanism for correctness and faithfulness, followed by  a manual review of top ranked submissions. The winners will be announced and prizes awarded during the LiveRAG Workshop at SIGIR 2025 in Padua, Italy.",
        "doi": "10.1145/3726302.3733591",
        "sheridan_id": "wk2025",
        "position": 0,
        "track_id": 3,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "e165421110ba03099a1c0393373c5b43",
        "title": "AgentIR: 2nd Workshop on Agent-based Information Retrieval",
        "abstract": "Information retrieval (IR) systems are essential in modern society, aiding users to efficiently locate relevant information through query expansion, document retrieval, ranking, and re-ranking. User feedback from ranked outputs forms a dynamic interaction loop with IR systems, which can be modeled as either one-time or sequential decision-making problems. Over the past decade, deep reinforcement learning (DRL) has emerged as a promising approach to decision-making, leveraging the high model capacity of deep learning for complex tasks. While significant research has explored the application of DRL to IR tasks, several fundamental challenges remain underexplored, including the underlying information theory in DRL settings, the limitations of reinforcement learning methods for industrial IR applications, and the simulation of DRL-based IR systems. Concurrently, the advent of large language models (LLMs) has introduced new opportunities for optimizing and simulating IR systems. Building on the success of the Agent-based IR Workshop at SIGIR 2024, we propose hosting the second Agent-based IR Workshop at SIGIR 2025. This workshop will continue to provide a platform for researchers and practitioners from academia and industry to present cutting-edge advances in DRL-based and LLM-based IR systems from an agent-based perspective. By building on the foundation laid in the first workshop, the 2025 edition aims to delve deeper into emerging research challenges, foster collaborations, and explore innovative applications. Through engaging discussions and insightful presentations, the workshop seeks to further expand the boundaries of IR research and solidify its role as a premier venue for advancing agent-based IR systems.",
        "doi": "10.1145/3726302.3730365",
        "sheridan_id": "wk0233",
        "position": 0,
        "track_id": 17,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "577ef1154f3240ad5b9b413aa7346a1e",
        "title": "FinIR: The 2nd Workshop on Financial Information Retrieval in the Era of Generative AI",
        "abstract": "Recent advancements in Generative AI, such as Large Language Models (LLMs), have demonstrated remarkable success across various general tasks. Extensive studies have explored leveraging generative models in finance, but significant challenges persist. This half-day workshop explores potential approaches and research directions to address these challenges by equipping generative models with advanced Information Retrieval (IR) models. Specifically, this workshop seeks to provide a platform for discussing innovative ideas that facilitate the advancement of IR technology to enrich generative models in finance from four key perspectives: (i) financial IR techniques, (ii) financial IR benchmarking and evaluation, (iii) financial systems and agents/assistants, (iv) and trustworthiness, privacy and security when applying financial IR and generative models. This workshop aims to deepen understanding, accelerate progress, and support the advancement of IR technology to enhance generative models to address financial challenges.",
        "doi": "10.1145/3726302.3730366",
        "sheridan_id": "wk0235",
        "position": 0,
        "track_id": 17,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "335f5352088d7d9bf74191e006d8e24c",
        "title": "LLM4Eval: Large Language Model for Evaluation in IR",
        "abstract": "Large language models (LLMs) have demonstrated increasing task-solving abilities not present in smaller models. Utilizing the capabilities and responsibilities of LLMs for automated evaluation (LLM4Eval) has recently attracted considerable attention in multiple research communities. Building on the success of previous workshops, which established foundations in automated judgments and RAG evaluation, this third iteration aims to address emerging challenges as IR systems become increasingly personalized and interactive. The main goal of the third LLM4Eval workshop is to bring together researchers from industry and academia to explore three critical areas: the evaluation of personalized IR systems while maintaining fairness, the boundaries between automated and human assessment in subjective scenarios, and evaluation methodologies for systems that combine multiple IR paradigms (search, recommendations, and dialogue). By examining these challenges, we seek to understand how evaluation approaches can evolve to match the sophistication of modern IR applications. The format of the workshop is interactive, including roundtable discussion sessions, fostering dialogue about the future of IR evaluation while avoiding one-sided discussions. This is the third iteration of the workshop series, following successful events at SIGIR 2024 and WSDM 2025, with the first iteration attracting over 50 participants.",
        "doi": "10.1145/3726302.3730367",
        "sheridan_id": "wk0240",
        "position": 0,
        "track_id": 18,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "6c9882bbac1c7093bd25041881277658",
        "title": "MANILA25: SIGIR 2025 Workshop on Information Retrieval for Climate Impact",
        "abstract": "The MANILA25 workshop is aimed at collaborative agenda setting around the general area of information retrieval for climate impact in general and around adaptation tracking in particular. To this end, the workshop starts by creating a shared understanding of the problem space through invited talks around information needs in climate impact, search and analysis of climate impact literature, adaptation tracking, and resources. It then brings in different perspectives on the four topics through a number of brief ``flash`` presentations by participants in the workshop. Then, the participants will work to co-develop a research agenda in a small-scale, highly interactive setting.",
        "doi": "10.1145/3726302.3730368",
        "sheridan_id": "wk0250",
        "position": 0,
        "track_id": 17,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "8f121ce07d74717e0b1f21d122e04521",
        "title": "GENNEXT: The Next Generation of IR and Recommender Systems with Language Agents, Generative Models, and Conversational AI",
        "abstract": "We present GENNEXT, a workshop dedicated to exploring the integration of language agents, generative models, and conversational AI within information retrieval (IR) and recommender systems (RS). Building on the success of our recent RecSys`24 workshop, GENNEXT aims to advance discussions on the applications of language agents powered by Large Language Models (LLMs). The workshop will focus on enhancing interactivity between users and systems through multi-turn dialogues, improving creative content generation, advancing personalization, and enabling multifaceted, context-aware decision-making. For example, a language agent could respond to a query like \"Suggest an eco-friendly food tour for a weekend in my city\" by using a recommendation API to identify eateries specializing in sustainable or organic cuisine and a pollution API to ensure the selected routes have low air pollution levels.GENNEXT will bring together leading researchers and practitioners through keynotes, paper presentations, and a panel discussion. We invite full papers, short papers, and extended abstracts covering theoretical advancements, practical applications, and evaluation strategies for generative technologies in IR and RS. The workshop will address key themes such as conversational adaptation, generative content creation, and agentic tool usage, while tackling challenges like bias, data privacy, and hallucination risks. Overall, our main ambition is to foster dialogue on creating ethical, sustainable, and innovative systems while addressing emerging opportunities and risks in modern IR and RS.",
        "doi": "10.1145/3726302.3730369",
        "sheridan_id": "wk0268",
        "position": 0,
        "track_id": 17,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "4ebccfb3e317c7789f04f7a558df4537",
        "title": "Strategic Multi-Agent Dynamics in Competitive IR",
        "abstract": "In the Web ecosystem, document authors often strategically modify content to maximize visibility in search rankings. These ranking-incentivized modifications pose challenges to retrieval effectiveness, content diversity, and long-term stability. At the same time, the rise of large language models (LLMs) is transforming IR: queries and documents that were once assumed to be generated exclusively by humans can now also be created by automated agents [5]. These agents can  formulate queries, generate documents, and perform ranking. This introduces a variety of new challenges and opportunities in competitive search environments, where interactions between strategic agents can substantially influence outcomes. This research pursues two primary goals. First, it seeks to understand strategic interactions, particularly how different configurations of users (query), authors (document) and systems (ranker) influence competition outcomes. Second, it explores methods for designing systems that foster beneficial outcomes, such as stability and fairness.  To this end, this research employs a combination of game-theoretic analysis, empirical ranking competitions between humans, and simulation-based experiments to investigate competitive dynamics in information retrieval systems [1-4]. Our theoretical analysis begins by modeling settings where authors compete to promote their documents across multiple queries as a continuous game in which each author allocates emphasis across different queries. We fully characterize when pure Nash equilibria exist and show that, unlike single-query settings, a stable state almost never exists [4]. To address this instability, we propose a novel method of strategic corpus enrichment. Specifically, we show using theoretical analysis how the mediator, by strategically planting documents in the corpus, can achieve stability in the system [2].",
        "doi": "10.1145/3726302.3730122",
        "sheridan_id": "dc2598",
        "position": 1,
        "track_id": 11,
        "slot_id": 45
      }
    },
    {
      "paper": {
        "hashed_id": "880610aa9f9de9ea7c545169c716f477",
        "title": "Enhancing AI Agents with Human Theory of Mind (ToM) for Context-Aware Actions",
        "abstract": "In the domain of artificial intelligence, the role of agents is rapidly expanding. An agent is an autonomous entity that perceives its environment, makes informed decisions, and takes actions to complete tasks. However, enabling agents to accurately interpret and respond to human requests\u2014particularly through understanding human Theory of Mind (ToM)\u2014remains a complex and pivotal challenge. ToM encompasses the ability to recognize that individuals possess distinct mental states, such as intentions, beliefs, and desires, which may differ from one`s own. This cognitive faculty is fundamental to human interaction, enabling empathy and understanding across diverse contexts. As AI agents are increasingly deployed across new domains, approximating ToM becomes vital for producing appropriate and context-sensitive responses. Recent studies have explored methodologies to enhance ToM capabilities in large language models (LLMs), aiming to refine their ability to infer and track human mental states. By leveraging ToM, LLMs have been shown to approximate key aspects of human-like social cognition. However, most existing research has focused primarily on evaluating ToM within LLMs, overlooking the broader challenge of enabling AI agents to actively understand and respond to human cognitive and mental states. While previous studies have developed agents focused on extracting human mental states, further research is needed to design agents capable of performing diverse tasks while integrating ToM reasoning. AI agents must not only infer mental states but also leverage them to enhance reasoning, planning, decision-making, and task execution. For example, an educational tutor agent assisting a student with a math problem must recognize whether the student seeks step-by-step guidance or conceptual clarification, and whether their broader intent is to master the material or to prepare for an exam. Without accurately inferring and leveraging such mental states, agents risk producing ineffective interactions, leading to user frustration and disengagement. Incorporating ToM information is therefore crucial for improving decision-making and enabling more contextually appropriate responses.  To address this gap,ToM capabilities must be incorporated into AI agents by modeling core mental states such as Belief, Desire, and Intention (BDI). Building on BDI as a structured foundation for representing human cognition, ToM-Act is proposed as a framework to enhance agent decision-making and action-taking through ToM-informed reasoning. This motivation stems from the increasing deployment of AI agents, highlighting the need for methods that optimize their decision-making.",
        "doi": "10.1145/3726302.3730127",
        "sheridan_id": "dc2604",
        "position": 3,
        "track_id": 11,
        "slot_id": 45
      }
    },
    {
      "paper": {
        "hashed_id": "6403675579f6114559c90de0014cd3d6",
        "title": "Conversational Search: Towards Personalization and Evaluation",
        "abstract": "Conversational information seeking (CIS) systems aim to understand a user`s evolving information needs in the context of a conversation and respond effectively. These systems are especially valuable for users who may struggle with traditional interfaces, offering a more natural and accessible mode of interaction. To ensure the groundedness and accuracy of responses, existing methods break the task into several subtasks, namely, dialogue context modeling, retrieval, and answer generation. The user`s information need is often represented by either a single rewritten query or a single representation in the query embedding space. This leads to several limitations, especially in cases where the information need cannot be answered using a single passage and requires complex reasoning over multiple facts from different sources. We address this limitation by proposing the MQ4CS model, which breaks the information need of the user into multiple queries with different aspects. In MQ4CS, the retrieval is done for each query and rank list fusion is done over the list of documents retrieved for each query.  Evaluation of responses generated by Retrieval Augmented Generation (RAG) systems remains an open problem. The quality of the response is mainly assessed using surface-based QA metrics, human evaluation, or instructing the Large Language Models (LLMs). Since RAG-generated responses integrate both retrieved documents and the LLMs`s internal knowledge, traditional surface-based QA metrics are not effective for assessment. Furthermore, existing RAG benchmarks address more complex information needs compared to ad-hoc retrieval and QA, highlighting the necessity of measuring the completeness of generated responses. To better evaluate completeness and correctness, we propose a nugget-based evaluation pipeline called CONE-RAG that measures the precision and recall of key information nuggets in generated answers.  Personalization is an emerging key challenge in Conversational Search (CS). A personalized CS system must adapt its response based on the user`s personal information and search history. Given the same user question, the response of a personalized CS system must be different for different users. To facilitate the research on the development and evaluation of personalized CS systems, I have co-organized the iKAT track at TREC, where we released the iKAT 2023 and 2024 datasets.",
        "doi": "10.1145/3726302.3730126",
        "sheridan_id": "dc2602",
        "position": 2,
        "track_id": 11,
        "slot_id": 48
      }
    },
    {
      "paper": {
        "hashed_id": "577fd60255d4bb0f466464849ffe6d8e",
        "title": "R^2LLMs: Retrieval and Ranking with LLMs",
        "abstract": "Generative Large Language Models (LLMs) like GPT, Gemini, and Llama are transforming Information Retrieval, enabling new and more effective approaches to document retrieval and ranking. The switch from the previous generation pre-trained language models backbones (e.g., BERT, T5) to the new generative LLMs backbones has required the field to adapt training processes; it also has provided unprecedented capabilities and opportunities, stimulating research into zero-shot approaches, reasoning approaches, reinforcement learning based training, and multilingual and multimodal applications. This tutorial will provide a structured overview of LLM-based retrievers and rankers, covering fundamental architectures, training paradigms, real-world deployment considerations, and open challenges and research directions.",
        "doi": "10.1145/3726302.3731689",
        "sheridan_id": "tut2689",
        "position": 0,
        "track_id": 14,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "0747b9be4f90056c30eb5241f06bfe9b",
        "title": "Content Moderation in TV Search: Balancing Policy Compliance, Relevance, and User Experience",
        "abstract": "Millions of people rely on search functionality to find and explore content on entertainment platforms. Modern search systems use a combination of candidate generation and ranking approaches, with advanced methods leveraging deep learning and LLM-based techniques to retrieve, generate, and categorize search results. Despite these advancements, search algorithms can still surface inappropriate or irrelevant content due to factors like model unpredictability, metadata errors, or overlooked design flaws. Such issues can misalign with product goals and user expectations, potentially harming user trust and business outcomes. In this work, we introduce an additional monitoring layer using Large Language Models (LLMs) to enhance content moderation. This additional layer flags content if the user did not intend to search for it. This approach serves as a baseline for product quality assurance, with collected feedback used to refine the initial retrieval mechanisms of the search model, ensuring a safer and more reliable user experience.",
        "doi": "10.1145/3726302.3731962",
        "sheridan_id": "sir2535",
        "position": 3,
        "track_id": 12,
        "slot_id": 181
      }
    },
    {
      "paper": {
        "hashed_id": "70c445ee64b1ed0583367a12a79a9ef2",
        "title": "IRA: Adaptive Interest-aware Representation and Alignment for Personalized Multi-interest Retrieval",
        "abstract": "Online community platforms require dynamic personalized retrieval and recommendation that can continuously adapt to evolving user interests and new documents. However, optimizing models to handle such changes in real-time remains a major challenge in large-scale industrial settings. To address this, we propose the Interest-aware Representation and Alignment (IRA) framework, an efficient and scalable approach that dynamically adapts to new interactions through a cumulative structure. IRA leverages two key mechanisms: (1) Interest Units that capture diverse user interests as contextual texts, while reinforcing or fading over time through cumulative updates, and (2) a retrieval process that measures the relevance between Interest Units and documents based solely on semantic relationships, eliminating dependence on click signals to mitigate temporal biases. By integrating cumulative Interest Unit updates with the retrieval process, IRA continuously adapts to evolving user preferences, ensuring robust and fine-grained personalization without being constrained by past training distributions. We validate the effectiveness of IRA through extensive experiments on real-world datasets, including its deployment in the Home Section of NAVER`s CAFE, South Korea`s leading community platform.",
        "doi": "10.1145/3726302.3731943",
        "sheridan_id": "sir2464",
        "position": 3,
        "track_id": 12,
        "slot_id": 182
      }
    },
    {
      "paper": {
        "hashed_id": "4f398cb9d6bc79ae567298335b51ba8a",
        "title": "A Reproducibility Study of Graph-Based Legal Case Retrieval",
        "abstract": "Legal retrieval is a widely studied area in Information Retrieval (IR) and a key task in this domain is retrieving relevant cases based on a given query case, often done by applying language models as encoders to model case similarity. Recently, Tang et al. proposed CaseLink, a novel graph-based method for legal case retrieval, which models both cases and legal charges as nodes in a network, with edges representing relationships such as references and shared semantics. This approach offers a new perspective on the task by capturing higher-order relationships of cases going beyond the stand-alone level of documents. However, while this shift in approaching legal case retrieval is a promising direction in an understudied area of graph-based legal IR, challenges in reproducing novel results have recently been highlighted, with multiple studies reporting difficulties in reproducing previous findings. Thus, in this work we reproduce CaseLink, a graph-based legal case retrieval method, to support future research in this area of IR. In particular, we aim to assess its reliability and generalizability by (i) first reproducing the original study setup and (ii) applying the approach to an additional dataset. We then build upon the original implementations by (iii) evaluating the approach`s performance when using a more sophisticated graph data representation and (iv) using an open large language model (LLM) in the pipeline to address limitations that are known to result from using closed models accessed via an API. Our findings aim to improve the understanding of graph-based approaches in legal IR and contribute to improving reproducibility in the field. To achieve this, we share all our implementations and experimental artifacts with the community.",
        "doi": "10.1145/3726302.3730282",
        "sheridan_id": "rr1664",
        "position": 1,
        "track_id": 6,
        "slot_id": 177
      }
    },
    {
      "paper": {
        "hashed_id": "11c484ea9305ea4c7bb6b2e6d570d466",
        "title": "Benchmark Granularity and Model Robustness for Image-Text Retrieval: A Reproducibility Study",
        "abstract": "Image-Text Retrieval (ITR) systems are central to multimodal information access, with Vision-Language Models (VLMs) showing strong performance on standard benchmarks. However, these benchmarks predominantly rely on coarse-grained annotations, limiting their ability to reveal how models would perform under real-world conditions, where query granularity varies.  Motivated by this gap, we examine how dataset granularity and query perturbations affect retrieval performance and robustness across four architecturally diverse VLMs (ALIGN, AltCLIP, CLIP, and GroupViT).  Using both standard benchmarks (MS-COCO, Flickr30k) and their fine-grained variants, we show that richer captions consistently enhance retrieval, especially in text-to-image tasks, where we observe an average improvement of 16.23%, compared to 6.44% in image-to-text.  To assess robustness, we introduce a taxonomy of perturbations and conduct extensive experiments, revealing that while perturbations typically degrade performance, they can also unexpectedly improve retrieval, exposing nuanced model behaviors. Notably, word order emerges as a critical factor -- contradicting prior assumptions of model insensitivity to it.  Our results highlight variation in model robustness and a dataset-dependent relationship between caption granularity and perturbation sensitivity and emphasize the necessity of evaluating models on datasets of varying granularity.",
        "doi": "10.1145/3726302.3730290",
        "sheridan_id": "rr1752",
        "position": 2,
        "track_id": 6,
        "slot_id": 177
      }
    },
    {
      "paper": {
        "hashed_id": "e45823afe1e5120cec11fc4c379a0c67",
        "title": "Assessing Effective Token Length of Multimodal Models for Text-to-Image Retrieval",
        "abstract": "Multimodal embedding models have been widely adopted in text-to-image retrieval, enabling direct comparison between text and image modalities. However, how well they handle long text is poorly understood. For instance, Long-CLIP found that OpenAI`s CLIP model, despite having a 77-token input limit, maintains optimal performance for only 20 tokens- its effective token length. In this paper, we build on the Long-CLIP study, and extend the analysis to other widely used multimodal models and find their effective token length. Unlike Long-CLIP, we examine how domain-specific language influences changes in effective token length and explore its implications on different domains. Based on our findings, we create a comprehensive reference of various models` effective token length across different domains; offering deeper insights into the true limitations of multimodal models used in text-to-image retrieval. Finally, we introduce a systematic benchmark that determines the effective token length of any multimodal model using a given dataset. Our results show that the effective token length is consistently lower than the input token limit for all models, meaning that these models cannot utilize all the text that can be given to them. We also find that the effective token length varies by dataset, with domain-specific language influencing how much text a model can use before retrieval performance plateaus. Our code is available for reproducibility at https://github.com/aiforsec/EffectiveTokenLength-MModels",
        "doi": "10.1145/3726302.3730326",
        "sheridan_id": "rr2201",
        "position": 4,
        "track_id": 5,
        "slot_id": 177
      }
    },
    {
      "paper": {
        "hashed_id": "299570476c6f0309545110c592b6a63b",
        "title": "Refined Medical Search via Dense Retrieval and User Interaction",
        "abstract": "Users formulate search queries that reflect an information need. Those queries are then submitted to a search service in the expectation that the retrieved results will allow the user to complete an external task, and align with their broader information context.  In this study, we reimplement and reproduce the log-augmented dense retrieval approach introduced by Jin, Shin, and Lu in 2023. As part of our study we extend the experimentation by: (1) using all of the available training data rather than a subset; (2) exploring a second dense retrieval model; and (3) enhancing the approach by incorporating user reformulation behavior into the dense retrieval computation so as to improve ranking effectiveness. To evaluate these modifications, we again utilize the TripClick IR benchmark, which comprises approximately four million click log entries from a health domain web search engine.  Although we were unable to exactly replicate the results of Jin, Shin, and Lu, our findings confirm the overall trends reported in their study. Specifically, our results support the conclusion that incorporating user interactions into dense retrieval models improves ranking effectiveness compared to when no user information is available. Moreover, our enhanced formulation allows further small gains to be made in retrieval effectiveness.",
        "doi": "10.1145/3726302.3730292",
        "sheridan_id": "rr1772",
        "position": 5,
        "track_id": 6,
        "slot_id": 177
      }
    },
    {
      "paper": {
        "hashed_id": "e9412ee564384b987d086df32d4ce6b7",
        "title": "Post-event Modeling via Causal Optimal Transport for CTR Prediction",
        "abstract": "Accurate click-through rate (CTR) prediction is critical for online advertising, relying on regular features like browsing history and demographics and post-event features such as exposed position and detailed page behaviors. However, post-event features, unavailable during inference, often face training-inference inconsistency and low coverage issues, especially post-click features like dwell time that are available only for clicked items. To address these challenges, we propose Causal Optimal Transport (COT), a novel framework that (1) generates pseudo post-click features via semi-supervised pseudo-labeling, (2) causally generates accurate feature distributions using a Causal Distribution Shaper (CDS), and (3) refines generated features through optimal transport to minimize distributional divergence, facilitating further knowledge transfer. Experiments on real-world data confirm COT`s superiority and practical efficacy in enhancing CTR prediction via improved user interest modeling and bias mitigation. Theoretical guarantees underpin the framework`s robustness.",
        "doi": "10.1145/3726302.3731942",
        "sheridan_id": "sir2460",
        "position": 4,
        "track_id": 12,
        "slot_id": 180
      }
    },
    {
      "paper": {
        "hashed_id": "9457fc28ceb408103e13533e4a5b6bd1",
        "title": "Data-efficient Meta-models for Evaluation of Context-based Questions and Answers in LLMs",
        "abstract": "Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems are increasingly deployed in industry applications, yet their reliability remains hampered by challenges in detecting hallucinations. While supervised state-of-the-art (SOTA) methods that leverage LLM hidden states\u2014such as activation tracing and representation analysis\u2014show promise, their dependence on extensively annotated datasets limits scalability in real-world applications. This paper addresses the critical bottleneck of data annotation by investigating the feasibility of reducing training data requirements for two SOTA hallucination detection frameworks: Lookback Lens, which analyzes attention head dynamics, and probing-based approaches, which decode internal model representations. We propose a methodology combining efficient classification algorithms with dimensionality reduction techniques to minimize sample size demands while maintaining competitive performance. Evaluations on standardized question-answering RAG benchmarks show that our approach achieves performance comparable to strong proprietary LLM-based baselines with only 250 training samples. These results highlight the potential of lightweight, data-efficient paradigms for industrial deployment, particularly in annotation-constrained scenarios.",
        "doi": "10.1145/3726302.3731969",
        "sheridan_id": "sir2578",
        "position": 1,
        "track_id": 12,
        "slot_id": 179
      }
    },
    {
      "paper": {
        "hashed_id": "8c59fd6fbe0e9793ec2b27971221cace",
        "title": "Large Scale Deployment of BERT Based Cross Encoder Model for Re-Ranking in Walmart Search Engine",
        "abstract": "Re-ranking plays a crucial role in product search by reassessing products from the primary retrieval system based on specific engagement and relevance criteria. While transformer-based models like the cross encoder have advanced the relevance of ranking models in recent years, a significant challenge arises from the high latency cost associated with running a cross encoder model at runtime. This challenge becomes more pronounced in the long-tail segment, where conventional techniques like caching prove ineffective. To tackle these issues, our paper introduces a scalable framework featuring a BERT-based cross encoder model for re-ranking, deployed in the Walmart search engine. We employ strategies such as intermediate representations, operator fusion, and vectorization to improve the inference latency of the cross encoder model. Furthermore, we provide a detailed discussion on the runtime implementation, highlighting key learnings and practical tricks that ensured minimal impact on response latency during production. Finally, we present the results of online experiments, including manual evaluation and interleaving test conducted on real-world e-commerce search traffic.",
        "doi": "10.1145/3726302.3731965",
        "sheridan_id": "sir2554",
        "position": 2,
        "track_id": 12,
        "slot_id": 179
      }
    },
    {
      "paper": {
        "hashed_id": "82ca5dd156cc926b2992f73c2896f761",
        "title": "Towards Improving Image Quality in Second-Hand Marketplaces with LLMs",
        "abstract": "The quality of image products in second-hand marketplaces is a critical factor as it can significantly impact a buyer`s decision-making process as well as overall user trust. Inspired by the successful application of LLM capabilities as text-based task evaluators, we propose an approach that leverages multi-modal large language models (MLLMs) as evaluators of image quality. In this work, we conduct a systematic comparison of several state-of-the-art MLLMs, evaluating the alignment between the scores generated by these models and the human scores collected from a survey of 929 users in a second-hand marketplace. Our findings demonstrate that some of the evaluated MLLMs can achieve a high level of agreement with human judgments. To further understand the differences between LLM-based and human scores, we also present an analysis of the alignment between explanations generated by LLMs and those provided by humans. Overall, we believe our findings underscore the potential of LLMs for automatic image quality assessment.",
        "doi": "10.1145/3726302.3731960",
        "sheridan_id": "sir2529",
        "position": 3,
        "track_id": 12,
        "slot_id": 179
      }
    },
    {
      "paper": {
        "hashed_id": "6b5754d737784b51ec5075c0dc437bf0",
        "title": "GRAIN: Group-Reinforced Adaptive Interaction Network for Cold-Start CTR Prediction in E-commerce Search",
        "abstract": "Accurate prediction of click-through rates (CTR) for cold-start entities (CSEs) within search engine ecosystems presents significant challenges. Notably, CSEs encompass novel users/items and new session search queries, each characterized by their limited interaction data and poor-quality embeddings, which collectively contribute to the complexity of CTR estimation.Existing studies predominantly address cold-start challenges in isolation, such as focusing separately on new users or new items, and lack a comprehensive framework to effectively integrate atomic ID features with group-level representations. To address these limitations, we propose GRAIN (Group Reinforced Adaptive Interaction Network), a novel framework that enhances CTR prediction across all maturity phases, namely Cold-Start, Warm-Up, and Common. GRAIN consists of three key components: 1) a Graph-based Id-to-Cluster (GIC) module that aggregates atomic ID features into cluster-level representations; 2) an ID-Cluster Cross (ICC) module that aligns ID-level and cluster-level features through contrastive learning and cross-grained interaction mechanism; 3) a lightweight auxiliary task that classifies entities into different maturity stages using a data-driven phase partitioning algorithm.Extensive experiments demonstrate GRAIN`s effectiveness in improving CTR prediction accuracy across multiple maturity phases. GRAIN has been successfully deployed on the 1688 App, handling billions of daily requests.",
        "doi": "10.1145/3726302.3731947",
        "sheridan_id": "sir2481",
        "position": 2,
        "track_id": 12,
        "slot_id": 180
      }
    },
    {
      "paper": {
        "hashed_id": "d9ff90f4000eacd3a6c9cb27f78994cf",
        "title": "ADORE: Autonomous Domain-Oriented Relevance Engine for E-commerce",
        "abstract": "Relevance modeling in e-commerce search remains challenged by semantic gaps in term-matching methods (e.g., BM25) and neural models` reliance on the scarcity of domain-specific hard samples. We propose ADORE, a self-sustaining framework that synergizes three innovations: (1) A Rule-aware Relevance Discrimination module, where a Chain-of-Thought LLM generates intent-aligned training data, refined via Kahneman-Tversky Optimization (KTO) to align with user behavior; (2) An Error-type-aware Data Synthesis module that auto-generates adversarial examples to harden robustness; and (3) A Key-attribute-enhanced Knowledge Distillation module that injects domain-specific attribute hierarchies into a deployable student model. ADORE automates annotation, adversarial generation, and distillation, overcoming data scarcity while enhancing reasoning. Large-scale experiments and online A/B testing verify the effectiveness of ADORE. The framework establishes a new paradigm for resource-efficient, cognitively aligned relevance modeling in industrial applications.",
        "doi": "10.1145/3726302.3731944",
        "sheridan_id": "sir2471",
        "position": 3,
        "track_id": 12,
        "slot_id": 180
      }
    },
    {
      "paper": {
        "hashed_id": "30aaf34d6afd4b11cc3b3ac4704c7908",
        "title": "Language Model Alignment for Conversational Shopping at Amazon",
        "abstract": "The rapid growth of online shopping stores, such as Amazon, has led to services reaching billions of people worldwide. With global retail sales exceeding $6 trillion in 2024, customer expectations for personalized and seamless shopping experiences have heightened. Traditional online shopping experiences, such as search and navigation systems, often fall short in addressing complex shopping journeys. Conversational shopping (such as Amazon Rufus) offers a transformative approach by enabling dynamic, multi-turn dialogues that closely resemble human interactions. This allows customers to explore product options, seek clarifications, and receive personalized recommendations, thereby enhancing product discovery and informed decision-making. In this paper, we share our year-long journey of using language models for conversational shopping at Amazon and introduce how we use LLM fine-tuning techniques to enhance LLMs for a conversational shopping experience like Amazon Rufus. We also introduce innovative strategies for training data collection and demonstrate real-world applications, including product recommendations, clarification mechanisms, and internationalization for global customers.",
        "doi": "10.1145/3726302.3731955",
        "sheridan_id": "sir2508",
        "position": 4,
        "track_id": 12,
        "slot_id": 181
      }
    },
    {
      "paper": {
        "hashed_id": "9e984c108157cea74c894b5cf34efc44",
        "title": "A Generative Re-ranking Model for List-level Multi-objective Optimization at Taobao",
        "abstract": "E-commerce recommendation systems aim to generate ordered lists of items for customers, optimizing multiple business objectives, such as clicks, conversions and Gross Merchandise Volume (GMV). Traditional multi-objective optimization methods like formulas or Learning-to-rank (LTR) models take effect at item-level, neglecting dynamic user intent and contextual item interactions. List-level multi-objective optimization in the re-ranking stage can overcome this limitation, but most current re-ranking models focus more on accuracy improvement with context. In addition, re-ranking is faced with the challenges of time complexity and diversity. In light of this, we propose a novel end-to-end generative re-ranking model named Sequential Ordered Regression Transformer-Generator (SORT-Gen) for the less-studied list-level multi-objective optimization problem. Specifically, SORT-Gen is divided into two parts: 1)Sequential Ordered Regression Transformer innovatively uses Transformer and ordered regression to accurately estimate multi-objective values for variable-length sub-lists. 2)Mask-Driven Fast Generation Algorithm combines multi-objective candidate queues, efficient item selection and diversity mechanism into model inference, providing a fast online list generation method. Comprehensive online experiments demonstrate that SORT-Gen brings +4.13% CLCK and +8.10% GMV for Baiyibutie, a notable Mini-app of Taobao. Currently, SORT-Gen has been successfully deployed in multiple scenarios of Taobao App, serving for a vast number of users.",
        "doi": "10.1145/3726302.3731935",
        "sheridan_id": "sir1600",
        "position": 4,
        "track_id": 12,
        "slot_id": 184
      }
    },
    {
      "paper": {
        "hashed_id": "9ed9328611fe3f45b3cce8ffe386ee97",
        "title": "Adaptive Domain Scaling for Personalized Sequential Modeling in Recommenders",
        "abstract": "Users generally exhibit complex behavioral patterns and diverse intentions in multiple business scenarios of super APPs, presenting great challenges to industrial multi-domain recommenders. Current researches and practices generally emphasize sophisticated network structures to accommodate diverse data distributions, while neglecting the inherent understanding of user behavioral sequence from the multi-domain perspective. In this paper, we present Adaptive Domain Scaling (ADS) model, which comprehensively enhances the personalization capability in target-aware sequence modeling across multiple domains. Specifically, ADS comprises of two major modules, including personalized sequence representation generation (PSRG) and personalized candidate representation generation (PCRG). The modules contribute to the tailored multi-domain modeling by dynamically learning both the user interacted item representation and the candidate target item representation, facilitating adaptive user intention understanding. Experiments on both a public and two billion-scaled industrial datasets, and online A/B tests on two influential business scenarios at ByteDance validate its effectiveness. Currently, ADS has been fully deployed in dozens of recommendation services at ByteDance, serving billions of users.",
        "doi": "10.1145/3726302.3731939",
        "sheridan_id": "sir2445",
        "position": 4,
        "track_id": 12,
        "slot_id": 182
      }
    },
    {
      "paper": {
        "hashed_id": "d9fc0cdb67638d50f411432d0d41d0ba",
        "title": "Multi-objective Aligned Bidword Generation Model for E-commerce Search Advertising",
        "abstract": "The retrieval system is a crucial module in e-commerce search advertising that matches user queries with ads. The diverse expressions of users often produce massive tail queries that cannot match merchant bidwords, leading to poor retrieval efficiency. Existing methods, such as query log mining and vector matching, fail to optimize relevance, authenticity, and ad revenue of the rewrite.In this paper, we propose a novel Multi-objective aligned Bidword Generation Model (MoBGM), which includes a discriminator, generator, and preference alignment module. To simultaneously improve the relevance and authenticity of the query and rewrite and maximize the platform revenue, we design a discriminator to predict these scores for each query and rewrite pair. Using the feedback signal of the discriminator, we train a multi-objective aligned bidword generator to maximize the combined effect of the three objectives. Extensive offline and online experiments show that our proposed algorithm significantly outperforms the state of the art. After deployment, the algorithm created huge commercial value for the platform, verifying its feasibility and robustness.",
        "doi": "10.1145/3726302.3731952",
        "sheridan_id": "sir2497",
        "position": 2,
        "track_id": 12,
        "slot_id": 183
      }
    },
    {
      "paper": {
        "hashed_id": "7989edad14ebcd3adfacc7344dc6b739",
        "title": "SuperRS: Multi Scenario Reciprocal-Aware Dual MoE for Unified Recommendation-Search Ranking",
        "abstract": "In e-commerce, search and recommendation rankings require a deep understanding of user behaviors and personalized scoring of products. While existing systems maintain separate pipelines for search and recommendation, these two scenarios share aligned objectives and exhibit consistent data patterns during ranking. To address this, we propose a joint modeling approach for search-recommendation ranking that enables information gain exchange between the two scenarios, thus facilitating enhanced modeling of users` cross-scenario behaviors. Our proposed SuperRS framework employs a Dual-layer Multi-MoE (DualMoE) architecture to tackle scenario-specific disparities and achieve multi-interest fusion perception. A key aspect is the Search-Recommendation Sequence Fusion Unit, which integrates user interaction sequences from both scenarios. Additionally, we introduce a unified Representation Extraction method utilizing Reciprocal Scenario Interest Attention (RSIA) for feature alignment. Dynamic Feature Integration (DFI) employs a dual gating mechanism for controlled information fusion while preserving scenario identities, combined with multi-objective optimization. On the 1688 App, our framework demonstrates superior performance to baseline models across both offline evaluation metrics and online business indicators.",
        "doi": "10.1145/3726302.3731949",
        "sheridan_id": "sir2488",
        "position": 2,
        "track_id": 12,
        "slot_id": 184
      }
    },
    {
      "paper": {
        "hashed_id": "ff1418e8cc993fe8abcfe3ce2003e5c5",
        "title": "RecGaze: The First Eye Tracking and User Interaction Dataset for Carousel Interfaces",
        "abstract": "Carousel interfaces are widely used in e-commerce and streaming services, but little research has been devoted to them. Previous studies of interfaces for presenting search and recommendation results have focused on single ranked lists, but it appears their results cannot be extrapolated to carousels due to the added complexity. Eye tracking is a highly informative approach to understanding how users click, yet there are no eye tracking studies concerning carousels. There are very few interaction datasets on recommenders with carousel interfaces and none that contain gaze data.We introduce the RecGaze dataset: the first comprehensive feedback dataset on carousels that includes eye tracking results, clicks, cursor movements, and selection explanations. The dataset comprises of interactions from 3 movie selection tasks with 40 different carousel interfaces per user. In total, 87 users and 3,477 interactions are logged. In addition to the dataset, its description and possible use cases, we provide results of a survey on carousel design and the first analysis of gaze data on carousels, which reveals a golden triangle or F-pattern browsing behavior.Our work seeks to advance the field of carousel interfaces by providing the first dataset with eye tracking results on carousels. In this manner, we provide and encourage an empirical understanding of interactions with carousel interfaces, for building better recommender systems through gaze information, and also encourage the development of gaze-based recommenders.",
        "doi": "10.1145/3726302.3730301",
        "sheridan_id": "rr1851",
        "position": 59,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "effc299a1addb07e7089f9b269c31f2f",
        "title": "Class Activation Values: Lucid and Faithful Visual Interpretations for CLIP-based Text-Image Retrievals",
        "abstract": "Transformer-based text-image matching model, known as CLIP, has garnered significant attention owing to its exceptional performance in text-image retrieval tasks and downstream applications. However, the interpret-ability of CLIP remains underexplored. Existing interpretation methods for Transformers often struggle with incomplete and unreliable attributions within the image and text modalities, respectively. In this paper, we propose a fine-grained interpretation method, termed Class Activation Values (CAV), to provide lucid and faithful visual explanations for CLIP-based text-image retrievals. Specifically, we systematically perform multi-scale accumulation and fusion of class-specific gradients and activation value features to generate high-definition explanations for the image encoder. Furthermore, we present element-wise gradient-based weights to attribute fine-grained relevance between value features and output similarity within the text encoder. The proposed CAV is capable of simultaneously rendering detailed and credible explanations due to its precise feature attribution. Extensive qualitative and quantitative experiments are conducted on the ImageNet-1k and MS COCO datasets, and the experimental results demonstrate that CAV outperforms state-of-the-art interpretation methods in both faithfulness and localization assessments across image and text modalities.",
        "doi": "10.1145/3726302.3729923",
        "sheridan_id": "fp1364",
        "position": 6,
        "track_id": 1,
        "slot_id": 18
      }
    },
    {
      "paper": {
        "hashed_id": "a29d1598024f9e87beab4b98411d48ce",
        "title": "DataRec: A Python Library for Standardized and Reproducible Data Management in Recommender Systems",
        "abstract": "Recommender systems have demonstrated a significant impact across diverse domains, yet ensuring the reproducibility of experimental findings remains a persistent challenge. A primary obstacle lies in the fragmented and often opaque data management strategies employed during the preprocessing stage, where decisions about dataset selection, filtering, and splitting can substantially influence outcomes. To address these limitations, we introduce DataRec, an open-source Python-based library specifically designed to unify and streamline data handling in recommender system research. By providing reproducible routines for dataset preparation, data versioning, and seamless integration with other frameworks, DataRec promotes methodological standardization, interoperability, and comparability across different experimental setups. Our design is informed by an in-depth review of 55 state-of-the-art recommendation studies, ensuring that DataRec adopts best practices while addressing common pitfalls in data management. Ultimately, our contribution facilitates fair benchmarking, enhances reproducibility, and fosters greater trust in experimental results within the broader recommender systems community. The DataRec library, documentation, and examples are freely available at https://github.com/sisinflab/DataRec.",
        "doi": "10.1145/3726302.3730320",
        "sheridan_id": "rr2112",
        "position": 60,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "2451041557a22145b3701b0184109cab",
        "title": "PILs of Knowledge: A Synthetic Benchmark for Evaluating Question Answering Systems in Healthcare",
        "abstract": "Patient Information Leaflets (PILs) provide essential information about medication usage, side effects, precautions, and interactions, making them a valuable resource for Question Answering (QA) systems in healthcare. However, no dedicated benchmark currently exists to evaluate QA systems specifically on PILs, limiting progress in this domain. To address this gap, we introduce a fact-supported synthetic benchmark composed of multiple-choice questions and answers generated from real PILs.We construct the benchmark using a fully automated pipeline that leverages multiple Large Language Models (LLMs) to generate diverse, realistic, and contextually relevant question-answer pairs. The benchmark is publicly released as a standardized evaluation framework for assessing the ability of LLMs to process and reason over PIL content. To validate its effectiveness, we conduct an initial evaluation with state-of-the-art LLMs, showing that the benchmark presents a realistic and challenging task, making it a valuable resource for advancing QA research in the healthcare domain.",
        "doi": "10.1145/3726302.3730283",
        "sheridan_id": "rr1672",
        "position": 61,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "01a0683665f38d8e5e567b3b15ca98bf",
        "title": "MAAQR: An LLM-based Multi-Agent Framework for Adaptive Query Rewriting in Alipay Search",
        "abstract": "Query rewriting is essential in e-commerce search, as it bridges the lexical gap between user queries and item descriptions, thereby enhancing search performance. Despite recent advancements, current rewriting approaches are still limited by an inadequate comprehension of domain-specific knowledge and a lack of mechanisms for adaptive refinement in response to new or changing query-item relationships. To overcome these limitations, we propose a large language model (LLM) based Multi-Agent Framework for Adaptive Query Rewriting (MAAQR) in Alipay Search. Initially, we perform knowledge-enhanced fine-tuning to improve the LLM\u2019s understanding of query and item semantics. Subsequently, a multi-agent collaborative rewriting architecture is employed to enhance rewrite quality and adaptability. MAAQR has been successfully deployed to serve Alipay`s mini-app search since December 2024. Through offline experiments and online A/B testing, MAAQR significantly improves click-through rates (CTR) and the number of transactions for target queries, while substantially reducing the zero-results rate (ZRR).",
        "doi": "10.1145/3726302.3731950",
        "sheridan_id": "sir2491",
        "position": 3,
        "track_id": 12,
        "slot_id": 185
      }
    },
    {
      "paper": {
        "hashed_id": "831caa1b600f852b7844499430ecac17",
        "title": "Optimize Visual Shopping Journey with Embedding-based Retrieval in Pinterest Closeup",
        "abstract": "Pinterest is the visual discovery platform where people find inspiration, curate ideas, and shop products for all life`s moments. An intentful journey can start when Pinners (users) click on Pins and arrive at the Closeup surface, where they can continue to explore or refine their intent by browsing related content powered by our visual search and related recommendation engines. Product Pins, or contents that are linked to merchants and are buyable in general, are critical to realizable fulfillment in Pinners\u2019 exploratory journey. This paper focuses on optimizing embedding-based retrieval (EBR) to retrieve relevant and personalized product Pins to drive actionable engagement. In contrast to conventional EBR systems, we introduce complementary Shopping Priority Corpora that are prepared by probability models from a dynamic inventory with billions of candidates and highly skewed distributions. This novel design enabled us to significantly improve the retrieval efficiency, scale up the systems, and meet different business requirements. On top of that, we build retrieval models that infuse multimodal information with multi-task contrastive learning to balance relevance and engagement. We evaluate the EBR system on random off-policy traffic with thorough baseline comparisons and rigorous online A/B experiments. This work leads to significant metric gains in our production systems and provides practical lessons on improving early retrieval for multiple business objectives at large scales.",
        "doi": "10.1145/3726302.3731958",
        "sheridan_id": "sir2512",
        "position": 1,
        "track_id": 12,
        "slot_id": 187
      }
    },
    {
      "paper": {
        "hashed_id": "d860edd1dd83b36f02ce52bde626c653",
        "title": "LEMSS: LLM-Based Platform for Multi-Agent Competitive Search Simulation",
        "abstract": "In competitive search settings, document publishers (authors) respond to rankings induced for queries of interest: they modify the documents to improve their future ranking. Hence, for some queries there is an on-going ranking competition. Prior empirical studies of competitive search were based on controlled ranking competitions between humans. Large Language Models (LLMs), capable of generating high quality content, provide new opportunities for studying ranking competitions. Furthermore, there is a significant amount of content on the Web, which is a canonical example of a competitive search setting, generated by LLMs. In this paper, we introduce LEMSS: a multi-agent platform that leverages LLMs as publishers in competitive search settings. In addition to enabling the execution of large-scale and highly configurable ranking competitions, LEMSS includes tools to analyze and compare the competitions using a wide range of measures. We use these tools to analyze examples of datasets that result from ranking competitions executed using LEMSS. The analysis reveals, for example, that using LLMs as publishers reduced content diversity in the corpus to a larger extent than having human publishers.",
        "doi": "10.1145/3726302.3730312",
        "sheridan_id": "rr2028",
        "position": 66,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "eb1e78328c46506b46a4ac4a1e378b91",
        "title": "LUMA: A Benchmark Dataset for Learning from Uncertain and Multimodal Data",
        "abstract": "Multimodal Deep Learning enhances decision-making by integrating diverse information sources, such as texts, images, audio, and videos. To develop trustworthy multimodal approaches, it is essential to understand how uncertainty impacts these models. We propose LUMA, a unique multimodal dataset, featuring audio, image, and textual data from 50 classes, specifically designed for learning from uncertain data. It extends the well-known CIFAR 10/100 dataset with audio samples extracted from three audio corpora, and text data generated using the Gemma-7B Large Language Model (LLM). The LUMA dataset enables the controlled injection of varying types and degrees of uncertainty to achieve and tailor specific experiments and benchmarking initiatives. LUMA is also available as a Python package including the functions for generating multiple variants of the dataset with controlling the diversity of the data, the amount of noise for each modality, and adding out-of-distribution samples. A baseline pre-trained model is also provided alongside three uncertainty quantification methods: Monte-Carlo Dropout, Deep Ensemble, and Reliable Conflictive Multi-View Learning. This comprehensive dataset and its tools are intended to promote and support the development, evaluation, and benchmarking of trustworthy and robust multimodal deep learning approaches. We anticipate that the LUMA dataset will help the research community to design more trustworthy and robust machine learning approaches for safety critical applications. The code and instructions for downloading and processing the dataset can be found at: https://github.com/bezirganyan/LUMA.",
        "doi": "10.1145/3726302.3730302",
        "sheridan_id": "rr1852",
        "position": 70,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "f8b932c70d0b2e6bf071729a4fa68dfc",
        "title": "Retrieval-Augmented Image Captioning and Generation with Entity Concepts Enhancement for Baidu Multimodal Advertising",
        "abstract": "Recent advancements in generative artificial intelligence are driving a significant transformation in information retrieval and content generation, creating substantial opportunities for online advertising. Text-to-image generation technology has become increasingly prevalent in advertising content production, demonstrating promising performance improvements in terms of semantic relevance and visual appeal. However, existing models often suffer from inadequate representation of entity concepts, such as prominent product brands and recognizable landmarks. This inherent limitation subsequently leads to notable deficiencies in brand tonality, industry-specific relevance, and market adaptability of the generated advertising content. To address this challenge, we propose a multimodal ad content generation framework specifically engineered for online advertising system, particularly focused on resolving the deficiency in entity concepts. Our framework is comprised of two phases: first, an image captioning module with entity-aware learning based on multimodal large language model, leveraging retrieval-augmented techniques to incorporate entity concepts into image descriptions; second, a text-to-image diffusion model refined on image-text pairs enriched with entity concepts to facilitate entity-grounded image generation. Extensive experiments validate the effectiveness of our framework, demonstrating superior performance in both image captioning and image generation compared to existing methods, particularly in the accuracy of depiction of relevant entities in advertising images. Moreover, the deployment of the framework in the system primary traffic of Baidu Search Ads, has brought significant enhancements to advertisement revenue for both advertisers and the platform.",
        "doi": "10.1145/3726302.3731957",
        "sheridan_id": "sir2511",
        "position": 2,
        "track_id": 12,
        "slot_id": 187
      }
    },
    {
      "paper": {
        "hashed_id": "be6c7b094f88532b6c6b35bbcd525ee8",
        "title": "RankLLM: A Python Package for Reranking with LLMs",
        "abstract": "The adoption of large language models (LLMs) as rerankers in multi-stage retrieval systems has gained significant traction in academia and industry. These models refine a candidate list of retrieved documents, often through carefully designed prompts, and are typically used in applications built on retrieval-augmented generation (RAG). This paper introduces RankLLM, an open-source Python package for reranking that is modular, highly configurable, and supports both proprietary and open-source LLMs in customized reranking workflows. To improve usability, RankLLM features optional integration with Pyserini for retrieval and provides integrated evaluation for multi-stage pipelines. Additionally, RankLLM includes a module for detailed analysis of input prompts and LLM responses, addressing reliability concerns with LLM APIs and non-deterministic behavior in Mixture-of-Experts (MoE) models. This paper presents the architecture of RankLLM, along with a detailed step-by-step guide and sample code. We reproduce results from RankGPT, LRL, RankVicuna, RankZephyr, and other recent models. RankLLM integrates with common inference frameworks and a wide range of LLMs. This compatibility allows for quick reproduction of reported results, helping to speed up both research and real-world applications. The complete repository is available at \\url{rankllm.ai}, and the package can be installed via PyPI.",
        "doi": "10.1145/3726302.3730331",
        "sheridan_id": "rr2248",
        "position": 56,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "e0ab531ec312161511493b002f9be2ee",
        "title": "TIREx Tracker: The Information Retrieval Experiment Tracker",
        "abstract": "The reproducibility and transparency of retrieval experiments depends on the availability of information about the experimental setup. However, the manual collection of experiment metadata can be tedious, error-prone, and inconsistent, which calls for an automated systematic collection. Expanding ir_metadata, we present the TIREx tracker, a tool that records hardware configurations, power/CPU/RAM/GPU usage, and experiment/system versions. Implemented as a lightweight platform-independent C binary, the TIREx tracker integrates seamlessly into Python, Java, or C/C++ workflows and can be easily integrated into shard task submissions, as we demonstrate for the TIRA/TIREx platform. Code, binaries, and documentation of the TIREx tracker are publicly available at https://github.com/tira-io/tirex-tracker.",
        "doi": "10.1145/3726302.3730297",
        "sheridan_id": "rr1831",
        "position": 62,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "3a824154b16ed7dab899bf000b80eeee",
        "title": "U-Sticker: A Large-Scale Multi-Domain User Sticker Dataset for Retrieval and Personalization",
        "abstract": "Instant messaging with texts and stickers has become a widely adopted communication medium, enabling efficient expression of user semantics and emotions. With the increased use of stickers conveying information and feelings, sticker retrieval and recommendation has emerged as an important area of research. However, a major limitation in existing literature has been the lack of datasets capturing temporal and user-specific sticker interactions, which has hindered further progress in user modeling and sticker personalization. To address this, we introduce User-Sticker, a dataset that includes temporal and user anonymous ID across conversations. It is the largest publicly available sticker dataset to date, containing 22K unique users, 370K stickers, and 8.3M messages. The raw data was collected from a popular messaging platform from 67 conversations over 720 hours of crawling. All text and image data were carefully vetted for safety and privacy checks and modifications. Spanning 10 domains, the U-Sticker dataset captures rich temporal, multilingual, and cross-domain behaviors not previously available in other datasets. Extensive quantitative and qualitative experiments demonstrate U-Sticker\u2019s practical applications in user behavior modeling and personalized recommendation and highlight its potential to further research areas in personalized retrieval and conversational studies. U-Sticker dataset is publicly available.",
        "doi": "10.1145/3726302.3730311",
        "sheridan_id": "rr2022",
        "position": 100,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "01931a6925d3de09e5f87419d9d55055",
        "title": "SynthTRIPs: A Knowledge-Grounded Framework for Benchmark Data Generation for Personalized Tourism Recommenders",
        "abstract": "Tourism Recommender Systems (TRS) are crucial in personalizing travel experiences by tailoring recommendations to users` preferences, constraints, and contextual factors. However, publicly available travel datasets often lack sufficient breadth and depth, limiting their ability to support advanced personalization strategies --- particularly for sustainable travel and off-peak tourism. In this work, we explore using Large Language Models (LLMs) to generate synthetic travel queries that emulate diverse user personas and incorporate structured filters such as budget constraints and sustainability preferences.    This paper introduces a novel SynthTRIPs framework for generating synthetic travel queries using LLMs grounded in a curated knowledge base (KB). Our approach combines persona-based preferences (e.g., budget, travel style) with explicit sustainability filters (e.g., walkability, air quality) to produce realistic and diverse queries. We mitigate hallucination and ensure factual correctness by grounding the LLM responses in the KB. We formalize the query generation process and introduce evaluation metrics for assessing realism and alignment. Both human expert evaluations and automatic LLM-based assessments demonstrate the effectiveness of our synthetic dataset in capturing complex personalization aspects underrepresented in existing datasets. While our framework was developed and tested for personalized city trip recommendations, the methodology applies to other recommender system domains.Code and dataset are made public at https://bit.ly/synthTRIPs",
        "doi": "10.1145/3726302.3730321",
        "sheridan_id": "rr2113",
        "position": 67,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "2612aa892d962d6f8056b195ca6e550d",
        "title": "OnSET: Ontology and Semantic Exploration Toolkit",
        "abstract": "Retrieval over knowledge graphs is typically performed using specialized, complex query languages such as SPARQL. We propose a novel system, Ontology and Semantic Exploration Toolkit (OnSET), that allows novice users to quickly build queries with visual user guidance provided by topic modeling and semantic search throughout the application. OnSET enables users without prior knowledge of the ontology or networked knowledge to start exploring topics of interest over knowledge graphs, including the retrieval and detailed exploration of prototypical sub-graphs and their instances. Existing systems either focus on direct graph exploration or do not foster further exploration of the result set. We, however, provide a node-based editor that can extend these missing properties of existing systems to support search over large ontologies with sub-graph instances. Furthermore, OnSET combines efficient and open platforms to deploy the system on commodity hardware.",
        "doi": "10.1145/3726302.3730148",
        "sheridan_id": "de1758",
        "position": 5,
        "track_id": 10,
        "slot_id": 104
      }
    },
    {
      "paper": {
        "hashed_id": "3e7e0224018ab3cf51abb96464d518cd",
        "title": "MRAMG-Bench: A Comprehensive Benchmark for Advancing Multimodal Retrieval-Augmented Multimodal Generation",
        "abstract": "Recent advances in Retrieval-Augmented Generation (RAG) have significantly improved response accuracy and relevance by incorporating external knowledge into Large Language Models (LLMs). However, existing RAG methods primarily focus on generating text-only answers, even in Multimodal Retrieval-Augmented Generation (MRAG) scenarios, where multimodal elements are retrieved to assist in generating text answers. To address this, we introduce the Multimodal Retrieval-Augmented Multimodal Generation (MRAMG) task, in which we aim to generate multimodal answers that combine both text and images, fully leveraging the multimodal data within a corpus. Despite growing attention to this challenging task, a notable lack of a comprehensive benchmark persists for effectively evaluating its performance. To bridge this gap, we provide MRAMG-Bench, a meticulously curated, human-annotated benchmark comprising 4,346 documents, 14,190 images, and 4,800 QA pairs, distributed across six distinct datasets and spanning three domains: Web, Academia, and Lifestyle. The datasets incorporate diverse difficulty levels and complex multi-image scenarios, providing a robust foundation for evaluating the MRAMG task. To facilitate rigorous evaluation, MRAMG-Bench incorporates a comprehensive suite of both statistical and LLM-based metrics, enabling a thorough analysis of the performance of generative models in the MRAMG task. Additionally, we propose an efficient and flexible multimodal answer generation framework that can leverage LLMs/MLLMs to generate multimodal responses. Our datasets and complete evaluation results for 11 popular generative models are available at https://github.com/MRAMG-Bench/MRAMG.",
        "doi": "10.1145/3726302.3730288",
        "sheridan_id": "rr1725",
        "position": 99,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "1c54985e4f95b7819ca0357c0cb9a09f",
        "title": "Characterising Topic Familiarity and Query Specificity Using Eye-Tracking Data",
        "abstract": "Eye-tracking data has been shown to correlate with a user`s knowledge level and query formulation behaviour. While previous work has focused primarily on eye gaze fixations for attention analysis, often requiring additional contextual information, our study investigates the memory-related cognitive dimension by relying solely on pupil dilation and gaze velocity to infer users` topic familiarity and query specificity without needing any contextual information. Using eye-tracking data collected via a lab user study N=18, we achieved a Macro F1 score of 71.25% for predicting topic familiarity with a Gradient Boosting classifier, and a Macro F1 score of 60.54% with a k-nearest neighbours (KNN) classifier for query specificity. Furthermore, we developed a novel annotation guideline -- specifically tailored for question answering -- to manually classify queries as Specific or Non-specific. This study demonstrates the feasibility of eye-tracking to better understand topic familiarity and query specificity in search.",
        "doi": "10.1145/3726302.3730174",
        "sheridan_id": "sp1636",
        "position": 10,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "136f951362dab62e64eb8e841183c2a9",
        "title": "MMMORRF: Multimodal Multilingual MOdularized Reciprocal Rank Fusion",
        "abstract": "Videos inherently contain multiple modalities, including visual events, text overlays, sounds, and speech, all of which are important for retrieval. However, state-of-the-art multimodal language models like VAST and LanguageBind are built on vision-language models (VLMs), and thus overly prioritize visual signals. Retrieval benchmarks further reinforce this bias by focusing on visual queries and neglecting other modalities. We create a search system MMMORRF that extracts text and features from both visual and audio modalities and integrates them with a novel modality-aware weighted reciprocal rank fusion. MMMORRF is both effective and efficient, demonstrating practicality in searching videos based on users` information needs instead of visual descriptive queries. We evaluate MMMORRF on MultiVENT 2.0 and TVR, two multimodal benchmarks designed for more targeted information needs, and find that it improves nDCG@20 by 81% over leading multimodal encoders and 37% over single-modality retrieval.",
        "doi": "10.1145/3726302.3730157",
        "sheridan_id": "de1937",
        "position": 10,
        "track_id": 10,
        "slot_id": 104
      }
    },
    {
      "paper": {
        "hashed_id": "44a2e0804995faf8d2e3b084a1e2db1d",
        "title": "Resource for Error Analysis in Text Simplification: New Taxonomy and Test Collection",
        "abstract": "The general public often encounters complex texts but does not have the time or expertise to fully understand them, leading to the spread of misinformation. Automatic Text Simplification (ATS) helps make information more accessible, but its evaluation methods have not kept up with advances in text generation, especially with Large Language Models (LLMs). In particular, recent studies have shown that current ATS metrics do not correlate with the presence of errors. Manual inspections have further revealed a variety of errors, underscoring the need for a more nuanced evaluation framework, which is currently lacking. This resource paper addresses this gap by introducing a test collection for detecting and classifying errors in simplified texts. First, we propose a taxonomy of errors, with a formal focus on information distortion. Next, we introduce a parallel dataset of automatically simplified scientific texts. This dataset has been human-annotated with labels based on our proposed taxonomy. Finally, we analyze the quality of the dataset, and we study the performance of existing models to detect and classify errors from that taxonomy. These contributions give researchers the tools to better evaluate errors in ATS, develop more reliable models, and ultimately improve the quality of automatically simplified texts.",
        "doi": "10.1145/3726302.3730304",
        "sheridan_id": "rr1879",
        "position": 116,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "12b1e42dc0746f22cf361267de07073f",
        "title": "Dynamic-KGQA: A Scalable Framework for Generating Adaptive Question Answering Datasets",
        "abstract": "As question answering (QA) systems advance alongside the rapid evolution of foundation models, the need for robust, adaptable, and large-scale evaluation benchmarks becomes increasingly critical. Traditional QA benchmarks are often static and publicly available, making them susceptible to data contamination and memorization by large language models (LLMs). Consequently, static benchmarks may overestimate model generalization and hinder a reliable assessment of real-world performance.In this work, we introduce Dynamic-KGQA}, a scalable framework for generating adaptive QA datasets from knowledge graphs (KGs), designed to mitigate memorization risks while maintaining statistical consistency across iterations. Unlike fixed benchmarks, Dynamic-KGQA} generates a new dataset variant on every run while preserving the underlying distribution, enabling fair and reproducible evaluations. Furthermore, our framework provides fine-grained control over dataset characteristics, supporting domain-specific and topic-focused QA dataset generation. Additionally, Dynamic-KGQA} produces compact, semantically coherent subgraphs that facilitate both training and evaluation of KGQA models, enhancing their ability to leverage structured knowledge effectively.To align with existing evaluation protocols, we also provide static large-scale train/test/validation splits, ensuring comparability with prior methods. By introducing a dynamic, customizable benchmarking paradigm, Dynamic-KGQA} enables a more rigorous and adaptable evaluation of QA systems.",
        "doi": "10.1145/3726302.3730324",
        "sheridan_id": "rr2179",
        "position": 117,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "7750ca3559e5b8e1f44210283368fc16",
        "title": "Exploring \u21130 Sparsification for Inference-free Sparse Retrievers",
        "abstract": "With increasing demands for efficiency, information retrieval has developed a branch of sparse retrieval, further advancing towards inference-free retrieval where the documents are encoded during indexing time and there is no model-inference for queries. Existing sparse retrieval models rely on FLOPS regularization for sparsification, while this mechanism was originally designed for Siamese encoders, it is considered to be suboptimal in inference-free scenarios which is asymmetric. Previous attempts to adapt FLOPS for inference-free scenarios have been limited to rule-based methods, leaving the potential of sparsification approaches for inference-free retrieval models largely unexplored. In this paper, we explore \\ell0 inspired sparsification manner for inference-free retrievers. Through comprehensive out-of-domain evaluation on the BEIR benchmark, our method achieves state-of-the-art performance among inference-free sparse retrieval models and is comparable to leading Siamese sparse retrieval models. Furthermore, we provide insights into the trade-off between retrieval effectiveness and computational efficiency, demonstrating practical value for real-world applications.",
        "doi": "10.1145/3726302.3730192",
        "sheridan_id": "sp0616",
        "position": 4,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "f770b62bc8f42a0b66751fe636fc6eb0",
        "title": "Unbiased Collaborative Filtering with Fair Sampling",
        "abstract": "Recommender systems leverage extensive user interaction data to model preferences; however, directly modeling these data may introduce biases that disproportionately favor popular items. In this paper, we demonstrate that popularity bias arises from the influence of propensity factors during training. Building on this insight, we propose a fair sampling (FS) method that ensures each user and each item has an equal likelihood of being selected as both positive and negative instances, thereby mitigating the influence of propensity factors. The proposed FS method does not require estimating propensity scores, thus avoiding the risk of failing to fully eliminate popularity bias caused by estimation inaccuracies. Comprehensive experiments demonstrate that the proposed FS method achieves state-of-the-art performance in both point-wise and pair-wise recommendation tasks. The code implementation is available at https://github.com/jhliu0807/Fair-Sampling.",
        "doi": "10.1145/3726302.3730260",
        "sheridan_id": "sp0482",
        "position": 2,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "02e656adee09f8394b402d9958389b7d",
        "title": "CoachGPT: A Scaffolding-based Academic Writing Assistant",
        "abstract": "Academic writing skills are crucial for students` success but can feel overwhelming without proper guidance and practice, particularly when writing in a second language. Traditionally, students ask instructors or search dictionaries, which are not universally accessible. Early writing assistants emerged as rule?based systems that focused on detecting misspellings, subject?verb disagreements, and basic punctuation errors but are inaccurate and lack contextual understanding. Machine learning-based assistants demonstrate a strong ability for language understanding but are expensive to train. Large language models (LLMs) have shown remarkable capabilities in generating responses in natural languages based on given prompts, but they have a fundamental limitation in education: they generate essays without teaching, which can have detrimental effects on learning when misused. To address this limitation, we develop {\\em CoachGPT}, which leverages LLMs to assist academic writing for those with limited educational resources and those who prefer self-paced learning. CoachGPT is an AI agent-based web application that (1) takes instructions from experienced educators, (2) converts instructions into sub-tasks, and (3) provides real-time feedback and suggestions using large language models. This unique scaffolding structure makes CoachGPT unique among existing writing assistants. Compared with existing writing assistants, CoachGPT provides a more immersed writing experience with personalized messages. Our user studies prove the usefulness of CoachGPT and the potential of large language models for academic writing.",
        "doi": "10.1145/3726302.3730143",
        "sheridan_id": "de2215",
        "position": 7,
        "track_id": 10,
        "slot_id": 112
      }
    },
    {
      "paper": {
        "hashed_id": "e449b9317dad920c0dd5ad0a2a2d5e49",
        "title": "Evaluating Multi-Dimensional Cumulated Utility in Information Retrieval",
        "abstract": "Traditional Information Retrieval (IR) effectiveness metrics assume that a relevant document satisfies the information need as a whole. Nevertheless, if the information need is faceted or contains subtopics, this notion of relevance cannot model documents relevant only to one or a few subtopics. Furthermore, faceted documents in a ranked list may focus on the same subtopics, and their content may overlap while neglecting other subtopics. Hence, a search result, where topranked documents deal with different subtopics should be preferred over a result where documents are thematically limited and provide overlapping information. The Multi-Dimensional Cumulated Utility (MDCU) metric, recently formulated theoretically by J\u00e4rvelin and Sormunen, extends the evaluation of novelty and diversity by considering content overlapping among documents. While J\u00e4rvelin and Sormunen described the theory of MDCU and illustrated its application on a toy example, they did not investigate its empirical use. In this paper, we show the practical feasibility and validity of the MDCU by applying it to publicly available TREC test collections. Furthermore, we analyse its relation with the well-established \u03b1-nDCG, and finally, we provide a Python implementation of the MDCU, fostering its adoption as an evaluation framework. Our results indicate a positive correlation between \u03b1-nDCG and MDCU, suggesting that both measures correctly identify similar trends when evaluating the IR systems. Finally, compared to \u03b1-nDCG, MDCU exhibits a stronger statistical power and identifies up to 9 times more statistically significantly different pairs of systems.",
        "doi": "10.1145/3726302.3730191",
        "sheridan_id": "sp1663",
        "position": 12,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "d43ab110ab2489d6b9b2caa394bf920f",
        "title": "UTCS: Effective Unsupervised Temporal Community Search with Pre-training of Temporal Dynamics and Subgraph Knowledge",
        "abstract": "In many real-world applications, the evolving relationships between entities can be modeled as temporal graphs, where each edge has a timestamp representing the interaction time. As a fundamental problem in graph analysis, {\\it community search (CS)} in temporal graphs has received growing attention but exhibits two major limitations: (1) Traditional methods typically require predefined subgraph structures, which are not always known in advance. (2) Learning-based methods struggle to capture temporal interaction information. To fill this research gap, in this paper, we propose an effective \\textbf{U}nsupervised \\textbf{T}emporal \\textbf{C}ommunity \\textbf{S}earch withpre-training of temporal dynamics and subgraph knowledge model (\\textbf{UTCS}).\\model~contains two key stages: offline pre-training and online search.In the first stage, we introduce multiple learning objectives to facilitate the pre-training process in the unsupervised learning setting.In the second stage, we identify a candidate subgraph and compute community scores using the pre-trained node representations and a novel scoring mechanism to determine the final community members.Experiments on five real-world datasets demonstrate the effectiveness of the proposed method.",
        "doi": "10.1145/3726302.3730263",
        "sheridan_id": "sp1690",
        "position": 10,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "97d98119037c5b8a9663cb21fb8ebf47",
        "title": "Rational Retrieval Acts: Leveraging Pragmatic Reasoning to Improve Sparse Retrieval",
        "abstract": "Current sparse neural information retrieval (IR) methods, and to a lesser extent more traditional models such as BM25, do not take into account the document collection and the complex interplay between different term weights when representing a single document. In this paper, we show how the Rational Speech Acts (RSA), a linguistics framework used to minimize the number of features to be communicated when identifying an object in a set, can be adapted to the IR case -- and in particular to the high number of potential features (here, tokens). RSA dynamically modulates token-document interactions by considering the influence of other documents in the dataset, better contrasting document representations. Experiments show that incorporating RSA consistently improves multiple sparse retrieval models and achieves state-of-the-art performance on out-of-domain datasets from the BEIR benchmark.",
        "doi": "10.1145/3726302.3730239",
        "sheridan_id": "sp1745",
        "position": 15,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "ab7314887865c4265e896c6e209d1cd6",
        "title": "Translative Neural Team Recommendation: From Multilabel Classification to Sequence Prediction",
        "abstract": "Neural team recommendation has achieved state-of-the-art performance in forming teams of experts whose success in completing complex tasks is almost surely guaranteed. The proposed models frame the problem as a Boolean multilabel classification, mapping the dense vector representations of required skills to the sparse occurrence (multi-hot) vector representation of an optimum subset of experts using multilayer feedforward neural networks. Such approaches, however, suffer from the curse of sparsity in the high-dimensional vector of optimum experts in the output layer. In this paper, we propose to reformulate the team recommendation problem into a sequence prediction task and leverage seq-to-seq models, including transformers, to map an input sequence of the required subset of skills onto an output sequence of the optimum subset of experts. Our experiments on four large-scale datasets from various domains, with distinct distributions of skills in teams, show that the seq-to-seq approach is consistently superior overall in a host of classification and information retrieval metrics. Our codebase is available at https://github.com/fani-lab/OpeNTF/tree/nmt.",
        "doi": "10.1145/3726302.3730259",
        "sheridan_id": "sp1910",
        "position": 64,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "6f2688a5fce7d48c8d19762b88c32c3b",
        "title": "Response Quality Assessment for Retrieval-Augmented Generation via Conditional Conformal Factuality",
        "abstract": "Existing research on Retrieval-Augmented Generation (RAG) primarily focuses on improving overall question-answering accuracy, often overlooking the quality of sub-claims within generated responses. Recent methods that attempt to improve RAG trustworthiness, such as through auto-evaluation metrics, lack probabilistic guarantees or require ground truth answers. To address these limitations, we propose Conformal-RAG, a novel framework inspired by recent applications of conformal prediction (CP) on large language models (LLMs). Conformal-RAG leverages CP and internal information from the RAG mechanism to offer statistical guarantees on response quality. It ensures group-conditional coverage spanning multiple sub-domains without requiring manual labelling of conformal sets, making it suitable for complex RAG applications. Compared to existing RAG auto-evaluation methods, Conformal-RAG offers statistical guarantees on the quality of refined sub-claims, ensuring response reliability without the need for ground truth answers. Additionally, our experiments demonstrate that by leveraging information from the RAG system, Conformal-RAG retains up to 60% more high-quality sub-claims from the response compared to direct applications of CP to LLMs, while maintaining the same reliability guarantee.",
        "doi": "10.1145/3726302.3730244",
        "sheridan_id": "sp1944",
        "position": 27,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "a501bebf79d570651ff601788ea9d16d",
        "title": "More Than Just A Conversation: A Multi-agent Reasoning Graph Knowledge Distillation for Conversational Stance Detection",
        "abstract": "Conversational stance detection, which aims to identify stances within conversation threads, has become a research hotspot recently. As the number of dialogue turns increases and the conversation content becomes more complex, existing methods that simply incorporate conversational context are insufficient to effectively capture the nuanced information necessary for accurate stance detection. To address this issue, we introduce a Multi-agent Reasoning Graph Knowledge Distillation (MRGKD) framework, leveraging conversational reasoning among multiple Large Language Models (LLMs) into smaller language models. Specifically, we first construct a multi-agent reasoning graph to infer implicit logical relationships within the conversational history from the diverse perspectives of multiple LLMs. To fully leverage the in-context learning capabilities of LLMs, we design a reasoning knowledge editing mechanism that internalizes new information by aligning the output distribution of smaller language models with both the conversational history and the knowledge derived from the multi-agent reasoning graph. Additionally, we incorporate a contrastive loss to distinguish between correct and incorrect reasoning, alongside a stance detection loss, to fine-tune the smaller language models. This approach not only ensures the accurate acquisition of logical knowledge but also preserves the integrity of the conversational history. Experiments conducted on two public datasets demonstrate that our MRGKD significantly outperforms all baselines.",
        "doi": "10.1145/3726302.3730232",
        "sheridan_id": "sp2047",
        "position": 61,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "52dbb0686f8bd0c0c757acf716e28ec0",
        "title": "SEALR: Sequential Emotion-Aware LLM-Based Personalized Recommendation System",
        "abstract": "Large Language Models (LLMs) excel in various NLP tasks but remain underexplored in recommendation systems. This study proposes the \\textbf{S}equential \\textbf{E}motion-\\textbf{A}ware \\textbf{L}LM-Based Personalized \\textbf{R}ecommendation System (\\textbf{SEALR}) to leverage sentiment analysis in user-generated reviews, tracking emotional changes and extracting sentiment labels. It integrates candidate items produced by sequential models with user behavior data into an LLM, enhancing personalization. Experiments on Amazon and Yelp datasets explore the effect of varied candidate pool sizes and instruction-based fine-tuning ratios, demonstrating significant performance gains. The combination of sentiment insights and user behavior data effectively accommodates diverse user preferences and contexts.",
        "doi": "10.1145/3726302.3730249",
        "sheridan_id": "sp2061",
        "position": 35,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "6492d38d732122c58b44e3fdc3e9e9f3",
        "title": "Generate-Distill: Training Cross-Language IR Models with Synthetically-Generated Data",
        "abstract": "Most pretrained language models that support neural information retrievalare fine-tuned on the MS MARCO dataset. MS MARCO is expressed in English,so it naturally supports monolingual English retrieval. However, for Cross-Language Information Retrieval (CLIR),no similar training data naturally exists that matches the languages of the query and the documents. The main ways to address this problem have been to continue to fine-tune with English data,or to translate MS MARCO queries and/or documents to match the CLIR setting. Machine translation often introduces errors that reduce retrieval effectiveness.It is usually easy to find target language documents suitable for training,but difficult to find naturally-occurring queries in the query language.An alternative is to train on naturally-occurring documentsand synthetically-generated queries.Generate-Distill usesthis approach with state-of-the-art distillation methodsto match the effectiveness of training with translated MS~MARCO across different domains.",
        "doi": "10.1145/3726302.3730201",
        "sheridan_id": "sp2076",
        "position": 48,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "cbef46321026d8404bc3216d4774c8a9",
        "title": "Balancing Precision and Generalization: Dynamic Instruction Generation for Model Adaptive Zero-Shot Reasoning in LLMs",
        "abstract": "Current research shows that providing instructions to guide Large Language Models (LLMs) improves reasoning tasks, but existing methods struggle to balance accuracy and generalization. Manually crafted instructions tailored to specific LLMs and tasks improve performance but reduce generalizability, while more general instructions lack detail and lower performance. To address this, we propose a dynamic instruction-generation method using an Instruction-Generation Prompt (IGP). IGP categorizes problems into domains and integrates the model`s capabilities to generate detailed task-specific instructions, resulting in a comprehensive plan. This approach achieves high precision with general prompts without requiring in-depth knowledge of LLMs or tasks. We validated our method across five LLMs and ten datasets in three task categories. Our dynamically generated instructions outperformed traditionally handcrafted, LLM-specific instructions across various LLMs and tasks.",
        "doi": "10.1145/3726302.3730170",
        "sheridan_id": "sp2075",
        "position": 63,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "0d73a25092e5c1c9769a9f3255caa65a",
        "title": "Exploring the Role of Diversity in Example Selection for In-Context Learning",
        "abstract": "In-Context Learning (ICL) has gained prominence due to its ability to perform tasks without requiring extensive training data and its robustness to noisy labels. A typical ICL workflow involves selecting localized examples relevant to a given input using sparse or dense embedding-based similarity functions. However, relying solely on similarity-based selection may introduce topical biases in the retrieved contexts, potentially leading to suboptimal downstream performance. We posit that reranking the retrieved context to enhance topical diversity can improve downstream task performance. To achieve this, we leverage maximum marginal relevance (MMR) which balances topical similarity with inter-example diversity. Our experimental results demonstrate that diversifying the selected examples leads to consistent improvements in downstream performance across various context sizes and similarity functions. The implementation of our approach is made available at https://github.com/janak11111/Diverse-ICL.",
        "doi": "10.1145/3726302.3730194",
        "sheridan_id": "sp2147",
        "position": 71,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "9978b7063e297d84bb2ac8e46c1c845f",
        "title": "Towards Best Practices of Axiomatic Activation Patching in Information Retrieval",
        "abstract": "Mechanistic interpretability research, which aims to uncover the internal processes of machine learning models, has gained significant attention. One state-of-the-art technique, activation patching, has been applied to analyzing neural ranker behavior in relation to information retrieval (IR) axioms. To date, however, this remains a rapidly evolving topic in IR, with no established methodology for measuring results or constructing datasets to ensure pronounced, robust, and consistent patching effects. In this study, based on experimental results, we provide recommendations on measuring patching effects and designing diagnostic datasets for investigating term frequency. We identify the rareness and informativeness of injected terms as a key factor influencing the magnitude of patching effects. Additionally, we find that low score differences between baseline and perturbed documents introduce significant noise, which can be mitigated by filtering or applying penalty scores to the metric. More generally, we provide practical recommendations for the reliable application of activation patching in IR, advancing future interpretability research of neural ranking models. Our code is available at https://github.com/polgrisha/best-practices-ir-patching.",
        "doi": "10.1145/3726302.3730256",
        "sheridan_id": "sp2172",
        "position": 42,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "443dec3062d0286986e21dc0631734c9",
        "title": "Fast and Effective Early Termination for Simple Ranking Functions",
        "abstract": "Web search engines often perform an initial candidate generation phase using a fast and simple ranking function, followed by subsequent reranking with more expensive rankers. Such simple ranking functions usually compute the score of a document as the sum of term-wise impact scores, and they include traditional baselines such as BM25 and Query Likelihood, as well as some recently proposed learned sparse models based on document expansion and learned impact scores. In this paper, we explore extremely fast and highly effective early termination techniques for such simple ranking functions. Our extensive experiments with a number of different ranking functions show that our methods achieve very fast response times on MSMarco V1 and V2 data while maintaining retrieval quality close to that of a safe and much slower baseline.",
        "doi": "10.1145/3726302.3730197",
        "sheridan_id": "sp2225",
        "position": 45,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "4ae67a7dd7e491f8fb6f9ea0cf25dfdb",
        "title": "A Large-Scale Study of Reranker Relevance Feedback at Inference",
        "abstract": "Neural IR systems often employ a retrieve-and-rerank framework: a bi-encoder retrieves a fixed number of candidates (e.g., K=100), which a cross-encoder then reranks. Recent studies have indicated that relevance feedback from the reranker at inference time can improve the recall of the retriever. The approach works by updating the retriever`s query representations via a distillation process that aligns it with the reranker`s predictions. While a powerful idea, the arguably narrow scope of past studies focusing on a small number of specific domains such as english question answering and entity retrieval has left a gap in our understanding of how well it generalizes. In this paper, we study inference-time reranker relevance feedback extensively across multiple retrieval domains, languages, and modalities, while also investigating aspects such as the performance and latency implications of the number of distillation updates and feedback candidates.",
        "doi": "10.1145/3726302.3730160",
        "sheridan_id": "sp2228",
        "position": 78,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "1a0a283bfe7c549dee6c638a05200e32",
        "title": "Reinforcement Learning for Effective Few-Shot Ranking",
        "abstract": "Neural rankers have achieved strong retrieval effectiveness but require large amounts of labeled data, limiting their applicability in few-shot settings. In this paper, we address the sample inefficiency of neural ranking methods by introducing a Reinforcement Learning (RL)-based re-ranking model that achieves high effectiveness with minimal training data. Built on a Deep Q-learning Network (DQN) framework, our approach is designed for few-shot settings, maximizing sample efficiency to ensure robust generalization from limited interactions. Extensive experiments show that our model significantly outperforms data-intensive methods and existing few-shot baselines, demonstrating RL`s potential to enhance IR capabilities in few-shot scenarios.",
        "doi": "10.1145/3726302.3730243",
        "sheridan_id": "sp2111",
        "position": 69,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "01eee509ee2f68dc6014898c309e86bf",
        "title": "Dynamic Superblock Pruning for Fast Learned Sparse Retrieval",
        "abstract": "This paper proposes superblock pruning (SP) during top-k online document retrieval for learned sparse representations. SP structures the sparse index as a set of superblocks on a sequence of document blocks and conducts a superblock-level selection to decide if some superblocks can be pruned before visiting their child blocks. SP generalizes the previous flat block or cluster-based pruning, allowing the early detection of groups of documents that cannot or are less likely to appear in the final top-k list. SP can accelerate sparse retrieval in a rank-safe or approximate manner under a high-relevance competitiveness constraint. Our experiments show that the proposed scheme significantly outperforms state-of-the-art baselines on MS MARCO passages on a single-threaded CPU.",
        "doi": "10.1145/3726302.3730183",
        "sheridan_id": "sp2226",
        "position": 77,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "186fb23a33995d91ce3c2212189178c8",
        "title": "Understanding Audio-Text Retrieval Through Singular Value Decomposition",
        "abstract": "Audio-language retrieval faces a fundamental challenge due to many-to-one mappings, where multiple audio instances correspond to the same or similar textual descriptions. This ambiguity leads to overlapping representations, making it difficult for models to learn discriminative features between samples. Queue-based contrastive learning helps mitigate this ambiguity by maintaining a large pool of negatives, improving retrieval performance. However, selecting appropriate hyperparameters, such as the queue size for optimal performance and the number of epochs to prevent overfitting, remains a challenge. In this study, we propose a LAtent Space Embedding Rank (LASER) analysis. Specifically, we analyze that a low-rank property of a queue indicates the presence of informative negative samples, and demonstrate that the best performance is achieved when the queue has the lowest rank. Furthermore, the convergence of rank variation can be interpreted as the model parameters reaching an optimal state during training. Thanks to the proposed rank-based analysis, the model hyperparameters can be selected analytically rather than through trial and error. Experimental results confirm that retrieval performance depends on queue rank, with lower ranks yielding better performance. These findings suggest that our LASER analysis can provide insight into how rank-based analysis can improve retrieval performance in audio-language tasks.",
        "doi": "10.1145/3726302.3730261",
        "sheridan_id": "sp2412",
        "position": 87,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "e58aea67b01fa747687f038dfde066f6",
        "title": "LLM-Driven Usefulness Labeling for IR Evaluation",
        "abstract": "In the information retrieval (IR) domain, evaluation plays a crucial role in optimizing search experiences and supporting diverse user intents. In the recent LLM era, research has been conducted to automate document relevance labels. These labels have traditionally been assigned by crowd-sourced workers, a process that is both time consuming and costly. This study focuses on LLM-generated usefulness labels, a crucial evaluation metric that considers the user`s search intents and task objectives, an aspect where relevance falls short. Our experiment utilizes task-level, query-level, and document-level features along with user search behavior signals, which are essential in defining the usefulness of a document. Our research finds that (i) pre-trained LLMs can generate moderate usefulness labels by understanding the comprehensive search task session, and (ii) pre-trained LLMs perform better judgment in short search sessions when provided with search session contexts. Furthermore, we investigate whether LLMs can capture the unique divergence between relevance and usefulness, along with conducting an ablation study to identify the most critical metrics for accurate usefulness label generation. In conclusion, this work explores LLM-generated usefulness labels by evaluating critical metrics and optimizing for practicality in real-world settings.",
        "doi": "10.1145/3726302.3730223",
        "sheridan_id": "sp2308",
        "position": 49,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "23af4b45f1e166141a790d1a3126e77a",
        "title": "RSGEA: Relationship Structure Line Graph for Semi-supervised Entity Alignment based on Edge Weight Adjustment",
        "abstract": "Entity alignment (EA) aims to identify equivalent entities across different knowledge graphs (KGs). While existing approaches leverage KG neighborhood structures for alignment, they often fail to effectively distinguish relevant from irrelevant neighbors due to insufficient handling of neighbor heterogeneity. Additionally, entity enhancement strategies remain underutilized. To address these issues, we propose a novel Relationship Structure Line Graph for Semi-supervised Entity Alignment Based on Edge Weight Adjustment, named RSGEA. It first enhances entity representations by deeply analyzing relational connectivity structures in KGs, capturing key relational information from second-order and triangular-ring structures. It then employs an attention mechanism to dynamically adjust edge weights, mitigating the impact of noisy edges during information propagation. Finally, we employ the Sinkhorn algorithm to refine the similarity matrix, improving alignment accuracy. Furthermore, we introduce an unsupervised version to accommodate diverse scenarios. Extensive experiments on five cross-lingual datasets validate the effectiveness and robustness of the RSGEA, demonstrating significant performance improvements.",
        "doi": "10.1145/3726302.3730247",
        "sheridan_id": "sp2353",
        "position": 51,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "c2ba1bc54b239208cb37b901c0d3b363",
        "title": "HeterRec: Heterogeneous Information Transformer for Scalable Sequential Recommendation",
        "abstract": "Transformer-based sequential recommendation (TSR) models have shown superior performance in recommendation systems, where the quality of item representations plays a crucial role. Classical representation methods integrate item features using concatenation or neural networks to generate homogeneous representation sequences. While straightforward, these methods overlook the heterogeneity of item features, limiting the transformer`s ability to capture fine-grained patterns and restricting scalability. Recent studies have attempted to integrate user-side heterogeneous features into item representation sequences, but item-side heterogeneous features, which are vital for performance, remain excluded. To address these challenges, we propose a Heterogeneous Information Transformer model for Sequential Recommendation (HeterRec), which incorporates Heterogeneous Token Flatten Layer (HTFL) and Hierarchical Causal Transformer Layer (HCT). Our HTFL is a novel item tokenization method that converts items into a heterogeneous token set and organizes these tokens into heterogeneous sequences, effectively enhancing performance gains when scaling up the model. Moreover, HCT introduces token-level and item-level causal transformers to extract fine-grained patterns from the heterogeneous sequences. Experiments on offline and online datasets show that the HeterRec model achieves superior performance.",
        "doi": "10.1145/3726302.3730206",
        "sheridan_id": "sp2255",
        "position": 80,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "e4da3b7fbbce2345d7772b0674a318d5",
        "title": "LLM-based Search Assistant with Holistically Guided MCTS for Intricate Information Seeking",
        "abstract": "In the era of vast digital information, the sheer volume and heterogeneity of available information present significant challenges for intricate information seeking. Users frequently face multistep web search tasks that involve navigating vast and varied data sources. This complexity demands every step remains comprehensive, accurate, and relevant. However, traditional search methods often struggle to balance the need for localized precision with the broader context required for holistic understanding, leaving critical facets of intricate queries underexplored. In this paper, we introduce an LLM-based search assistant that adopts a new information seeking paradigm with holistically guided Monte Carlo tree search (HG-MCTS). We reformulate the task as a progressive information collection process with a knowledge memory and unite an adaptive checklist with multi-perspective reward modeling in MCTS. The adaptive checklist provides explicit sub-goals to guide the MCTS process toward comprehensive coverage of complex user queries. Simultaneously, our multi-perspective reward modeling offers both exploration and retrieval rewards, along with progress feedback that tracks completed and remaining sub-goals, refining the checklist as the tree search progresses. By striking a balance between localized tree expansion and global guidance, HG-MCTS reduces redundancy in search paths and ensures that all crucial aspects of an intricate query are properly addressed. Extensive experiments on real-world intricate information seeking tasks demonstrate that HG-MCTS acquires thorough knowledge collections and delivers more accurate final responses compared with existing baselines.",
        "doi": "10.1145/3726302.3730025",
        "sheridan_id": "fp0005",
        "position": 1,
        "track_id": 1,
        "slot_id": 42
      }
    },
    {
      "paper": {
        "hashed_id": "c9077732a294f90a75acea3ce5f2a4e8",
        "title": "Cooking with Conversation: Enhancing User Engagement and Learning with a Knowledge-Enhancing Assistant",
        "abstract": "We present two empirical studies to investigate users\u2019 expectations and behaviours when using digital assistants, such as Alexa and Google Home, in a kitchen context: First, a survey (N = 200) queries participants on their expectations for the kinds of information that such systems should be able to provide. While consensus exists on expecting information about cooking steps and processes, younger participants who enjoy cooking express a higher likelihood of expecting details on food history or the science of cooking. In a follow-up Wizard-of-Oz study (N = 48), users were guided through the steps of a recipe either by an active wizard that alerted participants to information it could provide or a passive wizard who only answered questions that were provided by the user. The active policy led to almost double the number of conversational utterances and 1.5 times more knowledge-related user questions compared to the passive policy. Also, it resulted in 1.7 times more knowledge communicated than the passive policy. We discuss the findings in the context of related work and reveal implications for the design and use of such assistants for cooking and other purposes such as DIY and craft tasks, as well as the lessons we learned for evaluating such systems.",
        "doi": "10.1145/3649500",
        "sheridan_id": "TOIS-2023-0161.R1",
        "position": 3,
        "track_id": 2,
        "slot_id": 24
      }
    },
    {
      "paper": {
        "hashed_id": "cf874aad79e14b401a4c86954a596fa5",
        "title": "Data Augmentation for Sample Efficient and Robust Document Ranking",
        "abstract": "Contextual ranking models have delivered impressive performance improvements over classical models in the document ranking task. However, these highly over-parameterized models tend to be data-hungry and require large amounts of data even for fine-tuning. In this article, we propose data-augmentation methods for effective and robust ranking performance. One of the key benefits of using data augmentation is in achieving sample efficiency or learning effectively when we have only a small amount of training data. We propose supervised and unsupervised data augmentation schemes by creating training data using parts of the relevant documents in the query-document pairs. We then adapt a family of contrastive losses for the document ranking task that can exploit the augmented data to learn an effective ranking model. Our extensive experiments on subsets of the MS MARCO and TREC-DL test sets show that data augmentation, along with the ranking-adapted contrastive losses, results in performance improvements under most dataset sizes. Apart from sample efficiency, we conclusively show that data augmentation results in robust models when transferred to out-of-domain benchmarks. Our performance improvements in in-domain and more prominently in out-of-domain benchmarks show that augmentation regularizes the ranking model and improves its robustness and generalization capability.",
        "doi": "110.1145/3634911",
        "sheridan_id": "TOIS-2023-0061.R1",
        "position": 5,
        "track_id": 2,
        "slot_id": 33
      }
    },
    {
      "paper": {
        "hashed_id": "e8647dce263d505d7b0d605a5d6c2d1b",
        "title": "An Analysis on Matching Mechanisms and Token Pruning for Late-interaction Models",
        "abstract": "With the development of pre-trained language models, the dense retrieval models have become promising alternatives to the traditional retrieval models that rely on exact match and sparse bag-of-words representations. Different from most dense retrieval models using a bi-encoder to encode each query or document into a dense vector, the recently proposed late-interaction multi-vector models (i.e., ColBERT and COIL) achieve state-of-the-art retrieval effectiveness by using all token embeddings to represent documents and queries and modeling their relevance with a sum-of-max operation. However, these fine-grained representations may cause unacceptable storage overhead for practical search systems. In this study, we systematically analyze the matching mechanism of these late-interaction models and show that the sum-of-max operation heavily relies on the co-occurrence signals and some important words in the document. Based on these findings, we then propose several simple document pruning methods to reduce the storage overhead and compare the effectiveness of different pruning methods on different late-interaction models. We also leverage query pruning methods to further reduce the retrieval latency. We conduct extensive experiments on both in-domain and out-domain datasets and show that some of the used pruning methods can significantly improve the efficiency of these late-interaction models without substantially hurting their retrieval effectiveness.",
        "doi": "10.1145/3639818",
        "sheridan_id": "TOIS-2023-0059.R1",
        "position": 4,
        "track_id": 2,
        "slot_id": 33
      }
    },
    {
      "paper": {
        "hashed_id": "49cc492aec9039819fc2b7a1a138a9fb",
        "title": "A Knowledge Graph Embedding Model for Answering Factoid Entity Questions",
        "abstract": "Factoid entity questions (FEQ), which seek answers in the form of a single entity from knowledge sources, such as DBpedia and Wikidata, constitute a substantial portion of user queries in search engines. This article introduces the knowledge graph embedding model for FEQ (KGE-FEQ) answering. Leveraging a textual knowledge graph derived from extensive text collections, KGE-FEQ encodes textual relationships between entities. The model employs a two-step process: (1) Triple Retrieval, where relevant triples are retrieved from the textual knowledge graph based on semantic similarities to the question, and (2) Answer Selection, where a knowledge graph embedding approach is utilized for answering the question. This involves positioning the embedding for the answer entity close to the embedding of the question entity, incorporating a vector representing the question and textual relations between entities. Extensive experiments evaluate the performance of the proposed approach, comparing KGE-FEQ to state-of-the-art baselines in FEQ answering and the most advanced open-domain question answering techniques applied to FEQs. The results show that KGE-FEQ outperforms existing methods across different datasets. Ablation studies highlights the effectiveness of KGE-FEQ when both the question and textual relations between entities are considered for answering questions.",
        "doi": "10.1145/3678003",
        "sheridan_id": "TOIS-2024-0071.R1",
        "position": 6,
        "track_id": 2,
        "slot_id": 42
      }
    },
    {
      "paper": {
        "hashed_id": "0392818b32472a09b84f2b13908c1243",
        "title": "Explaining Recommendation Fairness from a User/Item Perspective",
        "abstract": "Recommender systems play a crucial role in personalizing user experiences, yet ensuring fairness in their outcomes remains an elusive challenge. This work explores the impact of individual users or items on the fairness of recommender systems, thus addressing a significant knowledge gap in the field. We introduce an innovative approach called Adding-Based Counterfactual Fairness Reasoning (ACFR), designed to elucidate recommendation fairness from the unique perspectives of users and items. Conventional methodologies, like erasing-based counterfactual analysis, pose limitations, particularly in modern recommender systems dealing with a large number of users and items. These traditional methods, by excluding specific users or items, risk disrupting the crucial relational structure central to collaborative filtering recommendations. In contrast, ACFR employs an adding-based counterfactual analysis, a unique strategy allowing us to consider potential, yet-to-happen user-item interactions. This strategy preserves the core user-item relational structure, while predicting future behaviors of users or items. The commonly used feature-based counterfactual analysis, relying on gradient-based optimization to identify interference on each feature, is not directly applicable in our case. In the recommendation scenario we consider, only interactions between users and items are present during model training\u2014no distinct features are involved. Consequently, the traditional mechanism proves impractical for identifying interference on these existing interactions. Our extensive experiments validate the superiority of ACFR over traditional baseline methods, demonstrating significant improvements in recommendation fairness on benchmark datasets. This work, therefore, provides a fresh perspective and a promising methodology for enhancing fairness in recommender systems.",
        "doi": "10.1145/3698877",
        "sheridan_id": "TOIS-2023-0394.R1",
        "position": 0,
        "track_id": 2,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "576226389b62628b5a757e044e3c6a24",
        "title": "LTP-MMF: Towards Long-Term Provider Max-Min Fairness Under Recommendation Feedback Loops",
        "abstract": "Multi-stakeholder recommender systems involve various roles, such as users and providers. Previous work pointed out that max-min fairness (MMF) is a better metric to support weak providers. However, when considering MMF, the features or parameters of these roles vary over time, and how to ensure long-term provider MMF has become a significant challenge. We observed that recommendation feedback loops (RFL) will influence the provider MMF greatly in the long term. RFL means that recommender systems can only receive feedback on exposed items from users and update recommender models incrementally based on this feedback. When utilizing the feedback, the recommender model will regard the unexposed items as negative. In this way, the tail provider will not get the opportunity to be exposed, and its items will always be considered negative samples. Such phenomena will become more and more serious in RFL. To alleviate the problem, this article proposes an online ranking model named Long-Term Provider Max-min Fairness (LTP-MMF). Theoretical analysis shows that the long-term regret of LTP-MMF enjoys a sub-linear bound. Experimental results on three public recommendation benchmarks demonstrated that LTP-MMF can outperform the baselines in the long term.",
        "doi": "10.1145/3695867",
        "sheridan_id": "TOIS-2023-0301.R1",
        "position": 8,
        "track_id": 2,
        "slot_id": 15
      }
    },
    {
      "paper": {
        "hashed_id": "705e5b6b317d091229d9699f2d616df2",
        "title": "Feature-Enhanced Neural Collaborative Reasoning for Explainable Recommendation",
        "abstract": "Providing reasonable explanations for a specific suggestion given by the recommender can help users trust the system more. As logic rule-based inference is concise, transparent, and aligned with human cognition, it can be adopted to improve the interpretability of recommendation models. Previous work that interprets user preference with logic rules merely focuses on the construction of rules while neglecting the usage of feature embeddings. This limits the model in capturing implicit relationships between features. In this article, we aim to improve both the effectiveness and explainability of recommendation models by simultaneously representing logic rules and feature embeddings. We propose a novel model-intrinsic explainable recommendation method named Feature-Enhanced Neural Collaborative Reasoning (FENCR). The model automatically extracts representative logic rules from massive possibilities in a data-driven way. In addition, we utilize feature interaction-based neural modules to represent logic operators on embeddings. Experiments on two large public datasets show our model outperforms state-of-the-art neural logical recommendation models. Further case analyses demonstrate that FENCR can derive reasonable rules, indicating its high robustness and expandability.",
        "doi": "10.1145/3690381",
        "sheridan_id": "TOIS-2024-0028.R2",
        "position": 7,
        "track_id": 2,
        "slot_id": 15
      }
    },
    {
      "paper": {
        "hashed_id": "90599c8fdd2f6e7a03ad173e2f535751",
        "title": "Reproducing NevIR: Negation in Neural Information Retrieval",
        "abstract": "Negation is a fundamental aspect of human communication, yet it remains a challenge for Language Models (LMs) in Information Retrieval (IR). Despite the heavy reliance of modern neural IR systems on LMs, little attention has been given to their handling of negation. In this study, we reproduce and extend the findings of NevIR, a benchmark study that revealed most IR models perform at or below the level of random ranking when dealing with negation. We replicate NevIR`s original experiments and evaluate newly developed state-of-the-art IR models. Our findings show that a recently emerging category\u2014listwise Large Language Model (LLM) re-rankers\u2014outperforms other models but still underperforms human performance. Additionally, we leverage ExcluIR, a benchmark dataset designed for exclusionary queries with extensive negation, to assess the generalisability of negation understanding. Our findings suggest that fine-tuning on one dataset does not reliably improve performance on the other, indicating notable differences in their data distributions. Furthermore, we observe that only cross-encoders and listwise LLM re-rankers achieve reasonable performance across both negation tasks.",
        "doi": "10.1145/3726302.3730294",
        "sheridan_id": "rr1796",
        "position": 6,
        "track_id": 6,
        "slot_id": 6
      }
    },
    {
      "paper": {
        "hashed_id": "17065b3b2fe15f5c974a4065b18e030c",
        "title": "Automated Disentangled Sequential Recommendation with Large Language Models",
        "abstract": "Sequential recommendation aims to recommend the next items that a target user may have interest in based on the user\u2019s sequence of past behaviors, which has become a hot research topic in both academia and industry. In the literature, sequential recommendation adopts a Sequence-to-Item or Sequence-to-Sequence training strategy, which supervises a sequential model with a user\u2019s next one or more behaviors as the labels and the sequence of the past behaviors as the input. However, existing powerful sequential recommendation approaches employ more and more complex deep structures such as Transformer in order to accurately capture the sequential patterns, which heavily rely on hand-crafted designs on key attention mechanism to achieve state-of-the-art performance, thus failing to automatically obtain the optimal design of attention representation architectures in various scenarios with different data. Other works on classic automated deep recommender systems only focus on traditional settings, ignoring the problem of sequential scenarios. In this article, we study the problem of automated sequential recommendation, which faces two main challenges: (1) How can we design a proper search space tailored for attention automation in sequential recommendation, and (2) How can we accurately search effective attention representation architectures considering multiple user interests reflected in the sequential behavior. To tackle these challenges, we propose an automated disentangled sequential recommendation (AutoDisenSeq) model. In particular, we employ neural architecture search (NAS) and design a search space tailored for automated attention representation in attentive intention-disentangled sequential recommendation with an expressive and efficient space complexity of O(n^2) given as the number of layers. We further propose a context-aware parameter sharing mechanism taking characteristics of each sub-architecture into account to enable accurate architecture performance estimations and great flexibility for disentanglement of latent intention representation. Moreover, we propose AutoDisenSeq-large language model (LLM), which utilizes the textual understanding power of LLM as a guidance to refine the candidate list for recommendation from AutoDisenSeq. We conduct extensive experiments to show that our proposed AutoDisenSeq model and AutoDisenSeq-LLM model outperform existing baseline methods on four real-world datasets in both overall recommendation and cold-start recommendation scenarios.",
        "doi": "10.1145/3675164",
        "sheridan_id": "TOIS-2024-0085.R1",
        "position": 4,
        "track_id": 2,
        "slot_id": 21
      }
    },
    {
      "paper": {
        "hashed_id": "28102e526765b0ac82736c2c205b94ab",
        "title": "Generalized Weak Supervision for Neural Information Retrieval",
        "abstract": "Neural ranking models (NRMs) have demonstrated effective performance in several information retrieval (IR) tasks. However, training NRMs often requires large-scale training data, which is difficult and expensive to obtain. To address this issue, one can train NRMs via weak supervision, where a large dataset is automatically generated using an existing ranking model (called the weak labeler) for training NRMs. Weakly supervised NRMs can generalize from the observed data and significantly outperform the weak labeler. This paper generalizes this idea through an iterative re-labeling process, demonstrating that weakly supervised models can iteratively play the role of weak labeler and significantly improve ranking performance without using manually labeled data. The proposed Generalized Weak Supervision (GWS) solution is generic and orthogonal to the ranking model architecture. This paper offers four implementations of GWS: self-labeling, cross-labeling, joint cross- and self-labeling, and greedy multi-labeling. GWS also benefits from a query importance weighting mechanism based on query performance prediction methods to reduce noise in the generated training data. We further draw a theoretical connection between self-labeling and Expectation-Maximization. Our experiments on four retrieval benchmarks suggest that our implementations of GWS lead to substantial improvements compared to weak supervision if the weak labeler is sufficiently reliable.",
        "doi": "10.1145/3647639",
        "sheridan_id": "TOIS-2023-0044.R2",
        "position": 6,
        "track_id": 2,
        "slot_id": 20
      }
    },
    {
      "paper": {
        "hashed_id": "7fea637fd6d02b8f0adf6f7dc36aed93",
        "title": "Bias in Language Models: Interplay of Architecture and Data?",
        "abstract": "Pre-trained language models (PLMs), despite showing strong performance, can carry and increase biases, which can limit the development of fair NLP and IR systems. This research investigates the foundational origins of bias within PLMs, moving beyond detection to a detailed analysis of its formation and propagation across diverse architectures. Through a novel attention weight analysis, we reveal distinct attention patterns for biased versus neutral content, offering insights into the internal representations learned by PLMs. Our findings demonstrate a complex interplay between training data and model architecture, revealing that while the transformer\u2019s self-attention mechanism amplifies existing biases, the training data plays a crucial role in the initial encoding of bias within the model\u2019s representations.",
        "doi": "10.1145/3726302.3730172",
        "sheridan_id": "sp1687",
        "position": 20,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "feab05aa91085b7a8012516bc3533958",
        "title": "MSCRS: Multi-modal Semantic Graph Prompt Learning Framework for Conversational Recommender Systems",
        "abstract": "Conversational Recommender Systems (CRSs) aim to provide personalized recommendations by interacting with users through conversations. Most existing studies of CRS focus on extracting user preferences from conversational contexts. However, due to the short and sparse nature of conversational contexts, it is difficult to fully capture user preferences by conversational contexts only. We argue that multi-modal semantic information can enrich user preference expressions from diverse dimensions (e.g., a user preference for a certain movie may stem from its magnificent visual effects and compelling storyline). In this paper, we propose a multi-modal semantic graph prompt learning framework for CRS, named MSCRS. First, we extract textual and image features of items mentioned in the conversational contexts. Second, we capture higher-order semantic associations within different semantic modalities (collaborative, textual, and image) by constructing modality-specific graph structures. Finally, we propose an innovative integration of multi-modal semantic graphs with prompt learning, harnessing the power of large language models to comprehensively explore high-dimensional semantic relationships. Experimental results demonstrate that our proposed method significantly improves accuracy in item recommendation, as well as generates more natural and contextually relevant content in response generation. Code and extended multi?modal CRS datasets are available at https://github.com/BIAOBIAO12138/MSCRS-main.",
        "doi": "10.1145/3726302.3730040",
        "sheridan_id": "fp1145",
        "position": 5,
        "track_id": 1,
        "slot_id": 32
      }
    },
    {
      "paper": {
        "hashed_id": "38ca89564b2259401518960f7a06f94b",
        "title": "Action First: Leveraging Preference-Aware Actions for More Effective Decision-Making in Interactive Recommender Systems",
        "abstract": "Interactive recommender systems (IRSs) aim to meet user needs through natural language dialogues, optimizing recommendations with minimal interactions. Typically, IRSs are based on large language models (LLMs). Existing methods generally consist of two stages: decision-making (deciding whether to recommend or ask clarification questions) and action execution (generating recommendations or clarification questions). These methods usually follow a decision-first paradigm, where the model first decides on the action based on past conversations, and then executes the corresponding action. Since LLMs struggle to process a large number of candidate items, the recommendation process is often carried out in collaboration with external recommendation tools, which provide a small candidate set for LLMs to refine.  Existing methods face two key information gaps: (1) In the decision-making stage, the decision-first paradigm relies solely on past conversations, leading to incomplete decisions due to the uncertainty of subsequent actions` outcomes. (2) In the action execution stage, there is a unidirectional flow from external recommendation tools to LLMs, where these tools fail to interpret user preferences effectively, thus reducing the recommendation accuracy. To address these challenges, we introduce Action-First Interactive Recommender System(AF-IRS), a novel model that uses preference-aware actions to guide decision-making. Our Action-First paradigm informs decisions with future recommendations, ensuring more accurate decisions. Additionally, we establish a bidirectional interaction loop between LLMs and external recommendation tools, enabling LLMs to interpret and transmit session preferences for more precise recommendations. Experimental results on three benchmark datasets demonstrate that AF-IRS significantly improves both recommendation accuracy and efficiency, addressing the information gaps in both stages.",
        "doi": "10.1145/3726302.3729885",
        "sheridan_id": "fp1161",
        "position": 6,
        "track_id": 1,
        "slot_id": 32
      }
    },
    {
      "paper": {
        "hashed_id": "7810ccd41bf26faaa2c4e1f20db70a71",
        "title": "Bridging the Gap: From Ad-hoc to Proactive Search in Conversations",
        "abstract": "Proactive search in conversations (PSC) aims to reduce user effort in formulating explicit queries by proactively retrieving useful relevant information given conversational context. Previous work in PSC either directly uses this context as input to off-the-shelf ad-hoc retrievers or further fine-tunes them on PSC data. However, ad-hoc retrievers are pre-trained on short and concise queries, while the PSC input is longer and noisier. This input mismatch between ad-hoc search and PSC limits retrieval quality. While fine-tuning on PSC data helps, its benefits remain constrained by this input gap. In this work, we propose Conv2Query, a novel conversation-to-query framework that adapts ad-hoc retrievers to PSC by bridging the input gap between ad-hoc search and PSC. Conv2Query maps conversational context into ad-hoc queries, which can either be used as input for off-the-shelf ad-hoc retrievers or for further fine-tuning on PSC data. Extensive experiments on two PSC datasets show that Conv2Query significantly improves ad-hoc retrievers` performance, both when used directly and after fine-tuning on PSC.",
        "doi": "10.1145/3726302.3729915",
        "sheridan_id": "fp1272",
        "position": 7,
        "track_id": 1,
        "slot_id": 32
      }
    },
    {
      "paper": {
        "hashed_id": "daa96d9681a21445772454cbddf0cac1",
        "title": "Search-Based Interaction For Conversation Recommendation via Generative Reward Model Based Simulated User",
        "abstract": "Conversational recommendation systems (CRSs) use multi-turn interaction to capture user preferences and provide personalized recommendations. A fundamental challenge in CRSs lies in effectively understanding user preferences from conversations. Previous research primarily focuses on the issue of insufficient contextual information in conversations. They address this by introducing external knowledge sources, such as knowledge graphs, large language models (LLMs), and conversational recommendation corpora. Based on this, they design specific alignment strategies (e.g., prompt learning and instruction tuning) to integrate such knowledge for user preference understanding and item recommendation. However, user preferences can be multifaceted and complex, posing significant challenges for accurate recommendations even with access to abundant external knowledge. While interaction with users can clarify their true preferences, frequent user involvement may lead to a degraded user experience. To address this problem, we propose a Generative Reward model based Simulated User, named GRSU, for automatic interaction with CRSs. The simulated user provides feedback to the items recommended by CRSs, enabling them to better capture intricate user preferences through multi-turn interaction. Inspired by generative reward models, we design two types of feedback actions for the simulated user: i.e., generative item scoring, which offers coarse-grained feedback, and attribute-based item critiquing, which provides fine-grained feedback. To ensure seamless integration, these feedback actions are unified into an instruction-based format, allowing the development of a unified simulated user via instruction tuning on synthesized data. With this simulated user, automatic multi-turn interaction with CRSs can be effectively conducted. Furthermore, to strike a balance between effectiveness and efficiency, we draw inspiration from the paradigm of reward-guided search in complex reasoning tasks and employ beam search for the interaction process. On top of this, we propose an efficient candidate ranking method to improve the recommendation results derived from interaction. Extensive experiments on public datasets demonstrate the effectiveness, efficiency, and transferability of our approach.",
        "doi": "10.1145/3726302.3730080",
        "sheridan_id": "fp1472",
        "position": 8,
        "track_id": 1,
        "slot_id": 32
      }
    },
    {
      "paper": {
        "hashed_id": "71ad16ad2c4d81f348082ff6c4b20768",
        "title": "DiSCo: LLM Knowledge Distillation for Efficient Sparse Retrieval in Conversational Search",
        "abstract": "Conversational Search (CS) involves retrieving relevant documents from a corpus while considering the conversational context, integrating retrieval with context modeling. Recent advancements in Large Language Models (LLMs) have significantly enhanced CS by enabling query rewriting based on conversational context. However, employing LLMs during inference poses efficiency challenges. Existing solutions mitigate this issue by distilling embeddings derived from human-rewritten queries, focusing primarily on learning the context modeling task. These methods, however, often separate the contrastive retrieval task from the distillation process, treating it as an independent loss term. To overcome these limitations, we introduce DiSCo (Distillation of Sparse Conversational retrieval), a novel approach that unifies retrieval and context modeling through a relaxed distillation objective. Instead of relying exclusively on representation learning, our method distills similarity scores between conversations and documents, providing more freedom in the representation space and better leveraging the contrastive nature of document relevance. Extensive experiments on Learned Sparse Retrieval (LSR) across five CS datasets demonstrate that DiSCo achieves substantial improvements in both in-domain and out-of-domain retrieval tasks, achieving up to a six-point gain in recall for out-of-domain datasets over state-of-the-art methods. Additionally, DiSCo employs a multi-teacher distillation strategy, using multiple LLMs as teachers, further enhancing performance and surpassing the individual teachers in in-domain settings. Furthermore, analysis of model sparsity reveals that DiSCo allows for more effective control over the sparsity of the trained models.",
        "doi": "10.1145/3726302.3729966",
        "sheridan_id": "fp0815",
        "position": 2,
        "track_id": 1,
        "slot_id": 32
      }
    },
    {
      "paper": {
        "hashed_id": "766ebcd59621e305170616ba3d3dac32",
        "title": "Two-Stage Adversarial Training for Deep Hashing via Representation Distillation",
        "abstract": "In recent years, the study on defending deep hashing models against adversarial attacks has garnered increasing attention. Among them, adversarial training is an effective method to train robust deep hashing models. Existing adversarial training methods for deep hashing simultaneously optimize original deep hashing loss and proposed adversarial training loss to train a robust model. However, we argue that directly using the original deep hashing loss will guide the model to learn excessive non-robust patterns from clean examples when extracting discriminative semantic information, thereby limiting model robustness. To tackle this, we propose a novel Clean model Representation Distillation based Adversarial Training (CRDAT) method, which enables the robust model to learn both discriminative semantic information and robust patterns by separating these two losses into two stages, i.e., standard training stage of a clean teacher model and adversarial training stage of a robust student model. Specifically, we propose a novel representation distillation based adversarial training loss, which distills the representations of the teacher model on clean examples at both the hash code level and feature level to guide the student model`s learning on adversarial examples. Extensive experiments on multiple datasets and deep hashing methods demonstrate that our CRDAT method can greatly improve model robustness and achieve state-of-the-art defense performance.",
        "doi": "10.1145/3726302.3730103",
        "sheridan_id": "fp0587",
        "position": 7,
        "track_id": 1,
        "slot_id": 18
      }
    },
    {
      "paper": {
        "hashed_id": "971fdce755640b988ae8f01733cd1f73",
        "title": "Please meet AI, Our Dear New Colleague. In other Words: Can Scientists and Machines Truly Cooperate?",
        "abstract": "How can AI and LLMs facilitate the work of scientists in different stages of the research process? Can technology even make scientists obsolete? The role of AI and Large Language Models (LLMs) in science as the target application domain has recently been rapidly growing. This includes assessing the impact of scientific work, facilitating writing and revising manuscripts as well as intelligent support for manuscript quality assessment, peer-review and scientific discussions. The talk will illustrate such methods and models using several tasks from the scientific domain. We argue that while AI and LLMs can effectively support and augment specific steps of the research process, expert-AI collaboration may be a more promising mode for complex research tasks.",
        "doi": "10.1145/3726302.3730057",
        "sheridan_id": "kn2511",
        "position": 1,
        "track_id": 1,
        "slot_id": 115
      }
    },
    {
      "paper": {
        "hashed_id": "23cd9e0ce513fa08ed79fc876db1d25d",
        "title": "Proactive Conversational AI: A Comprehensive Survey of Advancements and Opportunities",
        "abstract": "Dialogue systems are designed to offer human users social support or functional services through natural language interactions. Traditional conversation research has put significant emphasis on a system\u2019s response-ability, including its capacity to understand dialogue context and generate appropriate responses. However, the key element of proactive behavior\u2014a crucial aspect of intelligent conversations\u2014is often overlooked in these studies. Proactivity empowers conversational agents to lead conversations towards achieving pre-defined targets or fulfilling specific goals on the system side. Proactive dialogue systems are equipped with advanced techniques to handle complex tasks, requiring strategic and motivational interactions, thus representing a significant step towards artificial general intelligence. Motivated by the necessity and challenges of building proactive dialogue systems, we provide a comprehensive review of various prominent problems and advanced designs for implementing proactivity into different types of dialogue systems, including open-domain dialogues, task-oriented dialogues, and information-seeking dialogues. We also discuss real-world challenges that require further research attention to meet application needs in the future, such as proactivity in dialogue systems that are based on large language models, proactivity in hybrid dialogues, evaluation protocols and ethical considerations for proactive dialogue systems. By providing a quick access and overall picture of the proactive dialogue systems domain, we aim to inspire new research directions and stimulate further advancements towards achieving the next level of conversational AI capabilities, paving the way for more dynamic and intelligent interactions within various application domains.",
        "doi": "10.1145/3715097",
        "sheridan_id": "TOIS-2023-0387.R2",
        "position": 1,
        "track_id": 2,
        "slot_id": 32
      }
    },
    {
      "paper": {
        "hashed_id": "f7f580e11d00a75814d2ded41fe8e8fe",
        "title": "Beyond Whole Dialogue Modeling: Contextual Disentanglement for Conversational Recommendation",
        "abstract": "Conversational recommender systems aim to provide personalized recommendations by analyzing and utilizing contextual information related to dialogue. However, existing methods typically model the dialogue context as a whole, neglecting the inherent complexity and entanglement within the dialogue. Specifically, a dialogue comprises both focus information and background information, which mutually influence each other. Current methods tend to model these two types of information mixedly, leading to misinterpretation of users` actual needs, thereby lowering the accuracy of recommendations. To address this issue, this paper proposes a novel model to introduce contextual disentanglement for improving conversational recommender systems, named DisenCRS. The proposed model DisenCRS employs a dual disentanglement framework, including self-supervised contrastive disentanglement and counterfactual inference disentanglement, to effectively distinguish focus information and background information from the dialogue context under unsupervised conditions. Moreover, we design an adaptive prompt learning module to automatically select the most suitable prompt based on the specific dialogue context, fully leveraging the power of large language models. Experimental results on two widely used public datasets demonstrate that DisenCRS significantly outperforms existing conversational recommendation models, achieving superior performance on both item recommendation and response generation tasks.",
        "doi": "10.1145/3726302.3729903",
        "sheridan_id": "fp1141",
        "position": 4,
        "track_id": 1,
        "slot_id": 32
      }
    },
    {
      "paper": {
        "hashed_id": "aff1621254f7c1be92f64550478c56e6",
        "title": "Clarifying Ambiguities: on the Role of Ambiguity Types in Prompting Methods for Clarification Generation",
        "abstract": "In information retrieval (IR), providing appropriate clarifications to better understand users` information needs is crucial for building a proactive search-oriented dialogue system. Due to the strong in-context learning ability of large language models (LLMs), recent studies investigate prompting methods to generate clarifications using few-shot or Chain of Thought (CoT) prompts. However, vanilla CoT prompting does not distinguish the characteristics of different information needs, making it difficult to understand how LLMs resolve ambiguities in user queries. In this work, we focus on the concept of ambiguity for clarification, seeking to model and integrate ambiguities in the clarification process. Following the reasoning and acting paradigm, we propose a new prompting scheme Ambiguity Type-Chain of Thought (AT-CoT), which enhances the reasoning abilities of LLMs by limiting CoT to first predict ambiguity types that can be interpreted as actions, then generate clarifications correspondingly. Experiments are conducted on various datasets containing human-annotated clarifying questions to compare AT-CoT with multiple baselines. We also perform user simulation to implicitly measure the quality of generated clarifications under various IR scenarios. Our codes are available at: https://github.com/anfutang/ClarifyingAmbiguities/.",
        "doi": "10.1145/3726302.3729922",
        "sheridan_id": "fp0853",
        "position": 3,
        "track_id": 1,
        "slot_id": 32
      }
    },
    {
      "paper": {
        "hashed_id": "5fd0b37cd7dbbb00f97ba6ce92bf5add",
        "title": "Unified Category and Style Generalization for Instance-Level Sketch Retrieval",
        "abstract": "Zero-shot instance-level sketch retrieval addresses a practical retrieval scenario in which sketches from unseen categories during training serve as queries to retrieve matching RGB images. The core challenges of this task lie in two aspects: unknown category generalization and subjective style adaptation. Existing methods either focus solely on category generalization or apply simplistic style elimination techniques within a specific category, leading to suboptimal performance when both challenges are present. To this end, we propose the Dual-Attentive Prompt (DAP) method, which unifies category generalization and style adaptation into a single, interpretable framework. Central to DAP is a dual-attentive prompt composer, consisting of two self-attention-based modules. This composer dynamically integrates pre-learned category-specific knowledge with instance-specific prompts that adapt to sketch-specific styles. By cooperating with additional style alignment loss, the proposed method ensures robust generalization of unseen categories while mitigating the impact of subjective style variations. Extensive experimental results demonstrate the state-of-the-art performance of the proposed method. Additionally, some insights are provided into the challenges of traditional training processes when handling multi-style sketches, along with quantitative and qualitative evidence showing how the proposed approach effectively mitigates the negative impact of subjective style variations.",
        "doi": "10.1145/3726302.3730108",
        "sheridan_id": "fp0114",
        "position": 8,
        "track_id": 1,
        "slot_id": 18
      }
    },
    {
      "paper": {
        "hashed_id": "771e8cf06fa57452133bbb588d63bb9e",
        "title": "Graph-Enhanced Prompt Learning for Cross-Domain Contract Element Extraction",
        "abstract": "Cross-domain contract element extraction (CEE) aims to transfer knowledge from a source domain to facilitate the extraction of legally relevant elements (e.g., contract dates or payments) from contracts in a target domain. To achieve this goal, recent studies encode the domain-invariant relations between elements and legal clause types and enhance performance through bidirectional supervision between the CEE task and the clause classification task. However, two challenges remain unresolved\u2014(i) data sparsity due to expensive annotation costs and a large number of element types, and (ii) label discrepancies among element types across domains, both of which severely impede effective knowledge transfer from the source to the target domain. Recent developments in prompt learning have shown promising performance in low-resource settings. Drawing inspiration from these advances, we propose a novel framework, graph-enhanced prompt learning (GEPL), for the cross-domain CEE task to address these challenges. GEPL includes two kinds of prompt: (i) instance-oriented prompts and (ii) label-oriented prompts. Given the input instances, instance-oriented prompts are automatically generated by retrieving relevant examples in the training data, providing auxiliary supervision to enhance the transfer process in low-resource scenarios. To mitigate label discrepancies across different domains, we identify relations among element types using mutual-information criteria and transform these into label-oriented prompt templates. On this basis, a multi-task training strategy is designed to simultaneously optimize the representations of the original input sentence and prompts, enabling GEPL to better understand the tasks and capture label relations in both source and target domains. Empirical results on cross-domain CEE datasets indicate that GEPL significantly outperforms state-of-the-art baselines. Moreover, extensive experiments reveal that GEPL achieves the state-of-the-art performance on cross-domain named entity recognition datasets and demonstrates a high level of generalizability. Our code is released at https://github.com/WZH-NLP/GEPL.",
        "doi": "10.1145/3715100",
        "sheridan_id": "TOIS-2024-0101.R1",
        "position": 54,
        "track_id": 2,
        "slot_id": 190
      }
    },
    {
      "paper": {
        "hashed_id": "c8ed21db4f678f3b13b9d5ee16489088",
        "title": "Revolutionizing Text-to-Image Retrieval as Autoregressive Token-to-Voken Generation",
        "abstract": "Text-to-image retrieval is a fundamental task in multimedia retrieval. Traditional studies have typically approached this task as a discriminative problem, matching the text and image via the cross-attention mechanism (one-tower framework) or in a common embedding space (two-tower framework). The one-tower framework excels in effectiveness but falls short in efficiency, whereas the two-tower framework is efficient but struggles to maintain competitive effectiveness. In this study, we aim to enhance both effectiveness and efficiency by transforming the text-to-image retrieval task into a token-to-voken generation problem, where fine-grained interactions are incorporated to improve effectiveness while maintaining high efficiency. Despite its potential advantages, this paradigm shift presents significant challenges: 1) misalignment with high-level semantics and 2) learning gap towards the retrieval target. To address the challenges, we propose AVG, which discretizes images into vokens while aligning with both the visual information and high-level semantics. Additionally, to bridge the learning gap between generative training and the retrieval target, AVG incorporates discriminative training to modify the learning direction during token-to-voken training. Experiments demonstrate that the benefits of paradigm innovation are realized: compared with the classical two-tower method, CLIP, AVG achieves the 7.53% relative effectiveness improvement and also 4\u00d7 efficiency improvement.",
        "doi": "10.1145/3726302.3730077",
        "sheridan_id": "fp0722",
        "position": 4,
        "track_id": 1,
        "slot_id": 18
      }
    },
    {
      "paper": {
        "hashed_id": "b056eb1587586b71e2da9acfe4fbd19e",
        "title": "Diffusion Augmented Retrieval: A Training-Free Approach to Interactive Text-to-Image Retrieval",
        "abstract": "Interactive Text-to-image retrieval (I-TIR) is an important enabler for a wide range of state-of-the-art services in domains such as e-commerce and education. However, current methods rely on finetuned Multimodal Large Language Models (MLLMs), which are costly to train and update, and exhibit poor generalizability. This latter issue is of particular concern, as: 1) finetuning narrows the pretrained distribution of MLLMs, thereby reducing generalizability; and 2) I-TIR introduces increasing query diversity and complexity. As a result, I-TIR solutions are highly likely to encounter queries and images not well represented in any training dataset. To address this, we propose leveraging Diffusion Models (DMs) for text-to-image mapping, to avoid finetuning MLLMs while preserving robust performance on complex queries. Specifically, we introduce Diffusion Augmented Retrieval (DAR), a framework that generates multiple intermediate representations via LLM-based dialogue refinements and DMs, producing a richer depiction of the user`s information needs. This augmented representation facilitates more accurate identification of semantically and visually related images. Extensive experiments on four benchmarks show that for simple queries, DAR achieves results on par with finetuned I-TIR models, yet without incurring their tuning overhead. Moreover, as queries become more complex through additional conversational turns, DAR surpasses finetuned I-TIR models by up to 7.61% in Hits@10 after ten turns, illustrating its improved generalization for more intricate queries.",
        "doi": "10.1145/3726302.3729950",
        "sheridan_id": "fp0749",
        "position": 5,
        "track_id": 1,
        "slot_id": 18
      }
    },
    {
      "paper": {
        "hashed_id": "4d5b995358e7798bc7e9d9db83c612a5",
        "title": "Rethinking Pseudo Word Learning in Zero-Shot Composed Image Retrieval: From an Object-Aware Perspective",
        "abstract": "Composed Image Retrieval (CIR) takes a composed query of a reference image and a text describing the user`s intention, with the aim to retrieve the target image under both conditions. Conventional CIR approaches heavily rely on massive annotated triplets, which often comes at a considerable cost. Zero-Shot CIR (ZS-CIR) offers a new solution that can perform diverse CIR tasks without training on the triplet datasets. The key to the ZS-CIR task is to make specified changes to specific objects in the reference image based on the text. Previous works utilize a projection module to map the reference image into single or multiple pseudo words. However, they are either only applicable to single-object scenarios, or naively convert entire image features into multiple pseudo words and fail to focus on the desired target objects specified by the text description. In this work, we rethink how to learn pseudo words based on the objects attended by the text and propose a Multi-Object Aware ZS-CIR framework (MOA). Specifically, a multi-object recognizer first recognizes valid objects in the reference image guided by a set of learnable object queries. Then, we devise an object filtering strategy, which utilizes contextual prompts comprised of noun categories to guide the model in precisely screening out the objects that need to be modified. Finally, the pseudo word learning branch adaptively converts the screened objects into multiple pseudo words for accurate ZS-CIR. Although simple, our MOA consistently outperforms previous state-of-the-art methods across diverse benchmarks and even achieves competitive results with many supervised methods.",
        "doi": "10.1145/3726302.3730074",
        "sheridan_id": "fp0835",
        "position": 1,
        "track_id": 1,
        "slot_id": 18
      }
    },
    {
      "paper": {
        "hashed_id": "b6d767d2f8ed5d21a44b0e5886680cb9",
        "title": "Beyond General Alignment: Fine-Grained Entity-Centric Image-Text Matching with Multimodal Attentive Experts",
        "abstract": "Recent progress in aligning images with texts has achieved remarkable results, however, existing models tend to serve general queries and often fall short when dealing with detailed query requirements. In this paper, we work towards \\textbf{E}ntity-centric \\textbf{I}mage-\\textbf{T}ext \\textbf{M}atching (EITM), a finer-grained image-text matching task that aligns texts and images centered around specific entities. The main challenge in EITM lies in bridging the substantial semantic gap between entity-related information in texts and images, which is more pronounced than in general image-text matching problems. To address this challenge, we adopt CLIP as our foundational model and devise a Multimodal Attentive Experts (MMAE)-based contrastive learning to adapt CLIP into an expert for EITM problem. Particularly, the core of our multimodal attentive experts learning is to generate explanation texts by Large Language Models (LLMs) as bridging clues. In specific, we first employ off-the-shelf LLMs to generate explanatory text. This text, along with the original image and text, is then fed into our Multimodal Attentive Experts module to narrow the semantic gap within a unified semantic space. Upon the enriched feature representations generated by MMAE, we have further developed an effective Gated Integrative Image-text Matching (GI-ITM) strategy. GI-ITM utilizes an adaptive gating mechanism to combine features from MMAE, followed by applying image-text matching constraints to enhance the alignment precision. Our method has been extensively evaluated on three social media news benchmarks: N24News, VisualNews, and GoodNews. The experimental results demonstrate that our approach significantly outperforms competing methods. Our code is available at: \\url{https://github.com/wangyxxjtu/ETE}.",
        "doi": "10.1145/3726302.3729902",
        "sheridan_id": "fp0022",
        "position": 2,
        "track_id": 1,
        "slot_id": 18
      }
    },
    {
      "paper": {
        "hashed_id": "2afe4567e1bf64d32a5527244d104cea",
        "title": "FiRE: Enhancing MLLMs with Fine-Grained Context Learning for Complex Image Retrieval",
        "abstract": "Due to their strong generalizable multimodal processing and reasoning capabilities, Multimodal Large Language Models (MLLMs) have demonstrated significant potential as universal image retrievers, effectively addressing diverse real-world image retrieval tasks. Nevertheless, pioneering studies, while promising, overlook the potential of fine-grained context modeling and disentangled fine-tuning objectives in enhancing MLLMs` retrieval performance, particularly for complex tasks such as long-text-to-image retrieval, visual dialog retrieval, and composed image retrieval (CIR).Therefore, in this work,  we propose an automated fine-grained multimodal quintuple dataset construction pipeline and a novel two-stage fine-grained multimodal fine-tuning strategy.  The dataset generation pipeline produces a comprehensive CIR dataset with fine-grained image captions and modification text, facilitating fine-grained context modeling. Beyond the previously entangled fine-tuning paradigm, our approach separates the fine-tuning process into two distinct stages: (1) fine-grained context reasoning-oriented fine-tuning and (2) fine-grained retrieval-oriented fine-tuning. These stages aim to sequentially enhance the model`s context understanding and query-target alignment capabilities, thereby improving retrieval performance. Extensive experiments across five datasets encompassing diverse and complex image retrieval tasks demonstrate the remarkable superiority of our method over existing approaches in zero-shot retrieval settings, even with a more lightweight MLLM backbone compared to those methods.",
        "doi": "10.1145/3726302.3729979",
        "sheridan_id": "fp0719",
        "position": 3,
        "track_id": 1,
        "slot_id": 18
      }
    },
    {
      "paper": {
        "hashed_id": "d1ca3aaf52b41acd68ebb3bf69079bd1",
        "title": "TEST PAPER",
        "abstract": "TEST PAPER",
        "doi": "10.1145/3726302.3730125",
        "sheridan_id": "tst10000000",
        "position": 0,
        "track_id": 1,
        "slot_id": 0
      }
    },
    {
      "paper": {
        "hashed_id": "6a9aeddfc689c1d0e3b9ccc3ab651bc5",
        "title": "A Knowledge Extraction Framework on Cyber Threat Reports with Enhanced Security Profiles",
        "abstract": "Knowledge extraction on Cyber Threat Reports (CTRs) is critical for attack investigation and defenses. The granularity and the usability of the knowledge are key issues: the former is determined by entity recognition on CTRs, whereas the latter mainly depends on proper relation extraction. Nevertheless, in the state-of-the-art entity recognition methods on CTRs using span representation, the local semantics of behavior are not considered and the sequential features of entity labels within behavior descriptions are not utilized. Besides, domain-specific definitions/forms of the relation types and knowledge representations are also crucial for effective utilization of knowledge. In this paper, we propose a novel knowledge extraction framework on CTRs to address the above concerns. The framework is formed by the Enhanced Security Profiles (ESP) that can be directly utilized by security detection devices. In the ESP framework, we propose 3 modules to facilitate fine-grained and accurate knowledge extractions: (1) The entity recognition module utilizes a label-aware subsequence autoregressive algorithm to integrate local semantic and label sequence features, enabling accurate identification of cybersecurity entities; (2) The relation extraction module employs LLM-based strategies with shared partition representations to enhance semantic understanding and domain relevance; and (3) The security profile generation module leverages Chain-of-Thought reasoning and In-Context Learning to produce machine-readable rules executable in security detection systems. Extensive experiments on 6 datasets demonstrate that the ESP framework largely outperform the state-of-the-art solutions e.g., the Micro-Fl scores on entity recognition and relation extraction are at least 1.54% and 13.12% better, respectively. Our code can be found in https://github.com/YxinMiracle/ESP.",
        "doi": "10.1145/3726302.3729880",
        "sheridan_id": "fp0282",
        "position": 3,
        "track_id": 1,
        "slot_id": 10
      }
    },
    {
      "paper": {
        "hashed_id": "d2ddea18f00665ce8623e36bd4e3c7c5",
        "title": "LIGHT: Enhancing Learning Path Recommendation via Knowledge Topology-Aware Sequence Optimization",
        "abstract": "Learning path recommendation (LPR) aims to provide individualized and effective learning item routes by modeling learners\u2019 learning histories and goals, which has been widely considered a essential task in the field of personalized education. Indeed, considerable research efforts have been dedicated to this direction in recent years, focusing on step-based and sequence-based modeling approaches. However, most of existing studies overlook the complementarity between explicit and implicit relationships among knowledge concepts, while failing to harmonize static knowledge structures with dynamic path generation. To this end, in this paper, we propose LIGHT, a knowLedge topology-aware sequence optImization model for enhancing learninG patH recommendaTion. Specifically, we first construct a composite concept graph that incorporates explicit prerequisite relationships and implicit collaborative relationships, achieved by mining interaction statistics and collaborative signals from learners\u2019 learning processes. Next, we design a complementary contrastive fusion module to fully capture the interplay between the two relational views of concepts through graph structure learning and contrastive constraints, which enhances the effectiveness of the learned representations. Following this, we introduce a knowledge topology-aware modeling module that integrates structural semantics clustering with candidate path sampling. Finally, we develop a bidirectional sensing path optimization network to deeply model and optimize the sampled paths from a sequential perspective, thereby enhancing modeling efficiency while preserving structural semantics. Extensive experiments on three real-world educational datasets clearly demonstrate the effectiveness of the proposed LIGHT model in the LPR task.",
        "doi": "10.1145/3726302.3730022",
        "sheridan_id": "fp0073",
        "position": 8,
        "track_id": 1,
        "slot_id": 10
      }
    },
    {
      "paper": {
        "hashed_id": "54072f485cdb7897ebbcaf7525139561",
        "title": "Interpretable Knowledge Tracing with Difficulty-Aware Attention and Selective State Space Model",
        "abstract": "Knowledge Tracing (KT) aims to model students` knowledge states based on their historical learning sequence, playing a critical role in online education platforms. As the performance of sequence-based KT methods continues to improve, their increasing model complexity and lack of transparency have become significant limitations. In contrast, educational theory-driven KT methods incorporate educationally meaningful features (such as question difficulty or time spent on questions) to enhance interpretability and performance. However, these models typically adopt simpler structures to reduce complexity and avoid overfitting, which limits their ability to effectively capture the sequential characteristics of learning compared to sequence-based methods. To address these limitations, this paper aims to integrate the strengths of both types of methods by proposing an Interpretable KT approach with Difficulty-Aware Attention and Selective State Space Model (ASIKT). Specifically, leveraging educational context, we design a difficulty-enhanced attention mechanism to model students` knowledge retrieval process at a fine-grained level without introducing additional parameters. Moreover, we employ selective state space model to capture the dynamic evolution of students` knowledge states based on their historical performance, ensuring both efficiency and simplicity in the model. Experimental results on four real-world datasets demonstrate that ASIKT outperforms state-of-the-art KT methods, achieving superior predictive performance. Additionally, ASIKT provides explanations for its predictions from multiple perspectives, showcasing strong interpretability. The code can be found at https://github.com/mrsser/ASIKT.",
        "doi": "10.1145/3726302.3730012",
        "sheridan_id": "fp1411",
        "position": 2,
        "track_id": 1,
        "slot_id": 10
      }
    },
    {
      "paper": {
        "hashed_id": "3c7781a36bcd6cf08c11a970fbe0e2a6",
        "title": "Enhancing the Patent Matching Capability of Large Language Models via the Memory Graph",
        "abstract": "Intellectual Property (IP) management involves strategically protecting and utilizing intellectual assets to enhance organizational innovation, competitiveness, and value creation. Patent matching is a crucial task in intellectual property management, which facilitates the organization and utilization of patents. Existing models often rely on the emergent capabilities of Large Language Models (LLMs) and leverage them to identify related patents directly. However, these methods usually depend on matching keywords and overlook the hierarchical classification and categorical relationships of patents. In this paper, we propose MemGraph, a method that augments the patent matching capabilities of LLMs by incorporating a memory graph derived from their parametric memory. Specifically, MemGraph prompts LLMs to traverse their memory to identify relevant entities within patents, followed by attributing these entities to corresponding ontologies. After traversing the memory graph, we utilize extracted entities and ontologies to improve the capability of LLM in comprehending the semantics of patents. Experimental results on the PatentMatch dataset demonstrate the effectiveness of MemGraph, achieving a 17.68% performance improvement over baseline LLMs. The further analysis highlights the generalization ability of MemGraph across various LLMs, both in-domain and out-of-domain, and its capacity to enhance the internal reasoning processes of LLMs during patent matching. All data and codes are available at https://github.com/NEUIR/MemGraph.",
        "doi": "10.1145/3726302.3729970",
        "sheridan_id": "fp0424",
        "position": 4,
        "track_id": 1,
        "slot_id": 10
      }
    },
    {
      "paper": {
        "hashed_id": "674186b8c66a85578d54f339a58ca3cf",
        "title": "Structure-Aware Conversational Legal Case Retrieval",
        "abstract": "Legal case retrieval is an important task in information retrieval that aims to retrieve relevant cases for given query cases. Conversational search paradigms have been shown to improve the search experience in legal case retrieval. However, there are two challenges in applying conversational search to legal scenarios. Firstly, legal search conversations often focus on different parts of legal case documents, but existing models struggle to capture the complex structural information and extract accurate relevance signals. Secondly, collecting large-scale conversational search datasets is costly, making it difficult to build reliable conversational legal case retrieval models. To address these challenges, we propose a Structure-Aware Matching Model (SAMM) for conversational legal case retrieval. SAMM extracts matching signals between conversational utterances and segments of the legal cases to incorporate structural information. We decouple the conversational search task into three subtasks and design pre-training tasks to overcome the lack of training data. Additionally, we create ConvLegal, the largest conversational legal case retrieval dataset to the best of our knowledge, for better evaluation of different methods. We train and evaluate SAMM and baselines on both a public dataset (CLCR) and ConvLegal. Experimental results demonstrate that SAMM outperforms existing models in legal case retrieval and conversational search.",
        "doi": "10.1145/3711854",
        "sheridan_id": "TOIS-2023-0463.R2",
        "position": 7,
        "track_id": 2,
        "slot_id": 10
      }
    },
    {
      "paper": {
        "hashed_id": "16ba72172e6a4f1de54d11ab6967e371",
        "title": "Meta-Learning for Incomplete Multimodal Sentiment Analysis",
        "abstract": "Modality incompleteness is a critical yet underexplored challenge in multimodal sentiment analysis (MSA). Existing efforts, trained and evaluated under fixed missing rates, struggle to adapt to real-world scenarios with varying missing rates. To address this, we propose the Missing Modality Adaptation Framework (M2AF), leveraging model-agnostic meta-learning to enhance robustness against different levels of modality incompleteness. M2AF operates in two stages: meta-training and meta-testing. In the meta-training stage, a pre-trained MSA model, initially optimized for fixed missing rates, is further adapted to different levels of missing rates\u2014low, moderate, and high. In the meta-testing stage, the model rapidly updates its parameters using minimal training data to handle target missing scenarios. Experiments on two popular datasets demonstrate that M2AF significantly improves the performance and generalization of various MSA models, ensuring more robust sentiment analysis in real-world settings with different modality incompleteness.",
        "doi": "10.1145/3726302.3730231",
        "sheridan_id": "sp2063",
        "position": 36,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "54ff9e9e3a2ec0300d4ce11261f5169f",
        "title": "Evaluating Contrastive Feedback for Effective User Simulations",
        "abstract": "The use of Large Language Models (LLMs) for simulating user behavior in the domain of Interactive Information Retrieval has recently gained significant popularity. However, their application and capabilities remain highly debated and understudied. This study explores whether the underlying principles of contrastive training techniques, which have been effective for fine-tuning LLMs, can also be applied beneficially in the area of prompt engineering for user simulations. Previous research has shown that LLMs possess comprehensive world knowledge, which can be leveraged to provide accurate estimates of relevant documents. This study attempts to simulate a knowledge state by enhancing the model with additional implicit contextual information gained during the simulation. This approach enables the model to refine the scope of desired documents further. The primary objective of this study is to analyze how different modalities of contextual information influence the effectiveness of user simulations. Various user configurations were tested, where models are provided with summaries of already judged relevant, irrelevant, or both types of documents in a contrastive manner. The focus of this study is the assessment of the impact of the prompting techniques on the simulated user agent performance. We hereby lay the foundations for leveraging LLMs as part of more realistic simulated users.",
        "doi": "10.1145/3726302.3730189",
        "sheridan_id": "sp2080",
        "position": 38,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "884d247c6f65a96a7da4d1105d584ddd",
        "title": "MIDI-Zero: A MIDI-driven Self-Supervised Learning Approach for Music Retrieval",
        "abstract": "Content-based Music Retrieval (CBMR) is a fundamental task in music information retrieval, encompassing sub-tasks including Audio Identification, Audio Matching, and Version Identification. Traditional methods typically analyze audio signals or spectrograms to extract features related to rhythm, melody, harmony, and timbre. However, with the rapid development of Music Transcription and digital music technologies, MIDI representation has emerged as a powerful alternative for music analysis. In this paper, we propose MIDI-Zero, a novel self-supervised learning framework for CBMR that operates entirely on MIDI representations. Unlike existing approaches, MIDI-Zero requires no external training data; all training data is automatically generated based on predefined task rules, eliminating the need for labeled datasets or external music collections. MIDI-Zero is designed to handle both symbolic music data and audio-based tasks by leveraging Music Transcription models. Its strong robustness ensures effectiveness even with low-quality transcriptions. Extensive experiments demonstrate that MIDI-Zero achieves competitive performance across various CBMR sub-tasks, particularly excelling in Audio Matching. Our approach simplifies the feature extraction process, bridges the gap between audio and symbolic music representations, and offers a versatile and scalable solution for music retrieval.",
        "doi": "10.1145/3726302.3730034",
        "sheridan_id": "fp0650",
        "position": 5,
        "track_id": 1,
        "slot_id": 10
      }
    },
    {
      "paper": {
        "hashed_id": "e069ea4c9c233d36ff9c7f329bc08ff1",
        "title": "Unlearning for Federated Online Learning to Rank: A Reproducibility Study",
        "abstract": "This paper reports on findings from a comparative study on the effectiveness and efficiency of federated unlearning strategies within Federated Online Learning to Rank (FOLTR), with specific attention to systematically analysing the unlearning capabilities of methods in a verifiable manner. Federated approaches to ranking of search results have recently garnered attention to address users privacy concerns. In FOLTR, privacy is safeguarded by collaboratively training ranking models across decentralized data sources, preserving individual user data while optimizing search results based on implicit feedback, such as clicks.Recent legislation introduced across numerous countries is establishing the so called ``\\emph{the right to be forgotten}``, according to which services based on machine learning models like those in FOLTR should provide capabilities that allow users to remove their own data from those used to train models. This has sparked the development of unlearning methods, along with evaluation practices to measure whether unlearning of a user data successfully occurred. Current evaluation practices are however often controversial, necessitating the use of multiple metrics for a more comprehensive assessment -- but previous proposals of unlearning methods only used single evaluation metrics. This paper addresses this limitation: our study rigorously assesses the effectiveness of unlearning strategies in managing both under-unlearning and over-unlearning scenarios using adapted, and newly proposed evaluation metrics.Thanks to our detailed analysis, we uncover the strengths and limitations of five unlearning strategies, offering valuable insights into optimizing federated unlearning to balance data privacy and system performance within FOLTR. We publicly release our code and complete results at \\url{https://github.com/Iris1026/Unlearning-for-FOLTR.git}.",
        "doi": "10.1145/3726302.3730336",
        "sheridan_id": "rr2297",
        "position": 3,
        "track_id": 6,
        "slot_id": 6
      }
    },
    {
      "paper": {
        "hashed_id": "c5a4e7e6882845ea7bb4d9462868219b",
        "title": "Variations in Relevance Judgments and the Shelf Life of Test Collections",
        "abstract": "The fundamental property of Cranfield-style evaluations, that system rankings are stable even when assessors disagree on individual relevance decisions, was validated on traditional test collections. However, the paradigm shift towards neural retrieval models affected the characteristics of modern test collections, e.g., documents are short, judged with four grades of relevance, and information needs have no descriptions or narratives. Under these changes, it is unclear whether assessor disagreement remains negligible for system comparisons. We investigate this aspect under the additional condition that the few modern test collections are heavily re-used. Given more possible query interpretations due to less formalized information needs, an ``expiration date`` for test collections might be needed if top-effectiveness requires overfitting to a single interpretation of relevance. We run a reproducibility study and re-annotate the relevance judgments of the 2019~TREC Deep Learning track. We can reproduce prior work in the neural retrieval setting, showing that assessor disagreement does not affect system rankings. However, we observe that some models substantially degrade with our new relevance judgments, and some have already reached the effectiveness of humans as rankers, providing evidence that test collections can expire.",
        "doi": "10.1145/3726302.3730308",
        "sheridan_id": "rr1993",
        "position": 5,
        "track_id": 6,
        "slot_id": 6
      }
    },
    {
      "paper": {
        "hashed_id": "f80bf05527157a8c2a7bb63b22f49aaa",
        "title": "A Worrying Reproducibility Study of Intent-Aware Recommendation Models",
        "abstract": "Lately, we have observed a growing interest in intent-aware recommender systems (IARS). The promise of such systems is that they are capable of generating better recommendations by predicting and considering the underlying motivations and short-term goals of consumers. From a technical perspective, various sophisticated neural models were recently proposed in this emerging and promising area. In the broader context of complex neural recommendation models, a growing number of research works unfortunately indicates that (i) reproducing such works is often difficult and (ii) that the true benefits of such models may be limited in reality, e.g., because the reported improvements were obtained through comparisons with untuned or weak baselines. In this work, we investigate if recent research in IARS is similarly affected by such problems. Specifically, we tried to reproduce five contemporary IARS models that were published in top-level outlets, and we benchmarked them against a number of traditional non-neural recommendation models.  In two of the cases, running the provided code with the optimal hyperparameters reported in the paper did not yield the results reported in the paper. Worryingly, we find that all examined IARS approaches are consistently outperformed by at least one traditional model. These findings point to sustained methodological issues and to a pressing need for more rigorous scholarly practices.",
        "doi": "10.1145/3726302.3730307",
        "sheridan_id": "rr1980",
        "position": 8,
        "track_id": 6,
        "slot_id": 6
      }
    },
    {
      "paper": {
        "hashed_id": "1b5230e3ea6d7123847ad55a1e06fffd",
        "title": "Reassessing the Effectiveness of Reinforcement Learning based Recommender Systems for Sequential Recommendation",
        "abstract": "Over the past few years, researchers have explored the use of reinforcement learning (RL) for sequential recommendation problems. However, since RL techniques commonly target at optimizing long-term rewards, it is surprising that RL-based models are reported to be competitive with traditional supervised models when evaluated under the myopic next-item prediction protocol. A recent study suggests that reported performance gains of combining RL with supervised learning techniques, as done in the Self-Supervised Q-Learning (SQN) framework, may actually not come from learning an optimal policy, but that the RL component helps to learn embeddings that encode the users` past interactions. Given these observations, we aimed to reassess the performance of RL-enhanced sequential recommendations in the SQN framework. While we were able to reproduce the results reported in the respective papers, we found that properly-tuned supervised learning models like GRU4Rec substantially outperform the proposed RL-models from the literature. Our analyses furthermore revealed that there is a significant inconsistency in terms of evaluation protocols in the literature, and that the use of third-party implementations of existing models may lead to unreliable conclusions. Overall, still more research and alternative evaluation schemes seem required to fully leverage the power of RL for sequential recommendation tasks.",
        "doi": "10.1145/3726302.3730322",
        "sheridan_id": "rr2119",
        "position": 4,
        "track_id": 6,
        "slot_id": 6
      }
    },
    {
      "paper": {
        "hashed_id": "5352696a9ca3397beb79f116f3a33991",
        "title": "Replication and Exploration of Generative Retrieval over Dynamic Corpora",
        "abstract": "Generative retrieval (GR) has emerged as a promising paradigm in information retrieval (IR). However, most existing GR models are developed and evaluated using a static document collection, and their performance in dynamic corpora where document collections evolve continuously is rarely studied. In this paper, we first reproduce and systematically evaluate various representative GR approaches over dynamic corpora. Through extensive experiments, we reveal that existing GR models with text-based docids show superior generalization to unseen documents. We observe that the more fine-grained the docid design in the GR model, the better its performance over dynamic corpora, surpassing BM25 and even being comparable to dense retrieval methods. While GR models with numeric-based docids show high efficiency, their performance drops significantly over dynamic corpora.  Furthermore, our experiments find that the underperformance of numeric-based docids is partly due to their excessive tendency toward the initial document set, which likely results from overfitting on the training set. We then conduct an in-depth analysis of the best-performing GR methods. We identify three critical advantages of text-based docids in dynamic corpora: (i) Semantic alignment with language models` pretrained knowledge, (ii) Fine-grained docid design, and (iii) High lexical diversity. Building on these insights, we finally propose a novel multi-docid design that leverages both the efficiency of numeric-based docids and the effectiveness of text-based docids, achieving improved performance in dynamic corpus without requiring additional retraining. Our work offers empirical evidence for advancing GR methods over dynamic corpora and paves the way for developing more generalized yet efficient GR models in real-world search engines.",
        "doi": "10.1145/3726302.3730314",
        "sheridan_id": "rr2032",
        "position": 2,
        "track_id": 6,
        "slot_id": 6
      }
    },
    {
      "paper": {
        "hashed_id": "db116b39f7a3ac5366079b1d9fe249a5",
        "title": "Interpreting Multilingual and Document-Length Sensitive Relevance Computations in Neural Retrieval Models through Axiomatic Causal Interventions",
        "abstract": "This reproducibility study analyzes and extends the paper ``Ax- iomatic Causal Interventions for Reverse Engineering Relevance Computation in Neural Retrieval Models,`` which investigates how neural retrieval models encode task-relevant properties such as term frequency. We reproduce key experiments from the original paper, confirming that information on query terms is captured in the model encoding. We extend this work by applying activa- tion patching to Spanish and Chinese datasets and by exploring whether document-length information is encoded in the model as well. Our results confirm that the designed activation patching method can isolate the behavior to specific components and to- kens in neural retrieval models. Moreover, our findings indicate that the location of term frequency generalizes across languages and that in later layers, the information for sequence-level tasks is represented in the CLS token. The results highlight the need for further research into interpretability in information retrieval and reproducibility in machine learning research. Our code is available at https://github.com/OliverSavolainen/axiomatic-ir-reproduce.",
        "doi": "10.1145/3726302.3730327",
        "sheridan_id": "rr2209",
        "position": 7,
        "track_id": 6,
        "slot_id": 13
      }
    },
    {
      "paper": {
        "hashed_id": "58a2fc6ed39fd083f55d4182bf88826d",
        "title": "Invariance Matters: Empowering Social Recommendation via Graph Invariant Learning",
        "abstract": "Graph-based social recommender systems have demonstrated great potential in alleviating data sparsity by leveraging high-order user influence embedded in social networks. However, most existing methods rely heavily on the observed social graph, which is often noisy and includes spurious or task-irrelevant connections that can mislead user preference learning. Identifying and removing these noisy relations is crucial but challenging due to the lack of ground-truth annotations. In this paper, we approach the social denoising problem from the perspective of graph invariant learning and propose a novel approach, Social Graph Invariant Learning(SGIL). Specifically, SGIL aims to uncover stable user preferences within the input social graph, thereby enhancing the robustness of graph-based social recommendation systems. To achieve this goal, SGIL first simulates multiple noisy social environments through graph generators. It then seeks to learn environment-invariant user preferences by minimizing invariant risk across these environments. To further promote diversity in the generated social environments, we employ an adversarial training strategy to simulate more potential social noisy distributions. Extensive experimental results demonstrate the effectiveness of the proposed SGIL. The code is available at https://github.com/yimutianyang/SIGIR2025-SGIL.",
        "doi": "10.1145/3726302.3730013",
        "sheridan_id": "fp0192",
        "position": 4,
        "track_id": 1,
        "slot_id": 2
      }
    },
    {
      "paper": {
        "hashed_id": "b5b41fac0361d157d9673ecb926af5ae",
        "title": "Hypercomplex Knowledge Graph-Aware Recommendation",
        "abstract": "Knowledge graphs (KGs) consist of well-organized external information and have been proven to enhance recommendation quality effectively. Most KG-aware recommender systems are developed using real number space embeddings. In recent years, learning representations in the hypercomplex space has gained success and attention. Compared to single-component real-valued vectors, multi-component hypercomplex embeddings offer greater expressiveness, facilitating more meaningful modeling of users, items, entities, and their relations in the user-item interaction graph and KG. In this paper, we explore the integration of hypercomplex algebras in KG-aware recommendation and propose a Hypercomplex Knowledge Graph-aware Recommender (HKGR) method. Our HKGR models the interaction graph and KG in the hypercomplex space by utilizing specially designed hypercomplex graph neural networks. In particular, HKGR employs a hypercomplex attention-based aggregator to capture the structure and semantics of the KG. In the recommendation prediction phase, we design a hypercomplex interaction network that can approximate the high-order component interactions between users and items. Furthermore, we introduce a hypercomplex contrastive learning operator to strengthen cooperative signals between the interaction graph and KG modelings. Experiment results on the four real-world datasets show that our HKGR outperforms the state-of-the-art recommender baselines.",
        "doi": "10.1145/3726302.3730001",
        "sheridan_id": "fp0502",
        "position": 2,
        "track_id": 1,
        "slot_id": 2
      }
    },
    {
      "paper": {
        "hashed_id": "2050e03ca119580f74cca14cc6e97462",
        "title": "CORONA: A Coarse-to-Fine Framework for Graph-based Recommendation with Large Language Models",
        "abstract": "Recommender systems (RSs) are designed to retrieve candidate items a user might be interested in from a large pool, with a typical approach being the use of graph neural networks (GNNs) to capture high-order interaction relationships. As large language models (LLMs) have demonstrated remarkable success across various domains, researchers are exploring ways to apply their capabilities for improving recommendation performance. However, existing work limits the use of LLMs to either re-ranking recommendation results of traditional RSs or pre-processing the datasets as data augmenters. Both lines of work failed to explore LLMs` capabilities during the filtering process of candidate items, which may lead to suboptimal performance. Instead, we propose to leverage LLMs` reasoning abilities during the candidate filtering process, and introduce Chain Of Retrieval ON grAphs (CORONA) to progressively narrow down the range of candidate items on interaction graphs with the help of LLMs: (1) First, LLM performs preference reasoning based on user profiles, with the response serving as a query to extract relevant users and items from the interaction graph as preference-assisted retrieval ; (2) Then, using the information retrieved in the previous step along with the purchase history of target user, LLM conducts intent reasoning to help refine an even smaller interaction subgraph as intent-assisted retrieval ; (3) Finally, we employ a GNN to capture high-order collaborative filtering information from the extracted subgraph, performing GNN-enhanced retrieval to generate the final recommendation results. The proposed framework leverages the reasoning capabilities of LLMs during the retrieval process, while seamlessly integrating GNNs to enhance overall recommendation performance. Extensive experiments on various datasets and settings demonstrate that our proposed CORONA achieves state-of-the-art (SOTA) performance with an 18.6% relative improvement in recall and an 18.4% relative improvement in NDCG on average. Our code is available on GitHub at https://github.com/BUPT-GAMMA/CORONA.",
        "doi": "10.1145/3726302.3729937",
        "sheridan_id": "fp0473",
        "position": 5,
        "track_id": 1,
        "slot_id": 2
      }
    },
    {
      "paper": {
        "hashed_id": "ec5aa0b7846082a2415f0902f0da88f2",
        "title": "Bridging Short Videos and Streamers with Multi-Graph Contrastive Learning for Live Streaming Recommendation",
        "abstract": "Recently, live streaming services have seen a surge in popularity, prompting many platforms to offer both short video and live streaming services to meet the diverse needs of users and streamers. This has resulted in a close connection between short videos and live streaming within these platforms. Incorporating short video data into live streaming recommendation through cross-domain approaches can effectively mitigate the sparsity of live streaming gifting data. However, existing cross-domain recommendation methods primarily focus on transferring information across domains through overlapping users or items, while overlooking the strong connection between non-overlapping short videos and streamers. In this paper, we propose MGCCDR, a Multi-Graph Contrastive learning framework for Cross-Domain Recommendation, which leverages both overlapping users and non-overlapping items to enhance information transfer. Specifically, we first learn global representations from a global graph to establish connections between streamers and short videos. Subsequently, we construct three bipartite graphs among users, authors, and videos and introduce multi-graph learning to capture preferences within the target domain view, the source domain view, and the cross-domain view. Additionally, to address the varying contributions of each graph to the final recommendation task, we design an attention-based method to effectively integrate these representations, facilitating the information aggregation across domains. Extensive experiments on both commercial and public datasets demonstrate that our MGCCDR significantly outperforms the state-of-the-art methods.",
        "doi": "10.1145/3726302.3729914",
        "sheridan_id": "fp0997",
        "position": 1,
        "track_id": 1,
        "slot_id": 2
      }
    },
    {
      "paper": {
        "hashed_id": "3dd48ab31d016ffcbf3314df2b3cb9ce",
        "title": "Distributionally Robust Optimization for Unbiased Learning to Rank",
        "abstract": "Unbiased learning to rank (ULTR), which utilizes historical click logs to train ranking models, has attracted much attention in the IR community. Previous studies on ULTR have focused on mitigating a variety of biases in click logs, such as position bias, trust bias, and presentation bias, to recover the true relevance of the query-document pairs. However, they overlooked the intrinsic distribution shifts between the training data and test data. In this paper, we first validate and analyze the distribution shift problem with a real-world ULTR dataset. To solve this problem, we propose distributionally robust unbiased learning to rank (DRO-ULTR) methods. Specifically, we design two kinds of group distributionally robust optimization (group-DRO) frameworks for the existing ULTR methods, one using the pointwise click prediction loss and the other using the listwise counterfactual ranking loss. Finally, we empirically verify the effectiveness of our DRO-ULTR methods by conducting extensive experiments on the real-world dataset.",
        "doi": "10.1145/3726302.3729954",
        "sheridan_id": "fp0341",
        "position": 4,
        "track_id": 1,
        "slot_id": 29
      }
    },
    {
      "paper": {
        "hashed_id": "cf67355a3333e6e143439161adc2d82e",
        "title": "Zero-Shot Reranking with Large Language Models and Precomputed Ranking Features: Opportunities and Limitations",
        "abstract": "LLMs have been explored for their use in IR as end-to-end rankers, rerankers and assessors. Recently, the exploration of the prompt-and-predict paradigm for reranking in combination with highly performant LLMs have drawn the attention of researchers. Instead of training or fine-tuning a reranker, LLMs are prompted in a zero-shot manner to produce relevance scores, pairwise preferences, or reranked lists.Existing research, though, has been confined to \\emph{unstructured} text corpora, leaving a gap in our understanding: to what extent do the findings of zero-shot LLM rerankers established on plain text corpora hold for datasets containing predominantly precomputed ranking features as is common in industrial settings? We explore this question via an empirical study on one public learning-to-rank dataset (MSLR-WEB10K) and two datasets collected from an audio streaming platform`s search logs. Our results paint a differentiated picture: \\emph{On average}, there remains a significant performance gap: prompting the high-capacity LLM GPT-4 results in up to 16\\% lower NDCG@10 compared to the traditional supervised learning-to-rank (LTR) approach LambdaMART on the public MSLR-WEB10K dataset. However, when focusing \\emph{only} on a subset of hard queries---i.e. queries where the LTR approach ranks a non-relevant document at the top---the zero-shot LLM reranking outperforms the LTR baseline. We confirm the same trends on two proprietary audio search datasets. We also provide insights into prompt design choices and their impact on LLM reranking. We show that LLMs remain brittle, with the same strategies sometimes helping or hurting depending on the model size and dataset.",
        "doi": "10.1145/3726302.3730119",
        "sheridan_id": "fp0520",
        "position": 5,
        "track_id": 1,
        "slot_id": 29
      }
    },
    {
      "paper": {
        "hashed_id": "8d9fc2308c8f28d2a7d2f6f48801c705",
        "title": "Fact Verification in Knowledge Graphs Using LLMs",
        "abstract": "Automated fact-checking systems often struggle with trustworthiness, as they lack transparency in their reasoning processes and fail to handle relationships in data.  This work presents FactCheck, a fact verification system topped by a web platform that shows how Large Language Models (LLMs) can be collectively used to verify facts within Knowledge Graphs (KGs).  While the underlying verification engine implements a system that combines Retrieval Augmented Generation (RAG) with an ensemble of LLMs to validate KG facts, the platform focuses on making the results of this complex process as transparent and accessible as possible.  Users can explore how different models interpret the same evidence, compare their reasoning patterns, and understand the factors that lead to the final verification result. The platform supports technical users who want to analyze the model behavior and general users who need to verify whether the facts in the dataset are correct.",
        "doi": "10.1145/3726302.3730142",
        "sheridan_id": "de1797",
        "position": 6,
        "track_id": 10,
        "slot_id": 104
      }
    },
    {
      "paper": {
        "hashed_id": "8562ae5e286544710b2e7ebe9858833b",
        "title": "Nugget-based Annotation Protocol and Tool For Evaluating Long-form Retrieval-Augmented Generation",
        "abstract": "Retrieval-augmented generation (RAG) summarizes retrieved documents into a text passage that fulfills the information need expressed by the user. Such generated responses should faithfully distill the relevant information and provide sufficient attribution back to the source documents. Nugget-based evaluation was proposed for text summarization and has been adapted to evaluate RAG output in recent shared tasks such as 2024 TREC RAG, BioGen, and NeuCLIR tracks. However, annotating such detailed and nuanced information is complex and errorful. Multiple pieces of information need to be labeled, extracted, linked, and cross-referenced. In this work, we present an annotation protocol and tool tailored to collecting information for evaluating RAG systems. Our tool has four steps: nugget creation, nugget revision, document support assessment, and finally, nugget alignment. Each step aims to minimize the annotator`s cognitive load, improving the efficiency and reliability.",
        "doi": "10.1145/3726302.3730156",
        "sheridan_id": "de1934",
        "position": 9,
        "track_id": 10,
        "slot_id": 104
      }
    },
    {
      "paper": {
        "hashed_id": "2290a7385ed77cc5592dc2153229f082",
        "title": "Breaking the Lens of the Telescope: Online Relevance Estimation over Large Retrieval Sets",
        "abstract": "Advanced relevance models, such as those that use large language models (LLMs), provide highly accurate relevance estimations. However, their computational costs make them infeasible for processing large document corpora. To address this, retrieval systems often employ a telescoping approach, where computationally efficient but less precise lexical and semantic retrievers filter potential candidates for further ranking. However, this approach heavily depends on the quality of early-stage retrieval, which can potentially exclude relevant documents early in the process. In this work, we propose a novel paradigm for re-ranking called online relevance estimation that continuously updates relevance estimates for a query throughout the ranking process. Instead of re-ranking a fixed set of top-k documents in a single step, online relevance estimation iteratively re-scores smaller subsets of the most promising documents while adjusting relevance scores for the remaining pool based on the estimations from the final model using an online bandit-based algorithm. This dynamic process mitigates the recall limitations of telescoping systems by re-prioritizing documents initially deemed less relevant by earlier stages--including those completely excluded by earlier-stage retrievers. We validate our approach on TREC benchmarks under two scenarios: hybrid retrieval and adaptive retrieval. Experimental results demonstrate that our method is sample-efficient and significantly improves recall, highlighting the effectiveness of our online relevance estimation framework for modern search systems.",
        "doi": "10.1145/3726302.3729910",
        "sheridan_id": "fp1064",
        "position": 1,
        "track_id": 1,
        "slot_id": 29
      }
    },
    {
      "paper": {
        "hashed_id": "be83ab3ecd0db773eb2dc1b0a17836a1",
        "title": "Learning to Rank with Variable Result Presentation Lengths",
        "abstract": "Learning to Rank (LTR) methods generally assume that each document in a top-K ranking is presented in an equal format. However, previous work has shown that users` perceptions of relevance can be changed by varying presentations, i.e., allocating more vertical space to some documents to provide additional textual or image information. Furthermore, presentation length can also redirect attention, as users are more likely to notice longer presentations when scrolling through results. Deciding on the document presentation lengths in a fixed vertical space ranking is an important problem that has not been addressed by existing LTR methods. We address this gap by introducing the variable presentation length ranking task, where simultaneously the ordering of documents and their presentation length is decided. Despite being a generalization of standard ranking, we show that this setting brings significant new challenges: Firstly, the probability ranking principle no longer applies to this setting, and secondly, the problem cannot be divided into separate ordering and length selection tasks. We therefore propose VLPL -- a new family of Plackett-Luce list-wise gradient estimation methods for the joint optimization of document ordering and lengths. Our semi-synthetic experiments show that VLPL can effectively balance the expected exposure and attractiveness of all documents, achieving the best performance across different ranking settings. Furthermore, we observe that even simple length-aware methods can achieve significant performance improvements over fixed-length models. Altogether, our theoretical and empirical results highlight the importance and difficulties of combining document presentation with LTR.",
        "doi": "10.1145/3726302.3730020",
        "sheridan_id": "fp0232",
        "position": 2,
        "track_id": 1,
        "slot_id": 29
      }
    },
    {
      "paper": {
        "hashed_id": "bbc06d679f244cc6b1e7a851bb22cc85",
        "title": "Digital Health",
        "abstract": "The \"AI revolution\" is lavished with accolades and showered with concerns, including some dire warnings. Regardless, this revolution continues to shape nearly all technology and domains. We focus specifically on medical applications that rely on search or recommendation technology. Relying on these technologies, we alleviate the ever-growing shortage of medical care personnel. Specifically, patient interactions are simplified by conversational agents, medical triage is accomplished by self-administered surrogates, early-onset of mental health conditions are detected through opt-in monitoring agents, and treatment suggestions are generated and evaluated via retrieval and mining applications. These are just some examples where search and related technologies are reshaping medical practice. Currently or soon to be deployed systems are described. \"In progress\" efforts are likewise highlighted. While some of the described systems rely on recent technology advances, others are simply based on \"bread and butter\" approaches, reminding us that \"new and improved\" is not always needed, and at times, is overkill and needlessly costly. We conclude with some observations.",
        "doi": "10.1145/3726302.3729951",
        "sheridan_id": "kn2508",
        "position": 1,
        "track_id": 1,
        "slot_id": 108
      }
    },
    {
      "paper": {
        "hashed_id": "415e1af7ea95f89f4e375162b21ae38c",
        "title": "BM25 and all that -- a look back",
        "abstract": "It is 30 years since the weighting-and-ranking function BM25 was published, and more than 55 years since I started work in the field we know as information retrieval. I will be talking about my experiences as an IR researcher over the period from 1968 to the early 2000s, including the development of the probabilistic model which led to BM25, and also some of the work on IR evaluation in the years since the Cranfield experiment. More generally, I will talk about some of the ways in which the field has changed and developed over that time, and about some of the characters who helped to shape the field, including my own interactions with them.",
        "doi": "10.1145/3726302.3729905",
        "sheridan_id": "kn2515",
        "position": 1,
        "track_id": 1,
        "slot_id": 89
      }
    },
    {
      "paper": {
        "hashed_id": "877a9ba7a98f75b90a9d49f53f15a858",
        "title": "HTGformer: Heterogeneous Temporal Graph Transformer",
        "abstract": "In recent years, heterogeneous temporal graphs (HTGs) have attracted substantial attention in applications of information retrieval such as recommender systems and social networks. To enhance representation learning in HTGs, numerous tailored neural networks have recently been proposed. Despite these successes, existing methods adopt independent parameterization strategies to handle various data distributions in HTGs, leading to optimization challenges and speed bottlenecks. To bridge this gap, this paper proposes a novel transformer-based representation learning paradigm for HTGs called HTGformer. Specifically, assisted by two major modules, i.e., a graph embedding layer and a heterogeneous-temporal encoder, HTGformer can effectively and efficiently capture spatio-temporal heterogeneous information in HTGs for comprehensive node representations. Extensive experiments demonstrate that HTGformer achieves up to 6\u00d7 speed-up compared to the state-of-the-art baseline while maintaining the best forecasting accuracy.",
        "doi": "10.1145/3726302.3730209",
        "sheridan_id": "sp0468",
        "position": 1,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "a516a87cfcaef229b342c437fe2b95f7",
        "title": "AgentCF++: Memory-enhanced LLM-based Agents for Popularity-aware Cross-domain Recommendations",
        "abstract": "LLM-based user agents, which simulate user interaction behavior, are emerging as a promising approach to enhancing recommender systems. In real-world scenarios, users` interactions often exhibit cross-domain characteristics and are influenced by others. However, the memory design in current methods causes user agents to introduce significant irrelevant information during decision-making in cross-domain scenarios and makes them unable to recognize the influence of other users` interactions, such as popularity factors. To tackle this issue, we propose a dual-layer memory architecture combined with a two-step fusion mechanism. This design avoids irrelevant information during decision-making while ensuring effective integration of cross-domain preferences. We also introduce the concepts of interest groups and group-shared memory to better capture the influence of popularity factors on users with similar interests. Comprehensive experiments validate the effectiveness of AgentCF++. Our code is available at https://github.com/jhliu0807/AgentCF-plus.",
        "doi": "10.1145/3726302.3730161",
        "sheridan_id": "sp0487",
        "position": 3,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "70efba66d3d8d53194fb1a8446ae07fa",
        "title": "Do LLMs Memorize Recommendation Datasets? A Preliminary Study on MovieLens-1M",
        "abstract": "Large Language Models (LLMs) have become increasingly central to recommendation scenarios due to their remarkable natural language understanding and generation capabilities. Although significant research has explored the use of LLMs for various recommendation tasks, little effort has been dedicated to verifying whether they have memorized public recommendation dataset as part of their training data. This is undesirable because memorization reduces the generalizability of research findings, as benchmarking on memorized datasets does not guarantee generalization to unseen datasets. Furthermore, memorization can amplify biases, for example, some popular items may be recommended more frequently than others. In this work, we investigate whether LLMs have memorized public recommendation datasets. Specifically, we examine two model families (GPT and Llama) across multiple sizes, focusing on one of the most widely used dataset in recommender systems: MovieLens-1M. First, we define dataset memorization as the extent to which item attributes, user profiles, and user-item interactions can be retrieved by prompting the LLMs. Second, we analyze the impact of memorization on recommendation performance. Lastly, we examine whether memorization varies across model families and model sizes. Our results reveal that all models exhibit some degree of memorization of MovieLens-1M, and that recommendation performance is related to the extent of memorization.",
        "doi": "10.1145/3726302.3730178",
        "sheridan_id": "sp1575",
        "position": 5,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "a368b0de8b91cfb3f91892fbf1ebd4b2",
        "title": "Interest Changes: Considering User Interest Life Cycle in Recommendation System",
        "abstract": "In recommendation systems, user interests are always in a state of constant flux. Typically, a user interest experiences a emergent phase, a stable phase, and a declining phase, which are referred to as the ``user interest life-cycle``. Recent papers on user interest modeling have primarily focused on how to compute the correlation between the target item and user`s historical behaviors, without thoroughly considering the life-cycle features of user interest. In this paper, we propose an effective method called Deep Interest Life-cycle Network (DILN), which not only captures the interest life-cycle features efficiently, but can also be easily integrated to existing ranking models. DILN contains two key components: Interest Life-cycle Encoder Module constructs historical activity histograms of the user interest and then encodes them into dense representation. Interest Life-cycle Fusion Module injects the encoded dense representation into multiple expert networks, with the aim of enabling the specific phase of interest life-cycle to activate distinct experts. Online A/B testing reveals that DILN achieves significant improvements of +0.38% in CTR, +1.04% in CVR and +0.25% in duration per user, which demonstrates its effectiveness. In addition, DILN inherently increase the exposure of users` emergent and stable interests while decreasing the exposure of declining interests. DILN has been deployed on the Lofter App.",
        "doi": "10.1145/3726302.3730215",
        "sheridan_id": "sp1604",
        "position": 6,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "be3e9d3f7d70537357c67bb3f4086846",
        "title": "Improving Link Sign Prediction in Signed Bipartite Graphs via Balanced Line Graphs",
        "abstract": "Signed bipartite graphs are widely employed in social networks, recommender systems, and other domains, where the nodes represent two different sets, such as users and commodities, and the links have positive and negative signs to reflect the ratings. Link sign prediction is a crucial task, but the link class imbalance when one type of link (e.g., the head class) is significantly more numerous than another (e.g., the tail class) makes this task extremely challenging. To address this challenge, we propose a Line-Graph-Based Dynamic Balancing Prediction (LDBP) method. Specifically, we first convert the links of a signed bipartite graph into nodes of a line graph, and then the link class imbalance problem in the bipartite graph is naturally transformed to the problem of node class imbalance in the line graph. To tackle this problem, we introduce a Centroid Contrastive Learning (CCL) method and design a Dynamic Synthesis & Deletion (DSD) strategy for the tail-class nodes. By dynamically adjusting the quantity of synthesized tail-class nodes, we obtain a Balanced Line Graph (BaLG). Extensive experiments on real-world datasets demonstrate the effectiveness of our method in improving the accuracy of link sign prediction and addressing the issue of link class imbalance.",
        "doi": "10.1145/3726302.3730210",
        "sheridan_id": "sp1651",
        "position": 7,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "2a27b8144ac02f67687f76782a3b5d8f",
        "title": "EIoU-EMC: A Novel Loss for Domain-specific Nested Entity Recognition",
        "abstract": "Nested NER tasks have some challenges in specific domains, such as biomedical and industrial fields, particularly due to low resource and class imbalance, which impede its wide application. In this study, we design a novel loss EIoU-EMC, by enhancing the implement of Intersection over Union loss and Multi-class loss. Our proposed method specially leverages the information of  entity boundary and entity classification, thereby enhancing the model`s capacity to learn from a limited number of data samples. To validate the performance of this innovative method in enhancing NER task, we conducted experiments on three distinct biomedical NER datasets and one dataset constructed by ourselves from industrial complex equipment maintenance documents. Comparing to strong baselines, our method   demonstrates the competitive performance   across all datasets. During the experimental analysis, our proposed method exhibits significant advancements in entity boundary recognition and entity classification. Our code and data are available at https://github.com/luminous11/EIoU-EMC/",
        "doi": "10.1145/3726302.3730187",
        "sheridan_id": "sp1705",
        "position": 11,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "66be31e4c40d676991f2405aaecc6934",
        "title": "ELEC: Efficient Large Language Model-Empowered Click-Through Rate Prediction",
        "abstract": "Click-through rate (CTR) prediction plays an important role in online advertising systems. On the one hand, traditional CTR prediction models capture the collaborative signals in tabular data via feature interaction modeling, but they lose semantics in text. On the other hand, Large Language Models (LLMs) excel in understanding the context and meaning behind text, but they face challenges in capturing collaborative signals and they have long inference latency. In this paper, we aim to leverage the benefits of both types of models and pursue collaboration, semantics and efficiency. We present ELEC, which is an Efficient LLM-Empowered CTR prediction framework. We first adapt an LLM for the CTR prediction task. In order to leverage the ability of the LLM but simultaneously keep efficiency, we utilize the pseudo-siamese network which contains a gain network and a vanilla network. We inject the high-level representation vector generated by the LLM into a collaborative CTR model to form the gain network such that it can take advantage of both tabular modeling and textual modeling. However, its reliance on the LLM limits its efficiency. We then distill the knowledge from the gain network to the vanilla network on both the score level and the representation level, such that the vanilla network takes only tabular data as input, but can still generate comparable performance as the gain network. Our approach is model-agnostic. It allows for the integration with various existing LLMs and collaborative CTR models. Experiments on real-world datasets demonstrate the effectiveness and efficiency of ELEC for CTR prediction.",
        "doi": "10.1145/3726302.3730188",
        "sheridan_id": "sp1716",
        "position": 13,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "442cde81694ca09a626eeddefd1b74ca",
        "title": "Scaling Sparse and Dense Retrieval in Decoder-Only LLMs",
        "abstract": "Scaling large language models (LLMs) has shown great potential for improving retrieval model performance; however, previous studies have mainly focused on dense retrieval trained with contrastive loss (CL), neglecting the scaling behavior of other retrieval paradigms and optimization techniques, such as sparse retrieval and knowledge distillation (KD). In this work, we conduct a systematic comparative study on how different retrieval paradigms (sparse vs. dense) and fine-tuning objectives (CL vs. KD vs. their combination) affect retrieval performance across different model scales. Using MSMARCO passages as the training dataset, decoder-only LLMs (Llama-3 series: 1B, 3B, 8B), and a fixed compute budget, we evaluate various training configurations on both in-domain (MSMARCO, TREC DL) and out-of-domain (BEIR) benchmarks. Our key findings reveal that: (1) Scaling behaviors emerge clearly only with CL, where larger models achieve significant performance gains, whereas KD-trained models show minimal improvement, performing similarly across the 1B, 3B, and 8B scales. (2) Sparse retrieval models consistently outperform dense retrieval across both in-domain (MSMARCO, TREC DL) and out-of-domain (BEIR) benchmarks, and they demonstrate greater robustness to imperfect supervised signals. (3) We successfully scale sparse retrieval models with the combination of CL and KD losses at 8B scale, achieving state-of-the-art (SOTA) results in all evaluation sets.",
        "doi": "10.1145/3726302.3730225",
        "sheridan_id": "sp1746",
        "position": 16,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "36d7534290610d9b7e9abed244dd2f28",
        "title": "PUB: An LLM-Enhanced Personality-Driven User Behaviour Simulator for Recommender System Evaluation",
        "abstract": "Traditional offline evaluation methods for recommender systems struggle to capture the complexity of modern platforms due to sparse behavioural signals, noisy data, and limited modelling of user personality traits. While simulation frameworks can generate synthetic data to address these gaps, existing methods fail to replicate behavioural diversity, limiting their effectiveness. To overcome these challenges, we propose the Personality-driven User Behaviour Simulator (PUB), an LLM-based simulation framework that integrates the Big Five personality traits to model personalised user behaviour. PUB dynamically infers user personality from behavioural logs (e.g., ratings, reviews) and item metadata, then generates synthetic interactions that preserve statistical fidelity to real-world data. Experiments on the Amazon review datasets show that logs generated by PUB closely align with real user behaviour and reveal meaningful associations between personality traits and recommendation outcomes. These results highlight the potential of the personality-driven simulator to advance recommender system evaluation, offering scalable, controllable, high-fidelity alternatives to resource-intensive real-world experiments.",
        "doi": "10.1145/3726302.3730238",
        "sheridan_id": "sp1775",
        "position": 17,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "bf201d5407a6509fa536afc4b380577e",
        "title": "Template-Based Financial Report Generation in Agentic and Decomposed Information Retrieval",
        "abstract": "Tailoring structured financial reports from companies` earnings releases is crucial for understanding financial performance and has been widely adopted in real-world analytics. However, existing summarization methods often generate broad, high-level summaries, which may lack the precision and detail required for financial reports that typically focus on specific, structured sections. While Large Language Models (LLMs) hold promise, generating reports adhering to predefined multi-section templates remains challenging. This paper investigates two LLM-based approaches popular in industry for generating templated financial reports: an agentic information retrieval (IR) framework and a decomposed IR approach, namely AgenticIR and DecomposedIR. The AgenticIR utilizes collaborative agents prompted with the full template. In contrast, the DecomposedIR approach applies a prompt chaining workflow to break down the template and reframe each section as a query answered by the LLM using the earnings release. To quantitatively assess the generated reports, we evaluated both methods in two scenarios: one using a financial dataset without direct human references, and another with a weather-domain dataset featuring expert-written reports. Experimental results show that while AgenticIR may excel in orchestrating tasks and generating concise reports through agent collaboration, DecomposedIR statistically significantly outperforms AgenticIR approach in providing broader and more detailed coverage in both scenarios, offering reflection on the utilization of the agentic framework in real-world applications.",
        "doi": "10.1145/3726302.3730253",
        "sheridan_id": "sp1791",
        "position": 18,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "a3545bd79d31f9a72d3a78690adf73fc",
        "title": "Echoes in the Feed: Evolution-aware Prompt-augmented Micro-video Popularity Prediction",
        "abstract": "Micro-video popularity prediction (MVPP) is a crucial research topic with important implications for social media marketing and stakeholders. Current works in MVPP utilized the pre-trained vision-language models (PVLs) to model the multimodal features for prediction, failing to capture the evolving popularity trend in micro-videos and leading to suboptimal results. To tackle this limitation, we propose EvoPro, an Evolution-aware Prompt-augmented framework that enhances MVPP. First, inspired by the powerful multimodal understanding and text generation skills of Large Multimodal Models (LMMs), an LMM-driven generative retriever is proposed to create contextually rich retrieval queries and perform precise video-to-video retrieval, forming dynamic micro-video support sets that effectively reflect evolving patterns. Building upon this, a graph-based prompter generates evolutionary prompts by capturing the relational structures within the support set. These prompts, representing the latest trend dynamics, serve as few-shot examples to guide PVLs. By integrating evolutionary prompts, the PVLs are empowered to model the evolving popularity trends more accurately, yielding stronger and more predictive representations. Extensive experiments conducted on three benchmarks demonstrate that EvoPro significantly outperforms competitive baselines.",
        "doi": "10.1145/3726302.3730184",
        "sheridan_id": "sp1857",
        "position": 19,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "944626adf9e3b76a3919b50dc0b080a4",
        "title": "A Human-AI Comparative Analysis of Prompt Sensitivity in LLM-Based Relevance Judgment",
        "abstract": "Large Language Models (LLMs) are increasingly used to automate relevance judgments for information retrieval (IR) tasks, often demonstrating agreement with human labels that approaches inter-human agreement. To assess the robustness and reliability of LLM-based relevance judgments, we systematically investigate impact of prompt sensitivity on the task. We collected prompts for relevance assessment from 15 human experts and 15 LLMs across three tasks---binary, graded, and pairwise---yielding 90 prompts in total. We compare LLM-generated labels with TREC official human labels using Cohen`s \u03ba and pairwise agreement measures. In addition, we compare human- and LLM-generated prompts and analyze differences among different LLMs as judges. We release all data and prompts at https://github.com/Narabzad/prompt-sensitivity-relevance-judgements/.",
        "doi": "10.1145/3726302.3730159",
        "sheridan_id": "sp1903",
        "position": 23,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "c44799b04a1c72e3c8593a53e8000c78",
        "title": "Fact-Level Calibration and Correction for Long-Form Generations",
        "abstract": "Large language models (LLMs) have achieved remarkable progress across various domains, yet their tendency to generate hallucinations remains a critical barrier to their practical reliability. Confidence calibration addresses this challenge by aligning a model`s confidence with its actual accuracy, improving self-evaluation and trustworthiness. However, traditional confidence calibration, operating at response level, are inadequate for long-form generation, which involve complex outputs composed of multiple atomic facts, each with varying confidence, correctness, and relevance to the query. To overcome this limitation, we propose a fact-level confidence calibration framework that evaluates and adjusts confidence at the granularity of individual facts, incorporating both relevance and correctness. This framework identifies finer-grained calibration discrepancies, reduces overconfidence, and reveals confidence variance. Based on this framework, we introduce CARE (Confidence-Aware Fact Correction), a method that leverages high-confidence facts to iteratively refine and correct low-confidence ones. Experimental results demonstrate that our CARE effectively improves the quality of generated content. Our code is available at https://github.com/yuanyige/fact-calibration.",
        "doi": "10.1145/3726302.3730195",
        "sheridan_id": "sp1913",
        "position": 24,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "03e7d2ebec1e820ac34d054df7e68f48",
        "title": "LREA: Low-Rank Efficient Attention on Modeling Long-Term User Behaviors for CTR Prediction",
        "abstract": "With the rapid growth of user historical behavior data, user interest modeling has become a prominent aspect in Click-Through Rate (CTR) prediction, focusing on learning user intent representations. However, this complexity poses computational challenges, requiring a balance between model performance and acceptable response times for online services. Traditional methods often utilize filtering techniques. These techniques can lead to the loss of significant information by prioritizing top K items based on item attributes or employing low-precision attention mechanisms. In this study, we introduce LREA, a novel attention mechanism that overcomes the limitations of existing approaches while ensuring computational efficiency. LREA leverages low-rank matrix decomposition to optimize runtime performance and incorporates a specially designed loss function to maintain attention capabilities while preserving information integrity. During the inference phase, matrix absorption and pre-storage strategies are employed to effectively meet runtime constraints. The results of extensive offline and online experiments demonstrate that our method outperforms state-of-the-art approaches.",
        "doi": "10.1145/3726302.3730228",
        "sheridan_id": "sp1950",
        "position": 29,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "8c249675aea6c3cbd91661bbae767ff1",
        "title": "Large Language Model Relevance Assessors Agree With One Another More Than With Human Assessors",
        "abstract": "Relevance judgments can differ between assessors, but previous work has shown that such disagreements have little impact on the effectiveness rankings of retrieval systems. This applies to disagreements between humans as well as between human and large language model (LLM) assessors. However, the agreement between different LLM~assessors has not yet been systematically investigated. To close this gap, we compare eight LLM~assessors on the TREC DL tracks and the retrieval task of the RAG track with each other and with human assessors. We find that the agreement between LLM~assessors is higher than between LLMs and humans and, importantly, that LLM~assessors favor retrieval systems that use LLMs in their ranking decisions: our analyses with 30-50 retrieval systems show that the system rankings obtained by LLM~assessors overestimate LLM-based re-rankers by 9~to 17~positions on average.",
        "doi": "10.1145/3726302.3730218",
        "sheridan_id": "sp1986",
        "position": 32,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "ea6b2efbdd4255a9f1b3bbc6399b58f4",
        "title": "Measuring Hypothesis Testing Errors in the Evaluation of Retrieval Systems",
        "abstract": "The evaluation of Information Retrieval (IR) systems typically uses query-document pairs with corresponding human-labelled relevance assessments (qrels). These qrels are used to determine if one system is better than another based on average retrieval performance. Acquiring large volumes of human relevance assessments is expensive. Therefore, more efficient relevance assessment approaches have been proposed, necessitating comparisons between qrels to ascertain their efficacy. Discriminative power, i.e. the ability to correctly identify significant differences between systems, is important for drawing accurate conclusions on the robustness of qrels. Previous work has measured the proportion of pairs of systems that are identified as significantly different and has quantified Type I statistical errors. Type I errors lead to incorrect conclusions due to false positive significance tests. We argue that also identifying Type II errors (false negatives) is important as they lead science in the wrong direction. We quantify Type II errors and propose that balanced classification metrics, such as balanced accuracy, can be used to portray the discriminative power of qrels. We perform experiments using qrels generated using alternative relevance assessment methods to investigate measuring hypothesis testing errors in IR evaluation. We find that additional insights into the discriminative power of qrels can be gained by quantifying Type II errors, and that balanced classification metrics can be used to give an overall summary of discriminative power in one, easily comparable, number.",
        "doi": "10.1145/3726302.3730229",
        "sheridan_id": "sp2019",
        "position": 33,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "24f0d2c90473b2bc949ad962e61d9bcb",
        "title": "Are Information Retrieval Approaches Good at Harmonising Longitudinal Surveys in Social Science?",
        "abstract": "Automated detection of semantically equivalent questions in longitudinal social science surveys is crucial for long-term studies informing empirical research in the social, economic, and health sciences. Retrieving equivalent questions faces dual challenges: inconsistent representation of theoretical constructs (i.e. concept/sub-concept) across studies as well as between question and response options, and the evolution of vocabulary and structure in longitudinal text. To address these challenges, our multi-disciplinary collaboration of computer scientists and survey specialists presents a new information retrieval (IR) task of identifying concept (e.g. Housing, Job, etc.) equivalence across question and response options to harmonise longitudinal population studies. This paper investigates multiple unsupervised approaches on a survey dataset spanning 1946-2020, including probabilistic models, linear probing of language models, and pre-trained neural networks specialised for IR. We show that IR-specialised neural models achieve the highest overall performance with other approaches performing comparably. Additionally, the re-ranking of the probabilistic model`s results with neural models only introduces modest improvements of 0.07 at most in F1-score. Qualitative post-hoc evaluation by survey specialists shows that models generally have a low sensitivity to questions with high lexical overlap, particularly in cases where sub-concepts are mismatched. Altogether, our analysis serves to further research on harmonising longitudinal studies in social science.",
        "doi": "10.1145/3726302.3730164",
        "sheridan_id": "sp2105",
        "position": 39,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "d2a27e83d429f0dcae6b937cf440aeb1",
        "title": "Low-Cost Document Retrieval with Dense Pseudo-Query Encoding",
        "abstract": "Low-cost retrieval is crucial for document search on resource-limited computing platforms. This paper presents a staged sparse-to-dense retrieval framework that substitutes expensive dense query encoding with a dense pseudo-query (DPQ), an approximation derived solely from sparse retrieval results. DPQ scheme employs a simple, rank-aware weighting to combine corresponding dense representations of top sparse results, providing an opportunity to efficiently leverage an expensive but expressive LLM or BERT-based dense model without requiring GPUs. The evaluation demonstrates that DPQ-based retrieval runs fast on an affordable platform and outperforms several low-cost baselines in zero-shot retrieval.",
        "doi": "10.1145/3726302.3730227",
        "sheridan_id": "sp2220",
        "position": 44,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "074177d3eb6371e32c16c55a3b8f706b",
        "title": "LLM-based Query Expansion Fails for Unfamiliar and Ambiguous Queries",
        "abstract": "Query expansion (QE) enhances retrieval by incorporating relevant terms, with large language models (LLMs) offering an effective alternative to traditional rule-based and statistical methods. However, LLM-based QE suffers from a fundamental limitation: it often fails to generate relevant knowledge, degrading search performance. Prior studies have focused on hallucination, yet its underlying cause\u2014LLM knowledge deficiencies\u2014remains underexplored. This paper systematically examines two failure cases in LLM-based QE: (1) when the LLM lacks query knowledge, leading to incorrect expansions, and (2) when the query is ambiguous, causing biased refinements that narrow search coverage. We conduct controlled experiments across multiple datasets, evaluating the effects of knowledge and query ambiguity on retrieval performance using sparse and dense retrieval models. Our results reveal that LLM-based QE can significantly degrade the retrieval effectiveness when knowledge in the LLM is insufficient or query ambiguity is high. We introduce a framework for evaluating QE under these conditions, providing insights into the limitations of LLM-based retrieval augmentation.",
        "doi": "10.1145/3726302.3730222",
        "sheridan_id": "sp2273",
        "position": 46,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "229754d7799160502a143a72f6789927",
        "title": "Bridging Time Gaps: Temporal Logic Relations for Enhancing Temporal Reasoning in Large Language Models",
        "abstract": "The understanding and cognition of time are the basis for large language models to understand the world. Although large language models (LLMs) have demonstrated strong capabilities in multiple reasoning tasks, they still have significant deficiencies in temporal reasoning, mainly due to the diversity of temporal expressions and the lack of temporal logic reasoning capabilities. In this study, we propose a novel Temporal Chain of Thought framework(TempCoT) to improve the performance of LLM in temporal reasoning tasks through a three-stage reasoning strategy. First, TempCoT explicitly extracts time constraints to ensure the accuracy of time references during reasoning. Second, a semantic retrieval mechanism is introduced to dynamically obtain key temporal facts to enhance the integrity and reliability of information. Finally, an explicit temporal logic reasoning module is constructed based on point algebra to improve the consistency and interpretability of reasoning. Experimental results show that TempCoT significantly improves the temporal reasoning performance of five different LLMs and shows stronger robustness on complex temporal tasks.",
        "doi": "10.1145/3726302.3730173",
        "sheridan_id": "sp2294",
        "position": 47,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "7cc532d783a7461f227a5da8ea80bfe1",
        "title": "HAETAE: In-domain Table Pretraining with Header Anchoring",
        "abstract": "Understanding structured table data with language models is crucial for various downstream tasks in information retrieval. However, transformer-based table embedding models struggle to consistently represent headers across varying entity contexts. This inconsistency undermines the generalizability of embeddings across in-domain tables that share universal semantics. To address this gap, we propose a novel pretraining method for in-domain tables, HAETAE, that explicitly separates header embeddings from contextual entity embeddings. Our method introduces a dedicated header encoder and learnable alignment mechanisms, built upon header-aware serialization. Experimental results demonstrate that HAETAE enhances generalization and stability in predicting headers and values of in-domain tables, achieving higher accuracy than baselines while showing the notable potential of knowledge transfer in cross-domain tables. The source code of HAETAE is available at https://github.com/woojoonjung/HAETAE.",
        "doi": "10.1145/3726302.3730205",
        "sheridan_id": "sp2343",
        "position": 50,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "5f14615696649541a025d3d0f8e0447f",
        "title": "LLM as User Simulator: Towards Training News Recommender without Real User Interactions",
        "abstract": "News recommendation systems traditionally rely on extensive real user interaction data to personalize content, which is often inaccessible and raises privacy concerns, particularly in regions lacking such data. To address these challenges, we propose LAUS (LLM As User Simulator), a novel framework that leverages LLM to simulate user interactions for training a news recommender without real user data. Our framework consists of two stages. First, we simulate user clicks by using an LLM to generate click probabilities for candidate news articles based on simulated user reading histories, with candidate sets generated through random sampling and embedding-based retrieval.Second, we train a lightweight news recommender using these simulated user interactions.Experiments on three datasets demonstrate that a news recommender trained with simulated data outperforms models using LLM prompting, while significantly reducing recommendation time per user.Our findings highlight the potential of using LLMs as user simulators to address data scarcity in news recommendation systems.",
        "doi": "10.1145/3726302.3730224",
        "sheridan_id": "sp2373",
        "position": 52,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "ad702a3ec1e6317dfdc06ececcc03d2e",
        "title": "Knowledge-Enhanced Conversational Recommendation via Transformer-Based Sequential Modeling",
        "abstract": "In conversational recommender systems (CRSs), conversations usually involve a set of items and item-related entities or attributes, e.g., director is a related entity of a movie. These items and item-related entities are often mentioned along the development of a dialog, leading to potential sequential dependencies among them. However, most of existing CRSs neglect these potential sequential dependencies. In this article, we first propose a Transformer-based sequential conversational recommendation method, named TSCR, to model the sequential dependencies in the conversations to improve CRS. In TSCR, we represent conversations by items and the item-related entities, and construct user sequences to discover user preferences by considering both the mentioned items and item-related entities. Based on the constructed sequences, we deploy a Cloze task to predict the recommended items along a sequence. Meanwhile, in certain domains, knowledge graphs formed by the items and their related entities are readily available, which provide various different kinds of associations among them. Given that TSCR does not benefit from such knowledge graphs, we then propose a knowledge graph enhanced version of TSCR, called TSCRKG. In specific, we leverage the knowledge graph to offline initialize our model TSCRKG, and augment the user sequence of conversations (i.e., sequence of the mentioned items and item-related entities in the conversation) with multi-hop paths in the knowledge graph. Experimental results demonstrate that our TSCR model significantly outperforms state-of-the-art baselines, and the enhanced version TSCRKG further improves recommendation performance on top of TSCR.",
        "doi": "10.1145/3677376",
        "sheridan_id": "TOIS-2023-0248.R2",
        "position": 53,
        "track_id": 2,
        "slot_id": 190
      }
    },
    {
      "paper": {
        "hashed_id": "a981f2b708044d6fb4a71a1463242520",
        "title": "Qilin: A Multimodal Information Retrieval Dataset with APP-level User Sessions",
        "abstract": "User-generated content (UGC) communities, especially those featuring multimodal content, improve user experiences by integrating visual and textual information into results (or items). The challenge of improving user experiences in complex systems with search and recommendation (S&R) services has drawn significant attention from both academia and industry these years. However, the lack of high-quality datasets has limited the research progress on multimodal S&R. To address the growing need for developing better S&R services, we present a novel multimodal information retrieval dataset in this paper, namely Qilin. The dataset is collected from Xiaohongshu, a popular social platform with over 300 million monthly active users and an average search penetration rate of over 70%. In contrast to existing datasets, Qilin offers a comprehensive collection of user sessions with heterogeneous results like image-text notes, video notes, commercial notes, and direct answers, facilitating the development of advanced multimodal neural retrieval models across diverse task settings. To better model user satisfaction and support the analysis of heterogeneous user behaviors, we also collect extensive APP-level contextual signals and genuine user feedback. Notably, Qilin contains user-favored answers and their referred results for search requests triggering the Deep Query Answering (DQA) module. This allows not only the training & evaluation of a Retrieval-augmented Generation (RAG) pipeline, but also the exploration of how such a module would affect users` search behavior. Through comprehensive analysis and experiments, we provide interesting findings and insights for further improving S&R systems. We hope that Qilin will significantly contribute to the advancement of multimodal content platforms with S&R services in the future.",
        "doi": "10.1145/3726302.3730279",
        "sheridan_id": "rr1625",
        "position": 55,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "f60bb6bb4c96d4df93c51bd69dcc15a0",
        "title": "PSCon: Product Search Through Conversations",
        "abstract": "Conversational Product Search ( CPS ) systems interact with users via natural language to offer personalized and context-aware product lists. However, most existing research on CPS is limited to simulated conversations, due to the lack of a real CPS dataset driven by human-like language. Moreover, existing conversational datasets for e-commerce are constructed for a particular market or a particular language and thus can not support cross-market and multi-lingual usage. In this paper, we propose a CPS data collection protocol and create a new CPS dataset, called PSCon, which assists product search through conversations with human-like language. The dataset is collected by a coached human-human data collection protocol and is available for dual markets and two languages. By formulating the task of CPS, the dataset allows for comprehensive and in-depth research on six subtasks: user intent detection, keyword extraction, system action prediction, question selection, item ranking, and response generation. Moreover, we present a concise analysis of the dataset and propose a benchmark model on the proposed CPS dataset. Our proposed dataset and model will be helpful for facilitating future research on CPS.",
        "doi": "10.1145/3726302.3730278",
        "sheridan_id": "rr1618",
        "position": 58,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "2b8eba3cb0d0f1d761cb74d94a5ace36",
        "title": "SAGraph: A Large-Scale Social Graph Dataset with Comprehensive Context for Influencer Selection in Marketing",
        "abstract": "Influencer marketing campaign success heavily depends on identifying key opinion leaders who can effectively leverage their credibility and reach to promote products or services. The selection of influencers is vital for boosting brand visibility, fostering consumer trust, and driving sales. While traditional research often simplifies complex factors like user attitudes, interaction frequency, and advertising content, into simple numerical values. However, this reductionist approach fails to capture the dynamic nature of influencer marketing effectiveness.To bridge this gap, we present SAGraph, a novel comprehensive dataset from Weibo that captures multi-dimensional marketing campaign data across six product domains. The dataset encompasses 345,039 user profiles with their complete interaction histories, including 1.3M comments and 554K reposts across 44K posts, providing unprecedented granularity in influencer marketing dynamics. SAGraph uniquely integrates user profiles, content features, and temporal interaction patterns, enabling in-depth analysis of influencer marketing mechanisms. Experimental results using both traditional baselines and state-of-the-art large language models (LLMs) demonstrate the crucial role of content analysis in predicting advertising effectiveness. Our findings reveal that LLM-based approaches achieve superior performance in understanding and predicting campaign success, opening new avenues for data-driven influencer marketing strategies.We hope that this dataset will inspire further research: \\url{https://github.com/xiaoqzhwhu/SAGraph/}.",
        "doi": "10.1145/3726302.3730334",
        "sheridan_id": "rr2268",
        "position": 63,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "6a5dfac4be1502501489fc0f5a24b667",
        "title": "An EEG Dataset of Word-level Brain Responses for Semantic Text Relevance",
        "abstract": "Electroencephalography (EEG) can enable non-invasive, real-time measurement of brain activity reflecting cognitive processes during human language processing. Previously released EEG datasets primarily capture brain signals recorded either during natural reading or within controlled psycholinguistic experimental settings. Given that information retrieval research depends on understanding and modelling relevance, we present a novel dataset including EEG data recorded while participants read text that is semantically relevant or irrelevant to self-selected topics. The dataset contains 23, 270 time-locked (\\sim 0.7s) word-level EEG recordings. Using these data, we conduct benchmark experiments with two evaluation protocols, cross-subject and within-subject, focusing on two prediction tasks: word relevance and sentence relevance. We report the performance of five well known models on these tasks. Altogether, our dataset paves the way for advancing research on language relevance, brain input and feedback-based recommendation and retrieval systems, and development of brain-computer interface (BCI) devices for online detection of language relevance. Our dataset and code are openly released at https://osf.io/xh3g5/wiki/home/ and at HuggingFace https://huggingface.co/datasets/Quoron/EEG-semantic-text-relevance.",
        "doi": "10.1145/3726302.3730289",
        "sheridan_id": "rr1750",
        "position": 64,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "be53d253d6bc3258a8160556dda3e9b2",
        "title": "FACTors: A New Dataset for Studying the Fact-checking Ecosystem",
        "abstract": "Our fight against false information is spearheaded by fact-checkers. They investigate the veracity of claims and document their findings as fact-checking reports. With the rapid increase in the amount of false information circulating online, the use of automation in fact-checking processes aims to strengthen this ecosystem by enhancing scalability. Datasets containing fact-checked claims play a key role in developing such automated solutions. However, to the best of our knowledge, there is no fact-checking dataset at the ecosystem level, covering claims from a sufficiently long period of time and sourced from a wide range of actors reflecting the entire ecosystem that admittedly follows widely-accepted codes and principles of fact-checking.  We present a new dataset FACTors, the first to fill this gap by presenting ecosystem-level data on fact-checking. It contains 118,112 claims from 117,993 fact-checking reports in English (co-)authored by 1,953 individuals and published during the period of 1995-2025 by 39 fact-checking organisations that are active signatories of the IFCN (International Fact-Checking Network) and/or EFCSN (European Fact-Checking Standards Network). It contains 7,327 overlapping claims investigated by multiple fact-checking organisations, corresponding to 2,977 unique claims. It allows to conduct new ecosystem-level studies of the fact-checkers (organisations and individuals).  To demonstrate the usefulness of our dataset, we present three example applications. They include a first-of-its-kind statistical analysis of the fact-checking ecosystem, examining the political inclinations of the fact-checking organisations, and attempting to assign a credibility score to each organisation based on the findings of the statistical analysis and political leanings. Our methods for constructing FACTors are generic and can be used to maintain a live dataset that can be updated dynamically.",
        "doi": "10.1145/3726302.3730339",
        "sheridan_id": "rr2329",
        "position": 68,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "093b60fd0557804c8ba0cbf1453da22f",
        "title": "MultiConAD: A Unified Multilingual Conversational Dataset for Early Alzheimer`s Detection",
        "abstract": "Dementia is a progressive cognitive syndrome with Alzheimer`s disease (AD) as the leading cause. Conversation-based AD detection offers a cost-effective alternative to clinical methods, as language dysfunction is an early biomarker of AD. However, most prior research has framed AD detection as a binary classification problem, limiting the ability to identify Mild Cognitive Impairment (MCI)\u2014a crucial stage for early intervention. Also, studies primarily rely on single-language datasets, mainly in English, restricting crosslanguage generalizability. To address this gap, we make three key contributions. First, we introduce a novel, multilingual dataset for AD detection by unifying 16 publicly available dementia-related conversational datasets. This corpus spans English, Spanish, Chinese, and Greek, and incorporates both audio and text data derived from a variety of cognitive assessment tasks. Second, we perform finer-grained classification, including MCI, and evaluate various classifiers using sparse and dense text representations. Third, we conduct experiments in monolingual and multilingual settings, finding that some languages benefit from multilingual training while others perform better independently. This study highlights the challenges in multilingual AD detection and enables future research on both language-specific approaches and techniques aimed at improving model generalization and robustness.",
        "doi": "10.1145/3726302.3730313",
        "sheridan_id": "rr2029",
        "position": 73,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "a1d0c6e83f027327d8461063f4ac58a6",
        "title": "RelEx: An XAI-Enhanced Relevance Feedback Model for User-Adaptive Explanations",
        "abstract": "The rise of Gen-AI and LLMs often makes it difficult for users to trust retrieved results. The risk of IR systems using LLMs and being susceptible to misinformation can be tackled under the lens of explainability in AI.  The topic of explainability in AI, machine learning (XAI) and information retrieval (IR) has been explored through various methods, yet few incorporate user feedback to adapt explanations. In this work, we present an XAI-driven extension to the classic relevance feedback model in IR, incorporating user feedback in the process of explaining the model behavior to the user. Our proposed model, RelEx, introduces XAI-specific elements, including key phrase vectors, text summaries, and contextual phrases combined with a neural ranker. RelEx interactively gathers user feedback, adapting search results based on the modified query and contextual vectors. We further introduce a novel additive similarity scheme that combines document similarity with key-phrase overlap. Retrieval performance is empirically evaluated on multiple benchmark datasets. In the absence of ground truth explanations, we assess explainability and assessability via user studies, where RelEx exhibit promising results.",
        "doi": "10.1145/3726302.3730132",
        "sheridan_id": "de0042",
        "position": 1,
        "track_id": 10,
        "slot_id": 104
      }
    },
    {
      "paper": {
        "hashed_id": "b710915795b9e9c02cf10d6d2bdb688c",
        "title": "FairWork: A Generic Framework For Evaluating Fairness In LLM-Based Job Recommender System",
        "abstract": "Large Language Models (LLMs) have revolutionized recommender systems by offering highly personalized and context-aware suggestions. However, their inherent biases pose significant challenges in sensitive scenarios like job recommendation, potentially compromising fairness and resulting in harmful effects on both users and platforms. While previous studies have explored fairness issues in LLM-based job recommendations, they often focus on limited dimensions. We introduce FairWork, a comprehensive fairness evaluation framework to examine LLM-based recommender system from both the user\u2019s and recruiter\u2019s perspectives, employing fairness metrics to assess how sensitive user attributes influence job recommendations. The system allows stakeholders such as recruitment platforms and job seekers to upload personalized profiles and job descriptions for fairness analysis. By integrating specific job requirements and user-driven data inputs, FairWork captures the relationship between candidate qualifications and job demands. This framework provides a robust foundation for evaluating fairness in LLM-based job recommender systems and supports future research on bias mitigation strategies. The demo is available at https://github.com/chenzhouli/FairWork.",
        "doi": "10.1145/3726302.3730145",
        "sheridan_id": "de1582",
        "position": 3,
        "track_id": 10,
        "slot_id": 104
      }
    },
    {
      "paper": {
        "hashed_id": "deb54ffb41e085fd7f69a75b6359c989",
        "title": "Advancing Scientific Knowledge Retrieval and Reuse with a Novel Digital Library for Machine-Readable Knowledge",
        "abstract": "Digital libraries for research, such as the ACM Digital Library or Semantic Scholar, do not enable the machine-supported, efficient reuse of scientific knowledge (e.g., in synthesis research). This is because these libraries are based on document-centric models with narrative text knowledge expressions that require manual or semi-automated knowledge extraction, structuring, and organization. We present ORKG reborn, an emerging digital library that supports finding, accessing, and reusing accurate, fine-grained, and reproducible machine-readable expressions of scientific knowledge that relate scientific statements and their supporting evidence in terms of data and code. The rich expressions of scientific knowledge are published as reborn (born-reusable) articles and provide novel possibilities for scientific knowledge retrieval, for instance by statistical methods, software packages, variables, or data matching specific constraints. We describe the proposed system and demonstrate its practical viability and potential for information retrieval in contrast to state-of-the-art digital libraries and document-centric scholarly communication using several published articles in research fields ranging from computer science to soil science. Our work underscores the enormous potential of scientific knowledge databases and a viable approach to their construction.",
        "doi": "10.1145/3726302.3730134",
        "sheridan_id": "de1973",
        "position": 11,
        "track_id": 10,
        "slot_id": 104
      }
    },
    {
      "paper": {
        "hashed_id": "f3d9de86462c28781cbe5c47ef22c3e5",
        "title": "InstInfo: A Just-in-Time Literature Recommendation System for Presentations",
        "abstract": "The efficient discovery of academic literature is critical for research progress, yet many researchers have difficulties in finding literature. This work proposes InstInfo: a novel just-in-time literature recommendation system for presentations. InstInfo transcribes audio in real-time and recommends literature according to the ideas being discussed, thereby helping researchers ground presentations in academic literature while saving them the time of having to manually search. Informal usability studies show that InstInfo is easy to use and that researchers find value in the recommendations. InstInfo can be accessed at https://instinfo.com.",
        "doi": "10.1145/3726302.3730146",
        "sheridan_id": "de2214",
        "position": 13,
        "track_id": 10,
        "slot_id": 104
      }
    },
    {
      "paper": {
        "hashed_id": "07811dc6c422334ce36a09ff5cd6fe71",
        "title": "Navigating Speech Recording Collections with AI-Generated Illustrations",
        "abstract": "Although the amount of available spoken content is steadily increasing, extracting information and knowledge from speech recordings remains challenging. Beyond enhancing traditional information retrieval methods such as speech search and keyword spotting, novel approaches for navigating and searching spoken content need to be explored and developed. In this paper, we propose a novel navigational method for speech archives that leverages recent advances in language and multimodal generative models. We demonstrate our approach with a Web application that organizes data into a structured format using interactive mind maps and image generation tools. The system is implemented using the TED-LIUM~3 dataset, which comprises over 2,000 speech transcripts and audio files of TED Talks. Initial user tests using a System Usability Scale (SUS) questionnaire indicate the application`s potential to simplify the exploration of large speech collections.",
        "doi": "10.1145/3726302.3730136",
        "sheridan_id": "de2024",
        "position": 2,
        "track_id": 10,
        "slot_id": 112
      }
    },
    {
      "paper": {
        "hashed_id": "7e3b7a5bafcb0fa8e8dfe3ea6aca9186",
        "title": "A Flexible User Study Platform for Generative Information Retrieval",
        "abstract": "User behavior and experience are important for improving information retrieval (IR) systems. While much research has focused on traditional IR systems, few studies have systematically examined user behavior and search experience with emerging generative IR systems. A key reason for this gap is the lack of publicly available toolkits to record user behavior and feedback in generative IR systems. We developed a comprehensive platform to collect user behavior and feedback on the generative IR system. This platform consists of: 1) a generative IR system that supports both API-based and customized retrieval-augmented generation (RAG) methods, 2) a user interface that logs various user behavior, including prompts, clicks, mouse movements, and scrolling, and 3) an annotation website that allows users to provide feedback. We believe the proposed platform has the potential to streamline data collection for user studies on generative IR systems, paving the way for future research on how users engage with and interact with these systems.",
        "doi": "10.1145/3726302.3730140",
        "sheridan_id": "de2334",
        "position": 10,
        "track_id": 10,
        "slot_id": 112
      }
    },
    {
      "paper": {
        "hashed_id": "ea159dc9788ffac311592613b7f71fbb",
        "title": "ReviewHQ: An API-Based System for Reviewer Assignment and Quality Control in Research Conferences",
        "abstract": "Managing the review process for large-scale academic conferences poses significant challenges in effectively matching papers to the right reviewers, detecting conflicts of interest, ensuring review quality, and addressing potential ethical issues such as dual submissions. In this demonstration paper, we introduce ReviewHQ, an API-based system designed to streamline conference management. For matching reviewers to publications, ReviewHQ constructs expertise profiles for potential reviewers by mining their publication records and representing both papers and reviewers as dense vectors. It then formulates paper assignment as a constrained optimization problem, leveraging dense vector similarity scores and other reviewer`s and submission`s features to produce high-quality assignments. Beyond its core functionality, ReviewHQ identifies conflicts of interest by analyzing co-authorship histories and flags suspected dual submissions by comparing manuscripts against submission information from other conferences. Further, the system employs methods to detect low-quality or automated (AI-generated) reviews and pinpoint discrepancies between reviewers` recommendations and final acceptance decisions. ReviewHQ has been used since 2024 across the SIGIR and SIGIR-AP conferences.",
        "doi": "10.1145/3726302.3730139",
        "sheridan_id": "de2384",
        "position": 11,
        "track_id": 10,
        "slot_id": 112
      }
    },
    {
      "paper": {
        "hashed_id": "3c947bc2f7ff007b86a9428b74654de5",
        "title": "Investigating Task Arithmetic for Zero-Shot Information Retrieval",
        "abstract": "Large Language Models (LLMs) have shown impressive zero-shot performance across a variety of Natural Language Processing tasks, including document re-ranking. However, their effectiveness degrades on unseen tasks and domains, largely due to shifts in vocabulary and word distributions. In this paper, we investigate Task Arithmetic, a technique that combines the weights of LLMs pre-trained on different tasks or domains via simple mathematical operations, such as addition or subtraction, to adapt retrieval models without requiring additional fine-tuning. Our method is able to synthesize diverse tasks and domain knowledge into a single model, enabling effective zero-shot adaptation in different retrieval contexts. Extensive experiments on publicly available scientific, biomedical, and multilingual datasets show that our method improves state-of-the-art re-ranking performance by up to 18% in NDCG@10 and 15% in P@10. In addition to these empirical gains, our analysis provides insights into the strengths and limitations of Task Arithmetic as a practical strategy for zero-shot learning and model adaptation. We make our code publicly available at https://github.com/DetectiveMB/Task-Arithmetic-for-ZS-IR.",
        "doi": "10.1145/3726302.3730216",
        "sheridan_id": "sp1856",
        "position": 38,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "b432f34c5a997c8e7c806a895ecc5e25",
        "title": "System Comparison Using Automated Generation of Relevance Judgements in Multiple Languages",
        "abstract": "Recent work has shown that Large Language Models (LLMs) can produce relevance judgements for English retrieval that are useful as a basis for system comparison, and they do so at vastly reduced cost compared to human assessors. Using relevance judgements and ranked retrieval runs from the TREC NeuCLIR track, this paper shows that LLMs can also produce reliable assessments in other languages, even when the topic description or the prompt are in a language different from the documents. Results with Chinese, Persian and Russian documents show that although document language affects both agreement with human assessors on graded relevance and on preference ordering among systems, prompt-language and topic-language effects are negligible. This has implications for the design of multilingual test collections, suggesting that prompts and topic descriptions can be developed in any convenient language.",
        "doi": "10.1145/3726302.3730252",
        "sheridan_id": "sp1915",
        "position": 50,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "7f16109f1619fd7a733daf5a84c708c1",
        "title": "ReCDAP: Relation-Based Conditional Diffusion with Attention Pooling for Few-Shot Knowledge Graph Completion",
        "abstract": "Knowledge Graphs (KGs), composed of triples in the form of (head, relation, tail) and consisting of entities and relations, play a key role in information retrieval systems such as question answering, entity search, and recommendation. In real-world KGs, although many entities exist, the relations exhibit a long-tail distribution, which can hinder information retrieval performance. Previous few-shot knowledge graph completion studies focused exclusively on the positive triple information that exists in the graph or, when negative triples were incorporated, used them merely as a signal to indicate incorrect triples. To overcome this limitation, we propose Relation-Based Conditional Diffusion with Attention Pooling (ReCDAP). First, negative triples are generated by randomly replacing the tail entity in the support set. By conditionally incorporating positive information in the KG and non-existent negative information into the diffusion process, the model separately estimates the latent distributions for positive and negative relations. Moreover, including an attention pooler enables the model to leverage the differences between positive and negative cases explicitly. Experiments on two widely used datasets demonstrate that our method outperforms existing approaches, achieving state-of-the-art performance. The code is available at https://github.com/hou27/ReCDAP-FKGC.",
        "doi": "10.1145/3726302.3730241",
        "sheridan_id": "sp1960",
        "position": 54,
        "track_id": 3,
        "slot_id": 103
      }
    },
    {
      "paper": {
        "hashed_id": "2cd4e8a2ce081c3d7c32c3cde4312ef7",
        "title": "Evaluating LLMs\u2019 (In)ability to Follow Prompts in QA Tasks",
        "abstract": "While LLMs have achieved impressive performance across various tasks, one under-explored area is evaluating their ability to follow instructions provided in the prompt when generating responses. In the context of question-answering (QA) tasks, a crucial research gap is \\textit{whether LLMs prioritize their own parametric knowledge or the context provided in the prompt when generating an answer}. Ignoring prompts, even when explicitly instructed to follow them, may adversely affect performance and potentially lead to unintended consequences. Additionally, LLMs should be self-reflective (i.e., LLMs should recognize when their knowledge is inadequate) and avoid hallucinations in such scenarios. To address our research question, we propose \\textit{Oedipus}, an evaluation framework to evaluate LLMs` ability to follow prompts. We further note that such abilities could also be influenced by contamination (i.e., exposure to datasets during training) and parametric knowledge. Consequently, we develop a novel QA dataset with four types of contexts\u2014\\textit{correct, masked, noisy}, and \\textit{absurd contexts} with \\textit{recent questions} that LLMs are unlikely to have encountered in pre-training data or corpus and cannot be answered from parametric knowledge. We evaluate eight LLMs through our proposed evaluation framework and observe that LLMs often fail to follow instructions correctly and are not self-reflective.",
        "doi": "10.1145/3726302.3730190",
        "sheridan_id": "sp2095",
        "position": 67,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "f976b57bb9dd27aa2e7e7df2825893a6",
        "title": "Augmenting Cross-Modal Art Retrieval: The Role of MLLM-Synthesized Captions",
        "abstract": "Multimodal Large Language Models (MLLMs) connect and interpret different data types, making them suitable for various vision-language tasks. Despite the rapid advancements in MLLMs, their effectiveness for specialized cross-modal retrieval tasks remains underexplored. A challenging example is art retrieval, where the task is to find visually and conceptually relevant artwork corresponding to a textual description. This paper investigates the effects of fine-tuning cross-modal retrieval models using both human-annotated and MLLM-generated captions for artistic paintings. To this end, two cross-modal retrieval models, Long-CLIP and BLIP, are studied. Experimental results show that models fine-tuned on MLLM-generated captions achieve search effectiveness comparable to those fine-tuned on human-annotated captions.",
        "doi": "10.1145/3726302.3730167",
        "sheridan_id": "sp2306",
        "position": 83,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "03255088ed63354a54e0e5ed957e9008",
        "title": "Permutation-Invariant Transformers for Attribute Embeddings in Information Retrieval",
        "abstract": "Generating robust embeddings for unordered sets of phrases is a challenging problem in NLP, particularly when embeddings must exhibit permutation invariance at the set level while preserving the inherent order of tokens within each phrase. This challenge is especially relevant in e-commerce, where product attributes such as size, color, and dimensions are often unstructured and vary across products. Embedding these unordered attribute sets is critical for query-product understanding, search ranking, and recommenda- tion systems. Existing set embedding methods have primarily focused on domains such as graphs, with limited applicability to NLP tasks. To address this gap, we propose a Phrase-Localized Attention Network (PLAN), a Transformer-based model that ensures intra-attribute order preservation while enabling permutation-invariant representations at the set level. Experimental results on the Amazon Shopping Queries dataset demonstrate that PLAN outperforms existing models, highlighting its effectiveness in search applications.",
        "doi": "10.1145/3726302.3730236",
        "sheridan_id": "sp2327",
        "position": 84,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "296472c9542ad4d4788d543508116cbc",
        "title": "Conversational Gold: Evaluating Personalized Conversational Search System Using Gold Nuggets",
        "abstract": "The rise of personalized conversational search systems has been driven by advancements in Large Language Models (LLMs), enabling these systems to retrieve and generate answers for complex information needs. However, the automatic evaluation of responses generated by Retrieval Augmented Generation (RAG) systems remains an understudied challenge. In this paper, we introduce a new resource for assessing the retrieval effectiveness and relevance of responses generated by RAG systems, using a nugget-based evaluation framework. Built upon the foundation of TREC iKAT 2023, our dataset extends to the TREC iKAT 2024 collection, which includes 17 conversations and 20,575 relevance passage assessments, together with 2,279 extracted gold nuggets and 62 manually written gold answers from NIST assessors. While maintaining the core structure of its predecessor, this new collection enables a deeper exploration of generation tasks in conversational settings. Key improvements in iKAT 2024 include: (1) ``gold nuggets`` -- concise, essential pieces of information extracted from relevant passages of the collection -- which serve as a foundation for automatic response evaluation; (2) manually written answers to provide a gold standard for response evaluation; (3) expanded user personas, providing richer contextual grounding; and (4) a transition from Personal Text Knowledge Base (PTKB) ranking to PTKB classification and selection. Built on this resource, we provide a framework for long-form answer generation evaluation, involving nugget extraction and nugget matching, linked to retrieval. This establishes a solid resource for advancing research in personalized conversational search and long-form answer generation. Our resources are publicly available at https://github.com/irlabamsterdam/CONE-RAG.",
        "doi": "10.1145/3726302.3730316",
        "sheridan_id": "rr2070",
        "position": 104,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "3f53d7190148675e3cd472fc826828c5",
        "title": "TAFSIL: Taxonomy Adaptable Fine-grained Entity Recognition through Distant Supervision for Indian Languages",
        "abstract": "Several studies have used distant supervision to create resources for fine-grained entity recognition (FgER) to mitigate the challenges of manual annotation. However, most of these methods are primarily developed for English and cannot be efficiently adapted to many other languages, including Indian languages. Moreover, the emergence of new and unseen entity types deteriorates the performance of the supervised models trained on FgER datasets with different predefined sets of entity types. This work introduces \\textbf{TAFSIL}, a taxonomy-adaptable FgER framework to create FgER datasets in six Indian languages. The chosen languages are spoken by more than a billion speakers across various countries. TAFSIL utilizes the high interlink between the knowledge base WikiData and linked corpora Wikipedia through multi-stage heuristics and improves annotation through fuzzy match and quality sentence selection. TAFSIL enables us to create datasets of a total size of around three million samples for six languages \\textit{Hindi (Hi)}, \\textit{Marathi (Mr)}, \\textit{Sanskrit (Sa)}, \\textit{Tamil (Ta)}, \\textit{Telugu (Te)}, and \\textit{Urdu (Ur)} belonging to two language families \\textit{Indo-European} and \\textit{Dravidian}. We evaluate the robustness of TAFSIL by creating various datasets in four taxonomies \\textit{FIGER}, \\textit{OntoNotes}, \\textit{HAnDS}, and \\textit{MultiCoNER2}. Our extensive experiments suggest the sound quality of the datasets as there is a relative improvement of 83\\% in average F1 score over zero-shot performance across various FgER state-of-the-art models. The resource is publicly available at \\href{https://huggingface.co/datasets/prachuryyaIITG/TAFSIL}{https://huggingface.co/datasets/prachuryyaIITG/TAFSIL}.",
        "doi": "10.1145/3726302.3730341",
        "sheridan_id": "rr2355",
        "position": 118,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "b865367fc4c0845c0682bd466e6ebf4c",
        "title": "Graph-Augmented Retrieval with Memory-Driven Reasoning and Constraint-Aware Filtering for MultiHop QA",
        "abstract": "Addressing multi-hop reasoning of complex query effectively is a challenging task in information retrieval field. It demands the ability to retrieve and integrate dispersed knowledge across multiple documents dynamically while maintaining coherence in multi-step reasoning process. This study addresses these challenges with three primary contributions. It explores the integrating of large language models with graph-augmented retrieval methods for complex multihop reasoning. Moreover, the Memory-Driven Chain-of-Reasoning strategy is introduced, leveraging the memory of historical queries and results to optimize multi-step reasoning dynamically. Additionally, the Constraint-Aware Filtering in Chunked Window strategy is developed to improve retrieval precision by partitioning and filtering large retrieval windows based on query constraints. The experiments on public benchmarks indicate that our method substantially outperforms competitive approaches, achieving up to 13.8% and 14.0% improvements in EM and F1 on HotpotQA, 9.4% and 12.8% on MuSiQue, and 6.4% and 3.2% on 2WikiMultiHopQA, respectively.",
        "doi": "10.1145/3726302.3730203",
        "sheridan_id": "sp1783",
        "position": 28,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "d2ed45a52bc0edfa11c2064e9edee8bf",
        "title": "Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions for Deep Research",
        "abstract": "Existing question answering (QA) datasets are no longer challenging to most powerful Large Language Models (LLMs). Traditional QA benchmarks like TriviaQA, NaturalQuestions, ELI5 and HotpotQA mainly study ``known unknowns`` with clear indications of both what information is missing, and how to find it to answer the question. A yet unmet need of the NLP community is a bank of non-factoid, multi-perspective questions involving a great deal of unclear information needs, i.e. ``unknown unknowns``. We claim we can find such questions in search engine logs, which is surprising because most question-intent queries are indeed factoid. Furthermore, recent products like Google`s DeepResearch (announced a year after this resource was released publicly) specifically address such queries, retrieving hundreds of documents to synthesize report-style responses. We present Researchy Questions, the world`s first, only and largest public dataset of ``Deep Research`` questions filtered from real search engine logs to be non-factoid, ``decompositional`` and multi-perspective. We show that users spend substantial ``effort`` on these questions in terms of signals like clicks and session length. We also show that ``slow thinking`` answering techniques, like decomposition into sub-questions shows benefit over answering directly. We release (at https://huggingface.co/datasets/corbyrosset/researchy_questions) about 100k Researchy Questions with a permissive CDLA-2.0 license, along with click histograms on over 350k Clueweb22 URLs that were clicked for each question.",
        "doi": "10.1145/3726302.3730275",
        "sheridan_id": "rr0932",
        "position": 57,
        "track_id": 7,
        "slot_id": 102
      }
    },
    {
      "paper": {
        "hashed_id": "c5866e93cab1776890fe343c9e7063fb",
        "title": "CoSRec: A Joint Conversational Search and Recommendation Dataset",
        "abstract": "Conversational Information Access systems have experienced widespread diffusion thanks to the natural and effortless interactions they enable with the user. In particular, they represent an effective interaction interface for conversational search (CS) and conversational recommendation (CR) scenarios. Despite their commonalities, CR and CS systems are often devised, developed, and evaluated as isolated components. Integrating these two elements would allow for handling complex information access scenarios, such as exploring unfamiliar recommended product aspects, enabling richer dialogues, and improving user satisfaction. As of today, the scarce availability of integrated datasets - focused exclusively on either of the tasks - limits the possibilities for evaluating by-design integrated CS and CR systems. To address this gap, we propose CoSRec, the first dataset for joint Conversational Search and Recommendation (CSR) evaluation. The CoSRec test set includes 20 high-quality conversations, with human-made annotations for the quality of conversations, and manually crafted relevance judgments for products and documents. Additionally, we provide supplementary training data comprising partially annotated dialogues and raw conversations to support diverse learning paradigms. CoSRec is the first resource to model CR and CS tasks in a unified framework, enabling the training and evaluation of systems that must shift between answering queries and making suggestions dynamically.",
        "doi": "10.1145/3726302.3730319",
        "sheridan_id": "rr2101",
        "position": 91,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "af5afd7f7c807171981d443ad4f4f648",
        "title": "NAM: A Normalization Attention Model for Personalized Product Search In Fliggy",
        "abstract": "Personalized product search provides significant benefits to e-commerce platforms by extracting more accurate user preferences from historical behaviors. Previous studies largely focused on the user factors when personalizing the search query, while ignoring the item perspective, which leads to the following two challenges that we summarize in this paper: First, previous approaches relying only on co-occurrence frequency tend to overestimate the conversion rates for popular items and underestimate those for long-tail items, resulting in inaccurate item similarities; Second, user purchasing propensity is highly heterogeneous according to the popularity of the target item: it is less correlated with the user`s historical behavior for a popular item and more correlated for a long-tail item. To address these challenges, in this paper we propose NAM, a Normalization Attention Model, which optimizes ``when to personalize`` by utilizing Inverse Item Frequency (IIF) and employing a gating mechanism, as well as optimizes ``how to personalize`` by normalizing the attention mechanism from a global perspective. Through comprehensive experiments, we demonstrate that our proposed NAM model significantly outperforms state-of-the-art baseline models. Furthermore, we conducted an online A/B test at Fliggy, and obtained a significant improvement of 0.8% over the latest production system in conversion rate.",
        "doi": "10.1145/3726302.3730235",
        "sheridan_id": "sp1576",
        "position": 6,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "c91591a8d461c2869b9f535ded3e213e",
        "title": "An Alternative to FLOPS Regularization to Effectively Productionize SPLADE-doc",
        "abstract": "Learned Sparse Retrieval (LSR) models encode text as weighted term vectors, which need to be sparse to leverage inverted index structures during retrieval. SPLADE, the most popular LSR model, uses FLOPS regularization to encourage vector sparsity during training. However, FLOPS regularization does not ensure sparsity among terms---only within a given query or document. Terms with very high Document Frequencies (DFs) substantially increase latency in production retrieval engines, such as Apache Solr, due to their lengthy posting lists. To address the issue of high DFs, we present a new variant of FLOPS regularization: DF-FLOPS. This new regularization technique penalizes the usage of high-DF terms, thereby shortening posting lists and reducing retrieval latency. Unlike other inference-time sparsification methods, such as stopword removal, DF-FLOPS regularization allows for the selective inclusion of high-frequency terms in cases where the terms are truly salient. We find that DF-FLOPS successfully reduces the prevalence of high-DF terms and lowers retrieval latency (around 10x faster) in a production-grade engine while maintaining effectiveness both in-domain (only a 2.2-point drop in MRR@10) and cross-domain (improved performance in 12 out of 13 tasks on which we tested). With retrieval latencies on par with BM25, this work provides an important step towards making LSR practical for deployment in production-grade search engines.",
        "doi": "10.1145/3726302.3730163",
        "sheridan_id": "sp1904",
        "position": 44,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "ba9a56ce0a9bfa26e8ed9e10b2cc8f46",
        "title": "Squeeze and Excitation: A Weighted Graph Contrastive Learning for Collaborative Filtering",
        "abstract": "Contrastive Learning (CL) has recently emerged as a powerful technique in recommendation systems, particularly for its capability to harness self-supervised signals from perturbed views to mitigate the data sparsity problem. The process of constructing perturbed views of the user-item bipartite graph and performing CL between perturbed views in a graph convolutional network (GCN) is called graph contrastive learning (GCL). Although existing GCL-based models are effective, the weight assignment method for perturbed views has not been fully explored. A critical problem in existing GCL-based models is the irrational allocation of feature attention. This problem limits the model`s ability to effectively leverage crucial features, resulting in suboptimal performance. To address this, we propose a Weighted Graph Contrastive Learning framework (WeightedGCL). Specifically, WeightedGCL applies a robust perturbation strategy, which perturbs only the view of the final GCN layer. In addition, WeightedGCL incorporates a squeeze and excitation network to dynamically weight the features of the perturbed views. Our WeightedGCL strengthens the model`s focus on crucial features and reduces the impact of less relevant information. Extensive experiments on widely used datasets demonstrate that our WeightedGCL achieves significant accuracy improvements compared to competitive baselines.",
        "doi": "10.1145/3726302.3730251",
        "sheridan_id": "sp1876",
        "position": 41,
        "track_id": 3,
        "slot_id": 111
      }
    },
    {
      "paper": {
        "hashed_id": "c5b2cebf15b205503560c4e8e6d1ea78",
        "title": "WebClasSeg-25: A Dual-Classified Webpage Segmentation Dataset - Integrating Functional and Maturity-Based Analysis",
        "abstract": "Webpage segmentation is a crucial task in web analysis, enablingimprovements in information retrieval, user experience, and automated web understanding. However, existing segmentation datasetsoften lack both comprehensive visual and textual segmentation, aswell as classification systems that capture the functional and qualitative aspects of webpages. In this paper, we introduce a novel webpage segmentation dataset that addresses these gaps by providingboth visual and textual segmentations, alongside two classificationframeworks. The first framework defines a nominal classificationof segments based on their functional roles, such as main content, header, footer, and navigation bar. The second introduces anordinal classification assessing the digital maturity of webpage segments, offering a structured evaluation of their design evolutionand complexity. By integrating both classification schemes intoa single dataset, our approach enables a more holistic analysis ofwebpage structures. Furthermore, given the rapid evolution of webdesign conventions, content structures, and technological trends,our dataset is designed to reflect contemporary webpage characteristics, ensuring its relevance for modern applications in webanalysis and machine learning. Additionally, we provide first results on visual segmentation, demonstrating the effectiveness ofour dataset in practical applications.",
        "doi": "10.1145/3726302.3730309",
        "sheridan_id": "rr1998",
        "position": 103,
        "track_id": 7,
        "slot_id": 110
      }
    },
    {
      "paper": {
        "hashed_id": "85f007f8c50dd25f5a45fca73cad64bd",
        "title": "KIMERA: From Evaluation-as-a-Service to Evaluation-in-the-Cloud",
        "abstract": "Experimental evaluation steers the development of Information Retrieval (IR) systems, and large-scale evaluation campaigns provide the field with a common infrastructure to conduct comparable evaluation exercises. Over the years, tools and platforms have been developed to manage and automate these activities, enhance the reproducibility of conducted experiments and facilitate data sharing. In this context, Evaluation-as-a-Service (EaaS) emerged as an approach to avoid distributing experimental collections, which may contain copyrighted or sensitive data, and instead execute containerised code on that data on remote servers. We propose Kubernetes Infrastructure for Managed Evaluation and Resource Access (KIMERA) as the next step from EaaS into Evaluation-in-the-Cloud (EitC), allowing researchers to directly code and execute their systems through their browsers, requiring only an internet connection. Moreover, recent advancements, such as Large Language Models, or new computing paradigms, such as quantum computers, require external third party services and computational resources. In this respect, KIMERA streamlines and simplifies access to such services on-demand via their APIs. More in detail, KIMERA relies on state-of-the-art containerization and orchestration tools, such as Docker and Kubernetes, to provide a robust, scalable, secure, and fault-tolerant IR evaluation platform. KIMERA monitors and stores all the participants` submissions, accurately keeping track of the resource usage, allowing for evaluating both the efficiency and the effectiveness of the deployed methods. Moreover, all participants can be assigned workspaces sharing the same resources (i.e., CPU and RAM), thus enhancing reproducibility and comparability among systems. Finally, KIMERA has been designed with modularity and extensibility in mind, allowing it to be easily adapted to new use cases and usage scenarios. KIMERA has been developed and adopted in the context of the QuantumCLEF lab, to allow for mixed experiments, comparing approaches running on traditional hardware and on real quantum annealers provided by external companies. KIMERA has also been used as a learning resource to provide Quantum Computing tutorials for IR at major conferences, such as ECIR and SIGIR. The source code of KIMERA is openly available at https://github.com/MjPaxter/KIMERA.",
        "doi": "10.1145/3726302.3730298",
        "sheridan_id": "rr1837",
        "position": 120,
        "track_id": 7,
        "slot_id": 110
      }
    }
  ]
}